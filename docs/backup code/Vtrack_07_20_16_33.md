# üì¶ T·ªïng h·ª£p m√£ ngu·ªìn Vtrack

**T·ªïng c·ªông:** 68 file `.py`, 43 file `.js`

---

## üìÑ File: `tailwind.config.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/tailwind.config.js`

```javascript
module.exports = {
  content: ["./src/**/*.{js,jsx,ts,tsx}"],
  theme: {
    extend: {
      colors: {
        'blue-custom': '#0066CC',
        'red-custom': '#E32222',
        'gray-custom': '#3F3F3F',
        'yellow-custom': '#FFD700',
      },
    },
  },
  plugins: [],
};
```
## üìÑ File: `postcss.config.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/postcss.config.js`

```javascript
module.exports = {
   plugins: {
     tailwindcss: {},
     autoprefixer: {},
   },
 };
```
## üìÑ File: `reportWebVitals.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/reportWebVitals.js`

```javascript
const reportWebVitals = onPerfEntry => {
  if (onPerfEntry && onPerfEntry instanceof Function) {
    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {
      getCLS(onPerfEntry);
      getFID(onPerfEntry);
      getFCP(onPerfEntry);
      getLCP(onPerfEntry);
      getTTFB(onPerfEntry);
    });
  }
};

export default reportWebVitals;

```
## üìÑ File: `Sidebar.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/Sidebar.js`

```javascript
import { Play, Search, Settings, User } from "lucide-react";
import Title from "./Title";

const Sidebar = ({ setActiveMenu, activeMenu }) => (
  <div className="w-64 bg-black text-white min-h-screen p-4 flex flex-col font-montserrat">
    <Title text="V_TRACK UI" />
    <ul>
      {[
        { name: "Ch∆∞∆°ng tr√¨nh", icon: <Play className="mr-2 text-blue-custom" /> },
        { name: "Truy v·∫•n", icon: <Search className="mr-2 text-red-custom" /> },
        { name: "C·∫•u h√¨nh", icon: <Settings className="mr-2 text-gray-custom" /> },
        { name: "T√†i kho·∫£n", icon: <User className="mr-2 text-yellow-custom" /> },
      ].map((item) => (
        <li
          key={item.name}
          className={`flex items-center p-3 hover:bg-gray-800 cursor-pointer transition duration-300 ${
            activeMenu === item.name ? "bg-gray-800" : ""
          }`}
          onClick={() => setActiveMenu(item.name)}
        >
          {item.icon} {item.name}
        </li>
      ))}
    </ul>
  </div>
);

export default Sidebar;
```
## üìÑ File: `index.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/index.js`

```javascript
import React from 'react';
import ReactDOM from 'react-dom/client';
import './index.css';
import App from './App';
import reportWebVitals from './reportWebVitals';
import "@fontsource/montserrat";
import "react-datepicker/dist/react-datepicker.css";

const root = ReactDOM.createRoot(document.getElementById('root'));
root.render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
);

// If you want to start measuring performance in your app, pass a function
// to log results (for example: reportWebVitals(console.log))
// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals
reportWebVitals();

```
## üìÑ File: `QueryComponent.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/QueryComponent.js`

```javascript
import { useState, useEffect } from "react";
import SearchModeSelector from "./components/ui/SearchModeSelector";
import FileInputSection from "./components/query/FileInputSection";
import TextInputSection from "./components/query/TextInputSection";
import TimeAndQuerySection from "./components/query/TimeAndQuerySection";
import ResultList from "./components/result/ResultList";
import VideoCutter from "./components/result/VideoCutter"; // Thay CutVideoSection b·∫±ng VideoCutter
import ColumnSelectorModal from "./components/query/ColumnSelectorModal";
import api from "./api";

const QueryComponent = () => {
  const [searchType, setSearchType] = useState("Text");
  const [path, setPath] = useState("");
  const [startDate, setStartDate] = useState(null);
  const [endDate, setEndDate] = useState(null);
  const [results, setResults] = useState([]);
  const [selectedVideos, setSelectedVideos] = useState([]);
  const [cutVideos, setCutVideos] = useState([]);
  const [searchString, setSearchString] = useState("");
  const [defaultDays, setDefaultDays] = useState(30);
  const [fileContent, setFileContent] = useState("");
  const [trackingCodes, setTrackingCodes] = useState([]);
  const [showModal, setShowModal] = useState(false);
  const [headers, setHeaders] = useState([]);
  const [selectedColumn, setSelectedColumn] = useState("tracking_codes");
  const [history, setHistory] = useState({
    Shopee: "M√£ v·∫≠n ƒë∆°n",
    Lazada: "V·∫≠n ƒë∆°n",
    Tiktok: "QR m√£ v·∫≠n ƒë∆°n",
    Custom1: "Custom 1",
    Custom2: "Custom 2",
  });
  const [selectedPlatform, setSelectedPlatform] = useState("Shopee");
  const [shopeeLabel, setShopeeLabel] = useState("Shopee");
  const [lazadaLabel, setLazadaLabel] = useState("Lazada");
  const [tiktokLabel, setTiktokLabel] = useState("Tiktok");
  const [customLabel1, setCustomLabel1] = useState("Custom 1");
  const [customLabel2, setCustomLabel2] = useState("Custom 2");
  const [queryCount, setQueryCount] = useState(0);
  const [trackingCodeCount, setTrackingCodeCount] = useState(0);
  const [foundCount, setFoundCount] = useState(0);
  const [isQuerying, setIsQuerying] = useState(false);
  const [selectedCameras, setSelectedCameras] = useState([]);
  const [availableCameras, setAvailableCameras] = useState([]);
  const [hasQueried, setHasQueried] = useState(false);

  useEffect(() => {
    const savedHistory = localStorage.getItem("trackingColumnHistory");
    if (savedHistory) {
      setHistory(JSON.parse(savedHistory));
    }
    const savedLabels = localStorage.getItem("platformLabels");
    if (savedLabels) {
      const labels = JSON.parse(savedLabels);
      setShopeeLabel(labels.Shopee || "Shopee");
      setLazadaLabel(labels.Lazada || "Lazada");
      setTiktokLabel(labels.Tiktok || "Tiktok");
      setCustomLabel1(labels.Custom1 || "Custom 1");
      setCustomLabel2(labels.Custom2 || "Custom 2");
    }

    const isConfigSet = localStorage.getItem("configSet");
    if (isConfigSet) {
      const fetchCameras = async () => {
        try {
          const response = await api.get("/get-cameras");
          setAvailableCameras(response.data.cameras || []);
          const savedCameras = localStorage.getItem("selectedCameras");
          if (savedCameras) {
            setSelectedCameras(JSON.parse(savedCameras));
          }
        } catch (error) {
          console.error("Error fetching cameras:", error);
        }
      };
      fetchCameras();
    }
  }, []);

  useEffect(() => {
    let count = 0;
    if (searchString) {
      const lines = searchString.split("\n");
      count = lines.filter(line => line.trim() !== "" && line.split('. ')[1]?.trim()).length;
    }
    setTrackingCodeCount(count);
  }, [searchString]);

  const debounce = (func, delay) => {
    let timeoutId;
    return (...args) => {
      clearTimeout(timeoutId);
      timeoutId = setTimeout(() => func(...args), delay);
    };
  };

  const handleQuery = async () => {
    setIsQuerying(true);
    setHasQueried(true);
    try {
      const queryData = {
        search_string: searchString,
        default_days: defaultDays,
        from_time: startDate ? startDate.toISOString() : null,
        to_time: endDate ? endDate.toISOString() : null,
        selected_cameras: selectedCameras,
      };

      const response = await api.post("/query", queryData);
      const events = response.data.events || [];

      setResults(events);
      setSelectedVideos(events.map(event => event.event_id));
      setQueryCount(prev => prev + 1);
      setFoundCount(events.length);
    } catch (error) {
      console.error("Error in query:", error);
    } finally {
      setIsQuerying(false);
    }
  };

  const debouncedHandleQuery = debounce(handleQuery, 1000);

  const handleCameraSelection = (camera) => {
    const updatedCameras = selectedCameras.includes(camera)
      ? selectedCameras.filter((c) => c !== camera)
      : [...selectedCameras, camera];
    setSelectedCameras(updatedCameras);
    localStorage.setItem("selectedCameras", JSON.stringify(updatedCameras));
  };

  return (
    <div className="p-6 flex gap-6 w-screen h-screen">
      <div className="w-[26.67%] bg-gray-800 p-6 rounded-lg flex flex-col">
        <h1 className="text-3xl font-bold mb-4">Truy v·∫•n</h1>
        <SearchModeSelector searchType={searchType} setSearchType={setSearchType} />
        {searchType === "File" && (
          <FileInputSection
            path={path}
            setPath={setPath}
            fileContent={fileContent}
            setFileContent={setFileContent}
            setShowModal={setShowModal}
            setHeaders={setHeaders}
          />
        )}
        <TextInputSection
          searchString={searchString}
          setSearchString={setSearchString}
          searchType={searchType}
        />
        <div className="mb-4">
          <label className="block mb-1">Truy v·∫•n t·∫°i camera:</label>
          <div className="max-h-24 overflow-y-auto">
            {availableCameras.map((camera) => (
              <label key={camera} className="flex items-center mb-2">
                <input
                  type="checkbox"
                  checked={selectedCameras.includes(camera)}
                  onChange={() => handleCameraSelection(camera)}
                  className="mr-2"
                />
                {camera}
              </label>
            ))}
          </div>
        </div>
        <TimeAndQuerySection
          startDate={startDate}
          setStartDate={setStartDate}
          endDate={endDate}
          setEndDate={setEndDate}
          defaultDays={defaultDays}
          setDefaultDays={setDefaultDays}
          searchString={searchString}
          searchType={searchType}
          fileContent={fileContent}
          results={results}
          setResults={setResults}
          setSelectedVideos={setSelectedVideos}
          setQueryCount={setQueryCount}
          setFoundCount={setFoundCount}
          foundCount={foundCount}
          onQuery={debouncedHandleQuery}
          isQuerying={isQuerying}
        />
      </div>
      <div className="w-[53.33%] bg-gray-800 p-6 rounded-lg flex flex-col">
        <div className="flex items-center mb-4">
          <h1 className="text-3xl font-bold mr-4">K·∫øt qu·∫£</h1>
          {(trackingCodeCount > 0 || foundCount > 0) && (
            <span className="text-lg text-gray-300">
              (Truy v·∫•n {trackingCodeCount}/ T√¨m ƒë∆∞·ª£c {foundCount})
            </span>
          )}
        </div>
        <ResultList
          results={results}
          selectedVideos={selectedVideos}
          setSelectedVideos={setSelectedVideos}
          hasQueried={hasQueried}
        />
        <VideoCutter
          results={results}
          selectedVideos={selectedVideos}
          setResults={setResults}
          setSelectedVideos={setSelectedVideos}
        /> {/* Thay CutVideoSection b·∫±ng VideoCutter */}
      </div>
      <ColumnSelectorModal
        showModal={showModal}
        setShowModal={setShowModal}
        headers={headers}
        selectedColumn={selectedColumn}
        setSelectedColumn={setSelectedColumn}
        history={history}
        setHistory={setHistory}
        selectedPlatform={selectedPlatform}
        setSelectedPlatform={setSelectedPlatform}
        shopeeLabel={shopeeLabel}
        setShopeeLabel={setShopeeLabel}
        lazadaLabel={lazadaLabel}
        setLazadaLabel={setLazadaLabel}
        tiktokLabel={tiktokLabel}
        setTiktokLabel={setTiktokLabel}
        customLabel1={customLabel1}
        setCustomLabel1={setCustomLabel1}
        customLabel2={customLabel2}
        setCustomLabel2={setCustomLabel2}
        path={path}
        fileContent={fileContent}
        setSearchString={setSearchString}
        setSearchType={setSearchType}
      />
    </div>
  );
};

export default QueryComponent;
```
## üìÑ File: `Title.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/Title.js`

```javascript
const Title = ({ text }) => {
   return <h2 className="text-xl font-bold text-center mb-6 tracking-widest">{text}</h2>;
 };
 
 export default Title;
```
## üìÑ File: `Account.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/Account.js`

```javascript
const Account = () => {
   return (
     <div className="p-6">
       <h1 className="text-3xl font-bold">T√†i kho·∫£n</h1>
       <p>ƒê√¢y l√† trang T√†i kho·∫£n. N·ªôi dung s·∫Ω ƒë∆∞·ª£c th√™m sau.</p>
     </div>
   );
 };
 
 export default Account;
```
## üìÑ File: `App.test.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/App.test.js`

```javascript
import { render, screen } from '@testing-library/react';
import App from './App';

test('renders learn react link', () => {
  render(<App />);
  const linkElement = screen.getByText(/learn react/i);
  expect(linkElement).toBeInTheDocument();
});

```
## üìÑ File: `VtrackConfig.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/VtrackConfig.js`

```javascript
import React from "react";
import useVtrackConfig from "./hooks/useVtrackConfig";
import GeneralInfoForm from "./components/config/GeneralInfoForm";
import ConfigForm from "./components/config/ConfigForm";
import CameraDialog from "./components/config/CameraDialog";
import ProcessingRegionForm from "./components/config/ProcessingRegionForm";

const VtrackConfig = () => {
  const {
    fromTime,
    setFromTime,
    toTime,
    setToTime,
    country,
    setCountry,
    timezone,
    setTimezone,
    brandName,
    setBrandName,
    inputPath,
    setInputPath,
    outputPath,
    setOutputPath,
    workingDays,
    setWorkingDays,
    defaultDays,
    setDefaultDays,
    minPackingTime,
    setMinPackingTime,
    maxPackingTime,
    setMaxPackingTime,
    frameRate,
    setFrameRate,
    frameInterval,
    setFrameInterval,
    videoBuffer,
    setVideoBuffer,
    cameras,
    setCameras,
    selectedCameras,
    setSelectedCameras,
    showCameraDialog,
    setShowCameraDialog,
    error,
    setError,
    handleCountryChange,
    handleFromTimeChange,
    handleToTimeChange,
    handleWorkingDayChange,
    handleOpenExplorer,
    handleSaveGeneralInfo,
    handleSaveConfig,
    handleShowCameraDialog,
    handleCameraSelection,
    runDefaultOnStart,
    setRunDefaultOnStart,
  } = useVtrackConfig();

  const [configFormCameras, setConfigFormCameras] = React.useState([]);
  const [configFormSelectedCameras, setConfigFormSelectedCameras] = React.useState([]);
  const [activeVideoSource, setActiveVideoSource] = React.useState(null);

  const [videoPath, setVideoPath] = React.useState("");
  const [qrSize, setQrSize] = React.useState("");
  
  const handleAnalyzeRegions = () => {
    console.log("Ph√¢n t√≠ch v√πng:", videoPath, qrSize);
  };

  // ‚úÖ FIX: Helper function ƒë·ªÉ get correct input path based on source type
  const getInputPathForSource = (source) => {
    if (!source) return "";
    
    let resultPath = "";
    
    switch (source.source_type) {
      case 'nvr':
        // NVR: Use working directory for downloaded videos
        resultPath = `/Users/annhu/vtrack_app/V_Track/nvr_downloads/${source.name}`;
        console.log(`üîó NVR Path Mapping: ${source.path} ‚Üí ${resultPath}`);
        break;
      case 'local':
        // Local: Use actual file system path
        resultPath = source.path;
        console.log(`üìÅ Local Path Mapping: ${source.path} ‚Üí ${resultPath}`);
        break;
      case 'cloud':
        // Cloud: Use sync directory (future)
        resultPath = `/Users/annhu/vtrack_app/V_Track/cloud_sync/${source.name}`;
        console.log(`‚òÅÔ∏è Cloud Path Mapping: ${source.path} ‚Üí ${resultPath}`);
        break;
      default:
        resultPath = source.path;
        console.log(`‚ùì Unknown Path Mapping: ${source.path} ‚Üí ${resultPath}`);
    }
    
    return resultPath;
  };

  // ‚úÖ FIX: Auto sync inputPath - USE HELPER FUNCTION
  React.useEffect(() => {
    console.log("=== INPUT PATH SYNC DEBUG ===");
    console.log("activeVideoSource changed:", activeVideoSource);
    
    if (activeVideoSource) {
      const correctPath = getInputPathForSource(activeVideoSource);
      console.log(`${activeVideoSource.source_type.toUpperCase()} source detected - setting path:`, correctPath);
      setInputPath(correctPath);
    } else {
      console.log("activeVideoSource is null");
    }
  }, [activeVideoSource, setInputPath]);

  React.useEffect(() => {
    if (configFormCameras && configFormCameras.length > 0) {
      const cameraObjects = configFormCameras.map(name => ({
        name: name,
        path: name
      }));
      setCameras(cameraObjects);
      console.log("Synced cameras to hook state:", cameraObjects);
    }
  }, [configFormCameras, setCameras]);

  React.useEffect(() => {
    if (configFormSelectedCameras && configFormSelectedCameras.length > 0) {
      setSelectedCameras(configFormSelectedCameras);
      console.log("Synced selectedCameras to hook state:", configFormSelectedCameras);
    }
  }, [configFormSelectedCameras, setSelectedCameras]);

  const handleCamerasUpdate = React.useCallback((sourceCameras, selectedCameras, activeSource) => {
    console.log("=== CAMERAS UPDATE BACKUP DEBUG ===");
    console.log("sourceCameras:", sourceCameras);
    console.log("selectedCameras:", selectedCameras);
    console.log("activeSource:", activeSource);
    
    // Backup logic - ch·ªâ khi direct setters kh√¥ng work
    if (!activeVideoSource && activeSource) {
      console.log("Backup: Setting activeVideoSource:", activeSource);
      setActiveVideoSource(activeSource);
      setInputPath(activeSource.path);
    }
  }, [activeVideoSource, setInputPath]);

  // ‚úÖ NEW: Smart camera dialog logic - skip if cameras already selected
  const handleShowCameraDialogCustom = () => {
    console.log("=== SMART CAMERA DIALOG LOGIC ===");
    console.log("configFormSelectedCameras:", configFormSelectedCameras);
    console.log("configFormCameras:", configFormCameras);
    
    // ‚úÖ Check if cameras are already selected
    if (configFormSelectedCameras && configFormSelectedCameras.length > 0) {
      console.log("‚úÖ Cameras already selected, skipping dialog and saving directly");
      console.log("Selected cameras:", configFormSelectedCameras);
      
      // ‚úÖ Sync cameras to dialog state for save process
      const cameraObjects = configFormCameras.map(name => ({
        name: name,
        path: name
      }));
      setCameras(cameraObjects);
      setSelectedCameras(configFormSelectedCameras);
      
      // ‚úÖ Save directly without showing dialog
      handleSaveConfigCustom();
      return;
    }
    
    // ‚úÖ No cameras selected, show dialog for user to select
    console.log("‚ö†Ô∏è No cameras selected, showing dialog for user selection");
    
    if (!configFormCameras || configFormCameras.length === 0) {
      alert("Kh√¥ng t√¨m th·∫•y camera n√†o. Vui l√≤ng:\n1. Ki·ªÉm tra video source ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh\n2. ƒê·∫£m b·∫£o c√≥ camera folders trong source");
      return;
    }
    
    const cameraObjects = configFormCameras.map(name => ({
      name: name,
      path: name
    }));
    setCameras(cameraObjects);
    setSelectedCameras([]); // Start with empty selection for user to choose
    setShowCameraDialog(true);
  };

  // ‚úÖ FIX: Custom handleSaveConfig - USE HELPER FUNCTION  
  const handleSaveConfigCustom = () => {
    console.log("=== DEBUG SAVE CONFIG SIMPLIFIED ===");
    console.log("activeVideoSource:", activeVideoSource);
    console.log("configFormCameras:", configFormCameras);
    console.log("configFormSelectedCameras:", configFormSelectedCameras);
    console.log("selectedCameras from dialog:", selectedCameras);
    console.log("inputPath BEFORE:", inputPath);
    
    // ‚úÖ FIX: Use the correct camera selection (prioritize dialog selection, fallback to pre-selected)
    const camerasToUse = selectedCameras && selectedCameras.length > 0 
      ? selectedCameras 
      : configFormSelectedCameras;
      
    console.log("Final cameras to use:", camerasToUse);
    
    if (!camerasToUse || camerasToUse.length === 0) {
      alert("Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt camera.\n\nCameras found: " + configFormCameras.join(", "));
      return;
    }

    // ‚úÖ Get correct path using helper function
    let pathToUse = inputPath;
    
    if (activeVideoSource) {
      pathToUse = getInputPathForSource(activeVideoSource);
      console.log(`Setting correct path for ${activeVideoSource.source_type}:`, pathToUse);
      setInputPath(pathToUse);
    } else if (!pathToUse || pathToUse.trim() === "") {
      alert("Kh√¥ng t√¨m th·∫•y video source.\n\nVui l√≤ng:\n1. Refresh page\n2. C·∫•u h√¨nh l·∫°i video source\n3. Th·ª≠ l·∫°i");
      return;
    }

    console.log("Final pathToUse:", pathToUse);

    // ‚úÖ Validation: Ensure no URL in file system path
    if (pathToUse.includes('://') || pathToUse.includes('localhost:')) {
      alert("‚ùå Invalid input path detected!\n\nURL cannot be used as file system path.\nPath: " + pathToUse);
      return;
    }

    setShowCameraDialog(false);
    console.log("Calling handleSaveConfig...");
    handleSaveConfig();
  };

  const countries = [
    "Vi·ªát Nam", "Nh·∫≠t B·∫£n", "H√†n Qu·ªëc", "Th√°i Lan", "Singapore",
    "M·ªπ", "Anh", "Ph√°p", "ƒê·ª©c", "√öc"
  ];

  return (
    <div className="p-6 flex gap-6 w-[100%]">
      <GeneralInfoForm
        country={country}
        setCountry={setCountry}
        timezone={timezone}
        setTimezone={setTimezone}
        brandName={brandName}
        setBrandName={setBrandName}
        workingDays={workingDays}
        setWorkingDays={setWorkingDays}
        fromTime={fromTime}
        setFromTime={setFromTime}
        toTime={toTime}
        setToTime={setToTime}
        handleCountryChange={handleCountryChange}
        handleFromTimeChange={handleFromTimeChange}
        handleToTimeChange={handleToTimeChange}
        handleWorkingDayChange={handleWorkingDayChange}
        handleSaveGeneralInfo={handleSaveGeneralInfo}
        countries={countries}
      />
      <ConfigForm
        inputPath={inputPath}
        setInputPath={setInputPath}
        outputPath={outputPath}
        setOutputPath={setOutputPath}
        defaultDays={defaultDays}
        setDefaultDays={setDefaultDays}
        minPackingTime={minPackingTime}
        setMinPackingTime={setMinPackingTime}
        maxPackingTime={maxPackingTime}
        setMaxPackingTime={setMaxPackingTime}
        frameRate={frameRate}
        setFrameRate={setFrameRate}
        frameInterval={frameInterval}
        setFrameInterval={setFrameInterval}
        videoBuffer={videoBuffer}
        setVideoBuffer={setVideoBuffer}
        error={error}
        handleOpenExplorer={handleOpenExplorer}
        handleShowCameraDialog={handleShowCameraDialogCustom}
        runDefaultOnStart={runDefaultOnStart}
        setRunDefaultOnStart={setRunDefaultOnStart}
        onCamerasUpdate={handleCamerasUpdate}
        setActiveVideoSource={setActiveVideoSource}
        setConfigFormCameras={setConfigFormCameras}
        setConfigFormSelectedCameras={setConfigFormSelectedCameras}
      />
      <ProcessingRegionForm
        videoPath={videoPath}
        setVideoPath={setVideoPath}
        qrSize={qrSize}
        setQrSize={setQrSize}
        handleAnalyzeRegions={handleAnalyzeRegions}
      />
      <CameraDialog
        showCameraDialog={showCameraDialog}
        setShowCameraDialog={setShowCameraDialog}
        cameras={cameras}
        selectedCameras={selectedCameras}
        handleCameraSelection={handleCameraSelection}
        handleSaveConfig={handleSaveConfigCustom}
      />
    </div>
  );
};

export default VtrackConfig;
```
## üìÑ File: `Dashboard.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/Dashboard.js`

```javascript
import Sidebar from "./Sidebar";
import VtrackConfig from "./VtrackConfig";
import QueryComponent from "./QueryComponent";
import Account from "./Account";
import ProgramTab from "./components/program/ProgramTab";
import useProgramLogic from "./hooks/useProgramLogic";

const Dashboard = ({ setActiveMenu, activeMenu }) => {
  const {
    runningCard,
    fileList,
    customPath,
    showConfirmButton,
    firstRunCompleted,
    handleRunStop,
    handleConfirmRun,
    isRunning,
    setCustomPath,
  } = useProgramLogic();

  return (
    <div className="flex min-h-screen bg-gray-900 text-white font-montserrat">
      <Sidebar setActiveMenu={setActiveMenu} activeMenu={activeMenu} />
      <div className="flex-1 p-6 w-full">
        {activeMenu === "Ch∆∞∆°ng tr√¨nh" ? (
          <ProgramTab
            runningCard={runningCard}
            fileList={fileList}
            customPath={customPath}
            showConfirmButton={showConfirmButton}
            firstRunCompleted={firstRunCompleted}
            handleRunStop={handleRunStop}
            handleConfirmRun={handleConfirmRun}
            isRunning={isRunning}
            setCustomPath={setCustomPath}
          />
        ) : activeMenu === "C·∫•u h√¨nh" ? (
          <VtrackConfig />
        ) : activeMenu === "Truy v·∫•n" ? (
          <QueryComponent />
        ) : activeMenu === "T√†i kho·∫£n" ? (
          <Account />
        ) : (
          <div>
            <h1 className="text-3xl font-bold">ƒêang ph√°t tri·ªÉn: {activeMenu}</h1>
            <p>N·ªôi dung cho {activeMenu} s·∫Ω ƒë∆∞·ª£c th√™m sau.</p>
          </div>
        )}
      </div>
    </div>
  );
};

export default Dashboard;
```
## üìÑ File: `api.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/api.js`

```javascript
import axios from "axios";

const api = axios.create({
  baseURL: "http://localhost:8080",
});

export const getConfig = () => api.get("/config");
export const updateConfig = (configData) => api.post("/config", configData);
export const runQuery = (queryData) => api.post("/query", queryData);
export const runProgram = (programData) => api.post("/program", programData);
export const confirmRun = (confirmData) => api.post("/confirm-run", confirmData);
export const getCameras = () => api.get("/get-cameras");
export const cutVideos = (cutData) => api.post("/cut-videos", cutData);
export const analyzeRegions = (data) => api.post("/analyze-regions", data);
export const getFrames = (data) => api.post("/get-frames", data);
export const submitRois = (data) => api.post("/submit-rois", data);
export const sendHandDetection = (data) => api.post("/api/hand-detection", data);
export const getRoiFrame = () => api.get("/get-roi-frame");
export const getFinalRoiFrame = (cameraId, timestamp) => api.get(`/get-final-roi-frame?camera_id=${cameraId}&timestamp=${timestamp}`);

// Video Sources APIs
export const getSources = () => api.get("/get-sources");
export const addSources = (sourcesData) => api.post("/save-sources", sourcesData);
export const testSourceConnection = (sourceData) => api.post("/test-source", sourceData);
export const updateSource = (id, sourceData) => api.put(`/update-source/${id}`, sourceData);
export const deleteSource = (id) => api.delete(`/delete-source/${id}`);
export const toggleSource = (id, active) => api.post(`/toggle-source/${id}`, { active });

// NEW: Camera Detection APIs
export const detectCameras = (pathData) => api.post("/detect-cameras", pathData);
export const updateSourceCameras = (cameraData) => api.post("/update-source-cameras", cameraData);

export default api;
```
## üìÑ File: `setupTests.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/setupTests.js`

```javascript
// jest-dom adds custom jest matchers for asserting on DOM nodes.
// allows you to do things like:
// expect(element).toHaveTextContent(/react/i)
// learn more: https://github.com/testing-library/jest-dom
import '@testing-library/jest-dom';

```
## üìÑ File: `App.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/App.js`

```javascript
import "@fontsource/montserrat";
import { useState } from "react";
import Dashboard from "./Dashboard";

function App() {
  const [activeMenu, setActiveMenu] = useState("Ch∆∞∆°ng tr√¨nh");
  return (
    <div className="flex min-h-screen bg-gray-900 text-white font-montserrat">
      <Dashboard setActiveMenu={setActiveMenu} activeMenu={activeMenu} />
    </div>
  );
}

export default App;
```
## üìÑ File: `SearchModeSelector.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/ui/SearchModeSelector.js`

```javascript
const SearchModeSelector = ({ searchType, setSearchType }) => {
  return (
    <div className="mb-4">
      <label className="block mb-1">Lo·∫°i t√¨m ki·∫øm:</label>
      <div className="flex gap-4">
        <label className="flex items-center">
          <input
            type="radio"
            name="searchType"
            value="File"
            className="mr-1"
            checked={searchType === "File"}
            onChange={() => setSearchType("File")}
          />
          File
        </label>
        <label className="flex items-center">
          <input
            type="radio"
            name="searchType"
            value="Text"
            className="mr-1"
            checked={searchType === "Text"}
            onChange={() => setSearchType("Text")}
          />
          Text
        </label>
      </div>
    </div>
  );
};

export default SearchModeSelector;
```
## üìÑ File: `Button.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/ui/Button.js`

```javascript
const Button = ({ text }) => {
   return (
     <button className="bg-red-600 text-white font-bold py-2 px-4 rounded mt-4">
       {text}
     </button>
   );
 };
 
 export default Button;
```
## üìÑ File: `Card.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/ui/Card.js`

```javascript
import { useState } from "react";

const Card = ({ title, description, isRunning, onRunStop, onPathChange, isLocked }) => {
  const [path, setPath] = useState("");

  const handleOpenExplorer = () => {
    const input = document.createElement("input");
    input.type = "file";
    input.onchange = (e) => {
      const selectedPath = e.target.files[0]?.name || "";
      setPath(selectedPath);
      if (onPathChange) {
        onPathChange(selectedPath);
      }
    };
    input.click();
  };

  return (
    <div className="bg-gray-800 p-6 rounded-lg flex flex-col items-center h-full">
      <h3 className="text-lg font-bold mb-2">{title}</h3>
      <p className="mb-4 text-center flex-1">{description}</p>
      <div className="mt-auto w-full flex flex-col items-center">
        {title === "Ch·ªâ ƒë·ªãnh" && (
          <div className="mb-4 w-full">
            <div className="relative w-full">
              <input
                type="text"
                value={path}
                onChange={(e) => {
                  setPath(e.target.value);
                  if (onPathChange) {
                    onPathChange(e.target.value);
                  }
                }}
                placeholder="Nh·∫≠p ƒë∆∞·ªùng d·∫´n file..."
                className="w-full p-2 rounded bg-gray-700 text-white"
              />
              <button
                type="button"
                onClick={handleOpenExplorer}
                className="absolute right-2 top-1/2 transform -translate-y-1/2 text-white"
              >
                ...
              </button>
            </div>
          </div>
        )}
        {isLocked || (title === "L·∫ßn ƒë·∫ßu" && isRunning) ? (
          <button
            className="w-1/2 py-2 px-4 rounded font-bold text-white bg-gray-500"
            disabled
          >
            LOCKED
          </button>
        ) : (
          <button
            className={`w-1/2 py-2 px-4 rounded font-bold text-white ${
              isRunning && title !== "L·∫ßn ƒë·∫ßu" ? "bg-[#E82127]" : "bg-[#00D4FF]"
            }`}
            onClick={onRunStop}
            disabled={title === "Ch·ªâ ƒë·ªãnh" && !path && !isRunning}
          >
            {(isRunning && title !== "L·∫ßn ƒë·∫ßu") ? "STOP" : "RUN"}
          </button>
        )}
      </div>
    </div>
  );
};

export default Card;
```
## üìÑ File: `ResultList.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/result/ResultList.js`

```javascript
import React from "react";

const ResultList = ({ results, selectedVideos, setSelectedVideos, hasQueried }) => {
  const handleSelectVideo = (eventId) => {
    if (selectedVideos.includes(eventId)) {
      setSelectedVideos(selectedVideos.filter((id) => id !== eventId));
    } else {
      setSelectedVideos([...selectedVideos, eventId]);
    }
  };

  React.useEffect(() => {
    if (results.length > 0) {
      const newSelectedVideos = results.map(event => event.event_id);
      setSelectedVideos(newSelectedVideos);
    }
  }, [results]);

  return (
    <div className="flex-1 mb-4 bg-gray-700 rounded p-2 overflow-y-auto">
      {hasQueried ? (
        results.length > 0 ? (
          results.map((event, index) => (
            <label key={event.event_id} className="flex items-center mb-2">
              <input
                type="checkbox"
                className="mr-2"
                checked={selectedVideos.includes(event.event_id)}
                onChange={() => handleSelectVideo(event.event_id)}
              />
              {`${index + 1}. ${event.video_file}`}
            </label>
          ))
        ) : (
          <p>Kh√¥ng c√≥ k·∫øt qu·∫£</p>
        )
      ) : (
        <p>Vui l√≤ng th·ª±c hi·ªán truy v·∫•n</p>
      )}
    </div>
  );
};

export default ResultList;

```
## üìÑ File: `CutVideoSection.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/result/CutVideoSection.js`

```javascript
import api from "../../api"; // Th√™m import api ƒë·ªÉ g·ªçi /cut-videos

const CutVideoSection = ({ results, selectedVideos, setResults, setSelectedVideos, cutVideos, setCutVideos }) => {
  const handleCutVideos = async () => {
    if (selectedVideos.length === 0) {
      alert("Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt s·ª± ki·ªán ƒë·ªÉ c·∫Øt video.");
      return;
    }
    const videosToCut = results.filter((event) => selectedVideos.includes(event.event_id));
    try {
      const cutData = {
        selected_events: videosToCut,
      };
      const response = await api.post("/cut-videos", cutData); // G·ªçi API /cut-videos
      const cutFiles = response.data.cut_files || []; // L·∫•y danh s√°ch file t·ª´ ph·∫£n h·ªìi
      setCutVideos(prev => [...prev, ...cutFiles]); // T·ªëi ∆∞u v·ªõi prev
      setResults(results.filter((event) => !selectedVideos.includes(event.event_id)));
      setSelectedVideos([]);
    } catch (error) {
      console.error("Error cutting videos:", error);
      alert("C√≥ l·ªói x·∫£y ra khi c·∫Øt video. Vui l√≤ng th·ª≠ l·∫°i.");
    }
  };

  const handleRefresh = () => {
    setResults([]);
    setSelectedVideos([]);
    setCutVideos([]); // X√≥a danh s√°ch video ƒë√£ c·∫Øt
  };

  return (
    <>
      <div className="flex gap-4 mb-4">
        <button
          className="w-1/2 py-2 bg-red-600 text-white font-bold rounded"
          onClick={handleCutVideos}
        >
          C·∫Øt Video
        </button>
        <button
          className="w-1/2 py-2 px-4 rounded font-bold text-white bg-[#00D4FF]"
          onClick={handleRefresh}
        >
          Refresh
        </button>
      </div>
      <div className="flex-1 bg-gray-700 rounded p-2 overflow-y-auto">
        {cutVideos.map((video, index) => (
          <label key={index} className="flex items-center mb-2">
            <input type="checkbox" className="mr-2" />
            {`${index + 1}. ${video}`}
          </label>
        ))}
      </div>
    </>
  );
};

export default CutVideoSection;
```
## üìÑ File: `VideoCutter.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/result/VideoCutter.js`

```javascript
import { useState } from "react";
import api from "../../api"; // ƒêi·ªÅu ch·ªânh ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi t·ª´ th∆∞ m·ª•c result

const VideoCutter = ({ results, selectedVideos, setResults, setSelectedVideos }) => {
  const [cutVideos, setCutVideos] = useState([]);
  const [selectedCutVideo, setSelectedCutVideo] = useState(null); // Th√™m tr·∫°ng th√°i ƒë·ªÉ l∆∞u video ƒë√£ c·∫Øt ƒë∆∞·ª£c ch·ªçn

  // H√†m x·ª≠ l√Ω y√™u c·∫ßu c·∫Øt video
  const handleCutVideos = async () => {
    if (selectedVideos.length === 0) {
      alert("Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt s·ª± ki·ªán ƒë·ªÉ c·∫Øt video.");
      return;
    }
    try {
      const selectedEvents = results.filter(event => selectedVideos.includes(event.event_id));
      const cutData = {
        selected_events: selectedEvents,
        // tracking_codes_filter s·∫Ω ƒë∆∞·ª£c th√™m sau n·∫øu c·∫ßn t·ª´ QueryComponent
      };

      const response = await api.post("/cut-videos", cutData); // G·ªçi API c·∫Øt video
      const cutFiles = response.data.cut_files || [];

      setCutVideos(prev => [...prev, ...cutFiles]); // C·∫≠p nh·∫≠t danh s√°ch video ƒë√£ c·∫Øt
      setResults(prev => prev.filter(event => !selectedVideos.includes(event.event_id))); // X√≥a s·ª± ki·ªán ƒë√£ c·∫Øt
      setSelectedVideos([]); // Reset danh s√°ch ch·ªçn
    } catch (error) {
      console.error("Error cutting videos:", error);
      alert("C√≥ l·ªói x·∫£y ra khi c·∫Øt video. Vui l√≤ng th·ª≠ l·∫°i.");
    }
  };

  const handleRefresh = () => {
    setResults([]);
    setSelectedVideos([]);
    setCutVideos([]);
    setSelectedCutVideo(null); // Reset video ƒë√£ ch·ªçn khi refresh
  };

  // H√†m x·ª≠ l√Ω khi nh·∫•n n√∫t "Play Video"
  const handlePlayVideo = () => {
    if (!selectedCutVideo) {
      alert("Vui l√≤ng ch·ªçn m·ªôt video ƒë·ªÉ ph√°t");
      return;
    }
    alert(`ƒêang ph√°t video "${selectedCutVideo}" ƒë∆∞·ª£c ch·ªçn`);
  };

  return (
    <>
      <div className="flex gap-4 mb-4">
        <button
          className="w-1/3 py-2 bg-red-600 text-white font-bold rounded"
          onClick={handleCutVideos}
        >
          C·∫Øt Video
        </button>
        <button
          className="w-1/3 py-2 px-4 rounded font-bold text-white bg-[#00D4FF]"
          onClick={handleRefresh}
        >
          Refresh
        </button>
        <button
          className="w-1/3 py-2 px-4 rounded font-bold text-white bg-green-600"
          onClick={handlePlayVideo}
        >
          Play Video
        </button>
      </div>
      <div className="flex-1 bg-gray-700 rounded p-2 overflow-y-auto">
        {cutVideos.map((video, index) => (
          <label
            key={index}
            className="flex items-center mb-2 cursor-pointer hover:bg-gray-600 transition duration-300"
            onClick={() => setSelectedCutVideo(video)}
          >
            <input
              type="radio"
              name="cutVideo"
              className="mr-2"
              checked={selectedCutVideo === video}
              onChange={() => setSelectedCutVideo(video)}
            />
            <span className="flex-1 truncate">{`${index + 1}. ${video}`}</span>
          </label>
        ))}
      </div>
    </>
  );
};

export default VideoCutter;
```
## üìÑ File: `CloudConfigurationForm.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/CloudConfigurationForm.js`

```javascript
// components/config/CloudConfigurationForm.js - Google Drive Configuration Form
import React, { useState, useEffect } from 'react';
import GoogleDriveAuthButton from './GoogleDriveAuthButton';
import GoogleDrivePickerIntegration from './GoogleDrivePickerIntegration';
import CloudSyncSettings from './CloudSyncSettings';

const CloudConfigurationForm = ({ config, setConfig, onAuthenticate }) => {
  // Authentication state
  const [isAuthenticated, setIsAuthenticated] = useState(false);
  const [authLoading, setAuthLoading] = useState(false);
  const [authError, setAuthError] = useState(null);

  // Picker selection state
  const [pickerSelectedFolders, setPickerSelectedFolders] = useState([]);
  const [pickerLoading, setPickerLoading] = useState(false);

  // Sync settings state
  const [syncSettings, setSyncSettings] = useState({
    interval_minutes: 15,
    auto_sync_enabled: true,
    sync_only_new: true,
    skip_duplicates: true,
    organize_by_date: true,
    backup_metadata: true
  });

  // Configuration status
  const [configurationValid, setConfigurationValid] = useState(false);

  // Initialize from existing config
  useEffect(() => {
    if (config) {
      if (config.credentials && config.user_email) {
        setIsAuthenticated(true);
      }
      
      if (config.selected_folders) {
        setPickerSelectedFolders(config.selected_folders);
      }
      
      if (config.sync_settings) {
        setSyncSettings(prev => ({ ...prev, ...config.sync_settings }));
      }
    }
  }, [config]);

  // Validate configuration whenever state changes
  useEffect(() => {
    const isValid = isAuthenticated && 
                   pickerSelectedFolders.length > 0 &&
                   syncSettings.interval_minutes > 0;
    
    setConfigurationValid(isValid);
    
    // Update parent config
    if (isValid) {
      const newConfig = {
        ...config,
        provider: 'google_drive',
        selected_folders: pickerSelectedFolders,
        picker_selections: pickerSelectedFolders,
        sync_settings: syncSettings,
        configuration_valid: true
      };
      
      setConfig(newConfig);
    }
  }, [isAuthenticated, pickerSelectedFolders, syncSettings, setConfig]);

  // Handle Google Drive authentication
  const handleGoogleDriveAuth = async (authResult) => {
    setAuthLoading(true);
    setAuthError(null);
    
    try {
      if (authResult.success) {
        setIsAuthenticated(true);
        
        // Update parent config with auth data
        const authConfig = {
          ...config,
          provider: 'google_drive',
          credentials: authResult.credentials,
          user_email: authResult.user_email,
          authenticated: true
        };
        
        setConfig(authConfig);
        
        // Notify parent component
        if (onAuthenticate) {
          onAuthenticate(authResult);
        }
        
        console.log(`‚úÖ Google Drive authenticated: ${authResult.user_email}`);
      } else {
        setAuthError(authResult.message || 'Authentication failed');
        setIsAuthenticated(false);
      }
    } catch (error) {
      console.error('Authentication error:', error);
      setAuthError('Authentication process failed');
      setIsAuthenticated(false);
    } finally {
      setAuthLoading(false);
    }
  };

  // Handle picker folder selection
  const handlePickerFoldersSelected = (folders) => {
    setPickerSelectedFolders(folders);
    console.log(`üé• Selected ${folders.length} folders via picker:`, folders);
    
    // Update parent config immediately
    const updatedConfig = {
      ...config,
      selected_folders: folders,
      picker_selections: folders,
      folder_structure: 'picker_selected'
    };
    
    setConfig(updatedConfig);
  };

  // Handle sync settings change
  const handleSyncSettingsChange = (newSyncSettings) => {
    setSyncSettings(prev => ({ ...prev, ...newSyncSettings }));
    console.log('‚öôÔ∏è Sync settings updated:', newSyncSettings);
  };

  // Reset configuration
  const handleReset = () => {
    setIsAuthenticated(false);
    setPickerSelectedFolders([]);
    setSyncSettings({
      interval_minutes: 15,
      auto_sync_enabled: true,
      sync_only_new: true,
      skip_duplicates: true,
      organize_by_date: true,
      backup_metadata: true
    });
    setAuthError(null);
    setConfigurationValid(false);
    
    // Reset parent config
    setConfig({
      provider: 'google_drive',
      configuration_valid: false
    });
  };

  return (
    <div className="space-y-6">
      
      {/* Header */}
      <div className="flex items-center justify-between">
        <div>
          <h3 className="text-lg font-semibold text-white">‚òÅÔ∏è Google Drive Integration</h3>
          <p className="text-sm text-gray-400">Configure automatic video sync from Google Drive</p>
        </div>
        
        {/* Configuration Status Indicator */}
        <div className={`px-3 py-1 rounded-full text-xs font-medium ${
          configurationValid 
            ? 'bg-green-600 text-green-100' 
            : 'bg-gray-600 text-gray-300'
        }`}>
          {configurationValid ? '‚úÖ Ready' : '‚öôÔ∏è Configuring...'}
        </div>
      </div>

      {/* Error Display */}
      {authError && (
        <div className="bg-red-800 border border-red-600 rounded-lg p-4">
          <div className="flex items-center">
            <span className="text-red-300 text-sm">‚ùå {authError}</span>
            <button
              onClick={() => setAuthError(null)}
              className="ml-auto text-red-400 hover:text-red-300"
            >
              √ó
            </button>
          </div>
        </div>
      )}

      {/* Step 1: Authentication */}
      <div className="bg-gray-700 rounded-lg p-4">
        <div className="flex items-center justify-between mb-3">
          <h4 className="font-medium text-white">Step 1: Authenticate with Google Drive</h4>
          {isAuthenticated && (
            <button
              onClick={handleReset}
              className="text-xs text-gray-400 hover:text-gray-300"
            >
              Reset
            </button>
          )}
        </div>
        
        <GoogleDriveAuthButton
          onAuth={handleGoogleDriveAuth}
          isAuthenticated={isAuthenticated}
          isLoading={authLoading}
          userEmail={config?.user_email}
        />
      </div>

      {/* Step 2: Folder Selection with Google Picker */}
      {isAuthenticated && (
        <div className="bg-gray-700 rounded-lg p-4">
          <h4 className="font-medium text-white mb-3">Step 2: Select Camera Folders</h4>
          
          <div className="bg-blue-800 border border-blue-600 rounded-lg p-3 mb-4">
            <div className="text-sm text-blue-200">
              <div className="font-medium mb-1">üéØ Native Google Drive Experience</div>
              <div>‚Ä¢ Use the familiar Google Drive interface to browse and select folders</div>
              <div>‚Ä¢ Hold Ctrl/Cmd to select multiple folders containing camera videos</div>
              <div>‚Ä¢ Your selections will be automatically configured for VTrack processing</div>
            </div>
          </div>
          
          <GoogleDrivePickerIntegration
            onFoldersSelected={handlePickerFoldersSelected}
            isAuthenticated={isAuthenticated}
            credentials={config.credentials}
            multiSelect={true}
            userEmail={config?.user_email}
            className="mb-4"
          />
          
          {/* Selection Summary */}
          {pickerSelectedFolders.length > 0 && (
            <div className="mt-4 p-3 bg-gray-600 rounded">
              <div className="text-sm text-gray-300">
                <strong>üìÅ Selected via Google Picker:</strong> {pickerSelectedFolders.length} folders
              </div>
              <div className="text-xs text-gray-400 mt-2">
                <div className="space-y-1">
                  {pickerSelectedFolders.slice(0, 5).map((folder, index) => (
                    <div key={folder.id || index} className="flex items-center gap-2">
                      <span>üìπ</span>
                      <span>{folder.name}</span>
                      <span className="text-gray-500">({folder.id})</span>
                    </div>
                  ))}
                  {pickerSelectedFolders.length > 5 && (
                    <div className="text-gray-500">
                      +{pickerSelectedFolders.length - 5} more folders...
                    </div>
                  )}
                </div>
              </div>
            </div>
          )}
        </div>
      )}

      {/* Step 3: Sync Settings */}
      {isAuthenticated && pickerSelectedFolders.length > 0 && (
        <div className="bg-gray-700 rounded-lg p-4">
          <h4 className="font-medium text-white mb-3">Step 3: Configure Sync Settings</h4>
          
          <CloudSyncSettings
            config={syncSettings}
            onChange={handleSyncSettingsChange}
          />
        </div>
      )}

      {/* Configuration Summary */}
      {configurationValid && (
        <div className="bg-green-800 border border-green-600 rounded-lg p-4">
          <h4 className="font-medium text-green-100 mb-2">üéâ Configuration Complete</h4>
          <div className="text-sm text-green-200 space-y-1">
            <div>üìß Account: {config?.user_email}</div>
            <div>üìÅ Source: Google Drive Picker Selection</div>
            <div>üé• Camera Folders: {pickerSelectedFolders.length} selected</div>
            <div>‚è±Ô∏è Sync Interval: {syncSettings.interval_minutes} minutes</div>
            <div>üîÑ Auto-sync: {syncSettings.auto_sync_enabled ? 'Enabled' : 'Disabled'}</div>
            <div>üéØ Method: Native Google Picker Interface</div>
          </div>
        </div>
      )}

      {/* Progress Indicator */}
      <div className="bg-gray-800 rounded-lg p-3">
        <div className="flex items-center justify-between text-xs text-gray-400 mb-2">
          <span>Configuration Progress</span>
          <span>{configurationValid ? '100%' : isAuthenticated ? (pickerSelectedFolders.length > 0 ? '75%' : '33%') : '0%'}</span>
        </div>
        <div className="w-full bg-gray-600 rounded-full h-2">
          <div 
            className={`h-2 rounded-full transition-all duration-300 ${
              configurationValid ? 'bg-green-500' : 'bg-blue-500'
            }`}
            style={{ 
              width: configurationValid ? '100%' : 
                     isAuthenticated ? (pickerSelectedFolders.length > 0 ? '75%' : '33%') : '0%' 
            }}
          ></div>
        </div>
      </div>

      {/* Debug Info (Development Only) */}
      {process.env.NODE_ENV === 'development' && (
        <details className="bg-gray-800 rounded p-3">
          <summary className="text-xs text-gray-400 cursor-pointer">üîß Debug Info</summary>
          <pre className="text-xs text-gray-400 mt-2 overflow-auto">
            {JSON.stringify({
              isAuthenticated,
              pickerFolders: pickerSelectedFolders.length,
              syncSettings,
              configurationValid,
              hasCredentials: !!config?.credentials
            }, null, 2)}
          </pre>
        </details>
      )}
    </div>
  );
};

export default CloudConfigurationForm;
```
## üìÑ File: `ConfigForm.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/ConfigForm.js`

```javascript
import React, { useState, useEffect, useCallback } from 'react';
import AddSourceModal from './AddSourceModal';

const ConfigForm = ({
  inputPath,
  setInputPath,
  outputPath,
  setOutputPath,
  defaultDays,
  setDefaultDays,
  minPackingTime,
  setMinPackingTime,
  maxPackingTime,
  setMaxPackingTime,
  frameRate,
  setFrameRate,
  frameInterval,
  setFrameInterval,
  videoBuffer,
  setVideoBuffer,
  error,
  handleOpenExplorer,
  handleShowCameraDialog,
  // ‚úÖ FIX: Direct state setters thay v√¨ callback
  onCamerasUpdate,
  setActiveVideoSource,
  setConfigFormCameras,
  setConfigFormSelectedCameras,
}) => {
  // State for single active source
  const [activeSource, setActiveSource] = useState(null);
  const [sourceCameras, setSourceCameras] = useState([]);
  const [selectedCameras, setSelectedCameras] = useState([]);
  const [isLoadingSource, setIsLoadingSource] = useState(false);
  const [showAddSourceModal, setShowAddSourceModal] = useState(false);
  const [showUpdateSourceModal, setShowUpdateSourceModal] = useState(false);

  // API functions
  const getSources = async () => {
    const response = await fetch('/get-sources');
    return response.json();
  };

  const addSources = async (sourcesData) => {
    const response = await fetch('/save-sources', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(sourcesData)
    });
    return response.json();
  };

  const deleteSource = async (sourceId) => {
    const response = await fetch(`/delete-source/${sourceId}`, {
      method: 'DELETE'
    });
    return response.json();
  };

  const testSourceConnection = async (sourceData) => {
    const response = await fetch('/test-source', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(sourceData)
    });
    return response.json();
  };
  const detectCameras = async () => {
  try {
    const response = await fetch('/get-camera-folders');
    if (response.ok) {
      const result = await response.json();
      return {
        cameras: result.folders?.map(f => f.name) || [],
        selected_cameras: []
      };
    }
    return { cameras: [], selected_cameras: [] };
  } catch (error) {
    console.error('Camera detection error:', error);
    return { cameras: [], selected_cameras: [] };
  }
};

  const updateSourceCameras = async (sourceId, selectedCameras) => {
    const response = await fetch('/update-source-cameras', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ source_id: sourceId, selected_cameras: selectedCameras })
    });
    return response.json();
  };

  // ‚úÖ NEW: Get processing config cameras
  const getProcessingCameras = async () => {
    const response = await fetch('/get-processing-cameras');
    return response.json();
  };

  // Load active source
  const loadActiveSource = useCallback(async () => {
    setIsLoadingSource(true);
    try {
      const response = await getSources();
      const sources = response.sources || [];
      const active = sources.find(s => s.active);
      setActiveSource(active || null);
      
      let cameras = [];
      let selected = [];
      
      // Load camera info based on source type
      if (active) {
        if (active.source_type === 'local') {
          // Local source: detect camera folders
          try {
            const cameraResponse = await detectCameras();
            cameras = cameraResponse.cameras || [];
            selected = cameraResponse.selected_cameras || [];
          } catch (cameraError) {
            console.warn('Failed to load camera info:', cameraError);
            cameras = [];
            selected = [];
          }
        } else if (active.source_type === 'nvr') {
          // ‚úÖ FIX: NVR source - proper camera loading
          try {
            const nvrConfig = active.config || {};
            const detectedCameras = nvrConfig.detected_cameras || [];
            
            // Convert detected cameras to names
            const detectedCameraNames = detectedCameras.map(cam => 
              cam.name || cam.id || `Camera ${detectedCameras.indexOf(cam) + 1}`
            );
            
            // ‚úÖ NEW: Get selected cameras from processing_config
            const processingResponse = await getProcessingCameras();
            const selectedFromProcessingConfig = processingResponse.selected_cameras || [];
            
            // ‚úÖ Fallback hierarchy: processing_config ‚Üí source.config ‚Üí empty
            let finalSelectedCameras = [];
            if (selectedFromProcessingConfig && selectedFromProcessingConfig.length > 0) {
              finalSelectedCameras = selectedFromProcessingConfig;
              console.log("‚úÖ Using cameras from processing_config:", finalSelectedCameras);
            } else if (nvrConfig.selected_cameras && nvrConfig.selected_cameras.length > 0) {
              finalSelectedCameras = nvrConfig.selected_cameras;
              console.log("‚úÖ Fallback: Using cameras from source config:", finalSelectedCameras);
            } else {
              finalSelectedCameras = [];
              console.log("‚ö†Ô∏è No cameras found in processing_config or source config");
            }
            
            cameras = detectedCameraNames;
            selected = finalSelectedCameras;
            
            console.log('‚úÖ Loaded NVR cameras:', { 
              detected: detectedCameraNames.length, 
              selected: finalSelectedCameras.length,
              detectedNames: detectedCameraNames,
              selectedNames: finalSelectedCameras
            });
            
          } catch (nvrError) {
            console.warn('Failed to load NVR camera info:', nvrError);
            cameras = [];
            selected = [];
          }
        }
      }
      
      setSourceCameras(cameras);
      setSelectedCameras(selected);
      
    } catch (error) {
      console.error('Error loading active source:', error);
      alert('Failed to load video source');
      setSourceCameras([]);
      setSelectedCameras([]);
    } finally {
      setIsLoadingSource(false);
    }
  }, []);

  useEffect(() => {
    loadActiveSource();
  }, []); // ‚úÖ FIX: Ch·ªâ run m·ªôt l·∫ßn khi component mount

  // ‚úÖ FIX: Separate effect ƒë·ªÉ sync v·ªõi parent state - DIRECT UPDATE
  useEffect(() => {
    console.log("=== CONFIG FORM DIRECT UPDATE DEBUG ===");
    console.log("activeSource:", activeSource);
    console.log("sourceCameras:", sourceCameras);
    console.log("selectedCameras:", selectedCameras);
    
    // ‚úÖ Direct update parent state
    if (setActiveVideoSource) {
      console.log("Setting activeVideoSource directly:", activeSource);
      setActiveVideoSource(activeSource);
    }
    
    if (setConfigFormCameras) {
      console.log("Setting configFormCameras directly:", sourceCameras);
      setConfigFormCameras(sourceCameras);
    }
    
    if (setConfigFormSelectedCameras) {
      console.log("Setting configFormSelectedCameras directly:", selectedCameras);
      setConfigFormSelectedCameras(selectedCameras);
    }
    
    // ‚úÖ Also try callback as backup
    if (onCamerasUpdate) {
      console.log("Also calling onCamerasUpdate callback as backup");
      onCamerasUpdate(sourceCameras, selectedCameras, activeSource);
    }
    
  }, [sourceCameras, selectedCameras, activeSource, setActiveVideoSource, setConfigFormCameras, setConfigFormSelectedCameras, onCamerasUpdate]);

  // Enhanced Add Source Handler (supports NVR)
  const handleAddSource = async (sourceData) => {
    try {
      console.log('Adding source:', sourceData);
      
      // Add source
      await addSources({ sources: [sourceData] });
      
      // Post-processing based on source type
      if (sourceData.source_type === 'local') {
        // Local source: trigger camera detection
        try {
          const cameraResponse = await detectCameras();
          if (cameraResponse.cameras && cameraResponse.cameras.length > 0) {
            // Auto-select all detected cameras by default
            await updateSourceCameras(cameraResponse.source_id, cameraResponse.cameras);
          }
        } catch (cameraError) {
          console.warn('Camera detection failed:', cameraError);
          // Continue anyway - camera detection is optional
        }
      } else if (sourceData.source_type === 'nvr') {
        // NVR source: cameras already discovered and selected in modal
        const selectedCameras = sourceData.config?.selected_cameras || [];
        if (selectedCameras.length > 0) {
          try {
            // Update processing_config with selected NVR cameras
            await updateSourceCameras('nvr_source', selectedCameras);
            console.log('NVR cameras saved:', selectedCameras);
          } catch (nvrError) {
            console.warn('Failed to save NVR camera selection:', nvrError);
          }
        }
      }
      
      alert(`${sourceData.source_type.toUpperCase()} source added successfully!`);
      loadActiveSource();
    } catch (error) {
      console.error('Error adding source:', error);
      alert('Failed to add source: ' + (error.response?.data?.error || error.message));
    }
  };

  // Update Source Handler
  const handleUpdateSource = () => {
    if (!activeSource) return;
    setShowUpdateSourceModal(true);
  };

  // Change Source Type Handler (reset workflow)
  const handleChangeSourceType = async () => {
    if (!activeSource) return;
    
    const confirmMessage = `This will remove the current source "${activeSource.name}" and reset to add a new source.\n\nAre you sure you want to continue?`;
    
    if (!window.confirm(confirmMessage)) return;
    
    try {
      // Delete current source
      await deleteSource(activeSource.id);
      
      // Reload to show "No source configured" state
      await loadActiveSource();
      
    } catch (error) {
      console.error('Error removing source:', error);
      alert('Failed to remove source');
    }
  };

  const handleUpdateComplete = () => {
    loadActiveSource(); // Reload source and camera info
    setShowUpdateSourceModal(false);
  };

  const formatDate = (dateString) => {
    if (!dateString) return 'Unknown';
    try {
      return new Date(dateString).toLocaleString('vi-VN', {
        year: 'numeric',
        month: '2-digit',
        day: '2-digit',
        hour: '2-digit',
        minute: '2-digit',
        timeZone: 'Asia/Ho_Chi_Minh'
      });
    } catch {
      return dateString;
    }
  };

  // Get source type display info
  const getSourceTypeInfo = (sourceType) => {
    const sourceTypes = {
      local: {
        icon: 'üìÅ',
        name: 'LOCAL STORAGE',
        color: 'bg-blue-600'
      },
      nvr: {
        icon: 'üîó',
        name: 'NVR/DVR SYSTEM',
        color: 'bg-purple-600'
      },
      cloud: {
        icon: '‚òÅÔ∏è',
        name: 'CLOUD STORAGE',
        color: 'bg-cyan-600'
      }
    };
    return sourceTypes[sourceType] || { icon: '‚ùì', name: 'UNKNOWN', color: 'bg-gray-600' };
  };

  // ‚úÖ Helper to get working path for different source types
  const getWorkingPathForSource = (source) => {
    if (!source) return "";
    
    switch (source.source_type) {
      case 'nvr':
        return `/Users/annhu/vtrack_app/V_Track/nvr_downloads/${source.name}`;
      case 'local':
        return source.path;
      case 'cloud':
        return `/Users/annhu/vtrack_app/V_Track/cloud_sync/${source.name}`;
      default:
        return source.path;
    }
  };

  return (
    <div className="w-[25%] bg-gray-800 p-6 rounded-lg flex flex-col">
      <h1 className="text-3xl font-bold mb-4">C·∫•u h√¨nh</h1>
      {error && <div style={{ color: 'red' }}>{error}</div>}
      
      {/* Single Active Video Source Section */}
      <div className="mb-6 p-4 bg-gray-700 rounded-lg">
        <div className="flex justify-between items-center mb-3">
          <h3 className="text-lg font-bold text-white">Current Video Input Source</h3>
        </div>

        {isLoadingSource ? (
          <div className="text-center py-4">
            <div className="text-gray-400 text-sm">Loading source...</div>
          </div>
        ) : activeSource ? (
          <div className="bg-gray-600 p-4 rounded-lg">
            <div className="flex items-center gap-2 mb-3">
              <span className="font-medium text-white text-lg">{activeSource.name}</span>
              <span className="px-2 py-1 rounded text-xs bg-green-600 text-white">
                Active
              </span>
            </div>
            
            {/* Enhanced Source Type Display */}
            <div className="flex items-center gap-2 mb-2">
              <span className="text-sm text-gray-300"><strong>Type:</strong></span>
              <div className="flex items-center gap-1">
                <span className="text-sm">{getSourceTypeInfo(activeSource.source_type).icon}</span>
                <span className={`px-2 py-1 rounded text-xs text-white font-medium ${getSourceTypeInfo(activeSource.source_type).color}`}>
                  {getSourceTypeInfo(activeSource.source_type).name}
                </span>
              </div>
            </div>
            
            <div className="text-gray-300 text-sm mb-2 break-all">
              <strong>Path:</strong> {activeSource.path}
            </div>
            
            {/* NVR-specific information */}
            {activeSource.source_type === 'nvr' && activeSource.config && (
              <div className="text-gray-300 text-sm mb-2">
                <strong>Protocol:</strong> {activeSource.config.protocol?.toUpperCase() || 'ONVIF'}
                {activeSource.config.auto_sync && (
                  <span className="ml-2 px-1 py-0.5 bg-green-700 text-green-200 rounded text-xs">
                    Auto-Sync
                  </span>
                )}
              </div>
            )}
            
            <div className="text-gray-300 text-sm mb-2">
              <strong>Added:</strong> {formatDate(activeSource.created_at)}
            </div>
            
            {/* Camera Information */}
            {(activeSource.source_type === 'local' || activeSource.source_type === 'nvr') && (
              <div className="text-gray-300 text-sm mb-3">
                <strong>Cameras:</strong>{' '}
                {sourceCameras.length > 0 ? (
                  <span>
                    {selectedCameras.length} selected of {sourceCameras.length} detected
                    <div className="mt-1 text-xs">
                      {selectedCameras.length > 0 ? (
                        <span className="text-green-300">
                          Active: {selectedCameras.slice(0, 3).join(', ')}
                          {selectedCameras.length > 3 && ` +${selectedCameras.length - 3} more`}
                        </span>
                      ) : (
                        <span className="text-yellow-300">No cameras selected</span>
                      )}
                    </div>
                    {sourceCameras.length > selectedCameras.length && (
                      <div className="text-xs text-gray-400">
                        Available: {sourceCameras.filter(cam => !selectedCameras.includes(cam)).slice(0, 2).join(', ')}
                        {sourceCameras.filter(cam => !selectedCameras.includes(cam)).length > 2 && '...'}
                      </div>
                    )}
                  </span>
                ) : (
                  <span className="text-gray-400">
                    {activeSource.source_type === 'nvr' ? 'No cameras discovered' : 'No camera folders detected'}
                  </span>
                )}
              </div>
            )}
            
            {/* Action Buttons */}
            <div className="flex justify-end gap-2">
              <button
                onClick={handleUpdateSource}
                className="px-4 py-2 bg-blue-600 hover:bg-blue-700 text-white rounded text-sm font-medium"
              >
                Update
              </button>
              <button
                onClick={handleChangeSourceType}
                className="px-4 py-2 bg-orange-600 hover:bg-orange-700 text-white rounded text-sm font-medium"
              >
                Change
              </button>
            </div>
          </div>
        ) : (
          <div className="text-center py-6">
            <div className="text-gray-400 text-sm mb-3">
              No video source configured yet.
            </div>
            <button
              onClick={() => setShowAddSourceModal(true)}
              className="bg-green-600 hover:bg-green-700 text-white px-4 py-2 rounded font-medium"
            >
              Add Video Source
            </button>
          </div>
        )}
      </div>

      {/* ‚úÖ FIX: Input Path Section - DISTINGUISH NVR vs LOCAL */}
      <div className="mb-6 p-4 bg-gray-700 rounded-lg">
        <h3 className="text-lg font-bold text-white mb-3">Input Video Path</h3>
        
        {activeSource ? (
          <div className="bg-gray-600 p-3 rounded">
            <div className="text-sm text-gray-300 mb-1">
              <strong>Source:</strong> {activeSource.name}
            </div>
            
            {activeSource.source_type === 'nvr' ? (
              <>
                <div className="text-sm text-gray-300 mb-1">
                  <strong>NVR Connection:</strong> {activeSource.path}
                </div>
                <div className="text-sm text-gray-300 mb-1">
                  <strong>Working Directory:</strong> {getWorkingPathForSource(activeSource)}
                </div>
                <div className="mt-2 text-xs text-blue-300">
                  üîó NVR videos will be downloaded to working directory for processing
                </div>
              </>
            ) : activeSource.source_type === 'local' ? (
              <>
                <div className="text-sm text-gray-300 mb-1">
                  <strong>File System Path:</strong> {activeSource.path}
                </div>
                <div className="text-sm text-gray-300 mb-1">
                  <strong>Processing Path:</strong> {getWorkingPathForSource(activeSource)}
                </div>
                <div className="mt-2 text-xs text-green-300">
                  üìÅ Videos will be processed directly from this location
                </div>
              </>
            ) : (
              <>
                <div className="text-sm text-gray-300 mb-1">
                  <strong>Source Path:</strong> {activeSource.path}
                </div>
                <div className="text-sm text-gray-300 mb-1">
                  <strong>Working Path:</strong> {getWorkingPathForSource(activeSource)}
                </div>
                <div className="mt-2 text-xs text-yellow-300">
                  ‚ö†Ô∏è Source type: {activeSource.source_type}
                </div>
              </>
            )}
            
            <div className="text-sm text-gray-300">
              <strong>Type:</strong> {getSourceTypeInfo(activeSource.source_type).name}
            </div>
            <div className="mt-2 text-xs text-green-300">
              ‚úÖ Input path automatically configured from video source
            </div>
          </div>
        ) : (
          <div className="text-center py-4 bg-gray-600 rounded">
            <div className="text-gray-400 text-sm mb-3">
              No video source configured. Input path will be empty.
            </div>
            <button
              onClick={() => setShowAddSourceModal(true)}
              className="bg-green-600 hover:bg-green-700 text-white px-4 py-2 rounded text-sm font-medium"
            >
              Add Video Source First
            </button>
          </div>
        )}
      </div>

      {/* Legacy Input Path Field - Hidden khi c√≥ video source */}
      {!activeSource && (
        <div className="mb-4">
          <label className="block mb-1">Legacy Input Path (Deprecated):</label>
          <div className="relative w-full">
            <input
              type="text"
              value={inputPath}
              onChange={(e) => setInputPath(e.target.value)}
              placeholder="Please add a video source instead"
              className="w-full p-2 rounded bg-gray-700 text-white"
              disabled
            />
            <div className="text-xs text-yellow-400 mt-1">
              ‚ö†Ô∏è Please use "Add Video Source" button above instead
            </div>
          </div>
        </div>
      )}

      <div className="mb-4">
        <label className="block mb-1">V·ªã tr√≠ Output Video:</label>
        <div className="relative w-full">
          <input
            type="text"
            value={outputPath}
            onChange={(e) => setOutputPath(e.target.value)}
            placeholder="V·ªã tr√≠ Output Video (e.g., /Users/annhu/vtrack_app/V_Track/output_clips)"
            className="w-full p-2 rounded bg-gray-700 text-white"
          />
          <button
            type="button"
            onClick={() => handleOpenExplorer("output")}
            className="absolute right-2 top-1/2 transform -translate-y-1/2 text-white"
          >
            ...
          </button>
        </div>
      </div>
      <div className="flex flex-col gap-4 mb-4">
        <div>
          <label className="block mb-1">Th·ªùi gian l∆∞u tr·ªØ (ng√†y):</label>
          <input
            type="number"
            value={defaultDays}
            onChange={(e) => setDefaultDays(Number(e.target.value))}
            className="w-full p-2 rounded bg-gray-700 text-white"
          />
        </div>
        <div>
          <label className="block mb-1">Th·ªùi gian ƒë√≥ng h√†ng nhanh nh·∫•t (gi√¢y):</label>
          <input
            type="number"
            value={minPackingTime}
            onChange={(e) => setMinPackingTime(Number(e.target.value))}
            className="w-full p-2 rounded bg-gray-700 text-white"
          />
        </div>
        <div>
          <label className="block mb-1">Th·ªùi gian ƒë√≥ng h√†ng ch·∫≠m nh·∫•t (gi√¢y):</label>
          <input
            type="number"
            value={maxPackingTime}
            onChange={(e) => setMaxPackingTime(Number(e.target.value))}
            className="w-full p-2 rounded bg-gray-700 text-white"
          />
        </div>
        <div>
          <label className="block mb-1">T·ªëc ƒë·ªô frame:</label>
          <input
            type="number"
            value={frameRate}
            onChange={(e) => setFrameRate(Number(e.target.value))}
            className="w-full p-2 rounded bg-gray-700 text-white"
          />
        </div>
        <div>
          <label className="block mb-1">Kho·∫£ng c√°ch Frame:</label>
          <input
            type="number"
            value={frameInterval}
            onChange={(e) => setFrameInterval(Number(e.target.value))}
            min="2"
            max="30"
            className="w-full p-2 rounded bg-gray-700 text-white"
          />
        </div>
        <div>
          <label className="block mb-1">Buffer Video (gi√¢y):</label>
          <input
            type="number"
            value={videoBuffer}
            onChange={(e) => setVideoBuffer(Number(e.target.value))}
            className="w-full p-2 rounded bg-gray-700 text-white"
          />
        </div>
      </div>
      <div className="mt-auto flex justify-center">
        <button
          onClick={handleShowCameraDialog}
          className="w-1/2 py-2 bg-blue-600 text-white font-bold rounded"
        >
          G·ª≠i
        </button>
      </div>

      {/* Enhanced AddSourceModal with NVR support */}
      {showAddSourceModal && (
        <AddSourceModal
          show={showAddSourceModal}
          onClose={() => setShowAddSourceModal(false)}
          onAdd={handleAddSource}
          testSourceConnection={testSourceConnection}
        />
      )}

      {/* Simple Update Source Modal */}
      {showUpdateSourceModal && activeSource && (
        <SimpleUpdateSourceModal
          show={showUpdateSourceModal}
          source={activeSource}
          sourceCameras={sourceCameras}
          selectedCameras={selectedCameras}
          onClose={() => setShowUpdateSourceModal(false)}
          onUpdate={handleUpdateComplete}
          testSourceConnection={testSourceConnection}
          detectCameras={detectCameras}
          updateSourceCameras={updateSourceCameras}
        />
      )}
    </div>
  );
};

// Enhanced Update Source Modal Component (supports NVR)
const SimpleUpdateSourceModal = ({ 
  show, 
  source, 
  sourceCameras,
  selectedCameras: initialSelectedCameras,
  onClose, 
  onUpdate, 
  testSourceConnection, 
  detectCameras, 
  updateSourceCameras
}) => {
  const [path] = useState(source.path);
  const [detectedCameras, setDetectedCameras] = useState(sourceCameras);
  const [selectedCameras, setSelectedCameras] = useState(initialSelectedCameras);
  
  // Loading states
  const [isDetecting, setIsDetecting] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [testResult, setTestResult] = useState(null);

  useEffect(() => {
    setDetectedCameras(sourceCameras);
    setSelectedCameras(initialSelectedCameras);
  }, [sourceCameras, initialSelectedCameras]);

  const detectCamerasInPath = async () => {
    if (!path) return;
    
    setIsDetecting(true);
    try {
      if (source.source_type === 'local') {
        // Local source: scan for camera folders
        const response = await detectCameras();
        if (response.cameras) {
          setDetectedCameras(response.cameras);
          // Keep existing selected cameras that are still available
          const validSelectedCameras = selectedCameras.filter(cam => 
            response.cameras.includes(cam)
          );
          setSelectedCameras(validSelectedCameras);
        }
      } else if (source.source_type === 'nvr') {
        // NVR source: re-test connection to discover cameras
        const testData = {
          source_type: 'nvr',
          path: source.path,
          config: source.config || {}
        };
        
        const response = await testSourceConnection(testData);
        if (response.accessible && response.cameras) {
          const cameraNames = response.cameras.map(cam => 
            cam.name || cam.id || `Camera ${response.cameras.indexOf(cam) + 1}`
          );
          setDetectedCameras(cameraNames);
          
          // Keep existing selected cameras that are still available
          const validSelectedCameras = selectedCameras.filter(cam => 
            cameraNames.includes(cam)
          );
          setSelectedCameras(validSelectedCameras);
        }
      }
    } catch (error) {
      console.error('Camera detection failed:', error);
      setDetectedCameras([]);
      setSelectedCameras([]);
    } finally {
      setIsDetecting(false);
    }
  };

  const handleTestConnection = async () => {
    if (!path) {
      alert('No path to test');
      return;
    }

    setIsLoading(true);
    try {
      const testData = {
        source_type: source.source_type,
        path: path,
        config: source.config || {}
      };
      
      const response = await testSourceConnection(testData);
      setTestResult({
        success: response.accessible,
        message: response.message
      });
      
      // Auto-discover cameras on successful test for NVR
      if (response.accessible && source.source_type === 'nvr' && response.cameras) {
        const cameraNames = response.cameras.map(cam => 
          cam.name || cam.id || `Camera ${response.cameras.indexOf(cam) + 1}`
        );
        setDetectedCameras(cameraNames);
        setTestResult(prev => ({
          ...prev,
          message: `${prev.message} - Found ${response.cameras.length} camera(s)`
        }));
      }
      
    } catch (error) {
      setTestResult({
        success: false,
        message: error.message || 'Connection test failed'
      });
    } finally {
      setIsLoading(false);
    }
  };

  const handleCameraToggle = (cameraName) => {
    setSelectedCameras(prev => 
      prev.includes(cameraName) 
        ? prev.filter(c => c !== cameraName)
        : [...prev, cameraName]
    );
  };

  const handleSubmit = async (e) => {
    e.preventDefault();
    
    try {
      // Update camera selection
      await updateSourceCameras(source.id, selectedCameras);
      
      alert('Source updated successfully!');
      onUpdate();
    } catch (error) {
      console.error('Error updating source:', error);
      alert('Failed to update source: ' + (error.response?.data?.error || error.message));
    }
  };

  if (!show) return null;

  const getSourceTypeInfo = (sourceType) => {
    const sourceTypes = {
      local: { icon: 'üìÅ', name: 'LOCAL STORAGE' },
      nvr: { icon: 'üîó', name: 'NVR/DVR SYSTEM' },
      cloud: { icon: '‚òÅÔ∏è', name: 'CLOUD STORAGE' }
    };
    return sourceTypes[sourceType] || { icon: '‚ùì', name: 'UNKNOWN' };
  };

  return (
    <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
      <div className="bg-gray-800 rounded-lg p-6 w-full max-w-2xl mx-4 max-h-[90vh] overflow-y-auto">
        <div className="flex justify-between items-center mb-4">
          <h3 className="text-xl font-bold text-white">üîß Update Video Source</h3>
          <button
            onClick={onClose}
            className="text-gray-400 hover:text-white text-2xl"
          >
            √ó
          </button>
        </div>

        <form onSubmit={handleSubmit}>
          {/* Source Type Info */}
          <div className="mb-4">
            <label className="block text-sm font-medium text-gray-300 mb-2">
              Source Type
            </label>
            <div className="w-full p-3 border border-gray-600 rounded bg-gray-700 text-white flex items-center">
              <span className="mr-2">{getSourceTypeInfo(source.source_type).icon}</span>
              <span className="font-medium">{getSourceTypeInfo(source.source_type).name}</span>
              <span className="ml-2 text-gray-400 text-sm">(ReadOnly)</span>
            </div>
          </div>

          {/* Path Info */}
          <div className="mb-4">
            <label className="block text-sm font-medium text-gray-300 mb-2">
              {source.source_type === 'nvr' ? 'NVR Address' : 'Path'}
            </label>
            <div className="w-full p-3 border border-gray-600 rounded bg-gray-700 text-white break-all">
              {path}
            </div>
          </div>

          {/* NVR Configuration Display */}
          {source.source_type === 'nvr' && source.config && (
            <div className="mb-4">
              <label className="block text-sm font-medium text-gray-300 mb-2">
                NVR Configuration
              </label>
              <div className="p-3 bg-gray-700 rounded space-y-2">
                <div className="text-sm text-gray-300">
                  <strong>Protocol:</strong> {source.config.protocol?.toUpperCase() || 'ONVIF'}
                </div>
                <div className="text-sm text-gray-300">
                  <strong>Username:</strong> {source.config.username || 'Not set'}
                </div>
                <div className="text-sm text-gray-300">
                  <strong>Auto-sync:</strong> {source.config.auto_sync ? 'Enabled' : 'Disabled'}
                </div>
              </div>
            </div>
          )}

          {/* Camera Selection */}
          <div className="mb-4">
            <div className="flex justify-between items-center mb-3">
              <label className="block text-sm font-medium text-gray-300">
                {source.source_type === 'nvr' ? 'Discovered Cameras' : 'Camera Folders'}
              </label>
              <button
                type="button"
                onClick={detectCamerasInPath}
                disabled={isDetecting}
                className="bg-blue-600 hover:bg-blue-700 disabled:bg-gray-600 text-white px-3 py-1 rounded text-xs"
              >
                {isDetecting ? 'Scanning...' : source.source_type === 'nvr' ? 'Rediscover' : 'Rescan'}
              </button>
            </div>
            
            {isDetecting ? (
              <div className="text-center py-4">
                <div className="text-gray-400 text-sm">
                  {source.source_type === 'nvr' ? 'Discovering cameras...' : 'Detecting cameras...'}
                </div>
              </div>
            ) : detectedCameras.length > 0 ? (
              <div className="grid grid-cols-2 gap-2 p-3 bg-gray-700 rounded">
                {detectedCameras.map(camera => (
                  <label key={camera} className="flex items-center space-x-2 cursor-pointer">
                    <input
                      type="checkbox"
                      checked={selectedCameras.includes(camera)}
                      onChange={() => handleCameraToggle(camera)}
                      className="rounded"
                    />
                    <span className="text-white text-sm">{camera}</span>
                    {camera.status && (
                      <span className={`px-2 py-1 text-xs rounded ${camera.status === 'Connected' ? 'bg-green-600' : 'bg-red-600'}`}>
                        {camera.status}
                      </span>
                    )}
                  </label>
                ))}
              </div>
            ) : (
              <div className="text-center py-4 bg-gray-700 rounded">
                <div className="text-gray-400 text-sm">
                  {source.source_type === 'nvr' ? 'No cameras discovered' : 'No camera folders detected'}
                </div>
              </div>
            )}
            
            {selectedCameras.length > 0 && (
              <div className="mt-2 text-xs text-gray-400">
                Selected: {selectedCameras.length} camera(s)
              </div>
            )}
          </div>

          {/* Test Connection */}
          <div className="mb-4">
            <button
              type="button"
              onClick={handleTestConnection}
              disabled={isLoading}
              className="bg-yellow-600 hover:bg-yellow-700 disabled:bg-gray-600 text-white px-4 py-2 rounded font-medium"
            >
              {isLoading ? 'Testing...' : 'Test Connection'}
            </button>
            
            {testResult && (
              <div className={`mt-2 p-3 rounded text-sm ${
                testResult.success ? 'bg-green-800 text-green-200' : 'bg-red-800 text-red-200'
              }`}>
                {testResult.message}
              </div>
            )}
          </div>

          {/* Action Buttons */}
          <div className="flex gap-3">
            <button
              type="submit"
              className="bg-blue-600 hover:bg-blue-700 text-white px-4 py-2 rounded font-medium"
            >
              Save Changes
            </button>
            <button
              type="button"
              onClick={onClose}
              className="bg-gray-600 hover:bg-gray-700 text-white px-4 py-2 rounded font-medium"
            >
              Cancel
            </button>
          </div>
        </form>
      </div>
    </div>
  );
};

export default ConfigForm;
```
## üìÑ File: `GoogleDriveFolderSelector.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/GoogleDriveFolderSelector.js`

```javascript
// ‚ö†Ô∏è DEPRECATED: This component has been replaced by GoogleDrivePickerIntegration
// This file is kept for rollback purposes only and will be removed in future versions
// Use GoogleDrivePickerIntegration.js instead

console.warn('‚ö†Ô∏è GoogleDriveFolderSelector is deprecated. Use GoogleDrivePickerIntegration instead.');

// components/config/GoogleDriveFolderSelector.js - 2-Step Folder Selection
import React, { useState, useEffect } from 'react';

const GoogleDriveFolderSelector = ({
  rootFolders = [],
  subFolders = [],
  selectedRootFolder = null,
  selectedCameraFolders = [],
  isLoadingFolders = false,
  onSelectRoot,
  onSelectCameras
}) => {
  // ‚ö†Ô∏è DEPRECATION WARNING: Show to developers
  useEffect(() => {
    console.warn('‚ö†Ô∏è GoogleDriveFolderSelector is DEPRECATED');
    console.warn('   ‚Üí Replace with GoogleDrivePickerIntegration.js');
    console.warn('   ‚Üí This component will be removed in future versions');
    console.warn('   ‚Üí Phase 3 migration completed - update your imports');
  }, []);

  // Local state
  const [expandedFolders, setExpandedFolders] = useState(new Set());
  const [searchTerm, setSearchTerm] = useState('');
  const [viewMode, setViewMode] = useState('tree'); // 'tree' or 'list'
  const [folderStructure, setFolderStructure] = useState('unknown');

  // Filter folders based on search term
  const filteredRootFolders = rootFolders.filter(folder =>
    folder.name.toLowerCase().includes(searchTerm.toLowerCase())
  );

  const filteredSubFolders = subFolders.filter(folder =>
    folder.name.toLowerCase().includes(searchTerm.toLowerCase())
  );

  // Detect folder structure when subfolders load
  useEffect(() => {
    if (subFolders.length > 0) {
      // Check if subfolders look like camera folders
      const cameraKeywords = ['cam', 'camera', 'channel', 'ch', 'zone', 'area'];
      const cameraFolderCount = subFolders.filter(folder =>
        cameraKeywords.some(keyword => 
          folder.name.toLowerCase().includes(keyword)
        )
      ).length;

      if (cameraFolderCount > 0) {
        setFolderStructure('nested_cameras');
      } else {
        setFolderStructure('nested_general');
      }
    } else {
      setFolderStructure('unknown');
    }
  }, [subFolders]);

  // Handle root folder click/selection
  const handleRootFolderClick = (folder) => {
    if (selectedRootFolder?.id === folder.id) {
      // Already selected - toggle expansion
      const newExpanded = new Set(expandedFolders);
      if (newExpanded.has(folder.id)) {
        newExpanded.delete(folder.id);
      } else {
        newExpanded.add(folder.id);
      }
      setExpandedFolders(newExpanded);
    } else {
      // New selection
      if (onSelectRoot) {
        onSelectRoot(folder);
      }
      
      // Auto-expand the selected folder
      const newExpanded = new Set(expandedFolders);
      newExpanded.add(folder.id);
      setExpandedFolders(newExpanded);
    }
  };

  // Handle camera folder toggle
  const handleCameraFolderToggle = (cameraFolder) => {
    const currentSelected = [...selectedCameraFolders];
    const folderName = cameraFolder.name;
    
    if (currentSelected.includes(folderName)) {
      // Remove from selection
      const newSelected = currentSelected.filter(name => name !== folderName);
      if (onSelectCameras) {
        onSelectCameras(newSelected);
      }
    } else {
      // Add to selection
      const newSelected = [...currentSelected, folderName];
      if (onSelectCameras) {
        onSelectCameras(newSelected);
      }
    }
  };

  // Select all camera folders
  const handleSelectAllCameras = () => {
    const allCameraNames = subFolders.map(folder => folder.name);
    if (onSelectCameras) {
      onSelectCameras(allCameraNames);
    }
  };

  // Deselect all camera folders
  const handleDeselectAllCameras = () => {
    if (onSelectCameras) {
      onSelectCameras([]);
    }
  };

  // Get folder icon based on folder type
  const getFolderIcon = (folder) => {
    const name = folder.name.toLowerCase();
    
    if (name.includes('camera') || name.includes('cam')) return 'üìπ';
    if (name.includes('security') || name.includes('surveillance')) return 'üîí';
    if (name.includes('recording') || name.includes('video')) return 'üé¨';
    if (name.includes('storage') || name.includes('archive')) return 'üíæ';
    if (name.includes('backup')) return 'üîÑ';
    
    return 'üìÅ';
  };

  // Get selection status for bulk operations
  const getSelectionStatus = () => {
    if (subFolders.length === 0) return 'none';
    if (selectedCameraFolders.length === 0) return 'none';
    if (selectedCameraFolders.length === subFolders.length) return 'all';
    return 'partial';
  };

  return (
    <div className="space-y-4">
      
      {/* ‚ö†Ô∏è DEPRECATION WARNING BANNER */}
      <div className="bg-orange-800 border border-orange-600 rounded-lg p-4">
        <div className="flex items-center gap-2">
          <span className="text-orange-200 text-xl">‚ö†Ô∏è</span>
          <div className="text-orange-200">
            <div className="font-medium">DEPRECATED COMPONENT</div>
            <div className="text-sm">This component has been replaced by GoogleDrivePickerIntegration. Please update your code.</div>
          </div>
        </div>
      </div>
      
      {/* Header with Search and View Controls */}
      <div className="flex items-center justify-between">
        <div className="flex items-center gap-3">
          <h4 className="font-medium text-white">üìÅ Folder Selection</h4>
          
          {/* View Mode Toggle */}
          <div className="flex bg-gray-600 rounded overflow-hidden">
            <button
              onClick={() => setViewMode('tree')}
              className={`px-3 py-1 text-xs font-medium ${
                viewMode === 'tree' 
                  ? 'bg-blue-600 text-white' 
                  : 'text-gray-300 hover:text-white'
              }`}
            >
              Tree
            </button>
            <button
              onClick={() => setViewMode('list')}
              className={`px-3 py-1 text-xs font-medium ${
                viewMode === 'list' 
                  ? 'bg-blue-600 text-white' 
                  : 'text-gray-300 hover:text-white'
              }`}
            >
              List
            </button>
          </div>
        </div>

        {/* Search */}
        <div className="relative">
          <input
            type="text"
            placeholder="Search folders..."
            value={searchTerm}
            onChange={(e) => setSearchTerm(e.target.value)}
            className="w-48 px-3 py-1 bg-gray-600 text-white text-sm rounded border border-gray-500 focus:border-blue-500"
          />
          {searchTerm && (
            <button
              onClick={() => setSearchTerm('')}
              className="absolute right-2 top-1/2 transform -translate-y-1/2 text-gray-400 hover:text-white"
            >
              √ó
            </button>
          )}
        </div>
      </div>

      {/* Step 1: Root Folder Selection */}
      <div className="bg-gray-600 rounded-lg p-4">
        <div className="flex items-center justify-between mb-3">
          <h5 className="font-medium text-white">Step 1: Select Root Folder</h5>
          <span className="text-xs text-gray-300">
            {filteredRootFolders.length} folder(s) available
          </span>
        </div>

        {filteredRootFolders.length === 0 ? (
          <div className="text-center py-6 text-gray-400">
            <div className="text-2xl mb-2">üìÇ</div>
            <div className="text-sm">
              {searchTerm ? 'No folders match your search' : 'No folders available'}
            </div>
          </div>
        ) : (
          <div className="space-y-2 max-h-32 overflow-y-auto">
            {filteredRootFolders.map((folder) => (
              <div
                key={folder.id}
                onClick={() => handleRootFolderClick(folder)}
                className={`flex items-center gap-3 p-3 rounded cursor-pointer transition-colors ${
                  selectedRootFolder?.id === folder.id
                    ? 'bg-blue-600 text-white'
                    : 'bg-gray-700 hover:bg-gray-650 text-gray-300'
                }`}
              >
                <span className="text-lg">{getFolderIcon(folder)}</span>
                <div className="flex-1 min-w-0">
                  <div className="font-medium truncate">{folder.name}</div>
                  {folder.description && (
                    <div className="text-xs opacity-75 truncate">{folder.description}</div>
                  )}
                </div>
                {selectedRootFolder?.id === folder.id && (
                  <span className="text-green-300 text-sm">‚úì Selected</span>
                )}
              </div>
            ))}
          </div>
        )}
      </div>

      {/* Step 2: Camera Folder Selection */}
      {selectedRootFolder && (
        <div className="bg-gray-600 rounded-lg p-4">
          <div className="flex items-center justify-between mb-3">
            <h5 className="font-medium text-white">
              Step 2: Select Camera Folders
              <span className="text-sm text-gray-300 ml-2">
                from "{selectedRootFolder.name}"
              </span>
            </h5>
            
            {/* Bulk Selection Controls */}
            {subFolders.length > 0 && (
              <div className="flex gap-2">
                <button
                  onClick={handleSelectAllCameras}
                  disabled={getSelectionStatus() === 'all'}
                  className="px-3 py-1 bg-blue-600 hover:bg-blue-700 disabled:bg-gray-500 text-white rounded text-xs font-medium"
                >
                  Select All
                </button>
                <button
                  onClick={handleDeselectAllCameras}
                  disabled={getSelectionStatus() === 'none'}
                  className="px-3 py-1 bg-gray-500 hover:bg-gray-600 disabled:bg-gray-400 text-white rounded text-xs font-medium"
                >
                  Clear All
                </button>
              </div>
            )}
          </div>

          {/* Loading State */}
          {isLoadingFolders && (
            <div className="text-center py-6">
              <div className="animate-spin w-6 h-6 border-2 border-blue-500 border-t-transparent rounded-full mx-auto mb-2"></div>
              <div className="text-sm text-gray-400">Loading camera folders...</div>
            </div>
          )}

          {/* No Subfolders */}
          {!isLoadingFolders && subFolders.length === 0 && (
            <div className="text-center py-6 text-gray-400">
              <div className="text-2xl mb-2">üìπ</div>
              <div className="text-sm">
                No camera folders found in "{selectedRootFolder.name}"
              </div>
              <div className="text-xs mt-1">
                Try selecting a different root folder
              </div>
            </div>
          )}

          {/* Camera Folders List */}
          {!isLoadingFolders && filteredSubFolders.length > 0 && (
            <div>
              {/* Folder Structure Info */}
              {folderStructure === 'nested_cameras' && (
                <div className="bg-green-800 border border-green-600 rounded p-2 mb-3">
                  <div className="text-xs text-green-200">
                    üéØ Camera folder structure detected! These appear to be camera recording folders.
                  </div>
                </div>
              )}

              {viewMode === 'tree' ? (
                /* Tree View */
                <div className="space-y-1 max-h-48 overflow-y-auto">
                  {filteredSubFolders.map((folder) => (
                    <label
                      key={folder.id}
                      className="flex items-center gap-3 p-2 rounded cursor-pointer hover:bg-gray-700 transition-colors"
                    >
                      <input
                        type="checkbox"
                        checked={selectedCameraFolders.includes(folder.name)}
                        onChange={() => handleCameraFolderToggle(folder)}
                        className="w-4 h-4 text-blue-600 bg-gray-700 border-gray-600 rounded focus:ring-blue-500"
                      />
                      <span className="text-lg">{getFolderIcon(folder)}</span>
                      <div className="flex-1 min-w-0">
                        <div className="font-medium text-white truncate">{folder.name}</div>
                        {folder.file_count && (
                          <div className="text-xs text-gray-400">
                            {folder.file_count} files
                          </div>
                        )}
                      </div>
                      {folder.size && (
                        <div className="text-xs text-gray-400">
                          {(folder.size / 1024 / 1024).toFixed(1)} MB
                        </div>
                      )}
                    </label>
                  ))}
                </div>
              ) : (
                /* List View */
                <div className="grid grid-cols-2 gap-2 max-h-48 overflow-y-auto">
                  {filteredSubFolders.map((folder) => (
                    <label
                      key={folder.id}
                      className={`flex items-center gap-2 p-2 rounded cursor-pointer transition-colors ${
                        selectedCameraFolders.includes(folder.name)
                          ? 'bg-blue-600 text-white'
                          : 'bg-gray-700 hover:bg-gray-650 text-gray-300'
                      }`}
                    >
                      <input
                        type="checkbox"
                        checked={selectedCameraFolders.includes(folder.name)}
                        onChange={() => handleCameraFolderToggle(folder)}
                        className="w-4 h-4"
                      />
                      <span>{getFolderIcon(folder)}</span>
                      <span className="font-medium text-sm truncate">{folder.name}</span>
                    </label>
                  ))}
                </div>
              )}

              {/* Selection Summary */}
              <div className="mt-3 p-2 bg-gray-700 rounded">
                <div className="text-sm text-gray-300">
                  <strong>Selected:</strong> {selectedCameraFolders.length} of {subFolders.length} camera folders
                </div>
                {selectedCameraFolders.length > 0 && (
                  <div className="text-xs text-gray-400 mt-1">
                    {selectedCameraFolders.slice(0, 3).join(', ')}
                    {selectedCameraFolders.length > 3 && ` +${selectedCameraFolders.length - 3} more`}
                  </div>
                )}
              </div>
            </div>
          )}
        </div>
      )}

      {/* Configuration Summary */}
      {selectedRootFolder && selectedCameraFolders.length > 0 && (
        <div className="bg-green-800 border border-green-600 rounded-lg p-3">
          <h5 className="font-medium text-green-100 mb-2">üìã Selection Summary</h5>
          <div className="text-sm text-green-200 space-y-1">
            <div><strong>Root Folder:</strong> {selectedRootFolder.name}</div>
            <div><strong>Camera Folders:</strong> {selectedCameraFolders.length} selected</div>
            <div><strong>Structure:</strong> {folderStructure === 'nested_cameras' ? 'Nested Camera Folders' : 'Nested General Folders'}</div>
            <div className="text-xs text-green-300 mt-2">
              Videos will be synced from: {selectedRootFolder.name}/{selectedCameraFolders.join(', ')}
            </div>
          </div>
        </div>
      )}

      {/* Debug Info (Development) */}
      {process.env.NODE_ENV === 'development' && (
        <details className="bg-gray-800 rounded p-2">
          <summary className="text-xs text-gray-400 cursor-pointer">üîß Debug - Folder Selection</summary>
          <pre className="text-xs text-gray-400 mt-2 overflow-auto">
            {JSON.stringify({
              rootFolders: rootFolders.length,
              subFolders: subFolders.length,
              selectedRoot: selectedRootFolder?.name,
              selectedCameras: selectedCameraFolders,
              folderStructure,
              searchTerm,
              viewMode,
              DEPRECATED: true,
              replacement: 'GoogleDrivePickerIntegration.js'
            }, null, 2)}
          </pre>
        </details>
      )}
    </div>
  );
};

export default GoogleDriveFolderSelector;
```
## üìÑ File: `GeneralInfoForm.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/GeneralInfoForm.js`

```javascript
import DatePicker from "react-datepicker";

const GeneralInfoForm = ({
  country,
  setCountry,
  timezone,
  setTimezone,
  brandName,
  setBrandName,
  workingDays,
  setWorkingDays,
  fromTime,
  setFromTime,
  toTime,
  setToTime,
  handleCountryChange,
  handleFromTimeChange,
  handleToTimeChange,
  handleWorkingDayChange,
  handleSaveGeneralInfo,
  countries,
}) => {
  return (
    <div className="w-[25%] bg-gray-800 p-6 rounded-lg flex flex-col">
      <h1 className="text-3xl font-bold mb-4">Th√¥ng tin chung</h1>
      <div className="mb-4">
        <label className="block mb-1">Qu·ªëc gia:</label>
        <select
          value={country}
          onChange={handleCountryChange}
          className="w-full p-2 rounded bg-gray-700 text-white"
        >
          {countries.map((country) => (
            <option key={country} value={country}>
              {country}
            </option>
          ))}
        </select>
      </div>
      <div className="mb-4">
        <label className="block mb-1">M√∫i gi·ªù:</label>
        <input
          type="text"
          value={timezone}
          readOnly
          className="w-full p-2 rounded bg-gray-700 text-white"
        />
      </div>
      <div className="mb-4">
        <label className="block mb-1">T√™n th∆∞∆°ng hi·ªáu:</label>
        <input
          type="text"
          value={brandName}
          onChange={(e) => setBrandName(e.target.value)}
          placeholder="Nh·∫≠p t√™n th∆∞∆°ng hi·ªáu"
          className="w-full p-2 rounded bg-gray-700 text-white"
        />
      </div>
      <div className="mb-4">
        <h3 className="text-lg font-bold mb-2">Ng√†y l√†m vi·ªác</h3>
        {["Th·ª© Hai", "Th·ª© Ba", "Th·ª© T∆∞", "Th·ª© NƒÉm", "Th·ª© S√°u", "Th·ª© B·∫£y", "Ch·ªß Nh·∫≠t"].map((day) => (
          <label key={day} className="flex items-center mb-2">
            <input
              type="checkbox"
              className="mr-2"
              onChange={() => handleWorkingDayChange(day)}
              checked={workingDays.includes(day)}
            />
            {day}
          </label>
        ))}
      </div>
      <div className="mb-4">
        <h3 className="text-lg font-bold mb-2">Th·ªùi gian l√†m vi·ªác</h3>
        <div className="flex gap-4">
          <div className="flex-1">
            <label className="block mb-1">T·ª´:</label>
            <DatePicker
              selected={fromTime}
              onChange={handleFromTimeChange}
              showTimeSelect
              showTimeSelectOnly
              timeIntervals={30}
              timeCaption="Gi·ªù"
              dateFormat="HH:mm"
              className="w-full p-2 rounded bg-gray-700 text-white"
            />
          </div>
          <div className="flex-1">
            <label className="block mb-1">ƒê·∫øn:</label>
            <DatePicker
              selected={toTime}
              onChange={handleToTimeChange}
              showTimeSelect
              showTimeSelectOnly
              timeIntervals={30}
              timeCaption="Gi·ªù"
              dateFormat="HH:mm"
              className="w-full p-2 rounded bg-gray-700 text-white"
            />
          </div>
        </div>
      </div>
      <div className="mt-auto flex justify-center">
        <button
          onClick={handleSaveGeneralInfo}
          className="w-1/2 py-2 bg-blue-600 text-white font-bold rounded"
        >
          G·ª≠i
        </button>
      </div>
    </div>
  );
};

export default GeneralInfoForm;
```
## üìÑ File: `GoogleDriveAuthButton.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/GoogleDriveAuthButton.js`

```javascript
// components/config/GoogleDriveAuthButton.js - FIXED for COOP & OAuth State Issues
import React, { useState, useEffect } from 'react';

const GoogleDriveAuthButton = ({ 
  onAuth, 
  isAuthenticated = false, 
  isLoading = false, 
  userEmail = null,
  className = '' 
}) => {
  const [authState, setAuthState] = useState({
    loading: isLoading,
    authenticated: isAuthenticated,
    userEmail: userEmail,
    error: null
  });

  // üÜï NEW: Handle postMessage from OAuth popup
  useEffect(() => {
    const handleOAuthMessage = (event) => {
  console.log('üì¨ Received OAuth message:', event.data);

  // Security: Only accept messages from our backend
  if (event.origin !== 'http://localhost:8080') {
    console.warn('üö´ Ignoring message from unauthorized origin:', event.origin);
    return;
  }

  if (event.data.type === 'OAUTH_SUCCESS') {
    console.log('‚úÖ OAuth success via postMessage:', event.data);
    
    // üîß FIX: Handle different data formats from backend
    const userData = event.data.user_info || event.data.user || {};
    const userEmail = event.data.user_email || userData.email || 'unknown';
    const folders = event.data.folders || [];
    const credentials = event.data.credentials || {};
    
    console.log('üìß User email:', userEmail);
    console.log('üìÅ Folders count:', folders.length);
    
    setAuthState(prev => ({
      ...prev,
      loading: false,
      authenticated: true,
      userEmail: userEmail,
      error: null
    }));

    // Notify parent component with normalized data
    if (onAuth) {
      onAuth({
        success: true,
        user_email: userEmail,
        user_info: userData,
        credentials: credentials,
        folders: folders,
        message: `Authenticated as ${userEmail}`,
        backend_port: event.data.backend_port || 8080
      });
    }

  } else if (event.data.type === 'OAUTH_ERROR') {
    console.error('‚ùå OAuth error via postMessage:', event.data.error);
    
    setAuthState(prev => ({
      ...prev,
      loading: false,
      authenticated: false,
      error: event.data.error
    }));

    if (onAuth) {
      onAuth({
        success: false,
        message: event.data.error || 'Authentication failed',
        error: event.data.details || ''
      });
    }
  }
};

    // Listen for OAuth messages
    window.addEventListener('message', handleOAuthMessage);

    return () => {
      window.removeEventListener('message', handleOAuthMessage);
    };
  }, [onAuth]);

  const handleAuthenticate = async () => {
    if (authState.loading) return;

    try {
      setAuthState(prev => ({ ...prev, loading: true, error: null }));
      console.log('üîê Starting Google Drive authentication...');

      // Step 1: Initiate OAuth flow
      const response = await fetch('http://localhost:8080/api/cloud/authenticate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        credentials: 'include', // üîß FIX: Include session cookies
        body: JSON.stringify({
          provider: 'google_drive',
          action: 'initiate_auth',
          redirect_uri: 'http://localhost:8080/api/cloud/oauth/callback' // üîß Explicit redirect
        })
      });

      if (!response.ok) {
        throw new Error(`Authentication request failed: ${response.status}`);
      }

      const authData = await response.json();

      if (!authData.success || !authData.auth_url) {
        throw new Error(authData.message || 'Failed to get authorization URL');
      }

      console.log('üåê Opening OAuth popup...', authData.auth_url);

      // Step 2: Open OAuth popup - IMPROVED with better error handling
      await handleOAuthPopup(authData.auth_url);

    } catch (error) {
      console.error('‚ùå Authentication error:', error);
      setAuthState(prev => ({
        ...prev,
        loading: false,
        error: error.message
      }));

      if (onAuth) {
        onAuth({
          success: false,
          message: error.message || 'Authentication failed'
        });
      }
    }
  };

  // üîß IMPROVED: Better popup handling with COOP workaround
  const handleOAuthPopup = async (authUrl) => {
    return new Promise((resolve, reject) => {
      const popup = window.open(
        authUrl,
        'google_drive_auth',
        'width=600,height=700,scrollbars=yes,resizable=yes,popup=yes'
      );

      if (!popup) {
        reject(new Error('Popup blocked. Please allow popups for this site.'));
        return;
      }

      let checkCompleted = false;

      // üÜï NEW: Use postMessage instead of polling popup.closed (COOP workaround)
      const handlePopupMessage = (event) => {
        if (event.origin !== 'http://localhost:8080') return;
        
        if (event.data.type === 'OAUTH_SUCCESS' || event.data.type === 'OAUTH_ERROR') {
          if (!checkCompleted) {
            checkCompleted = true;
            popup.close();
            window.removeEventListener('message', handlePopupMessage);
            resolve();
          }
        }
      };

      window.addEventListener('message', handlePopupMessage);

      // üîß FALLBACK: Still try to detect popup close, but with error handling
      const checkPopupClosed = () => {
        try {
          if (popup.closed) {
            if (!checkCompleted) {
              checkCompleted = true;
              window.removeEventListener('message', handlePopupMessage);
              
              // Wait a bit for any pending messages
              setTimeout(async () => {
                try {
                  await checkAuthResult();
                  resolve();
                } catch (error) {
                  reject(error);
                }
              }, 1000);
            }
            return;
          }
        } catch (error) {
          // COOP prevents access to popup.closed - this is expected
          console.log('üîí COOP prevents popup.closed check (this is normal)');
        }

        // Continue checking
        if (!checkCompleted) {
          setTimeout(checkPopupClosed, 1000);
        }
      };

      // Start checking after initial delay
      setTimeout(checkPopupClosed, 2000);

      // üîß TIMEOUT: Auto-timeout after 5 minutes
      setTimeout(() => {
        if (!checkCompleted) {
          checkCompleted = true;
          window.removeEventListener('message', handlePopupMessage);
          
          try {
            popup.close();
          } catch (e) {
            // Ignore close errors
          }
          
          reject(new Error('Authentication timeout (5 minutes)'));
        }
      }, 300000);
    });
  };

  // üîß IMPROVED: Better auth result checking with retry logic
  const checkAuthResult = async (maxRetries = 3) => {
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`üîç Checking auth result (attempt ${attempt}/${maxRetries})...`);
        
        const response = await fetch('http://localhost:8080/api/cloud/auth-status', {
          credentials: 'include', // üîß FIX: Include session cookies
          cache: 'no-cache'       // üîß FIX: Force fresh request
        });

        if (!response.ok) {
          throw new Error(`Auth status check failed: ${response.status}`);
        }

        const result = await response.json();
        
        if (result.success && result.authenticated) {
          console.log('‚úÖ Authentication confirmed:', result.user_email);
          
          setAuthState(prev => ({
            ...prev,
            loading: false,
            authenticated: true,
            userEmail: result.user_email,
            error: null
          }));

          if (onAuth) {
            onAuth({
              success: true,
              user_email: result.user_email,
              user_info: result.user_info,
              credentials: result.credentials,
              folders: result.folders || [],
              message: `Authenticated as ${result.user_email}`,
              existing_auth: result.existing_auth || false
            });
          }
          
          return;
        } else if (attempt === maxRetries) {
          throw new Error(result.message || 'No authentication found');
        } else {
          // Wait before retrying
          await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
        }
        
      } catch (error) {
        console.error(`‚ùå Auth status check failed (attempt ${attempt}):`, error);
        
        if (attempt === maxRetries) {
          throw error;
        } else {
          // Wait before retrying
          await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
        }
      }
    }
  };

  // üÜï NEW: Disconnect handler
  const handleDisconnect = async () => {
    try {
      setAuthState(prev => ({ ...prev, loading: true }));
      
      const response = await fetch('http://localhost:8080/api/cloud/disconnect', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        credentials: 'include',
        body: JSON.stringify({
          provider: 'google_drive',
          user_email: authState.userEmail
        })
      });

      const result = await response.json();
      
      if (result.success) {
        setAuthState({
          loading: false,
          authenticated: false,
          userEmail: null,
          error: null
        });

        if (onAuth) {
          onAuth({
            success: false,
            message: 'Disconnected from Google Drive',
            disconnected: true
          });
        }
      } else {
        throw new Error(result.message || 'Disconnect failed');
      }
      
    } catch (error) {
      console.error('‚ùå Disconnect error:', error);
      setAuthState(prev => ({ ...prev, loading: false, error: error.message }));
    }
  };

  // üîß Handle auth failure
  const handleAuthFailure = (message) => {
    console.error('‚ùå Google Drive authentication failed:', message);
    setAuthState(prev => ({
      ...prev,
      loading: false,
      authenticated: false,
      error: message
    }));
  };

  // Update state when props change
  useEffect(() => {
    setAuthState(prev => ({
      ...prev,
      loading: isLoading,
      authenticated: isAuthenticated,
      userEmail: userEmail
    }));
  }, [isLoading, isAuthenticated, userEmail]);

  // Component render
  return (
    <div className={`google-drive-auth-button ${className}`}>
      {!authState.authenticated ? (
        <div className="auth-section">
          <button
            onClick={handleAuthenticate}
            disabled={authState.loading}
            className={`px-6 py-3 rounded-lg font-medium transition-all duration-200 ${
              authState.loading
                ? 'bg-gray-400 text-gray-600 cursor-not-allowed'
                : 'bg-blue-600 hover:bg-blue-700 text-white shadow-lg hover:shadow-xl transform hover:scale-105'
            }`}
          >
            {authState.loading ? (
              <span className="flex items-center">
                <svg className="animate-spin -ml-1 mr-2 h-4 w-4 text-white" fill="none" viewBox="0 0 24 24">
                  <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                  <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                </svg>
                Authenticating...
              </span>
            ) : (
              <span className="flex items-center">
                üîê Connect to Google Drive
                <span className="ml-2 text-xs opacity-75">(Required)</span>
              </span>
            )}
          </button>
          
          <div className="mt-2 text-xs text-gray-400">
            Click to authenticate and access your Google Drive folders
          </div>
        </div>
      ) : (
        <div className="authenticated-section">
          <div className="flex items-center justify-between p-4 bg-green-100 border border-green-400 rounded-lg">
            <div className="flex items-center">
              <span className="text-2xl mr-3">‚úÖ</span>
              <div>
                <div className="font-medium text-green-800">
                  Connected to Google Drive
                </div>
                <div className="text-sm text-green-600">
                  {authState.userEmail}
                </div>
              </div>
            </div>
            
            <button
              onClick={handleDisconnect}
              disabled={authState.loading}
              className="px-3 py-1 bg-red-600 hover:bg-red-700 disabled:bg-gray-400 text-white rounded text-sm transition-colors"
            >
              {authState.loading ? 'Disconnecting...' : 'Disconnect'}
            </button>
          </div>
        </div>
      )}

      {/* Error Display */}
      {authState.error && (
        <div className="error-display mt-3 p-3 bg-red-100 border border-red-400 rounded-lg">
          <div className="flex items-center justify-between">
            <div className="text-red-700">
              <div className="font-medium">Authentication Error</div>
              <div className="text-sm mt-1">{authState.error}</div>
            </div>
            <button
              onClick={() => setAuthState(prev => ({ ...prev, error: null }))}
              className="text-red-500 hover:text-red-700 text-lg leading-none"
            >
              √ó
            </button>
          </div>

          {/* Error Actions */}
          <div className="mt-3 flex gap-2">
            <button
              onClick={handleAuthenticate}
              className="px-3 py-1 bg-blue-600 text-white rounded text-sm hover:bg-blue-700"
            >
              Try Again
            </button>
            <button
              onClick={() => window.location.reload()}
              className="px-3 py-1 bg-gray-600 text-white rounded text-sm hover:bg-gray-700"
            >
              Refresh Page
            </button>
          </div>
        </div>
      )}

      {/* Help Text */}
      {!authState.authenticated && !authState.error && (
        <div className="help-text mt-3 p-3 bg-blue-50 border border-blue-200 rounded-lg">
          <div className="text-sm text-blue-700">
            <div className="font-medium mb-1">üîí Secure Authentication</div>
            <ul className="text-xs space-y-1 ml-4">
              <li>‚Ä¢ Opens Google's official OAuth login</li>
              <li>‚Ä¢ VTrack never sees your Google password</li>
              <li>‚Ä¢ Only folder access permission requested</li>
              <li>‚Ä¢ Can be revoked anytime from Google Account settings</li>
            </ul>
          </div>
        </div>
      )}

      {/* Development Debug Info */}
      {process.env.NODE_ENV === 'development' && (
        <details className="debug-info mt-3 p-2 bg-gray-100 rounded text-xs">
          <summary className="cursor-pointer text-gray-600">üîß Debug Info</summary>
          <pre className="mt-2 text-gray-500 overflow-auto">
            {JSON.stringify({
              authenticated: authState.authenticated,
              loading: authState.loading,
              userEmail: authState.userEmail,
              hasError: !!authState.error,
              errorMessage: authState.error,
              backendPort: 8080
            }, null, 2)}
          </pre>
        </details>
      )}
    </div>
  );
};

export default GoogleDriveAuthButton;
```
## üìÑ File: `GoogleDrivePickerIntegration.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/GoogleDrivePickerIntegration.js`

```javascript
// src/components/config/GoogleDrivePickerIntegration.js
// Google Drive Picker Integration Component - Auto-Auth & Native Picker Interface
import React, { useState, useEffect, useCallback } from 'react';

const GoogleDrivePickerIntegration = ({
  onFoldersSelected,
  credentials = null,
  multiSelect = true,
  disabled = false,
  className = '',
  userEmail = null
}) => {
  // Component state
  const [pickerApiLoaded, setPickerApiLoaded] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState(null);
  const [selectedFolders, setSelectedFolders] = useState([]);
  const [pickerToken, setPickerToken] = useState(null);
  const [isAuthenticated, setIsAuthenticated] = useState(false);

  // Check if Google APIs are available
  useEffect(() => {
    const checkGoogleApis = () => {
      if (window.gapi) {
        // Load the Picker API
        window.gapi.load('picker', {
          callback: () => {
            setPickerApiLoaded(true);
            console.log('‚úÖ Google Picker API loaded successfully');
          },
          onerror: (error) => {
            console.error('‚ùå Failed to load Google Picker API:', error);
            setError('Failed to load Google Picker API. Please refresh the page.');
          }
        });
      } else {
        // Retry after a short delay if gapi not available yet
        setTimeout(checkGoogleApis, 1000);
      }
    };

    checkGoogleApis();
  }, []);

  // Auto-authenticate flow
  const authenticateUser = useCallback(async () => {
    try {
      setError(null);
      console.log('üîê Starting auto-authentication...');

      // Step 1: Initiate authentication
      const authResponse = await fetch('http://localhost:8080/api/cloud/authenticate', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          provider: 'google_drive',
          action: 'initiate_auth'
        })
      });

      if (!authResponse.ok) {
        throw new Error(`Auth initiation failed: ${authResponse.status}`);
      }

      const authResult = await authResponse.json();

      if (authResult.success && authResult.auth_url) {
        console.log('üåê Opening OAuth popup...');
        
        // Step 2: Open OAuth popup
        const popup = window.open(
          authResult.auth_url,
          'google_drive_auth',
          'width=600,height=700,scrollbars=yes,resizable=yes'
        );

        if (!popup) {
          throw new Error('Popup blocked. Please allow popups for this site.');
        }

        // Step 3: Wait for popup completion
        await new Promise((resolve, reject) => {
          const checkClosed = setInterval(() => {
            if (popup.closed) {
              clearInterval(checkClosed);
              resolve();
            }
          }, 1000);

          // Timeout after 5 minutes
          setTimeout(() => {
            clearInterval(checkClosed);
            if (!popup.closed) {
              popup.close();
            }
            reject(new Error('Authentication timeout'));
          }, 300000);
        });

        console.log('‚úÖ OAuth popup completed, checking auth status...');

        // Step 4: Check authentication result
        const statusResponse = await fetch('http://localhost:8080/api/cloud/auth-status');
        if (!statusResponse.ok) {
          throw new Error('Failed to check auth status');
        }

        const statusResult = await statusResponse.json();

        if (statusResult.success && statusResult.authenticated) {
          console.log('‚úÖ Authentication successful:', statusResult.user_email);
          setIsAuthenticated(true);
          return statusResult;
        } else {
          throw new Error(statusResult.message || 'Authentication failed');
        }

      } else {
        throw new Error(authResult.message || 'Auth initiation failed');
      }

    } catch (error) {
      console.error('‚ùå Authentication error:', error);
      setError(`Authentication failed: ${error.message}`);
      return null;
    }
  }, []);

  // Get Picker token from backend
  const getPickerToken = useCallback(async () => {
    try {
      setError(null);
      
      const response = await fetch('http://localhost:8080/api/cloud/picker-token', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          provider: 'google_drive',
          user_email: userEmail
        })
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.message || `HTTP ${response.status}`);
      }

      const tokenData = await response.json();
      
      if (!tokenData.success) {
        throw new Error(tokenData.message || 'Failed to get picker token');
      }

      console.log('‚úÖ Picker token obtained successfully');
      return tokenData.picker_token;
      
    } catch (error) {
      console.error('‚ùå Error getting picker token:', error);
      setError(`Failed to get access token: ${error.message}`);
      return null;
    }
  }, [userEmail]);

  // Create and configure Google Picker
  const createPicker = useCallback((accessToken) => {
    if (!window.google || !window.google.picker) {
      setError('Google Picker API not available');
      return null;
    }

    try {
    // Create picker builder
    const picker = new window.google.picker.PickerBuilder()
      .addView(window.google.picker.ViewId.FOLDERS)
      .setOAuthToken(accessToken)
      .setCallback(handlePickerCallback)
      .setTitle('Select Camera Folders from Google Drive')
      .setSize(800, 600);

    // Enable multiselect if requested
    if (multiSelect) {
      picker.enableFeature(window.google.picker.Feature.MULTISELECT_ENABLED);
    }

    // Enable navigation
    picker.enableFeature(window.google.picker.Feature.NAV_HIDDEN);

    console.log('‚úÖ Google Picker created successfully');
    return picker.build();
      
    } catch (error) {
      console.error('‚ùå Error creating picker:', error);
      setError(`Failed to create picker: ${error.message}`);
      return null;
    }
  }, [multiSelect]);

  // Handle picker callback
  const handlePickerCallback = useCallback((data) => {
    console.log('üîÑ Picker callback received:', data);
    
    if (data.action === window.google.picker.Action.PICKED) {
      try {
        const selectedDocs = data.docs || [];
        
        // Process selected folders
        const folders = selectedDocs.map(doc => ({
          id: doc.id,
          name: doc.name,
          url: doc.url,
          type: 'folder',
          mimeType: doc.mimeType,
          lastEditedUtc: doc.lastEditedUtc,
          iconUrl: doc.iconUrl,
          description: doc.description || '',
          sizeBytes: doc.sizeBytes || 0
        }));

        console.log(`‚úÖ Selected ${folders.length} folder(s):`, folders);
        
        setSelectedFolders(folders);
        setError(null);

        // Notify parent component
        if (onFoldersSelected) {
          onFoldersSelected(folders);
        }

      } catch (error) {
        console.error('‚ùå Error processing picker selection:', error);
        setError(`Failed to process selection: ${error.message}`);
      }
    } else if (data.action === window.google.picker.Action.CANCEL) {
      console.log('üö´ Picker cancelled by user');
      setError(null);
    } else {
      console.log('‚ÑπÔ∏è Picker action:', data.action);
    }
  }, [onFoldersSelected]);

  // Main function to open picker with auto-auth
  const openPickerWithAuth = useCallback(async () => {
    if (!pickerApiLoaded) {
      setError('Google Picker API is still loading. Please try again in a moment.');
      return;
    }

    setIsLoading(true);
    setError(null);

    try {
      console.log('üéØ Starting picker flow with auto-auth...');

      // Step 1: Try to get picker token (may fail if not authenticated)
      let token = await getPickerToken();
      
      if (!token) {
        console.log('üîê No token available, starting authentication...');
        
        // Step 2: Authenticate user if no token
        const authResult = await authenticateUser();
        if (!authResult) {
          setIsLoading(false);
          return;
        }

        // Step 3: Get token after authentication
        token = await getPickerToken();
        if (!token) {
          setError('Failed to get picker token after authentication');
          setIsLoading(false);
          return;
        }
      }

      setPickerToken(token);

      // Step 4: Create and show picker
      const picker = createPicker(token);
      
      if (picker) {
        console.log('üéØ Opening Google Drive Picker...');
        picker.setVisible(true);
      }

    } catch (error) {
      console.error('‚ùå Error in picker flow:', error);
      setError(`Failed to open picker: ${error.message}`);
    } finally {
      setIsLoading(false);
    }
  }, [pickerApiLoaded, getPickerToken, authenticateUser, createPicker]);

  // Clear error
  const clearError = () => {
    setError(null);
  };

  // Clear selected folders
  const clearSelection = () => {
    setSelectedFolders([]);
    if (onFoldersSelected) {
      onFoldersSelected([]);
    }
  };

  // Component render
  return (
    <div className={`google-drive-picker-integration ${className}`}>
      
      {/* Main Picker Button */}
      <div className="picker-controls mb-4">
        <button
          onClick={openPickerWithAuth}
          disabled={disabled || isLoading || !pickerApiLoaded}
          className={`px-6 py-3 rounded-lg font-medium transition-all duration-200 ${
            disabled || isLoading || !pickerApiLoaded
              ? 'bg-gray-400 text-gray-600 cursor-not-allowed'
              : 'bg-blue-600 hover:bg-blue-700 text-white shadow-lg hover:shadow-xl transform hover:scale-105'
          }`}
        >
          {isLoading ? (
            <span className="flex items-center">
              <svg className="animate-spin -ml-1 mr-2 h-4 w-4 text-white" fill="none" viewBox="0 0 24 24">
                <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
              </svg>
              {isAuthenticated ? 'Opening Picker...' : 'Authenticating...'}
            </span>
          ) : (
            <span className="flex items-center">
              üìÅ Browse Google Drive Folders
              {!pickerApiLoaded && (
                <span className="ml-2 text-xs opacity-75">(Loading...)</span>
              )}
            </span>
          )}
        </button>

        {/* Status Indicators */}
        <div className="mt-2 text-xs text-gray-400">
          <span className={`inline-block w-2 h-2 rounded-full mr-2 ${
            pickerApiLoaded ? 'bg-green-500' : 'bg-yellow-500'
          }`}></span>
          {pickerApiLoaded ? 'Picker API Ready' : 'Loading Picker API...'}
          
          {isAuthenticated && (
            <>
              <span className="inline-block w-2 h-2 rounded-full bg-green-500 mr-2 ml-4"></span>
              Google Drive Connected
            </>
          )}
        </div>
      </div>

      {/* Error Display */}
      {error && (
        <div className="error-display mb-4 p-4 bg-red-100 border border-red-400 rounded-lg">
          <div className="flex items-center justify-between">
            <div className="text-red-700">
              <div className="font-medium">‚ö†Ô∏è Error</div>
              <div className="text-sm mt-1">{error}</div>
            </div>
            <button
              onClick={clearError}
              className="text-red-500 hover:text-red-700 text-lg leading-none"
            >
              √ó
            </button>
          </div>
          
          {/* Error Actions */}
          <div className="mt-3 flex gap-2">
            <button
              onClick={() => window.location.reload()}
              className="px-3 py-1 bg-red-600 text-white rounded text-sm hover:bg-red-700"
            >
              Refresh Page
            </button>
            <button
              onClick={openPickerWithAuth}
              className="px-3 py-1 bg-blue-600 text-white rounded text-sm hover:bg-blue-700"
            >
              Try Again
            </button>
          </div>
        </div>
      )}

      {/* Selected Folders Display */}
      {selectedFolders.length > 0 && (
        <div className="selected-folders mb-4 p-4 bg-green-100 border border-green-400 rounded-lg">
          <div className="flex items-center justify-between mb-3">
            <h4 className="font-medium text-green-800">
              ‚úÖ Selected Folders ({selectedFolders.length})
            </h4>
            <button
              onClick={clearSelection}
              className="text-green-600 hover:text-green-800 text-sm"
            >
              Clear Selection
            </button>
          </div>
          
          <div className="space-y-2">
            {selectedFolders.map((folder, index) => (
              <div key={folder.id} className="flex items-center gap-3 p-2 bg-white rounded border">
                <span className="text-lg">üìÅ</span>
                <div className="flex-1 min-w-0">
                  <div className="font-medium text-gray-900 truncate">
                    {folder.name}
                  </div>
                  <div className="text-xs text-gray-500 truncate">
                    ID: {folder.id}
                  </div>
                </div>
                <div className="text-xs text-gray-400">
                  {folder.sizeBytes > 0 && (
                    <span>{(folder.sizeBytes / 1024 / 1024).toFixed(1)} MB</span>
                  )}
                </div>
              </div>
            ))}
          </div>

          <div className="mt-3 text-xs text-green-700">
            üí° These folders will be used as camera sources for VTrack video processing
          </div>
        </div>
      )}

      {/* Help Text */}
      {selectedFolders.length === 0 && !error && (
        <div className="help-text p-4 bg-blue-50 border border-blue-200 rounded-lg">
          <h4 className="font-medium text-blue-800 mb-2">üìñ How to use Google Drive Picker:</h4>
          <ul className="text-sm text-blue-700 space-y-1">
            <li>‚Ä¢ Click "Browse Google Drive Folders" to authenticate & open picker</li>
            <li>‚Ä¢ First time: Google login popup will appear automatically</li>
            <li>‚Ä¢ Select folders that contain your camera videos</li>
            <li>‚Ä¢ Use Ctrl/Cmd+Click to select multiple folders</li>
            <li>‚Ä¢ Selected folders will be synced to VTrack for processing</li>
          </ul>
        </div>
      )}

      {/* Debug Info (Development Only) */}
      {process.env.NODE_ENV === 'development' && (
        <details className="debug-info mt-4 p-3 bg-gray-100 rounded text-xs">
          <summary className="cursor-pointer text-gray-600">üîß Debug Info</summary>
          <pre className="mt-2 text-gray-500 overflow-auto">
            {JSON.stringify({
              pickerApiLoaded,
              isAuthenticated,
              isLoading,
              hasError: !!error,
              selectedCount: selectedFolders.length,
              hasToken: !!pickerToken,
              userEmail: userEmail || 'auto-detect',
              multiSelect,
              disabled
            }, null, 2)}
          </pre>
        </details>
      )}
    </div>
  );
};

export default GoogleDrivePickerIntegration;
```
## üìÑ File: `CloudSyncSettings.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/CloudSyncSettings.js`

```javascript
// components/config/CloudSyncSettings.js - Focused Sync Configuration
import React, { useState, useEffect } from 'react';

const CloudSyncSettings = ({ config, onChange }) => {
  // Default settings
  const defaultSettings = {
    interval_minutes: 15,
    auto_sync_enabled: true,
    // Hidden/Fixed settings (not shown in UI) - BEST defaults for amature users
    organize_by_date: true,       // Always organize by date - optimal structure
    backup_metadata: true,        // Always preserve metadata - safe approach
    sync_only_new: true,          // Always incremental sync - efficient
    skip_duplicates: true,        // Always skip duplicates - smart behavior
    duplicate_handling: 'compare_size', // Compare by size - best balance
    max_file_size_mb: 1000,       // 30-min video ~1GB at standard quality
    bandwidth_limit_mbps: 10,     // 10 Mbps reasonable for background sync
    file_types: ['.mp4', '.avi', '.mov', '.mkv', '.m4v']
  };

  // Local state
  const [settings, setSettings] = useState({ ...defaultSettings, ...config });
  const [localStorageWarning, setLocalStorageWarning] = useState(false);

  // Sync interval options - focused on practical camera recording frequencies
  const syncIntervals = [
    { value: 5, label: "5 minutes", description: "High-frequency cameras (security)" },
    { value: 15, label: "15 minutes", description: "Standard recording (recommended)" },
    { value: 30, label: "30 minutes", description: "Low-frequency cameras" },
    { value: 60, label: "1 hour", description: "Periodic recording" },
    { value: 180, label: "3 hours", description: "Daily batch cameras" },
    { value: 360, label: "6 hours", description: "Archive/backup mode" }
  ];

  // Check local storage periodically
  useEffect(() => {
    const checkLocalStorage = () => {
      try {
        // Check available disk space (simplified estimation)
        if (navigator.storage && navigator.storage.estimate) {
          navigator.storage.estimate().then(estimate => {
            const usedGB = (estimate.usage || 0) / (1024 ** 3);
            const quotaGB = (estimate.quota || 0) / (1024 ** 3);
            const freeSpaceGB = quotaGB - usedGB;
            
            // Warn if less than 5GB free space
            if (freeSpaceGB < 5) {
              setLocalStorageWarning(true);
            } else {
              setLocalStorageWarning(false);
            }
          });
        }
      } catch (error) {
        console.warn('Could not check storage:', error);
      }
    };

    checkLocalStorage();
    // Check every 5 minutes
    const interval = setInterval(checkLocalStorage, 5 * 60 * 1000);
    
    return () => clearInterval(interval);
  }, []);

  // Update settings and notify parent
  const updateSetting = (key, value) => {
    const newSettings = { ...settings, [key]: value };
    setSettings(newSettings);
    
    if (onChange) {
      onChange(newSettings);
    }
  };

  // Get interval description
  const getIntervalDescription = (minutes) => {
    const interval = syncIntervals.find(i => i.value === minutes);
    return interval ? interval.description : '';
  };

  return (
    <div className="space-y-4">
      
      {/* Local Storage Warning */}
      {localStorageWarning && (
        <div className="bg-yellow-800 border border-yellow-600 rounded-lg p-3">
          <div className="flex items-center gap-2">
            <span className="text-yellow-200">‚ö†Ô∏è</span>
            <div className="text-yellow-200 text-sm">
              <div className="font-medium">Low disk space detected</div>
              <div className="text-xs">Consider freeing up space to continue video sync</div>
            </div>
          </div>
        </div>
      )}

      {/* Sync Frequency */}
      <div className="bg-gray-700 rounded-lg p-4">
        <h4 className="font-medium text-white mb-3">‚è±Ô∏è Sync Frequency</h4>
        
        <div className="space-y-3">
          <div>
            <label className="block text-sm font-medium text-gray-300 mb-2">
              How often should VTrack check for new videos?
            </label>
            <select
              value={settings.interval_minutes}
              onChange={(e) => updateSetting('interval_minutes', parseInt(e.target.value))}
              className="w-full p-3 bg-gray-800 text-white rounded-lg border border-gray-600 focus:border-blue-500"
            >
              {syncIntervals.map(interval => (
                <option key={interval.value} value={interval.value}>
                  {interval.label} - {interval.description}
                </option>
              ))}
            </select>
          </div>
          
          <div className="text-xs text-gray-400 bg-gray-600 p-3 rounded">
            <div className="font-medium mb-1">üí° Sync Frequency Guide:</div>
            <div>‚Ä¢ <strong>5-15 minutes:</strong> Security cameras with frequent recording</div>
            <div>‚Ä¢ <strong>30-60 minutes:</strong> Dashcams, action cameras with periodic recording</div>
            <div>‚Ä¢ <strong>3-6 hours:</strong> Archive cameras or manual uploads</div>
          </div>
        </div>
      </div>

      {/* File Size Limits (Info Only) */}
      <div className="bg-gray-700 rounded-lg p-4">
        <h4 className="font-medium text-white mb-3">üìè File Size Limits</h4>
        
        <div className="space-y-2">
          <div className="flex justify-between text-sm">
            <span className="text-gray-300">Maximum file size:</span>
            <span className="text-white font-medium">{settings.max_file_size_mb} MB</span>
          </div>
          <div className="flex justify-between text-sm">
            <span className="text-gray-300">Supported formats:</span>
            <span className="text-white font-medium">MP4, AVI, MOV, MKV, M4V</span>
          </div>
          <div className="flex justify-between text-sm">
            <span className="text-gray-300">Background bandwidth:</span>
            <span className="text-white font-medium">{settings.bandwidth_limit_mbps} Mbps max</span>
          </div>
        </div>
        
        <div className="text-xs text-gray-400 bg-gray-600 p-3 rounded mt-3">
          <div className="font-medium mb-1">‚ÑπÔ∏è Automatic optimizations:</div>
          <div>‚Ä¢ Videos organized by date folders for easy browsing</div>
          <div>‚Ä¢ Original timestamps and camera info preserved</div>
          <div>‚Ä¢ Duplicate files automatically skipped (smart detection)</div>
          <div>‚Ä¢ Only new files downloaded (incremental sync)</div>
          <div>‚Ä¢ Bandwidth limited to {settings.bandwidth_limit_mbps} Mbps (background mode)</div>
        </div>
      </div>



      {/* Advanced Settings Summary */}
      <div className="bg-gray-800 border border-gray-600 rounded-lg p-4">
        <h4 className="font-medium text-gray-200 mb-3">‚öôÔ∏è Advanced Settings (Auto-Configured)</h4>
        
        <div className="grid grid-cols-2 gap-4 text-xs text-gray-400">
          <div>
            <div className="font-medium text-gray-300 mb-1">File Handling:</div>
            <div>‚Ä¢ Organize by date: {settings.organize_by_date ? 'Yes' : 'No'}</div>
            <div>‚Ä¢ Backup metadata: {settings.backup_metadata ? 'Yes' : 'No'}</div>
            <div>‚Ä¢ Sync only new: {settings.sync_only_new ? 'Yes' : 'No'}</div>
          </div>
          <div>
            <div className="font-medium text-gray-300 mb-1">Performance:</div>
            <div>‚Ä¢ Skip duplicates: {settings.skip_duplicates ? 'Yes' : 'No'}</div>
            <div>‚Ä¢ Duplicate method: {settings.duplicate_handling}</div>
            <div>‚Ä¢ Max file size: {settings.max_file_size_mb}MB</div>
          </div>
        </div>
        
        <div className="mt-3 text-xs text-gray-500">
          üí° These advanced settings are automatically optimized for Google Drive Picker workflow
        </div>
      </div>

      {/* Debug Info (Development) */}
      {process.env.NODE_ENV === 'development' && (
        <details className="bg-gray-800 rounded p-3">
          <summary className="text-xs text-gray-400 cursor-pointer">üîß Debug - Sync Settings</summary>
          <pre className="text-xs text-gray-400 mt-2 overflow-auto">
            {JSON.stringify(settings, null, 2)}
          </pre>
        </details>
      )}
    </div>
  );
};

export default CloudSyncSettings;
```
## üìÑ File: `ProcessingRegionForm.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/ProcessingRegionForm.js`

```javascript
import { useState, useEffect } from "react";
import api from "../../api";
import InstructionsPanel from "./InstructionsPanel";

const ProcessingRegionForm = ({ handleAnalyzeRegions }) => {
  const [videoPath, setVideoPath] = useState("");
  const [selectedVideoPath, setSelectedVideoPath] = useState("");
  const [error, setError] = useState("");
  const [analysisResult, setAnalysisResult] = useState(null);
  const [roiFramePath, setRoiFramePath] = useState("");
  const [showResultModal, setShowResultModal] = useState(false);
  const [cameraList, setCameraList] = useState([]);
  const [selectedCamera, setSelectedCamera] = useState("");
  const [processedCameras, setProcessedCameras] = useState([]);

  useEffect(() => {
    handleGetCameras();
  }, []);

  const handleFileSelect = (e) => {
    const file = e.target.files[0];
    if (file) {
      const path = file.path || file.name;
      setVideoPath(path);
      setSelectedVideoPath(path);
      setError("");
    } else {
      setVideoPath("");
      setSelectedVideoPath("");
    }
  };

  const handleGetCameras = async () => {
    try {
      const response = await api.get("/get-cameras");
      setCameraList(response.data.cameras || []);
      setError("");
    } catch (err) {
      setError("Kh√¥ng th·ªÉ l·∫•y danh s√°ch camera.");
    }
  };

  const handleSelectCamera = (camera) => {
    setSelectedCamera(camera);
    setVideoPath("");
    setSelectedVideoPath("");
    setError("");
  };

  const handleContinue = async () => {
    if (!videoPath && !selectedVideoPath) {
      setError("Vui l√≤ng ch·ªçn video baseline.");
      return;
    }
    if (!selectedCamera) {
      setError("Vui l√≤ng ch·ªçn m·ªôt camera.");
      return;
    }
    try {
      const response = await fetch('http://127.0.0.1:8080/run-select-roi', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ videoPath: selectedVideoPath || videoPath, cameraId: selectedCamera })
      });
      const result = await response.json();
      console.log("Result from run-select-roi:", result);
      if (result.success) {
        const newAnalysisResult = {
          success: true,
          message: result.message || "Hand detection completed successfully",
          roi: result.roi,
          hand_detected: result.hand_detected,
          roi_frame: result.roi_frame
        };
        console.log("Setting analysisResult in handleContinue:", newAnalysisResult);
        setAnalysisResult(newAnalysisResult);
        setRoiFramePath(result.roi_frame); // L∆∞u roiFramePath
        setShowResultModal(true);
      } else {
        setError(result.error || "Kh√¥ng th·ªÉ ch·∫°y hand detection.");
      }
    } catch (err) {
      setError("L·ªói khi ch·∫°y hand detection: " + err.message);
    }
  };

  const handleRetry = async () => {
    if (!selectedVideoPath && !videoPath) {
      setError("Vui l√≤ng ch·ªçn video baseline.");
      return;
    }
    try {
      const response = await fetch('http://127.0.0.1:8080/run-select-roi', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ videoPath: selectedVideoPath || videoPath, cameraId: selectedCamera })
      });
      const result = await response.json();
      console.log("Result from run-select-roi (retry):", result);
      if (result.success) {
        const newAnalysisResult = {
          success: true,
          message: result.message || "Hand detection completed successfully",
          roi: result.roi,
          hand_detected: result.hand_detected,
          roi_frame: result.roi_frame
        };
        console.log("Setting analysisResult in handleRetry:", newAnalysisResult);
        setAnalysisResult(newAnalysisResult);
        setRoiFramePath(result.roi_frame); // C·∫≠p nh·∫≠t roiFramePath v·ªõi file m·ªõi nh·∫•t
        setShowResultModal(true);
      } else {
        setError(result.error || "Kh√¥ng th·ªÉ ch·∫°y hand detection.");
      }
    } catch (err) {
      setError("L·ªói khi ch·∫°y hand detection: " + err.message);
    }
  };

  const handleRoisSubmit = (rois) => {
    setProcessedCameras((prev) => [...new Set([...prev, selectedCamera])]);
    setSelectedCamera("");
  };

  const handleContinueWithAnotherCamera = () => {
    setAnalysisResult(null);
    setRoiFramePath("");
    setShowResultModal(false);
    setSelectedCamera("");
    setVideoPath("");
    setSelectedVideoPath("");
    setError("");
  };

  const handleExit = () => {
    setShowResultModal(false);
    handleAnalyzeRegions({
      success: true,
      message: "ƒê√£ ho√†n t·∫•t x·ª≠ l√Ω c√°c camera.",
      processedCameras,
    });
  };

  return (
    <div className="w-[25%] bg-gray-800 p-6 rounded-lg flex flex-col">
      <h1 className="text-3xl font-bold mb-4">V√πng x·ª≠ l√Ω</h1>
      <p className="text-gray-300 mb-4">
        T·∫£i l√™n video baseline (5s-5 ph√∫t) ƒë·ªÉ x√°c ƒë·ªãnh c√°c v√πng x·ª≠ l√Ω QR v√† ƒë√≥ng g√≥i.
      </p>
      <div className="mb-4">
        <button
          onClick={handleGetCameras}
          className="w-full py-2 bg-blue-600 hover:bg-blue-700 text-white font-bold rounded"
        >
          L·∫•y danh s√°ch camera
        </button>
      </div>
      {cameraList && cameraList.length > 0 && (
        <div className="mb-4">
          <h3 className="text-lg font-bold mb-2">Ch·ªçn camera:</h3>
          <div className="max-h-24 overflow-y-auto">
            {cameraList.map((camera) => (
              <label key={camera} className="flex items-center mb-2">
                <input
                  type="radio"
                  name="camera"
                  className="mr-2"
                  checked={selectedCamera === camera}
                  onChange={() => handleSelectCamera(camera)}
                  disabled={processedCameras.includes(camera)}
                />
                {camera}
                {processedCameras.includes(camera) && (
                  <span className="ml-2 text-green-500">‚úî ƒê√£ x·ª≠ l√Ω</span>
                )}
              </label>
            ))}
          </div>
        </div>
      )}
      <div className="mb-4">
        <label className="block mb-1">Video baseline:</label>
        <div className="relative w-full">
          <input
            type="text"
            value={videoPath}
            onChange={(e) => {
              setVideoPath(e.target.value);
              setSelectedVideoPath(e.target.value);
            }}
            placeholder="Ch·ªçn video (e.g., /Users/annhu/vtrack_app/V_Track/baseline.mp4)"
            className="w-full p-2 rounded bg-gray-700 text-white"
          />
          <button
            type="button"
            onClick={() => {
              const input = document.createElement("input");
              input.type = "file";
              input.accept = "video/*";
              input.onchange = handleFileSelect;
              input.click();
            }}
            className="absolute right-2 top-1/2 transform -translate-y-1/2 text-white"
          >
            ...
          </button>
        </div>
      </div>
      {videoPath && selectedCamera && (
        <div className="mb-4 flex justify-center">
          <button
            onClick={handleContinue}
            className="py-2 px-4 bg-blue-600 hover:bg-blue-700 text-white font-bold rounded"
          >
            Ti·∫øp t·ª•c
          </button>
        </div>
      )}
      {showResultModal && analysisResult && (
        <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
          <div className="bg-gray-800 p-6 rounded-lg w-3/4 h-3/4 flex">
            <InstructionsPanel
              customInstruction={
                analysisResult.qr_detected
                  ? "Ti·∫øp t·ª•c x√°c ƒë·ªãnh v√πng trigger."
                  : "V·∫Ω l·∫°i v√πng m√£ v·∫≠n ƒë∆°n ho·∫∑c nh·∫•n Ti·∫øp t·ª•c ƒë·ªÉ ƒë·ªìng √Ω v·ªõi v√πng hi·ªán t·∫°i."
              }
              analysisResult={analysisResult}
              handDetected={analysisResult.hand_detected}
              qrDetected={analysisResult.qr_detected}
              onClose={handleExit}
              onSave={handleContinueWithAnotherCamera}
              onRetry={handleRetry}
              errorMessage={error}
              videoPath={selectedVideoPath || videoPath}
              cameraId={selectedCamera}
              onSubmit={handleRoisSubmit}
              setAnalysisResult={setAnalysisResult}
              roiFramePath={roiFramePath}
            />
          </div>
        </div>
      )}
      {error && (
        <div className="mb-4 text-red-500 text-sm">{error}</div>
      )}
    </div>
  );
};

export default ProcessingRegionForm;

```
## üìÑ File: `GoogleDrivePickerConfig.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/GoogleDrivePickerConfig.js`

```javascript
// src/config/GoogleDrivePickerConfig.js
// Centralized configuration for Google Drive Picker integration

export const PICKER_CONFIG = {
  // API Configuration
  api: {
    tokenEndpoint: 'http://localhost:8080/api/cloud/picker-token',
    provider: 'google_drive',
    retryAttempts: 3,
    retryDelay: 1000, // milliseconds
  },

  // Picker View Configuration
  views: {
    FOLDERS_ONLY: 'folders',
    FILES_AND_FOLDERS: 'all',
    RECENT: 'recent',
    SHARED: 'shared',
    STARRED: 'starred'
  },

  // Default Picker Settings
  picker: {
    title: 'Select Camera Folders from Google Drive',
    size: {
      width: 800,
      height: 600
    },
    defaultView: 'folders',
    multiSelect: true,
    navigation: {
      hidden: true,
      folderSelect: true
    }
  },

  // Feature Flags
  features: {
    MULTISELECT: 'multiselect',
    SEARCH: 'search',
    NAV_HIDDEN: 'nav_hidden',
    SIMPLE_UPLOAD: 'simple_upload',
    FOLDER_SELECT: 'folder_select'
  },

  // UI Text and Labels
  ui: {
    buttons: {
      browse: 'Browse Google Drive Folders',
      loading: 'Opening Picker...',
      retry: 'Try Again',
      refresh: 'Refresh Page',
      clear: 'Clear Selection'
    },
    status: {
      apiReady: 'Picker API Ready',
      apiLoading: 'Loading Picker API...',
      connected: 'Google Drive Connected',
      authenticating: 'Authenticating...',
      tokenExpired: 'Token Expired'
    },
    labels: {
      selectedFolders: 'Selected Folders',
      errorTitle: 'Error',
      helpTitle: 'How to use Google Drive Picker:',
      debugTitle: 'Debug Info'
    }
  },

  // Error Messages
  errors: {
    // Authentication Errors
    notAuthenticated: 'Please authenticate with Google Drive first',
    tokenFailed: 'Failed to get access token',
    tokenExpired: 'Access token has expired. Please re-authenticate.',
    
    // API Errors
    apiNotLoaded: 'Google Picker API is still loading. Please try again in a moment.',
    apiNotAvailable: 'Google Picker API not available',
    apiLoadFailed: 'Failed to load Google Picker API. Please refresh the page.',
    
    // Picker Errors
    pickerCreateFailed: 'Failed to create picker',
    pickerOpenFailed: 'Failed to open picker',
    selectionProcessFailed: 'Failed to process selection',
    
    // Network Errors
    networkError: 'Network error occurred. Please check your connection.',
    serverError: 'Server error occurred. Please try again later.',
    rateLimitExceeded: 'Too many requests. Please wait a moment and try again.',
    
    // Generic
    unknownError: 'An unexpected error occurred'
  },

  // Help Text
  help: {
    instructions: [
      'Click "Browse Google Drive Folders" to open the picker',
      'Select folders that contain your camera videos',
      'Use Ctrl/Cmd+Click to select multiple folders',
      'Selected folders will be synced to VTrack for processing',
      'You can change selection anytime by opening the picker again'
    ],
    tips: [
      'Organize your videos in separate folders for each camera',
      'Folder names should be descriptive (e.g., "Front_Door_Camera")',
      'Large folders may take longer to sync initially',
      'Only video files will be processed from selected folders'
    ]
  },

  // Styling Classes (Tailwind CSS)
  styles: {
    button: {
      primary: 'px-6 py-3 bg-blue-600 hover:bg-blue-700 text-white rounded-lg font-medium transition-all duration-200 shadow-lg hover:shadow-xl transform hover:scale-105',
      disabled: 'px-6 py-3 bg-gray-400 text-gray-600 cursor-not-allowed rounded-lg font-medium',
      loading: 'px-6 py-3 bg-blue-600 text-white rounded-lg font-medium cursor-wait'
    },
    status: {
      ready: 'inline-block w-2 h-2 rounded-full bg-green-500 mr-2',
      loading: 'inline-block w-2 h-2 rounded-full bg-yellow-500 mr-2',
      error: 'inline-block w-2 h-2 rounded-full bg-red-500 mr-2'
    },
    containers: {
      main: 'google-drive-picker-integration',
      error: 'error-display mb-4 p-4 bg-red-100 border border-red-400 rounded-lg',
      success: 'selected-folders mb-4 p-4 bg-green-100 border border-green-400 rounded-lg',
      help: 'help-text p-4 bg-blue-50 border border-blue-200 rounded-lg',
      folder: 'flex items-center gap-3 p-2 bg-white rounded border'
    }
  },

  // File Type Filters
  fileTypes: {
    folders: 'application/vnd.google-apps.folder',
    videos: [
      'video/mp4',
      'video/avi',
      'video/mov',
      'video/mkv',
      'video/wmv',
      'video/flv',
      'video/webm'
    ]
  },

  // Performance Settings
  performance: {
    apiLoadTimeout: 10000, // 10 seconds
    pickerTimeout: 30000,  // 30 seconds
    tokenRefreshInterval: 3300000, // 55 minutes (before 1 hour expiry)
    maxFoldersDisplay: 50,
    debounceDelay: 300 // milliseconds
  },

  // Development Settings
  development: {
    enableDebug: process.env.NODE_ENV === 'development',
    enableConsoleLogging: true,
    mockMode: false,
    debugLevel: 'info' // 'error', 'warn', 'info', 'debug'
  }
};

// Picker Builder Helper Functions
export const PICKER_BUILDERS = {
  /**
   * Create standard folders-only picker configuration
   */
  createFoldersOnlyBuilder: (token, callback, options = {}) => {
    const config = {
      ...PICKER_CONFIG.picker,
      ...options
    };

    return new window.google.picker.PickerBuilder()
      .addView(window.google.picker.ViewId.FOLDERS)
      .setOAuthToken(token)
      .setCallback(callback)
      .setTitle(config.title)
      .setSize(config.size.width, config.size.height);
  },

  /**
   * Add features to picker builder
   */
  addFeatures: (builder, features = []) => {
    const featureMap = {
      [PICKER_CONFIG.features.MULTISELECT]: window.google.picker.Feature.MULTISELECT_ENABLED,
      [PICKER_CONFIG.features.NAV_HIDDEN]: window.google.picker.Feature.NAV_HIDDEN,
      [PICKER_CONFIG.features.SIMPLE_UPLOAD]: window.google.picker.Feature.SIMPLE_UPLOAD_ENABLED
    };

    features.forEach(feature => {
      if (featureMap[feature]) {
        builder.enableFeature(featureMap[feature]);
      }
    });

    return builder;
  },

  /**
   * Create complete picker with default VTrack settings
   */
  createVTrackPicker: (token, callback, options = {}) => {
    const builder = PICKER_BUILDERS.createFoldersOnlyBuilder(token, callback, options);
    
    // Add default features
    const features = [
      PICKER_CONFIG.features.MULTISELECT,
      PICKER_CONFIG.features.NAV_HIDDEN
    ];
    
    return PICKER_BUILDERS.addFeatures(builder, features).build();
  }
};

// Utility Functions
export const PICKER_UTILS = {
  /**
   * Format folder data for consistent structure
   */
  formatFolderData: (docs) => {
    return docs.map(doc => ({
      id: doc.id,
      name: doc.name,
      url: doc.url || '',
      type: 'folder',
      mimeType: doc.mimeType,
      lastEditedUtc: doc.lastEditedUtc,
      iconUrl: doc.iconUrl || '',
      description: doc.description || '',
      sizeBytes: doc.sizeBytes || 0,
      selected: true,
      source: 'google_drive'
    }));
  },

  /**
   * Validate folder selection
   */
  validateSelection: (folders) => {
    if (!Array.isArray(folders)) {
      return { valid: false, error: 'Invalid folder selection format' };
    }

    if (folders.length === 0) {
      return { valid: false, error: 'No folders selected' };
    }

    if (folders.length > PICKER_CONFIG.performance.maxFoldersDisplay) {
      return { 
        valid: false, 
        error: `Too many folders selected. Maximum ${PICKER_CONFIG.performance.maxFoldersDisplay} allowed.` 
      };
    }

    return { valid: true, error: null };
  },

  /**
   * Get error message by type
   */
  getErrorMessage: (errorType, customMessage = '') => {
    return PICKER_CONFIG.errors[errorType] || customMessage || PICKER_CONFIG.errors.unknownError;
  },

  /**
   * Check if API is ready
   */
  isApiReady: () => {
    return !!(window.gapi && window.google && window.google.picker);
  },

  /**
   * Generate unique picker ID
   */
  generatePickerId: () => {
    return `picker_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }
};

// Export default configuration
export default PICKER_CONFIG;
```
## üìÑ File: `AddSourceModal.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/AddSourceModal.js`

```javascript
// components/config/AddSourceModal.js - Drive API Simple Approach
import React, { useState } from 'react';
import CloudConfigurationForm from './CloudConfigurationForm';
import GoogleDriveAuthButton from './GoogleDriveAuthButton';
import CloudSyncSettings from './CloudSyncSettings';
import GoogleDriveFolderTree from './GoogleDriveFolderTree';

const AddSourceModal = ({ show, onClose, onAdd, testSourceConnection }) => {
 const [sourceType, setSourceType] = useState('local');
 const [path, setPath] = useState('');
 const [config, setConfig] = useState({});
 const [isLoading, setIsLoading] = useState(false);
 const [testResult, setTestResult] = useState(null);
 
 // üÜï NVR-specific states
 const [nvrCameras, setNvrCameras] = useState([]);
 const [selectedNvrCameras, setSelectedNvrCameras] = useState([]);
 const [isDiscoveringCameras, setIsDiscoveringCameras] = useState(false);

 // üÜï Cloud-specific states
 const [cloudAuthenticated, setCloudAuthenticated] = useState(false);
 const [authLoading, setAuthLoading] = useState(false);
 const [availableFolders, setAvailableFolders] = useState([]); // Keep for compatibility
 const [selectedFolders, setSelectedFolders] = useState([]); // Now handled by tree component
 const [treeFoldersSelected, setTreeFoldersSelected] = useState([]); // New: Tree selection

 const generateSourceName = (path, sourceType) => {
   if (!path) return '';
   
   if (sourceType === 'nvr') {
     // Extract hostname or IP from URL
     try {
       const url = new URL(path.startsWith('http') ? path : `http://${path}`);
       const hostname = url.hostname || path;
       return `nvr_${hostname.replace(/\./g, '_')}`;
     } catch {
       const cleanPath = path.replace(/[^\w\d]/g, '_');
       return `nvr_${cleanPath}`;
     }
   } else if (sourceType === 'cloud') {
     // Cloud source name based on selected folders
     const provider = config.provider || 'google_drive';
     const folderName = selectedFolders.length > 0 ? 'multiple_folders' : 'cloud_storage';
     return `${provider}_${folderName.replace(/[^\w\d]/g, '_')}`;
   } else {
     const folderName = path.split('/').pop() || path.split('\\').pop() || 'source';
     return `${sourceType}_${folderName}`;
   }
 };

 const resetForm = () => {
   setSourceType('local');
   setPath('');
   setConfig({});
   setTestResult(null);
   setNvrCameras([]);
   setSelectedNvrCameras([]);
   // Reset cloud states
   setCloudAuthenticated(false);
   setAvailableFolders([]);
   setSelectedFolders([]);
   setTreeFoldersSelected([]);
 };

 // üîß Enhanced validation for NVR (ZM credentials optional)
 const validateNvrConfig = () => {
   if (!config.url) {
     return { valid: false, message: 'Please enter NVR address first' };
   }
   
   // For ZoneMinder, credentials are optional
   if (config.protocol === 'zoneminder') {
     return { valid: true, message: 'Ready to test (ZM auth optional)' };
   }
   
   // For other protocols, credentials required
   if (!config.username || !config.password) {
     return { valid: false, message: 'Please fill in username and password for this protocol' };
   }
   
   return { valid: true, message: 'Ready to test' };
 };

 // üÜï Google Drive Authentication Handler
 const handleGoogleDriveAuth = async (authResult) => {
   if (authResult.success) {
     setCloudAuthenticated(true);
     
     setConfig(prev => ({
       ...prev,
       provider: 'google_drive',
       credentials: authResult.credentials,
       user_email: authResult.user_email
     }));

     // Store root folders for tree initialization (lazy loading enabled)
      if (authResult.lazy_loading_enabled) {
        console.log('‚úÖ Lazy loading tree enabled');
        // Root folders will be handled by GoogleDriveFolderTree component
      } else if (authResult.folders && authResult.folders.length > 0) {
        setAvailableFolders(authResult.folders);
      }
     
   }
 };

 // üÜï Folder Selection Handler
 const handleFolderToggle = (folder) => {
   setSelectedFolders(prev => {
     const isSelected = prev.some(f => f.id === folder.id);
     if (isSelected) {
       return prev.filter(f => f.id !== folder.id);
     } else {
       return [...prev, folder];
     }
   });
 };

 // üÜï Select All/None Handlers
 const handleSelectAllFolders = () => {
   setSelectedFolders([...availableFolders]);
 };

 const handleDeselectAllFolders = () => {
   setSelectedFolders([]);
 };

 const handleTreeFolderSelection = (selectedTreeFolders) => {
  setTreeFoldersSelected(selectedTreeFolders);
  console.log(`üìÅ Tree selection updated: ${selectedTreeFolders.length} folders`);
 };

 // üÜï Cloud Sync Settings Handler
 const handleCloudSyncSettings = (syncConfig) => {
   setConfig(prev => ({
     ...prev,
     sync_settings: syncConfig
   }));
 };

 const handleTestConnection = async () => {
   if (sourceType === 'local' && !path) {
     alert('Please enter a path first');
     return;
   }

   if (sourceType === 'nvr') {
     const validation = validateNvrConfig();
     if (!validation.valid) {
       alert(validation.message);
       return;
     }
   }

   setIsLoading(true);
   setIsDiscoveringCameras(true);
   setTestResult(null);
   setNvrCameras([]);
   
   try {
     const testData = {
       source_type: sourceType,
       path: sourceType === 'local' ? path : config.url,
       config: sourceType === 'nvr' ? {
         ...config,
         protocol: config.protocol || 'zoneminder',
         username: config.username || '',
         password: config.password || ''
       } : config
     };

     const response = await testSourceConnection(testData);
     
     setTestResult({
       success: response.accessible,
       message: response.message
     });

     // Handle NVR camera discovery
     if (response.accessible && sourceType === 'nvr' && response.cameras) {
       setNvrCameras(response.cameras);
       setSelectedNvrCameras(response.cameras.map(cam => cam.name || cam.id || `Camera ${response.cameras.indexOf(cam) + 1}`));
       
       setTestResult(prev => ({
         ...prev,
         message: `${prev.message} - Found ${response.cameras.length} camera(s)`
       }));
     }
     
   } catch (error) {
     setTestResult({
       success: false,
       message: error.message || 'Connection test failed'
     });
   } finally {
     setIsLoading(false);
     setIsDiscoveringCameras(false);
   }
 };

 // NVR Camera Selection Handler
 const handleNvrCameraToggle = (cameraName) => {
   setSelectedNvrCameras(prev => 
     prev.includes(cameraName) 
       ? prev.filter(name => name !== cameraName)
       : [...prev, cameraName]
   );
 };

 const handleSubmit = (e) => {
   e.preventDefault();
   
   if (sourceType === 'local' && !path) {
     alert('Please enter a path');
     return;
   }
   
   if (sourceType === 'nvr') {
     const validation = validateNvrConfig();
     if (!validation.valid) {
       alert(validation.message);
       return;
     }
   }

   // üÜï Cloud submission validation - SIMPLIFIED
   if (sourceType === 'cloud') {
     if (!cloudAuthenticated) {
       alert('Please authenticate with Google Drive first');
       return;
     }
     if (treeFoldersSelected.length === 0) {
       alert('Please select at least one folder to monitor');
       return;
     }
   }

   const autoName = generateSourceName(
     sourceType === 'local' ? path : 
     sourceType === 'cloud' ? `google_drive://selected_folders` :
     config.url || 'nvr', 
     sourceType
   );

   const newSource = {
     source_type: sourceType,
     name: autoName,
     path: sourceType === 'local' ? path : 
           sourceType === 'cloud' ? `google_drive://selected_folders` :
           config.url,
     config: sourceType === 'nvr' ? {
       ...config,
       protocol: config.protocol || 'zoneminder',
       username: config.username || '',
       password: config.password || '',
       detected_cameras: nvrCameras,
       selected_cameras: selectedNvrCameras
     } : sourceType === 'cloud' ? {
       ...config,
       provider: 'google_drive',
       selected_folders: [...selectedFolders, ...treeFoldersSelected], // Combine both selections
       selected_tree_folders: treeFoldersSelected, // Store tree selections separately
       legacy_folders: selectedFolders, // Keep legacy for compatibility
       sync_settings: config.sync_settings || {
         interval_minutes: 15,
         auto_sync_enabled: true,
         sync_only_new: true,
         skip_duplicates: true
       }
     } : {}
   };

   onAdd(newSource);
   resetForm();
   onClose();
 };

 if (!show) return null;

 return (
   <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
     <div className="bg-gray-800 rounded-lg p-6 w-full max-w-4xl mx-4 max-h-[90vh] overflow-y-auto">
       <div className="flex justify-between items-center mb-6">
         <h3 className="text-xl font-bold text-white">Add New Video Source</h3>
         <button
           onClick={onClose}
           className="text-gray-400 hover:text-white text-2xl"
         >
           √ó
         </button>
       </div>

       <form onSubmit={handleSubmit}>
         {/* Source Type Cards */}
         <div className="grid grid-cols-1 lg:grid-cols-3 gap-4 mb-6">
           
           {/* Local Storage Card */}
           <div 
             className={`border-2 rounded-lg p-4 cursor-pointer transition-all ${
               sourceType === 'local' 
                 ? 'border-blue-500 bg-blue-900' 
                 : 'border-gray-600 bg-gray-700 hover:border-gray-500'
             }`}
             onClick={() => setSourceType('local')}
           >
             <div className="flex items-center mb-3">
               <span className="text-3xl mr-3">üìÅ</span>
               <div>
                 <h4 className="font-semibold text-white text-lg">Browse Files Directly</h4>
                 <p className="text-sm text-gray-300">Access folders containing videos</p>
               </div>
             </div>
             <div className="text-xs text-gray-400 leading-relaxed">
               ‚Ä¢ Local server folders<br/>
               ‚Ä¢ Mounted network drives (NAS, SMB, NFS)<br/>
               ‚Ä¢ Mounted NVR file shares<br/>
               ‚Ä¢ Any accessible folder path<br/>
               <span className="text-yellow-300 font-medium">üìç Mount network sources first</span>
             </div>
           </div>

           {/* NVR/DVR Card */}
           <div 
             className={`border-2 rounded-lg p-4 cursor-pointer transition-all ${
               sourceType === 'nvr' 
                 ? 'border-blue-500 bg-blue-900' 
                 : 'border-gray-600 bg-gray-700 hover:border-gray-500'
             }`}
             onClick={() => setSourceType('nvr')}
           >
             <div className="flex items-center mb-3">
               <span className="text-3xl mr-3">üîó</span>
               <div>
                 <h4 className="font-semibold text-white text-lg">Connect & Auto-Download</h4>
                 <p className="text-sm text-gray-300">Direct NVR/DVR camera discovery</p>
               </div>
             </div>
             <div className="text-xs text-gray-400 leading-relaxed">
               ‚Ä¢ NVR/DVR systems (ONVIF)<br/>
               ‚Ä¢ IP Camera networks (RTSP)<br/>
               ‚Ä¢ Security management platforms<br/>
               ‚Ä¢ Auto-discover cameras<br/>
               <span className="text-green-300 font-medium">üîÑ Real-time camera detection</span>
             </div>
           </div>

           {/* üÜï Cloud Storage Card - SIMPLIFIED */}
           <div 
             className={`border-2 rounded-lg p-4 cursor-pointer transition-all ${
               sourceType === 'cloud' 
                 ? 'border-blue-500 bg-blue-900' 
                 : 'border-gray-600 bg-gray-700 hover:border-gray-500'
             }`}
             onClick={() => setSourceType('cloud')}
           >
             <div className="flex items-center mb-3">
               <span className="text-3xl mr-3">‚òÅÔ∏è</span>
               <div>
                 <h4 className="font-semibold text-white text-lg">Google Drive Integration</h4>
                 <p className="text-sm text-gray-300">Sync videos from cloud storage</p>
               </div>
             </div>
             <div className="text-xs text-gray-400 leading-relaxed">
               ‚Ä¢ Google Drive camera folders<br/>
               ‚Ä¢ Auto-sync new recordings<br/>
               ‚Ä¢ Simple folder selection<br/>
               ‚Ä¢ Background download to server<br/>
               <span className="text-green-300 font-medium">‚úÖ Simplified & Reliable!</span>
             </div>
           </div>
         </div>

         {/* Local Files Form */}
         {sourceType === 'local' && (
           <div className="bg-gray-700 rounded-lg p-6 mb-6">
             <h4 className="font-semibold text-white mb-4 text-lg">üìÅ Browse Files Directly Configuration</h4>
             
             <div className="bg-yellow-800 border border-yellow-600 rounded-lg p-4 mb-6">
               <div className="text-yellow-200">
                 <div className="font-semibold mb-2">üìç Network Storage Setup Guide:</div>
                 <div className="text-sm mb-2">For network sources (NAS, NVR file shares), mount them first:</div>
                 <div className="font-mono text-xs bg-black bg-opacity-30 p-2 rounded">
                   # SMB Example (NAS/NVR):<br/>
                   mount -t smbfs //server/share /mnt/folder<br/><br/>
                   # NFS Example:<br/>
                   mount -t nfs server:/export /mnt/folder
                 </div>
               </div>
             </div>

             <div className="mb-4">
               <label className="block text-sm font-medium text-gray-300 mb-2">
                 Folder Path *
               </label>
               <input
                 type="text"
                 value={path}
                 onChange={(e) => setPath(e.target.value)}
                 placeholder="/Users/videos or /mnt/nas-storage or /mnt/nvr-files"
                 className="w-full p-3 border border-gray-600 rounded-lg bg-gray-800 text-white text-sm"
                 required
               />
               <div className="text-xs text-gray-400 mt-2">
                 Local path or mounted network folder containing camera subfolders
               </div>
             </div>

             {path && (
               <div className="bg-gray-600 p-4 rounded-lg">
                 <div className="text-xs text-gray-400 mb-1">Auto-generated source name:</div>
                 <div className="text-lg text-white font-medium">{generateSourceName(path, sourceType)}</div>
               </div>
             )}
           </div>
         )}

         {/* NVR/DVR Form */}
         {sourceType === 'nvr' && (
           <div className="bg-gray-700 rounded-lg p-6 mb-6">
             <h4 className="font-semibold text-white mb-4 text-lg">üîó NVR/DVR Connection Configuration</h4>

             {/* Protocol & URL Row */}
             <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
               <div>
                 <label className="block text-sm font-medium text-gray-300 mb-2">
                   Protocol *
                 </label>
                 <select
                   value={config.protocol || 'zoneminder'}
                   onChange={(e) => setConfig(prev => ({...prev, protocol: e.target.value}))}
                   className="w-full p-3 border border-gray-600 rounded-lg bg-gray-800 text-white"
                   required
                 >
                   <option value="zoneminder">ZoneMinder API (Open Source NVR)</option>
                   <option value="onvif">ONVIF (Universal Standard)</option>
                   <option value="rtsp">RTSP Direct Stream</option>
                   <option value="hikvision">Hikvision API</option>
                   <option value="dahua">Dahua API</option>
                   <option value="generic">Generic HTTP API</option>
                 </select>
               </div>

               <div>
                 <label className="block text-sm font-medium text-gray-300 mb-2">
                   NVR/DVR Address *
                 </label>
                 <input
                   type="text"
                   value={config.url || ''}
                   onChange={(e) => setConfig(prev => ({...prev, url: e.target.value}))}
                   placeholder="localhost:5050 or 192.168.1.100:8080"
                   className="w-full p-3 border border-gray-600 rounded-lg bg-gray-800 text-white"
                   required
                 />
               </div>
             </div>

             {/* Credentials Section */}
             <div className="grid grid-cols-1 md:grid-cols-2 gap-6 mb-6">
               <div>
                 <label className="block text-sm font-medium text-gray-300 mb-2">
                   Username {config.protocol === 'zoneminder' ? '(Optional)' : '*'}
                 </label>
                 <input
                   type="text"
                   value={config.username || ''}
                   onChange={(e) => setConfig(prev => ({...prev, username: e.target.value}))}
                   placeholder={config.protocol === 'zoneminder' ? 'admin (leave blank if no auth)' : 'admin'}
                   className="w-full p-3 border border-gray-600 rounded-lg bg-gray-800 text-white"
                   required={config.protocol !== 'zoneminder'}
                 />
               </div>

               <div>
                 <label className="block text-sm font-medium text-gray-300 mb-2">
                   Password {config.protocol === 'zoneminder' ? '(Optional)' : '*'}
                 </label>
                 <input
                   type="password"
                   value={config.password || ''}
                   onChange={(e) => setConfig(prev => ({...prev, password: e.target.value}))}
                   placeholder={config.protocol === 'zoneminder' ? '‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢  (leave blank if no auth)' : '‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢'}
                   className="w-full p-3 border border-gray-600 rounded-lg bg-gray-800 text-white"
                   required={config.protocol !== 'zoneminder'}
                 />
               </div>
             </div>

             {/* Discovered Cameras Section */}
             {testResult?.success && nvrCameras.length > 0 && (
               <div className="mb-6">
                 <div className="flex items-center justify-between mb-3">
                   <h5 className="font-medium text-white">üìπ Discovered Cameras ({nvrCameras.length})</h5>
                 </div>
                 <div className="flex gap-2 mb-2">
                   <button
                     type="button"
                     onClick={() => setSelectedNvrCameras(nvrCameras.map(cam => cam.name || cam.id || `Camera ${nvrCameras.indexOf(cam) + 1}`))}
                     className="px-3 py-1 bg-blue-600 text-white rounded text-xs"
                   >
                     Select All
                   </button>
                   <button
                     type="button"
                     onClick={() => setSelectedNvrCameras([])}
                     className="px-3 py-1 bg-gray-600 text-white rounded text-xs"
                   >
                     Deselect All
                   </button>
                 </div>
                 
                 <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-3 p-4 bg-gray-600 rounded-lg max-h-48 overflow-y-auto">
                   {nvrCameras.map((camera, index) => {
                     const cameraName = camera.name || camera.id || `Camera ${index + 1}`;
                     
                     return (
                       <label 
                         key={cameraName}
                         className="flex items-start space-x-3 p-2 bg-gray-700 rounded cursor-pointer hover:bg-gray-650"
                       >
                         <input
                           type="checkbox"
                           checked={selectedNvrCameras.includes(cameraName)}
                           onChange={() => handleNvrCameraToggle(cameraName)}
                           className="mt-1"
                         />
                         <div className="flex-1 min-w-0">
                           <div className="text-white text-sm font-medium truncate">
                             {cameraName}
                           </div>
                           {camera.stream_url && (
                             <div className="text-xs text-gray-400 truncate">
                               Stream: {camera.stream_url}
                             </div>
                           )}
                         </div>
                       </label>
                     );
                   })}
                 </div>
               </div>
             )}

             {/* Source Name Preview */}
             {config.url && (
               <div className="bg-gray-600 p-4 rounded-lg">
                 <div className="text-xs text-gray-400 mb-1">Auto-generated source name:</div>
                 <div className="text-lg text-white font-medium">{generateSourceName(config.url, sourceType)}</div>
               </div>
             )}
           </div>
         )}

         {/* üÜï Cloud Storage Form - SIMPLIFIED */}
         {sourceType === 'cloud' && (
           <div className="bg-gray-700 rounded-lg p-6 mb-6">
             <h4 className="font-semibold text-white mb-4 text-lg">‚òÅÔ∏è Google Drive Integration Configuration</h4>
             
             {/* Step 1: Authentication */}
             <div className="mb-6">
               <h5 className="font-medium text-white mb-3">Step 1: Authenticate with Google Drive</h5>
               <GoogleDriveAuthButton 
                 onAuth={handleGoogleDriveAuth}
                 isAuthenticated={cloudAuthenticated}
                 isLoading={authLoading}
                 userEmail={config?.user_email}
               />
             </div>

              {/* Step 2: Folder Selection */}
              {cloudAuthenticated && (
                <div className="mb-6">
                  <h5 className="font-medium text-white mb-3">Step 2: Navigate & Select Camera Folders</h5>
                  
                  <GoogleDriveFolderTree
                    credentials={config?.credentials}
                    onFoldersSelected={handleTreeFolderSelection}
                    maxDepth={4}
                    selectableDepth={4}
                    className="border border-gray-600 rounded-lg"
                  />
                </div>
              )}

             {/* Step 3: Sync Settings */}
             {cloudAuthenticated && treeFoldersSelected.length > 0 && (
               <div className="mb-6">
                 <h5 className="font-medium text-white mb-3">Step 3: Configure Sync Settings</h5>
                 <CloudSyncSettings
                   config={config.sync_settings || {
                     interval_minutes: 15,
                     auto_sync_enabled: true,
                     sync_only_new: true,
                     skip_duplicates: true
                   }}
                   onChange={handleCloudSyncSettings}
                 />
               </div>
             )}

             {/* Source Name Preview */}
             {treeFoldersSelected.length > 0 && (
               <div className="bg-gray-600 p-4 rounded-lg">
                 <div className="text-xs text-gray-400 mb-1">Auto-generated source name:</div>
                 <div className="text-lg text-white font-medium">{generateSourceName(`google_drive://selected_folders`, sourceType)}</div>
                 <div className="text-xs text-gray-400 mt-2">
                    {treeFoldersSelected.length} folders selected for monitoring
                  </div>
               </div>
             )}
           </div>
         )}

         {/* Test Connection - CH·ªà CHO LOCAL/NVR */}
         {(sourceType === 'local' || sourceType === 'nvr') && (
           <div className="mb-6">
             <button
               type="button"
               onClick={handleTestConnection}
               disabled={isLoading || 
                 (sourceType === 'local' && !path) || 
                 (sourceType === 'nvr' && !validateNvrConfig().valid)
               }
               className="bg-yellow-600 hover:bg-yellow-700 disabled:bg-gray-600 text-white px-6 py-3 rounded-lg font-medium mr-4"
             >
               {isLoading ? (
                 <span className="flex items-center">
                   <svg className="animate-spin -ml-1 mr-2 h-4 w-4 text-white" fill="none" viewBox="0 0 24 24">
                     <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
                     <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                   </svg>
                   {sourceType === 'nvr' ? 'Discovering Cameras...' : 'Testing...'}
                 </span>
               ) : (
                 'Test Connection'
               )}
             </button>
             
             {testResult && (
               <div className={`inline-block p-4 rounded-lg text-sm ${
                 testResult.success 
                   ? 'bg-green-800 text-green-200 border border-green-600' 
                   : 'bg-red-800 text-red-200 border border-red-600'
               }`}>
                 <div className="font-medium mb-1">
                   {testResult.success ? '‚úÖ Connection Successful' : '‚ùå Connection Failed'}
                 </div>
                 <div>{testResult.message}</div>
               </div>
             )}
           </div>
         )}

         {/* Action Buttons - UPDATED CONDITIONS */}
         <div className="flex gap-4 pt-4 border-t border-gray-600">
           <button
             type="submit"
             disabled={
               (sourceType === 'local' && !path) ||
               (sourceType === 'nvr' && !testResult?.success) ||
               (sourceType === 'cloud' && (!cloudAuthenticated || treeFoldersSelected.length === 0))
             }
             className="bg-blue-600 hover:bg-blue-700 disabled:bg-gray-600 disabled:cursor-not-allowed text-white px-8 py-3 rounded-lg font-medium flex-1"
           >
             Add Source
           </button>
           <button
             type="button"
             onClick={() => {
               resetForm();
               onClose();
             }}
             className="bg-gray-600 hover:bg-gray-700 text-white px-8 py-3 rounded-lg font-medium flex-1"
           >
             Cancel
           </button>
         </div>
       </form>
     </div>
   </div>
 );
};

export default AddSourceModal;
```
## üìÑ File: `GoogleDriveFolderTree.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/GoogleDriveFolderTree.js`

```javascript
// components/config/GoogleDriveFolderTree.js - Fixed Selection UI
import React, { useState, useEffect, useCallback } from 'react';

const GoogleDriveFolderTree = ({ 
  credentials, 
  onFoldersSelected, 
  maxDepth = 4, 
  selectableDepth = 4,
  className = ''
}) => {
  // Tree state management
  const [treeData, setTreeData] = useState({});
  const [expandedFolders, setExpandedFolders] = useState(new Set(['root']));
  const [selectedFolders, setSelectedFolders] = useState([]);
  const [loadingFolders, setLoadingFolders] = useState(new Set());
  const [error, setError] = useState(null);
  const [breadcrumb, setBreadcrumb] = useState([]);

  // Initialize with root folders
  useEffect(() => {
    if (credentials) {
      loadRootFolders();
    }
  }, [credentials]);

  // Notify parent when selection changes
  useEffect(() => {
    if (onFoldersSelected) {
      onFoldersSelected(selectedFolders);
    }
  }, [selectedFolders, onFoldersSelected]);

  const loadRootFolders = async () => {
    try {
      setLoadingFolders(prev => new Set([...prev, 'root']));
      setError(null);

      const response = await fetch('http://localhost:8080/api/cloud/folders/list_subfolders', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        credentials: 'include',
        body: JSON.stringify({
          parent_id: 'root',
          max_results: 50
        })
      });

      if (!response.ok) {
        throw new Error(`Failed to load root folders: ${response.status}`);
      }

      const data = await response.json();

      if (!data.success) {
        throw new Error(data.message || 'Failed to load root folders');
      }

      // Initialize tree with root data
      setTreeData({
        'root': {
          id: 'root',
          name: 'My Drive',
          depth: 0,
          selectable: false,
          has_subfolders: true,
          children: data.folders,
          loaded: true
        }
      });

      console.log(`‚úÖ Loaded ${data.folders.length} root folders`);

    } catch (error) {
      console.error('‚ùå Error loading root folders:', error);
      setError(error.message);
    } finally {
      setLoadingFolders(prev => {
        const next = new Set(prev);
        next.delete('root');
        return next;
      });
    }
  };

  const loadSubfolders = async (parentId) => {
    try {
      setLoadingFolders(prev => new Set([...prev, parentId]));
      setError(null);

      const response = await fetch('http://localhost:8080/api/cloud/folders/list_subfolders', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        credentials: 'include',
        body: JSON.stringify({
          parent_id: parentId,
          max_results: 50
        })
      });

      if (!response.ok) {
        throw new Error(`Failed to load subfolders: ${response.status}`);
      }

      const data = await response.json();

      if (!data.success) {
        throw new Error(data.message || 'Failed to load subfolders');
      }

      // Update tree data
      setTreeData(prev => ({
        ...prev,
        [parentId]: {
          ...prev[parentId],
          children: data.folders,
          loaded: true
        }
      }));

      console.log(`‚úÖ Loaded ${data.folders.length} subfolders for ${parentId}`);

    } catch (error) {
      console.error(`‚ùå Error loading subfolders for ${parentId}:`, error);
      setError(error.message);
    } finally {
      setLoadingFolders(prev => {
        const next = new Set(prev);
        next.delete(parentId);
        return next;
      });
    }
  };

  const handleFolderExpand = useCallback(async (event, folder) => {
    // üîß FIX: Stop event propagation to prevent triggering selection
    event.stopPropagation();
    event.preventDefault();
    
    const folderId = folder.id;
    
    console.log(`üîΩ Expand/collapse action for: ${folder.name}`);
    
    if (expandedFolders.has(folderId)) {
      // Collapse folder
      setExpandedFolders(prev => {
        const next = new Set(prev);
        next.delete(folderId);
        return next;
      });
      console.log(`üìÅ Collapsed: ${folder.name}`);
    } else {
      // Expand folder
      setExpandedFolders(prev => new Set([...prev, folderId]));
      console.log(`üìÇ Expanded: ${folder.name}`);
      
      // Load subfolders if not already loaded
      if (folder.has_subfolders && (!treeData[folderId] || !treeData[folderId].loaded)) {
        await loadSubfolders(folderId);
      }
    }
  }, [expandedFolders, treeData]);

  const handleFolderSelect = useCallback((event, folder) => {
    // üîß FIX: Stop event propagation for checkbox clicks
    event.stopPropagation();
    
    console.log(`üîç Folder selection attempt:`, folder.name, `Depth: ${folder.depth}`, `Selectable: ${folder.selectable}`);
    
    const folderId = folder.id;
    
    setSelectedFolders(prev => {
      const isSelected = prev.some(f => f.id === folderId);
      if (isSelected) {
        console.log(`‚ùå Deselecting folder: ${folder.name}`);
        return prev.filter(f => f.id !== folderId);
      } else {
        console.log(`‚úÖ Selecting folder: ${folder.name}`);
        return [...prev, folder];
      }
    });
  }, []);

  const handleDeselectAll = useCallback(() => {
    console.log('üóëÔ∏è Clearing all selections');
    setSelectedFolders([]);
  }, []);

  const renderFolderIcon = (folder, isExpanded, isLoading) => {
    if (isLoading) {
      return (
        <svg className="animate-spin h-4 w-4 text-blue-400" fill="none" viewBox="0 0 24 24">
          <circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
          <path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
        </svg>
      );
    }

    if (folder.has_subfolders) {
      return isExpanded ? '‚ñº' : '‚ñ∂';
    }
    return 'üìÅ';
  };

  const renderFolderNode = (folder, depth = 0) => {
    const isExpanded = expandedFolders.has(folder.id);
    const isLoading = loadingFolders.has(folder.id);
    const isSelected = selectedFolders.some(f => f.id === folder.id);
    const hasSubfolders = folder.has_subfolders;
    
    // üîß FIX: Show checkbox for ALL folders, not just selectable ones (for testing)
    // Later we can restrict to depth === selectableDepth
    const showCheckbox = true; // folder.depth === selectableDepth || folder.selectable;

    return (
      <div key={folder.id} className="folder-node">
        {/* Folder Row */}
        <div 
          className={`flex items-center py-2 px-3 hover:bg-gray-600 rounded transition-colors ${
            isSelected ? 'bg-blue-600' : ''
          }`}
          style={{ paddingLeft: `${depth * 20 + 12}px` }}
        >
          {/* Expand/Collapse Button */}
          <button
            type="button"
            onClick={(e) => handleFolderExpand(e, folder)}
            disabled={isLoading || !hasSubfolders}
            className={`mr-2 w-6 h-6 flex items-center justify-center text-sm ${
              hasSubfolders ? 'text-gray-300 hover:text-white cursor-pointer' : 'text-gray-500 cursor-default'
            }`}
          >
            {renderFolderIcon(folder, isExpanded, isLoading)}
          </button>

          {/* Selection Checkbox - üîß FIX: Always show for testing */}
          {showCheckbox && (
            <input
              type="checkbox"
              checked={isSelected}
              onChange={(e) => handleFolderSelect(e, folder)}
              className="mr-3 h-4 w-4 text-blue-600 rounded border-gray-600 bg-gray-700"
            />
          )}

          {/* Folder Info */}
          <div className="flex-1 min-w-0">
            <div className={`text-sm truncate ${
              folder.depth === selectableDepth 
                ? 'text-white font-medium' 
                : 'text-gray-300'
            }`}>
              {folder.name}
            </div>
            <div className="text-xs text-gray-400">
              {folder.path && `${folder.path}`}
            </div>
          </div>


        </div>

        {/* Child Folders */}
        {isExpanded && treeData[folder.id] && treeData[folder.id].children && (
          <div className="children">
            {treeData[folder.id].children.map(childFolder => 
              renderFolderNode(childFolder, depth + 1)
            )}
          </div>
        )}
      </div>
    );
  };

  if (!credentials) {
    return (
      <div className="text-center py-8 text-gray-400">
        <div className="text-lg mb-2">üîê</div>
        <div>Please authenticate with Google Drive first</div>
      </div>
    );
  }

  return (
    <div className={`google-drive-folder-tree ${className}`}>
      {/* Header */}
      <div className="flex items-center justify-between mb-4">
        <h4 className="font-medium text-white">üìÅ Navigate & Select Camera Folders</h4>
        <div className="flex gap-2">
          <button
            type="button"
            onClick={(e) => {
              e.stopPropagation();
              e.preventDefault();
              handleDeselectAll();
            }}
            className="px-3 py-1 bg-gray-600 text-white rounded text-xs hover:bg-gray-700"
          >
            Clear All
          </button>
        </div>
      </div>

      {/* Selection Summary */}
      {selectedFolders.length > 0 && (
        <div className="mb-4 p-3 bg-green-800 border border-green-600 rounded-lg">
          <div className="text-green-200 text-sm">
            ‚úÖ Selected {selectedFolders.length} folder(s):
          </div>
          <div className="text-green-100 text-xs mt-1 max-h-20 overflow-y-auto">
            {selectedFolders.map((f, idx) => (
              <div key={f.id}>
                {idx + 1}. {f.name}
              </div>
            ))}
          </div>
        </div>
      )}

      {/* Error Display */}
      {error && (
        <div className="mb-4 p-3 bg-red-800 border border-red-600 rounded-lg">
          <div className="text-red-200 text-sm">
            ‚ùå Error: {error}
          </div>
          <button
            onClick={loadRootFolders}
            type="button"
            className="mt-2 px-3 py-1 bg-red-600 text-white rounded text-xs hover:bg-red-700"
          >
            Retry
          </button>
        </div>
      )}

      {/* Tree Container */}
      <div className="tree-container bg-gray-700 rounded-lg p-4 max-h-96 overflow-y-auto border border-gray-600">
        {treeData['root'] ? (
          <div>
            {/* Root Node */}
            <div className="flex items-center py-2 px-3 bg-gray-600 rounded mb-2">
              <span className="mr-2 text-lg">üíæ</span>
              <div className="flex-1">
                <div className="text-white font-medium">My Drive</div>
                <div className="text-xs text-gray-300">Root directory - expand to navigate</div>
              </div>
              <div className="text-xs px-2 py-1 bg-gray-500 text-gray-200 rounded">Root</div>
            </div>

            {/* Root Children */}
            {treeData['root'].children && treeData['root'].children.map(folder => 
              renderFolderNode(folder, 0)
            )}
          </div>
        ) : (
          <div className="text-center py-8 text-gray-400">
            <div className="text-lg mb-2">üîÑ</div>
            <div>Loading folders...</div>
          </div>
        )}
      </div>

      {/* Instructions */}
      <div className="mt-4 p-3 bg-blue-800 border border-blue-600 rounded-lg">
        <div className="text-blue-200 text-sm">
          <div className="font-medium mb-1">üìç Navigation Guide:</div>
          <div className="text-xs space-y-1">
            <div>‚Ä¢ Click ‚ñ∂ to expand folders and navigate deeper</div>
            <div>‚Ä¢ ‚òëÔ∏è Check boxes to select camera folders</div>
            <div>‚Ä¢ Selected folders will be monitored for new videos</div>
            <div>‚Ä¢ VTrack will sync videos automatically</div>
          </div>
        </div>
      </div>

      {/* Debug Info (Development) */}
      {process.env.NODE_ENV === 'development' && (
        <details className="mt-4 p-3 bg-gray-800 rounded">
          <summary className="text-xs text-gray-400 cursor-pointer">üîß Debug - Tree State</summary>
          <pre className="text-xs text-gray-400 mt-2 overflow-auto max-h-32">
            {JSON.stringify({
              selectedCount: selectedFolders.length,
              selectedFolders: selectedFolders.map(f => ({ name: f.name, depth: f.depth })),
              expandedCount: expandedFolders.size,
              loadingCount: loadingFolders.size,
              treeNodesLoaded: Object.keys(treeData).length,
              hasError: !!error
            }, null, 2)}
          </pre>
        </details>
      )}
    </div>
  );
};

export default GoogleDriveFolderTree;
```
## üìÑ File: `InstructionsPanel.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/InstructionsPanel.js`

```javascript
import React, { useState, useEffect } from 'react';
import { getFinalRoiFrame } from "../../api";

const InstructionsPanel = ({
  step,
  customInstruction,
  analysisResult,
  errorMessage,
  onSave,
  onClose,
  onRetry,
  handDetected,
  videoPath,
  cameraId,
  onSubmit,
  setAnalysisResult,
  roiFramePath,
}) => {
  const [roiFrameSrc, setRoiFrameSrc] = useState(null);
  const [finalRoiFrameSrc, setFinalRoiFrameSrc] = useState(null);
  const [rois, setRois] = useState([]);
  const [internalError, setInternalError] = useState("");
  const [currentStep, setCurrentStep] = useState("packing");
  const [roiImageState, setRoiImageState] = useState({
    step: "packing",
    file: "roi_packing.jpg",
    ready: false,
  });
  const [imageAspectRatio, setImageAspectRatio] = useState(null);

  const loadRoiImage = async (fileSuffix, retryCount = 0, maxRetries = 3) => {
    try {
      if (!cameraId) {
        console.error("Missing cameraId", { cameraId });
        setInternalError("Thi·∫øu cameraId.");
        return;
      }

      console.log(`Loading ROI image with camera_id: ${cameraId}, file: ${fileSuffix}`);
      const timestamp = new Date().getTime();
      const url = `http://localhost:8080/get-roi-frame?camera_id=${cameraId}&file=${fileSuffix}&t=${timestamp}`;
      const response = await fetch(url, {
        headers: { 'Cache-Control': 'no-cache' },
      });
      if (!response.ok && response.status !== 304) {
        const errorText = await response.text();
        throw new Error(`HTTP error! status: ${response.status}, message: ${errorText}`);
      }
      console.log("Response from /get-roi-frame:", response);
      setRoiFrameSrc(url);
      setRoiImageState({ step: currentStep, file: fileSuffix, ready: true });
      console.log("roiFrameSrc updated to:", url);
    } catch (error) {
      console.error("Error loading ROI image:", error);
      if (retryCount < maxRetries) {
        console.log(`Retrying loadRoiImage (${retryCount + 1}/${maxRetries})...`);
        setTimeout(() => loadRoiImage(fileSuffix, retryCount + 1, maxRetries), 500);
      } else {
        setInternalError(`Kh√¥ng th·ªÉ t·∫£i ·∫£nh t·∫°m: ${error.message}. Vui l√≤ng th·ª≠ l·∫°i.`);
      }
    }
  };

  useEffect(() => {
    console.log("useEffect triggered with analysisResult:", analysisResult, "currentStep:", currentStep, "roiImageState:", roiImageState);
    if (analysisResult && analysisResult.roi_frame && roiImageState.ready) {
      loadRoiImage(roiImageState.file);
    } else if (currentStep === "packing" && analysisResult?.roi_frame) {
      loadRoiImage("roi_packing.jpg");
    }
  }, [analysisResult, currentStep, roiImageState.ready]);

  const fetchFinalRoiFrame = async () => {
    try {
      console.log(`Calling /get-final-roi-frame with camera_id: ${cameraId}`);
      const timestamp = new Date().getTime();
      const url = `http://localhost:8080/get-final-roi-frame?camera_id=${cameraId}&t=${timestamp}`;
      const response = await fetch(url, {
        headers: { 'Cache-Control': 'no-cache' },
      });
      if (!response.ok && response.status !== 304) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }
      console.log("Response from /get-final-roi-frame:", response);
      setFinalRoiFrameSrc(url);
    } catch (error) {
      console.error("Error fetching final ROI frame:", error);
      setInternalError("Kh√¥ng th·ªÉ t·∫£i ·∫£nh t·ªïng h·ª£p. Vui l√≤ng th·ª≠ l·∫°i.");
    }
  };

  const handleConfirmRoi = async () => {
    if (currentStep === "packing" && analysisResult?.roi) {
      if (!analysisResult || typeof analysisResult.hand_detected === "undefined") {
        setInternalError("Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√°t hi·ªán tay t·ª´ backend. Vui l√≤ng th·ª≠ l·∫°i.");
        return;
      }
      if (!analysisResult.hand_detected) {
        setInternalError("Kh√¥ng ph√°t hi·ªán tay. Vui l√≤ng v·∫Ω l·∫°i v√πng packing ho·∫∑c tho√°t.");
        return;
      }
      if (!analysisResult.roi_frame) {
        setInternalError("Thi·∫øu ƒë∆∞·ªùng d·∫´n ·∫£nh t·∫°m packing. Vui l√≤ng th·ª≠ l·∫°i.");
        return;
      }

      const newRoi = { type: currentStep, ...analysisResult.roi };
      const updatedRois = [...rois, newRoi];
      setRois(updatedRois);
      setCurrentStep("mvd");
      setRoiImageState({ step: "mvd", file: "roi_packing.jpg", ready: true });
      try {
        console.log("Calling /run-qr-detector for mvd step with videoPath:", videoPath, "cameraId:", cameraId, "roiFramePath:", analysisResult.roi_frame);
        const response = await fetch('http://localhost:8080/run-qr-detector', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ videoPath, cameraId, roiFramePath: analysisResult.roi_frame }),
        });
        const result = await response.json();
        console.log("Result from /run-qr-detector (mvd):", result);
        if (result.success) {
          const tempResult = {
            success: true,
            message: result.message || "QR detection completed successfully",
            rois: result.rois,
            qr_detected: result.qr_detected,
            qr_detected_roi1: result.qr_detected_roi1,
            qr_detected_roi2: result.qr_detected_roi2,
            roi_frame: result.roi_frame,
            qr_content: result.qr_content,
            trigger_detected: result.trigger_detected,
            table_type: result.table_type,
          };
        
          if (result.roi_frame) {
            setRoiImageState({ step: "mvd", file: "roi_MVD.jpg", ready: true });
            await loadRoiImage("roi_MVD.jpg");
            setAnalysisResult(tempResult); // Ch·ªâ set sau khi ·∫£nh t·∫£i xong
          } else {
            console.log("No roi_frame in result, keeping roi_packing.jpg");
            setAnalysisResult(tempResult);
          }
        } else {
          setInternalError(result.error || "Kh√¥ng th·ªÉ v·∫Ω v√πng m√£ v·∫≠n ƒë∆°n.");
        }
      } catch (error) {
        setInternalError("L·ªói khi v·∫Ω v√πng m√£ v·∫≠n ƒë∆°n: " + error.message);
      }
    } else if (currentStep === "mvd" && analysisResult?.rois) {
      if (!analysisResult || typeof analysisResult.qr_detected === "undefined") {
        setInternalError("Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√°t hi·ªán QR t·ª´ backend. Vui l√≤ng th·ª≠ l·∫°i.");
        return;
      }
      if (!analysisResult.qr_detected) {
        setInternalError("Kh√¥ng ph√°t hi·ªán m√£ QR. Vui l√≤ng v·∫Ω l·∫°i v√πng MVD ho·∫∑c tho√°t.");
        return;
      }
      if (!analysisResult.roi_frame) {
        setInternalError("Thi·∫øu ƒë∆∞·ªùng d·∫´n ·∫£nh t·∫°m MVD. Vui l√≤ng th·ª≠ l·∫°i.");
        return;
      }

      const newRois = analysisResult.rois.map((roi) => ({ type: currentStep, ...roi }));
      const updatedRois = [...rois, ...newRois];
      setRois(updatedRois);
      setCurrentStep("done");
      try {
        const response = await fetch('http://localhost:8080/finalize-roi', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ videoPath, cameraId, rois: updatedRois }),
        });
        const result = await response.json();
        if (result.success) {
          await fetchFinalRoiFrame();
          onSubmit(updatedRois);
          onSave();
        } else {
          setInternalError(result.error || "Kh√¥ng th·ªÉ t·∫°o ·∫£nh t·ªïng h·ª£p.");
        }
      } catch (error) {
        setInternalError("L·ªói khi t·∫°o ·∫£nh t·ªïng h·ª£p: " + error.message);
      }
    }
    if (currentStep === "done") {
      onSave();
    }
  };

  const handleRetryStep = async () => {
    if (!videoPath || !cameraId) {
      setInternalError("Thi·∫øu videoPath ho·∫∑c cameraId.");
      return;
    }

    try {
      if (currentStep === "packing") {
        console.log("Calling /run-select-roi for retry with videoPath:", videoPath, "cameraId:", cameraId);
        const response = await fetch('http://localhost:8080/run-select-roi', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ videoPath, cameraId }),
        });
        const result = await response.json();
        console.log("Result from /run-select-roi (retry):", result);
        if (result.success) {
          const newAnalysisResult = {
            success: true,
            message: result.message || "Hand detection completed successfully",
            roi: result.roi,
            hand_detected: result.hand_detected,
            roi_frame: result.roi_frame,
          };
          setAnalysisResult(newAnalysisResult);
          if (result.roi_frame) {
            setRoiImageState({ step: "packing", file: "roi_packing.jpg", ready: true });
            await loadRoiImage("roi_packing.jpg");
          }
        } else {
          setInternalError(result.error || `Kh√¥ng th·ªÉ ch·∫°y l·∫°i hand detection.`);
        }
      } else if (currentStep === "mvd") {
        console.log("Calling /run-qr-detector for retry with videoPath:", videoPath, "cameraId:", cameraId, "roiFramePath:", analysisResult.roi_frame);
        const response = await fetch('http://localhost:8080/run-qr-detector', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ videoPath, cameraId, roiFramePath: analysisResult.roi_frame }),
        });
        const result = await response.json();
        console.log("Result from /run-qr-detector (retry):", result);
        if (result.success) {
          const newAnalysisResult = {
            success: true,
            message: result.message || "QR detection completed successfully",
            rois: result.rois,
            qr_detected: result.qr_detected,
            qr_detected_roi1: result.qr_detected_roi1,
            qr_detected_roi2: result.qr_detected_roi2,
            qr_content: result.qr_content,
            roi_frame: result.roi_frame,
            trigger_detected: result.trigger_detected,
            table_type: result.table_type,
          };
          setAnalysisResult(newAnalysisResult);
          if (result.roi_frame && result.qr_detected) {
            setRoiImageState({ step: "mvd", file: "roi_MVD.jpg", ready: true });
            await loadRoiImage("roi_MVD.jpg");
          } else {
            setInternalError("Kh√¥ng th·ªÉ t·∫£i ·∫£nh ho·∫∑c kh√¥ng ph√°t hi·ªán QR.");
          }
        } else {
          setInternalError(result.error || `Kh√¥ng th·ªÉ ch·∫°y l·∫°i QR detection.`);
        }
      }
    } catch (error) {
      setInternalError(`L·ªói khi ch·∫°y l·∫°i: ${error.message}`);
    }
  };

  const handleImageLoad = (e) => {
    const { width, height } = e.target;
    setImageAspectRatio(width / height);
  };

  return (
    <div className="flex w-full h-full">
      <div className="w-1/4 pr-4 flex flex-col border-r-2 border-gray-500">
        <div className="mb-4">
          <h3 className="text-2xl font-bold mb-2 text-white">K·∫øt qu·∫£</h3>
          {currentStep === "mvd" ? (
            <>
              {analysisResult?.table_type === "standard" ? (
                <>
                  <div className={`p-2 rounded text-white flex items-center ${analysisResult?.trigger_detected ? 'bg-green-600' : 'bg-red-600'}`}>
                    <span className="mr-2">{analysisResult?.trigger_detected ? '‚úî' : '‚úò'}</span>
                    <p>ROI Trigger: {analysisResult?.trigger_detected ? 'C√≥' : 'Kh√¥ng'}</p>
                  </div>
                  <div className={`p-2 rounded text-white flex items-center mt-2 ${analysisResult?.qr_detected_roi1 ? 'bg-green-600' : 'bg-red-600'}`}>
                    <span className="mr-2">{analysisResult?.qr_detected_roi1 ? '‚úî' : '‚úò'}</span>
                    <p>ROI MVD: {analysisResult?.qr_detected_roi1 ? 'C√≥' : 'Kh√¥ng'}</p>
                  </div>
                </>
              ) : (
                <>
                  {typeof analysisResult?.qr_detected_roi1 !== 'undefined' && (
                    <div className={`p-2 rounded text-white flex items-center ${analysisResult?.qr_detected_roi1 ? 'bg-green-600' : 'bg-red-600'}`}>
                      <span className="mr-2">{analysisResult?.qr_detected_roi1 ? '‚úî' : '‚úò'}</span>
                      <p>ROI 1: {analysisResult?.qr_detected_roi1 ? 'C√≥' : 'Kh√¥ng'}</p>
                    </div>
                  )}
                </>
              )}
            </>
          ) : (
            <div className={`p-2 rounded text-white flex items-center ${handDetected ? 'bg-green-600' : 'bg-red-600'}`}>
              <span className="mr-2">{handDetected ? '‚úî' : '‚úò'}</span>
              <p>{handDetected ? `X√°c nh·∫≠n v√πng ${currentStep}` : 'Kh√¥ng ph√°t hi·ªán chuy·ªÉn ƒë·ªông'}</p>
            </div>
          )}
          {errorMessage && (
            <div className="mt-2 p-2 bg-red-600 rounded text-white">
              <p>{errorMessage}</p>
            </div>
          )}
          {internalError && (
            <div className="mt-2 p-2 bg-red-600 rounded text-white">
              <p>{internalError}</p>
            </div>
          )}
        </div>
        <div className="mb-4 flex-1">
          <h3 className="text-xl font-bold mb-2 text-white">H∆∞·ªõng d·∫´n</h3>
          <p className="text-gray-300 text-lg">
            {currentStep === "done"
              ? "ƒê√£ ho√†n t·∫•t v·∫Ω v√πng v√† ph√°t hi·ªán m√£ QR. Nh·∫•n Tho√°t ƒë·ªÉ ti·∫øp t·ª•c."
              : currentStep === "mvd"
                ? analysisResult?.qr_detected
                  ? "ƒê√£ t√¨m th·∫•y m√£ QR. Nh·∫•n Ho√†n t·∫•t ƒë·ªÉ l∆∞u v√† ti·∫øp t·ª•c."
                  : "V·∫Ω l·∫°i v√πng m√£ v·∫≠n ƒë∆°n ho·∫∑c tho√°t."
                : handDetected
                  ? "Ti·∫øp t·ª•c x√°c ƒë·ªãnh v√πng m√£ v·∫≠n ƒë∆°n."
                  : "V·∫Ω l·∫°i v√πng packing ho·∫∑c tho√°t."}
          </p>
        </div>
        <div className="mt-auto space-y-2">
          {currentStep !== "done" && (
            <button
              onClick={handleRetryStep}
              className="w-full py-2 bg-yellow-600 hover:bg-yellow-700 text-white font-bold rounded"
            >
              V·∫Ω l·∫°i
            </button>
          )}
          {currentStep === "mvd" && analysisResult?.qr_detected && (
            <button
              onClick={handleConfirmRoi}
              className="w-full py-2 bg-blue-600 hover:bg-blue-700 text-white font-bold rounded"
            >
              Ho√†n t·∫•t
            </button>
          )}
          {currentStep === "packing" && handDetected && (
            <button
              onClick={handleConfirmRoi}
              className="w-full py-2 bg-blue-600 hover:bg-blue-700 text-white font-bold rounded"
            >
              Ti·∫øp t·ª•c
            </button>
          )}
          <button
            onClick={onClose}
            className="w-full py-2 bg-red-600 hover:bg-red-700 text-white font-bold rounded"
          >
            Tho√°t
          </button>
        </div>
      </div>
      <div className="w-3/4 pl-4 flex flex-col">
        <div className="mb-4 flex justify-center items-center" style={{ maxHeight: 'calc(75vh - 2rem)', overflow: 'hidden' }}>
          {console.log("Rendering ROI frame with roiFrameSrc:", roiFrameSrc, "roiImageState:", roiImageState)}
          {roiFrameSrc && (
            <img 
              src={roiFrameSrc} 
              alt="ROI Frame" 
              className={`max-w-full max-h-full rounded ${imageAspectRatio && imageAspectRatio < 1 ? 'portrait' : 'landscape'}`}
              onLoad={handleImageLoad}
            />
          )}
        </div>
        {finalRoiFrameSrc && currentStep === "done" && (
          <div className="mb-4 flex justify-center items-center" style={{ maxHeight: 'calc(75vh - 2rem)', overflow: 'hidden' }}>
            <h4 className="text-lg font-bold text-white">·∫¢nh t·ªïng h·ª£p:</h4>
            <img 
              src={finalRoiFrameSrc} 
              alt="Final ROI Frame" 
              className={`max-w-full max-h-full rounded ${imageAspectRatio && imageAspectRatio < 1 ? 'portrait' : 'landscape'}`}
              onLoad={handleImageLoad}
            />
          </div>
        )}
      </div>
      <style jsx>{`
        .max-w-full {
          max-width: 100%;
        }
        .max-h-full {
          max-height: 100%;
        }
        .landscape {
          object-fit: contain;
          width: 100%;
        }
        .portrait {
          object-fit: contain;
          height: 100%;
        }
      `}</style>
    </div>
  );
};

export default InstructionsPanel;
```
## üìÑ File: `SourceCard.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/SourceCard.js`

```javascript
// components/config/SourceCard.js
import React from 'react';

const SourceCard = ({ source, onEdit, onDelete, onToggle }) => {
  const getSourceTypeIcon = (type) => {
    const icons = {
      'local': 'üíª',
      'network': 'üåê', 
      'camera': 'üìπ',
      'cloud': '‚òÅÔ∏è'
    };
    return icons[type] || 'üìÅ';
  };

  return (
    <div className="bg-gray-800 border border-gray-600 rounded-lg p-4 mb-3">
      <div className="flex justify-between items-start">
        <div className="flex-1">
          <div className="flex items-center gap-2 mb-2">
            <span className="text-xl">{getSourceTypeIcon(source.source_type)}</span>
            <h4 className="text-lg font-medium text-white">{source.name}</h4>
            <span className={`px-2 py-1 rounded text-xs font-medium ${
              source.active ? 'bg-green-600 text-white' : 'bg-red-600 text-white'
            }`}>
              {source.active ? 'Active' : 'Inactive'}
            </span>
          </div>
          <p className="text-gray-300 text-sm mb-1">
            <strong>Type:</strong> {source.source_type.toUpperCase()}
          </p>
          <p className="text-gray-300 text-sm break-all">
            <strong>Path:</strong> {source.path}
          </p>
        </div>
        
        <div className="flex gap-2 ml-4">
          <button
            onClick={() => onToggle(source.id, !source.active)}
            className={`px-3 py-1 rounded text-sm font-medium ${
              source.active 
                ? 'bg-yellow-600 hover:bg-yellow-700 text-white' 
                : 'bg-green-600 hover:bg-green-700 text-white'
            }`}
          >
            {source.active ? 'Disable' : 'Enable'}
          </button>
          <button
            onClick={() => onEdit(source)}
            className="px-3 py-1 bg-blue-600 hover:bg-blue-700 text-white rounded text-sm font-medium"
          >
            Edit
          </button>
          <button
            onClick={() => onDelete(source.id)}
            className="px-3 py-1 bg-red-600 hover:bg-red-700 text-white rounded text-sm font-medium"
          >
            Delete
          </button>
        </div>
      </div>
    </div>
  );
};

export default SourceCard;
```
## üìÑ File: `CameraDialog.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/config/CameraDialog.js`

```javascript
const CameraDialog = ({
  showCameraDialog,
  setShowCameraDialog,
  cameras,
  selectedCameras,
  handleCameraSelection,
  handleSaveConfig,
}) => {
  if (!showCameraDialog) return null;

  return (
    <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center">
      <div className="bg-gray-800 p-6 rounded-lg w-1/2">
        <h2 className="text-2xl font-bold mb-4 text-white">X√°c nh·∫≠n camera</h2>
        <div className="max-h-64 overflow-y-auto">
          {cameras.map((camera) => (
            <label key={camera.name} className="flex items-center mb-2 text-white">
              <input
                type="checkbox"
                className="mr-2"
                checked={selectedCameras.includes(camera.name)}
                onChange={() => handleCameraSelection(camera.name)}
              />
              {camera.name} ({camera.path})
            </label>
          ))}
        </div>
        <div className="mt-4 flex justify-end gap-4">
          <button
            onClick={() => setShowCameraDialog(false)}
            className="py-2 px-4 bg-gray-600 text-white font-bold rounded"
          >
            H·ªßy
          </button>
          <button
            onClick={handleSaveConfig}
            className="py-2 px-4 bg-blue-600 text-white font-bold rounded"
          >
            X√°c nh·∫≠n
          </button>
        </div>
      </div>
    </div>
  );
};
export default CameraDialog;
```
## üìÑ File: `FileList.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/program/FileList.js`

```javascript
const FileList = ({ fileList }) => {
  if (!fileList || fileList.length === 0) {
    return (
      <div className="mt-4">
        <h3 className="text-lg font-bold">K·∫øt qu·∫£:</h3>
        <p>Kh√¥ng c√≥ file n√†o ƒë·ªÉ hi·ªÉn th·ªã.</p>
      </div>
    );
  }

  return (
    <div className="mt-4">
      <h3 className="text-lg font-bold">K·∫øt qu·∫£:</h3>
      <ul className="list-disc pl-5">
        {fileList.map((item, index) => (
          <li key={index}>{`${item.file}: ${item.status}`}</li>
        ))}
      </ul>
    </div>
  );
};

export default FileList;
```
## üìÑ File: `ProgramTab.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/program/ProgramTab.js`

```javascript
import { useState, useEffect } from "react";
import Card from "../ui/Card";
import FileList from "./FileList";

const ProgramTab = ({
  runningCard,
  fileList,
  customPath,
  firstRunCompleted,
  handleRunStop,
  isRunning,
  setCustomPath,
}) => {
  const [updatedFileList, setUpdatedFileList] = useState(fileList);

  useEffect(() => {
    const fetchProgress = async () => {
      try {
        const response = await fetch("http://localhost:8080/program-progress", {
          method: "GET",
          headers: { "Content-Type": "application/json" },
        });
        const data = await response.json();
        if (response.ok) {
          setUpdatedFileList(data.files);
        } else {
          console.error("Failed to fetch program progress:", data.error);
        }
      } catch (error) {
        console.error("Error fetching program progress:", error);
      }
    };

    fetchProgress();
    const intervalId = setInterval(fetchProgress, 10000);
    const timeoutId = setTimeout(() => {
      clearInterval(intervalId);
      console.log("Stopped polling /program-progress after 2 minutes");
    }, 120000);

    return () => {
      clearInterval(intervalId);
      clearTimeout(timeoutId);
    };
  }, [runningCard]);

  return (
    <div className="flex flex-col gap-6">
      <div className="grid grid-cols-3 gap-6">
        {!firstRunCompleted && (
          <Card
            title="L·∫ßn ƒë·∫ßu"
            description="Ch·∫°y l·∫ßn ƒë·∫ßu ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu c∆° s·ªü."
            isRunning={isRunning("L·∫ßn ƒë·∫ßu")}
            onRunStop={firstRunCompleted ? null : () => handleRunStop("L·∫ßn ƒë·∫ßu")}
            isLocked={firstRunCompleted}
          />
        )}
        <Card
          title="M·∫∑c ƒë·ªãnh"
          description="Ch·∫°y khi kh·ªüi ƒë·ªông, ch·∫°y n·ªÅn."
          isRunning={isRunning("M·∫∑c ƒë·ªãnh")}
          onRunStop={() => handleRunStop("M·∫∑c ƒë·ªãnh")}
        />
        <Card
          title="Ch·ªâ ƒë·ªãnh"
          description="Ch·ªâ ƒë·ªãnh file c·ª• th·ªÉ."
          isRunning={isRunning("Ch·ªâ ƒë·ªãnh")}
          onRunStop={() => handleRunStop("Ch·ªâ ƒë·ªãnh", customPath)}
          onPathChange={(path) => setCustomPath(path)}
        />
      </div>
      <FileList fileList={updatedFileList} />
    </div>
  );
};

export default ProgramTab;
```
## üìÑ File: `TextInputSection.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/query/TextInputSection.js`

```javascript
const TextInputSection = ({ searchString, setSearchString, searchType }) => {
  const handleTextInputChange = (e) => {
    const value = e.target.value;
    const lines = value.split("\n");
    const codes = [];
    
    lines.forEach(line => {
      const trimmedLine = line.trim();
      if (!trimmedLine) return;
      const match = trimmedLine.match(/^\d+\.\s*(.+)$/);
      const lineContent = match ? match[1].trim() : trimmedLine;
      const lineCodes = lineContent.split(";").map(code => code.trim()).filter(code => code);
      codes.push(...lineCodes);
    });

    let formattedCodes = codes
      .map((code, index) => `${index + 1}. ${code}`)
      .join("\n");

    if (value.endsWith("\n")) {
      formattedCodes += `\n${codes.length + 1}. `;
    }

    setSearchString(formattedCodes);
  };

  return (
    <textarea
      value={searchString}
      onChange={handleTextInputChange}
      placeholder="Nh·∫≠p chu·ªói t√¨m ki·∫øm (m·ªói m√£ tr√™n m·ªôt d√≤ng)"
      className="w-full p-2 mb-4 rounded bg-gray-700 text-white h-1/2 overflow-y-auto whitespace-pre-wrap resize-none"
      disabled={searchType === "File"}
    />
  );
};

export default TextInputSection;
```
## üìÑ File: `TimeAndQuerySection.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/query/TimeAndQuerySection.js`

```javascript
import DatePicker from "react-datepicker";
import "react-datepicker/dist/react-datepicker.css";

const TimeAndQuerySection = ({
  startDate,
  setStartDate,
  endDate,
  setEndDate,
  defaultDays,
  setDefaultDays,
  searchString,
  searchType,
  fileContent,
  results,
  setResults,
  setSelectedVideos,
  setQueryCount,
  setFoundCount,
  foundCount,
  onQuery, // Prop ƒë·ªÉ nh·∫≠n h√†m debounce t·ª´ QueryComponent
  isQuerying, // Prop ƒë·ªÉ v√¥ hi·ªáu h√≥a n√∫t
}) => {
  const handleStartDateChange = (date) => {
    setStartDate(date);
    if (endDate) {
      const diffDays = (endDate - date) / (1000 * 60 * 60 * 24);
      if (diffDays > 30) {
        setEndDate(new Date(date.getTime() + 30 * 24 * 60 * 60 * 1000));
      } else if (date > endDate) {
        setEndDate(date);
      }
    }
  };

  const handleEndDateChange = (date) => {
    const today = new Date();
    if (date > today) {
      date = today;
    }
    if (startDate) {
      const diffDays = (date - startDate) / (1000 * 60 * 60 * 24);
      if (diffDays > 30) {
        setStartDate(new Date(date.getTime() - 30 * 24 * 60 * 60 * 1000));
      } else if (date < startDate) {
        setStartDate(date);
      }
    }
    setEndDate(date);
  };

  return (
    <>
      <div className="mb-4">
        <label className="block mb-1">Th·ªùi gian m·∫∑c ƒë·ªãnh (ng√†y):</label>
        <input
          type="number"
          value={defaultDays}
          onChange={(e) => setDefaultDays(Number(e.target.value))}
          className="w-full p-2 rounded bg-gray-700 text-white"
        />
      </div>
      <div className="flex gap-4 mb-4">
        <div className="flex-1">
          <label className="block mb-1">T·ª´:</label>
          <DatePicker
            selected={startDate}
            onChange={handleStartDateChange}
            showTimeSelect
            timeIntervals={60}
            dateFormat="Pp"
            className="w-full p-2 rounded bg-gray-700 text-white"
          />
        </div>
        <div className="flex-1">
          <label className="block mb-1">ƒê·∫øn:</label>
          <DatePicker
            selected={endDate}
            onChange={handleEndDateChange}
            showTimeSelect
            timeIntervals={60}
            dateFormat="Pp"
            maxDate={new Date()}
            className="w-full p-2 rounded bg-gray-700 text-white"
          />
        </div>
      </div>
      <button
        onClick={onQuery} // D√πng onQuery t·ª´ props
        disabled={isQuerying} // V√¥ hi·ªáu h√≥a n√∫t khi ƒëang x·ª≠ l√Ω
        className={`w-full py-2 bg-green-600 text-white font-bold rounded ${isQuerying ? "opacity-50 cursor-not-allowed" : ""}`}
      >
        Truy v·∫•n
      </button>
    </>
  );
};

export default TimeAndQuerySection;
```
## üìÑ File: `FileInputSection.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/query/FileInputSection.js`

```javascript
const FileInputSection = ({ path, setPath, fileContent, setFileContent, setShowModal, setHeaders }) => {
  const handleOpenExplorer = () => {
    const input = document.createElement("input");
    input.type = "file";
    input.accept = ".csv,.xlsx";
    input.onchange = (e) => {
      const file = e.target.files[0];
      if (!file) return;
      const fileName = file.name.toLowerCase();
      const fileType = file.type;

      // Ki·ªÉm tra ƒëu√¥i file
      if (!fileName.endsWith(".csv") && !fileName.endsWith(".xlsx")) {
        alert("Vui l√≤ng ch·ªçn file CSV ho·∫∑c Excel (.csv, .xlsx)");
        return;
      }

      // Ki·ªÉm tra MIME type
      const validCsvMimeTypes = ["text/csv", "application/csv"];
      const validXlsxMimeTypes = [
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        "application/vnd.ms-excel",
      ];
      if (fileName.endsWith(".csv") && !validCsvMimeTypes.includes(fileType)) {
        alert("File kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng CSV. Vui l√≤ng ch·ªçn file CSV h·ª£p l·ªá.");
        return;
      }
      if (fileName.endsWith(".xlsx") && !validXlsxMimeTypes.includes(fileType)) {
        alert("File kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng Excel. Vui l√≤ng ch·ªçn file XLSX h·ª£p l·ªá.");
        return;
      }

      setPath(file.name);

      const reader = new FileReader();
      reader.onload = (event) => {
        const arrayBuffer = event.target.result;
        const bytes = new Uint8Array(arrayBuffer);
        const binary = Array.from(bytes).map((b) => String.fromCharCode(b)).join("");
        const base64 = btoa(binary); // Base64 encode t·ª´ nh·ªã ph√¢n
        setFileContent(base64);
      };
      reader.onerror = () => {
        alert("L·ªói khi ƒë·ªçc file");
      };
      reader.readAsArrayBuffer(file); // ƒê·ªçc raw binary
    };
    input.click();
  };

  const handleConfirmFile = async () => {
    if (!path) {
      alert("Vui l√≤ng ch·ªçn file CSV ho·∫∑c nh·∫≠p ƒë∆∞·ªùng d·∫´n");
      return;
    }
    try {
      const response = await fetch("http://localhost:8080/get-csv-headers", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          file_path: path,
          file_content: fileContent || "",
          is_excel: path.toLowerCase().endsWith(".xlsx"),
        }),
      });
      const result = await response.json();
      if (response.ok) {
        setHeaders(result.headers || []);
        setShowModal(true);
      } else {
        throw new Error(result.error || "Failed to get CSV headers");
      }
    } catch (error) {
      console.error("Error getting CSV headers:", error);
      alert(error.message || "Failed to get CSV headers");
    }
  };

  return (
    <div className="mb-4">
      <div className="relative w-full mb-2">
        <input
          type="text"
          value={path}
          onChange={(e) => setPath(e.target.value)}
          placeholder="Ch·ªçn file ƒë·ªãnh d·∫°ng *.csv ho·∫∑c *.xlsx"
          className="w-full p-2 rounded bg-gray-700 text-white"
        />
        <button
          type="button"
          onClick={handleOpenExplorer}
          className="absolute right-2 top-1/2 transform -translate-y-1/2 text-white"
        >
          ...
        </button>
      </div>
      <button
        onClick={handleConfirmFile}
        className="w-full py-2 bg-yellow-500 text-white font-bold rounded"
      >
        X√°c nh·∫≠n
      </button>
    </div>
  );
};

export default FileInputSection;
```
## üìÑ File: `ColumnSelectorModal.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/components/query/ColumnSelectorModal.js`

```javascript
const ColumnSelectorModal = ({
  showModal,
  setShowModal,
  headers,
  selectedColumn,
  setSelectedColumn,
  history,
  setHistory,
  selectedPlatform,
  setSelectedPlatform,
  shopeeLabel,
  setShopeeLabel,
  lazadaLabel,
  setLazadaLabel,
  tiktokLabel,
  setTiktokLabel,
  customLabel1,
  setCustomLabel1,
  customLabel2,
  setCustomLabel2,
  path,
  fileContent,
  setSearchString,
  setSearchType,
}) => {
  const handleModalConfirm = async () => {
    const columnName = history[selectedPlatform] || "tracking_codes";
    const data = {
      file_path: path,
      file_content: fileContent || "",
      column_name: columnName,
      is_excel: path.toLowerCase().endsWith(".xlsx"), // Th√™m logic x√°c ƒë·ªãnh is_excel d·ª±a tr√™n path
    };
    try {
      console.log("Sending file data:", data);
      const response = await fetch("http://localhost:8080/parse-csv", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(data),
      });
      const result = await response.json();
      console.log("Response from parse-csv:", result);
      if (response.ok) {
        const trackingCodes = result.tracking_codes || [];
        const formattedCodes = trackingCodes
          .map((code, index) => `${index + 1}. ${code}`)
          .join("\n");
        setSearchString(formattedCodes);
        setSearchType("Text");
        setShowModal(false);
      } else {
        throw new Error(result.error || "Failed to parse CSV");
      }
    } catch (error) {
      console.error("Error parsing CSV:", error);
      alert(error.message || "Failed to parse CSV");
    }
  };

  const handleUpdateColumn = () => {
    const newColumn = selectedColumn;
    const updatedHistory = { ...history };
    updatedHistory[selectedPlatform] = newColumn;
    setHistory(updatedHistory);
    localStorage.setItem("trackingColumnHistory", JSON.stringify(updatedHistory));

    const updatedLabels = {
      Shopee: shopeeLabel,
      Lazada: lazadaLabel,
      Tiktok: tiktokLabel,
      Custom1: customLabel1,
      Custom2: customLabel2,
    };
    localStorage.setItem("platformLabels", JSON.stringify(updatedLabels));
  };

  const handlePlatformChange = (platform) => {
    setSelectedPlatform(platform);
    setSelectedColumn(history[platform] || "tracking_codes");
  };

  if (!showModal) return null;

  return (
    <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center">
      <div className="bg-gray-800 p-6 rounded-lg w-1/2">
        <h2 className="text-xl font-bold mb-4">Ch·ªçn c·ªôt m√£ v·∫≠n ƒë∆°n</h2>
        <div className="mb-4">
          <label className="block mb-1">Ch·ªçn t·ª´ danh s√°ch:</label>
          <select
            value={selectedColumn}
            onChange={(e) => setSelectedColumn(e.target.value)}
            className="w-full p-2 rounded bg-gray-700 text-white"
          >
            {headers.map((header, index) => (
              <option key={index} value={header}>{header}</option>
            ))}
          </select>
        </div>
        <div className="mb-4">
          <button
            onClick={handleUpdateColumn}
            className="w-full py-2 bg-blue-600 text-white font-bold rounded"
          >
            C·∫≠p nh·∫≠t
          </button>
        </div>
        <div className="mb-4">
          <h3 className="text-lg font-bold mb-2">L·ªãch s·ª≠ l·ª±a ch·ªçn:</h3>
          <label className="flex items-center mb-2">
            <input
              type="radio"
              name="platform"
              value="Shopee"
              checked={selectedPlatform === "Shopee"}
              onChange={() => handlePlatformChange("Shopee")}
              className="mr-2"
            />
            <input
              type="text"
              value={shopeeLabel}
              onChange={(e) => setShopeeLabel(e.target.value)}
              placeholder="T√™n Shopee"
              className="mr-2 p-1 rounded bg-gray-700 text-white"
            />
            <input
              type="text"
              value={history.Shopee}
              onChange={(e) => setHistory({ ...history, Shopee: e.target.value })}
              className="p-1 rounded bg-gray-700 text-white"
            />
          </label>
          <label className="flex items-center mb-2">
            <input
              type="radio"
              name="platform"
              value="Lazada"
              checked={selectedPlatform === "Lazada"}
              onChange={() => handlePlatformChange("Lazada")}
              className="mr-2"
            />
            <input
              type="text"
              value={lazadaLabel}
              onChange={(e) => setLazadaLabel(e.target.value)}
              placeholder="T√™n Lazada"
              className="mr-2 p-1 rounded bg-gray-700 text-white"
            />
            <input
              type="text"
              value={history.Lazada}
              onChange={(e) => setHistory({ ...history, Lazada: e.target.value })}
              className="p-1 rounded bg-gray-700 text-white"
            />
          </label>
          <label className="flex items-center mb-2">
            <input
              type="radio"
              name="platform"
              value="Tiktok"
              checked={selectedPlatform === "Tiktok"}
              onChange={() => handlePlatformChange("Tiktok")}
              className="mr-2"
            />
            <input
              type="text"
              value={tiktokLabel}
              onChange={(e) => setTiktokLabel(e.target.value)}
              placeholder="T√™n Tiktok"
              className="mr-2 p-1 rounded bg-gray-700 text-white"
            />
            <input
              type="text"
              value={history.Tiktok}
              onChange={(e) => setHistory({ ...history, Tiktok: e.target.value })}
              className="p-1 rounded bg-gray-700 text-white"
            />
          </label>
          <label className="flex items-center mb-2">
            <input
              type="radio"
              name="platform"
              value="Custom1"
              checked={selectedPlatform === "Custom1"}
              onChange={() => handlePlatformChange("Custom1")}
              className="mr-2"
            />
            <input
              type="text"
              value={customLabel1}
              onChange={(e) => setCustomLabel1(e.target.value)}
              placeholder="T√™n t√πy ch·ªânh 1"
              className="mr-2 p-1 rounded bg-gray-700 text-white"
            />
            <input
              type="text"
              value={history.Custom1}
              onChange={(e) => setHistory({ ...history, Custom1: e.target.value })}
              className="p-1 rounded bg-gray-700 text-white"
            />
          </label>
          <label className="flex items-center mb-2">
            <input
              type="radio"
              name="platform"
              value="Custom2"
              checked={selectedPlatform === "Custom2"}
              onChange={() => handlePlatformChange("Custom2")}
              className="mr-2"
            />
            <input
              type="text"
              value={customLabel2}
              onChange={(e) => setCustomLabel2(e.target.value)}
              placeholder="T√™n t√πy ch·ªânh 2"
              className="mr-2 p-1 rounded bg-gray-700 text-white"
            />
            <input
              type="text"
              value={history.Custom2}
              onChange={(e) => setHistory({ ...history, Custom2: e.target.value })}
              className="p-1 rounded bg-gray-700 text-white"
            />
          </label>
        </div>
        <div className="flex justify-end gap-4">
          <button
            onClick={() => setShowModal(false)}
            className="py-2 px-4 bg-gray-600 text-white rounded"
          >
            H·ªßy
          </button>
          <button
            onClick={handleModalConfirm}
            className="py-2 px-4 bg-green-600 text-white rounded"
          >
            X√°c nh·∫≠n
          </button>
        </div>
      </div>
    </div>
  );
};

export default ColumnSelectorModal;
```
## üìÑ File: `useVtrackConfig.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/hooks/useVtrackConfig.js`

```javascript
import { useState, useEffect } from "react";

const useVtrackConfig = () => {
  const [fromTime, setFromTime] = useState(null);
  const [toTime, setToTime] = useState(null);
  const [country, setCountry] = useState("Vi·ªát Nam");
  const [timezone, setTimezone] = useState("UTC+7");
  const [brandName, setBrandName] = useState("");
  const [inputPath, setInputPath] = useState("");
  const [outputPath, setOutputPath] = useState("");
  const [workingDays, setWorkingDays] = useState([]);
  const [defaultDays, setDefaultDays] = useState(30);
  const [minPackingTime, setMinPackingTime] = useState(10);
  const [maxPackingTime, setMaxPackingTime] = useState(120);
  const [frameRate, setFrameRate] = useState(30);
  const [frameInterval, setFrameInterval] = useState(5);
  const [videoBuffer, setVideoBuffer] = useState(2);
  const [cameras, setCameras] = useState([]);
  const [selectedCameras, setSelectedCameras] = useState([]);
  const [showCameraDialog, setShowCameraDialog] = useState(false);
  const [error, setError] = useState(null);
  const [runDefaultOnStart, setRunDefaultOnStart] = useState(false);

  const countries = [
    "Vi·ªát Nam", "Nh·∫≠t B·∫£n", "H√†n Qu·ªëc", "Th√°i Lan", "Singapore",
    "M·ªπ", "Anh", "Ph√°p", "ƒê·ª©c", "√öc"
  ];

  const countryTimezones = {
    "Vi·ªát Nam": "UTC+7", "Nh·∫≠t B·∫£n": "UTC+9", "H√†n Qu·ªëc": "UTC+9",
    "Th√°i Lan": "UTC+7", "Singapore": "UTC+8", "M·ªπ": "UTC-5",
    "Anh": "UTC+0", "Ph√°p": "UTC+1", "ƒê·ª©c": "UTC+1", "√öc": "UTC+10"
  };

  const BASE_DIR = "/Users/annhu/vtrack_app/V_Track";

  useEffect(() => {
    const fetchCameraFolders = async () => {
      try {
        // ‚úÖ SIMPLIFIED - single source of truth
        const response = await fetch("http://localhost:8080/get-camera-folders");
        if (response.ok) {
          const data = await response.json();
          if (Array.isArray(data.folders)) {
            setCameras(data.folders);
            setError(null);
          } else {
            setCameras([]);
            setError(data.error || "Failed to load camera folders");
          }
        } else {
          setCameras([]);
          setError("Camera folders not available");
        }
      } catch (error) {
        console.error("Error fetching camera folders:", error);
        setError("Error fetching camera folders: " + error.message);
        setCameras([]);
      }
    };
    fetchCameraFolders();
  }, []);

  const handleCountryChange = (e) => {
    const selectedCountry = e.target.value;
    setCountry(selectedCountry);
    setTimezone(countryTimezones[selectedCountry] || "UTC+0");
  };

  const handleFromTimeChange = (time) => {
    setFromTime(time);
    if (toTime && time > toTime) setToTime(time);
  };

  const handleToTimeChange = (time) => {
    if (fromTime && time < fromTime) setFromTime(time);
    setToTime(time);
  };

  const handleWorkingDayChange = (day) => {
    setWorkingDays((prev) =>
      prev.includes(day) ? prev.filter((d) => d !== day) : [...prev, day]
    );
  };

  useEffect(() => {
    console.log("workingDays updated:", workingDays);
  }, [workingDays]);

  const handleOpenExplorer = (type) => {
    const input = document.createElement("input");
    input.type = "file";
    input.webkitdirectory = true;
    input.onchange = (e) => {
      const files = e.target.files;
      if (files.length > 0) {
        const file = files[0];
        let selectedPath = file.path || file.webkitRelativePath || file.name || "";
        if (!selectedPath.startsWith('/')) {
          selectedPath = `${BASE_DIR}/${selectedPath}`;
        }
        selectedPath = selectedPath.split('/').slice(0, -1).join('/');
        if (selectedPath.includes('.DS_Store')) {
          selectedPath = selectedPath.replace('/.DS_Store', '');
        }
        console.log(`Selected ${type} path:`, selectedPath);
        if (type === "input") setInputPath(selectedPath);
        else setOutputPath(selectedPath);
      }
    };
    input.click();
  };

  const handleSaveGeneralInfo = async () => {
    const data = {
      country,
      timezone,
      brand_name: brandName,
      working_days: workingDays.length > 0 ? workingDays : ["Th·ª© Hai", "Th·ª© Ba", "Th·ª© T∆∞", "Th·ª© NƒÉm", "Th·ª© S√°u", "Th·ª© B·∫£y", "Ch·ªß Nh·∫≠t"],
      from_time: fromTime ? fromTime.toLocaleTimeString('en-GB', { hour: '2-digit', minute: '2-digit', hour12: false }) : "07:00",
      to_time: toTime ? toTime.toLocaleTimeString('en-GB', { hour: "2-digit", minute: "2-digit", hour12: false }) : "23:00",
    };
    console.log("Data sent to /save-general-info:", data);
    try {
      const response = await fetch("http://localhost:8080/save-general-info", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(data),
      });
      if (response.ok) alert("General info saved successfully");
      else throw new Error("Failed to save general info");
    } catch (error) {
      console.error("Error saving general info:", error);
      alert("Failed to save general info");
    }
  };

  const handleSaveConfig = async () => {
    let normalizedInputPath = inputPath.trim();
    if (!normalizedInputPath) {
      alert("Input path cannot be empty");
      return;
    }
    if (!normalizedInputPath.startsWith('/')) {
      normalizedInputPath = `${BASE_DIR}/${normalizedInputPath}`;
    }
    if (normalizedInputPath.includes('.DS_Store')) {
      normalizedInputPath = normalizedInputPath.replace('/.DS_Store', '');
    }

    let normalizedOutputPath = outputPath.trim();
    if (!normalizedOutputPath) {
      normalizedOutputPath = `${BASE_DIR}/output_clips`;
    }
    if (!normalizedOutputPath.startsWith('/')) {
      normalizedOutputPath = `${BASE_DIR}/${normalizedOutputPath}`;
    }
    if (normalizedOutputPath.includes('.DS_Store')) {
      normalizedOutputPath = normalizedOutputPath.replace('/.DS_Store', '');
    }

    const data = {
      video_root: normalizedInputPath,
      output_path: normalizedOutputPath,
      db_path: "/Users/annhu/Downloads/V_Track project/events.db",
      default_days: defaultDays,
      min_packing_time: minPackingTime,
      max_packing_time: maxPackingTime,
      frame_rate: frameRate,
      frame_interval: frameInterval,
      video_buffer: videoBuffer,
      selected_cameras: selectedCameras,
    };
    console.log("Data sent to /save-config:", data);
    try {
      const response = await fetch("http://localhost:8080/save-config", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(data),
      });
      const result = await response.json();
      if (response.ok) {
        localStorage.setItem("configSet", "true");
        alert("Configuration saved successfully");
        setShowCameraDialog(false);
        const cameraResponse = await fetch("http://localhost:8080/get-cameras");
        const cameraData = await cameraResponse.json();
        if (cameraData && Array.isArray(cameraData.cameras)) {
          setCameras(cameraData.cameras.map(name => ({ name, path: "" })));
          setError(null);
        } else {
          setCameras([]);
          setError(cameraData?.error || "Failed to load cameras");
        }
      } else {
        throw new Error(result.error || "Failed to save config");
      }
    } catch (error) {
      console.error("Error saving config:", error);
      alert("Failed to save config: " + error.message);
    }
  };

  const handleShowCameraDialog = () => {
    setShowCameraDialog(true);
  };

  const handleCameraSelection = (cameraName) => {
    setSelectedCameras((prev) =>
      prev.includes(cameraName) ? prev.filter((c) => c !== cameraName) : [...prev, cameraName]
    );
  };

  return {
    fromTime,
    setFromTime,
    toTime,
    setToTime,
    country,
    setCountry,
    timezone,
    setTimezone,
    brandName,
    setBrandName,
    inputPath,
    setInputPath,
    outputPath,
    setOutputPath,
    workingDays,
    setWorkingDays,
    defaultDays,
    setDefaultDays,
    minPackingTime,
    setMinPackingTime,
    maxPackingTime,
    setMaxPackingTime,
    frameRate,
    setFrameRate,
    frameInterval,
    setFrameInterval,
    videoBuffer,
    setVideoBuffer,
    cameras,
    setCameras,
    selectedCameras,
    setSelectedCameras,
    showCameraDialog,
    setShowCameraDialog,
    error,
    setError,
    handleCountryChange,
    handleFromTimeChange,
    handleToTimeChange,
    handleWorkingDayChange,
    handleOpenExplorer,
    handleSaveGeneralInfo,
    handleSaveConfig,
    handleShowCameraDialog,
    handleCameraSelection,
    runDefaultOnStart,
    setRunDefaultOnStart,
  };
};

export default useVtrackConfig;
```
## üìÑ File: `useProgramLogic.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/hooks/useProgramLogic.js`

```javascript
import { useState, useEffect } from "react";
import { runProgram, confirmRun } from "../api";

const useProgramLogic = () => {
  const [runningCard, setRunningCard] = useState("M·∫∑c ƒë·ªãnh");
  const [fileList, setFileList] = useState([]);
  const [customPath, setCustomPath] = useState("");
  const [showConfirmButton, setShowConfirmButton] = useState(false);
  const [firstRunCompleted, setFirstRunCompleted] = useState(false);
  const [isLocked, setIsLocked] = useState(false);

  const checkFirstRun = async () => {
    try {
      const response = await fetch("http://localhost:8080/check-first-run");
      const data = await response.json();
      setFirstRunCompleted(data.first_run_completed);
    } catch (error) {
      console.error("Error checking first run:", error);
    }
  };

  const checkDefaultRunning = async () => {
    try {
      const response = await fetch("http://localhost:8080/program", {
        method: "GET",
      });
      const data = await response.json();
      setRunningCard("M·∫∑c ƒë·ªãnh"); // √âp M·∫∑c ƒë·ªãnh khi refresh
      setIsLocked(false);
    } catch (error) {
      console.error("Error checking default running state:", error);
      setRunningCard("M·∫∑c ƒë·ªãnh"); // √âp M·∫∑c ƒë·ªãnh n·∫øu l·ªói
      setIsLocked(false);
    }
  };

  useEffect(() => {
    const initializeState = async () => {
      await checkFirstRun();
      await checkDefaultRunning();
    };
    initializeState();
  }, []);

  const handleRunStop = async (cardTitle, path = "") => {
    if (cardTitle === "L·∫ßn ƒë·∫ßu" && firstRunCompleted) {
      return;
    }

    if (isLocked) {
      alert("H·ªá th·ªëng ƒëang x·ª≠ l√Ω, vui l√≤ng ƒë·ª£i!");
      return;
    }

    try {
      let days = null;
      if (cardTitle === "L·∫ßn ƒë·∫ßu" && !isRunning(cardTitle)) {
        days = prompt("B·∫°n mu·ªën x·ª≠ l√Ω bao nhi√™u ng√†y? (T·ªëi ƒëa 30 ng√†y)", "30");
        days = parseInt(days);
        if (isNaN(days) || days <= 0 || days > 30) {
          alert("S·ªë ng√†y kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p t·ª´ 1 ƒë·∫øn 30.");
          return;
        }
      } else if (cardTitle === "Ch·ªâ ƒë·ªãnh" && !isRunning(cardTitle)) {
        if (!path) {
          alert("Vui l√≤ng ch·ªçn ƒë∆∞·ªùng d·∫´n cho ch∆∞∆°ng tr√¨nh Ch·ªâ ƒë·ªãnh.");
          return;
        }
        setIsLocked(true);
      }

      const response = await runProgram({
        card: cardTitle,
        action: isRunning(cardTitle) ? "stop" : "run",
        days: days,
        custom_path: cardTitle === "Ch·ªâ ƒë·ªãnh" ? path : ""
      });

      if (response.status === 200) {
        if (isRunning(cardTitle)) {
          if (cardTitle === "M·∫∑c ƒë·ªãnh") {
            setRunningCard(null);
            setFileList([]);
            alert(`ƒê√£ d·ª´ng ch∆∞∆°ng tr√¨nh ${cardTitle}`);
          }
        } else {
          if (cardTitle !== "L·∫ßn ƒë·∫ßu" || !firstRunCompleted) {
            setRunningCard(cardTitle);
            setShowConfirmButton(true);
            if (cardTitle !== "Ch·ªâ ƒë·ªãnh") {
              setIsLocked(false);
            }
          }
        }
      }
    } catch (error) {
      console.error("Error calling API:", error);
      setIsLocked(false);
      if (error.response?.status === 400) {
        alert(error.response.data.error);
      } else {
        alert("C√≥ l·ªói x·∫£y ra khi g·ªçi API. Vui l√≤ng ki·ªÉm tra server.");
      }
    }
  };

  const handleConfirmRun = async () => {
    try {
      const response = await confirmRun({ card: runningCard });
      if (response.status === 200) {
        setShowConfirmButton(false);
        setFileList(response.data.files || []);
        if (runningCard === "L·∫ßn ƒë·∫ßu") {
          setFirstRunCompleted(true);
          await checkFirstRun();
        }
        if (runningCard === "Ch·ªâ ƒë·ªãnh") {
          setIsLocked(false);
          await checkDefaultRunning();
        }
      }
    } catch (error) {
      console.error("Error confirming run:", error);
      setIsLocked(false);
      alert("C√≥ l·ªói x·∫£y ra khi x√°c nh·∫≠n ch·∫°y ch∆∞∆°ng tr√¨nh.");
    }
  };

  const isRunning = (cardTitle) => runningCard === cardTitle;

  return {
    runningCard,
    setRunningCard,
    fileList,
    setFileList,
    customPath,
    setCustomPath,
    showConfirmButton,
    setShowConfirmButton,
    firstRunCompleted,
    setFirstRunCompleted,
    handleRunStop,
    handleConfirmRun,
    isRunning,
    isLocked
  };
};

export default useProgramLogic;
```
## üìÑ File: `useGoogleDrivePicker.js`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/frontend/src/hooks/useGoogleDrivePicker.js`

```javascript
// src/hooks/useGoogleDrivePicker.js
// Reusable hook for Google Drive Picker functionality
import { useState, useEffect, useCallback, useRef } from 'react';
import PICKER_CONFIG, { PICKER_BUILDERS, PICKER_UTILS } from '../config/GoogleDrivePickerConfig';

const useGoogleDrivePicker = (options = {}) => {
  const {
    multiSelect = true,
    userEmail = null,
    onFoldersSelected = null,
    onError = null,
    autoLoadApi = true
  } = options;

  // State management
  const [isApiLoaded, setIsApiLoaded] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState(null);
  const [pickerToken, setPickerToken] = useState(null);
  const [selectedFolders, setSelectedFolders] = useState([]);

  // Refs for cleanup
  const pickerRef = useRef(null);
  const tokenTimeoutRef = useRef(null);
  const apiLoadTimeoutRef = useRef(null);

  // Clear all timeouts on unmount
  useEffect(() => {
    return () => {
      if (tokenTimeoutRef.current) {
        clearTimeout(tokenTimeoutRef.current);
      }
      if (apiLoadTimeoutRef.current) {
        clearTimeout(apiLoadTimeoutRef.current);
      }
    };
  }, []);

  // Load Google Picker API
  const loadPickerApi = useCallback(() => {
    if (isApiLoaded || !window.gapi) return;

    const loadTimeout = setTimeout(() => {
      setError(PICKER_UTILS.getErrorMessage('apiLoadFailed'));
    }, PICKER_CONFIG.performance.apiLoadTimeout);

    apiLoadTimeoutRef.current = loadTimeout;

    window.gapi.load('picker', {
      callback: () => {
        clearTimeout(loadTimeout);
        setIsApiLoaded(true);
        setError(null);
        if (PICKER_CONFIG.development.enableConsoleLogging) {
          console.log('‚úÖ Google Picker API loaded successfully');
        }
      },
      onerror: (error) => {
        clearTimeout(loadTimeout);
        console.error('‚ùå Failed to load Google Picker API:', error);
        setError(PICKER_UTILS.getErrorMessage('apiLoadFailed'));
      }
    });
  }, [isApiLoaded]);

  // Auto-load API on mount
  useEffect(() => {
    if (autoLoadApi) {
      const checkAndLoad = () => {
        if (window.gapi) {
          loadPickerApi();
        } else {
          // Retry after delay if gapi not ready
          setTimeout(checkAndLoad, 1000);
        }
      };
      checkAndLoad();
    }
  }, [autoLoadApi, loadPickerApi]);

  // Get picker token from backend
  const getPickerToken = useCallback(async () => {
    try {
      setError(null);
      
      const response = await fetch(PICKER_CONFIG.api.tokenEndpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          provider: PICKER_CONFIG.api.provider,
          user_email: userEmail
        })
      });

      if (!response.ok) {
        const errorData = await response.json();
        
        // Handle specific error types
        if (response.status === 429) {
          throw new Error(PICKER_UTILS.getErrorMessage('rateLimitExceeded'));
        } else if (response.status === 401) {
          throw new Error(PICKER_UTILS.getErrorMessage('tokenExpired'));
        } else {
          throw new Error(errorData.message || PICKER_UTILS.getErrorMessage('serverError'));
        }
      }

      const tokenData = await response.json();
      
      if (!tokenData.success) {
        throw new Error(tokenData.message || PICKER_UTILS.getErrorMessage('tokenFailed'));
      }

      setPickerToken(tokenData.picker_token);
      
      // Set token refresh timer
      if (tokenData.expires_in) {
        const refreshTime = (tokenData.expires_in - 300) * 1000; // Refresh 5 min before expiry
        tokenTimeoutRef.current = setTimeout(() => {
          setPickerToken(null);
        }, refreshTime);
      }

      if (PICKER_CONFIG.development.enableConsoleLogging) {
        console.log('‚úÖ Picker token obtained successfully');
      }
      
      return tokenData.picker_token;
      
    } catch (error) {
      console.error('‚ùå Error getting picker token:', error);
      const errorMessage = error.message || PICKER_UTILS.getErrorMessage('tokenFailed');
      setError(errorMessage);
      
      if (onError) {
        onError(errorMessage);
      }
      
      return null;
    }
  }, [userEmail, onError]);

  // Handle picker callback
  const handlePickerCallback = useCallback((data) => {
    if (PICKER_CONFIG.development.enableConsoleLogging) {
      console.log('üîÑ Picker callback received:', data);
    }
    
    if (data.action === window.google.picker.Action.PICKED) {
      try {
        const selectedDocs = data.docs || [];
        
        // Format and validate selection
        const folders = PICKER_UTILS.formatFolderData(selectedDocs);
        const validation = PICKER_UTILS.validateSelection(folders);
        
        if (!validation.valid) {
          setError(validation.error);
          return;
        }

        setSelectedFolders(folders);
        setError(null);

        if (PICKER_CONFIG.development.enableConsoleLogging) {
          console.log(`‚úÖ Selected ${folders.length} folder(s):`, folders);
        }

        // Notify callbacks
        if (onFoldersSelected) {
          onFoldersSelected(folders);
        }

      } catch (error) {
        console.error('‚ùå Error processing picker selection:', error);
        const errorMessage = PICKER_UTILS.getErrorMessage('selectionProcessFailed', error.message);
        setError(errorMessage);
        
        if (onError) {
          onError(errorMessage);
        }
      }
    } else if (data.action === window.google.picker.Action.CANCEL) {
      if (PICKER_CONFIG.development.enableConsoleLogging) {
        console.log('üö´ Picker cancelled by user');
      }
      setError(null);
    }
  }, [onFoldersSelected, onError]);

  // Create picker instance
  const createPicker = useCallback((accessToken) => {
    if (!PICKER_UTILS.isApiReady()) {
      throw new Error(PICKER_UTILS.getErrorMessage('apiNotAvailable'));
    }

    try {
      const picker = PICKER_BUILDERS.createVTrackPicker(
        accessToken, 
        handlePickerCallback,
        {
          multiSelect,
          title: PICKER_CONFIG.picker.title
        }
      );

      pickerRef.current = picker;
      return picker;
      
    } catch (error) {
      console.error('‚ùå Error creating picker:', error);
      throw new Error(PICKER_UTILS.getErrorMessage('pickerCreateFailed', error.message));
    }
  }, [handlePickerCallback, multiSelect]);

  // Main function to open picker
  const openPicker = useCallback(async (isAuthenticated = true) => {
    if (!isAuthenticated) {
      const errorMessage = PICKER_UTILS.getErrorMessage('notAuthenticated');
      setError(errorMessage);
      if (onError) onError(errorMessage);
      return false;
    }

    if (!isApiLoaded) {
      const errorMessage = PICKER_UTILS.getErrorMessage('apiNotLoaded');
      setError(errorMessage);
      if (onError) onError(errorMessage);
      return false;
    }

    setIsLoading(true);
    setError(null);

    try {
      // Get fresh token if needed
      let token = pickerToken;
      if (!token) {
        token = await getPickerToken();
        if (!token) {
          setIsLoading(false);
          return false;
        }
      }

      // Create and show picker
      const picker = createPicker(token);
      
      if (PICKER_CONFIG.development.enableConsoleLogging) {
        console.log('üéØ Opening Google Drive Picker...');
      }
      
      picker.setVisible(true);
      return true;

    } catch (error) {
      console.error('‚ùå Error opening picker:', error);
      const errorMessage = error.message || PICKER_UTILS.getErrorMessage('pickerOpenFailed');
      setError(errorMessage);
      
      if (onError) {
        onError(errorMessage);
      }
      
      return false;
    } finally {
      setIsLoading(false);
    }
  }, [isApiLoaded, pickerToken, getPickerToken, createPicker, onError]);

  // Utility functions
  const clearError = useCallback(() => {
    setError(null);
  }, []);

  const clearSelection = useCallback(() => {
    setSelectedFolders([]);
    if (onFoldersSelected) {
      onFoldersSelected([]);
    }
  }, [onFoldersSelected]);

  const refreshToken = useCallback(async () => {
    setPickerToken(null);
    if (tokenTimeoutRef.current) {
      clearTimeout(tokenTimeoutRef.current);
    }
    return await getPickerToken();
  }, [getPickerToken]);

  const retryLastOperation = useCallback(async (isAuthenticated = true) => {
    setError(null);
    return await openPicker(isAuthenticated);
  }, [openPicker]);

  // Get current state summary
  const getState = useCallback(() => {
    return {
      isApiLoaded,
      isLoading,
      hasError: !!error,
      errorMessage: error,
      hasToken: !!pickerToken,
      selectedCount: selectedFolders.length,
      isReady: isApiLoaded && !isLoading && !error
    };
  }, [isApiLoaded, isLoading, error, pickerToken, selectedFolders.length]);

  // Return hook interface
  return {
    // State
    isApiLoaded,
    isLoading,
    error,
    selectedFolders,
    hasToken: !!pickerToken,

    // Actions
    openPicker,
    clearError,
    clearSelection,
    refreshToken,
    retryLastOperation,
    loadPickerApi,

    // Utilities
    getState,
    
    // Status helpers
    isReady: isApiLoaded && !isLoading && !error,
    canOpenPicker: isApiLoaded && !isLoading,
    
    // Config access
    config: PICKER_CONFIG
  };
};

export default useGoogleDrivePicker;
```
## üìÑ File: `debug_oauth_callback.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/debug_oauth_callback.py`

```python
#!/usr/bin/env python3
"""
Debug OAuth Callback Issues
Test OAuth callback handling and session management
"""

import os
import sys
import json

def check_callback_endpoint():
    """Test OAuth callback endpoint"""
    print("üîß Testing OAuth callback endpoint...")
    
    try:
        import requests
        
        # Test callback endpoint exists
        url = "http://localhost:8080/api/cloud/oauth/callback"
        
        # Test with GET request (Google will use GET)
        response = requests.get(f"{url}?error=test", timeout=5)
        
        print(f"üì° Callback endpoint status: {response.status_code}")
        
        if response.status_code == 200:
            print("‚úÖ Callback endpoint is accessible")
            return True
        else:
            print(f"‚ùå Callback endpoint error: {response.status_code}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("‚ùå Cannot connect to backend - is it running?")
        return False
    except Exception as e:
        print(f"‚ùå Callback test error: {e}")
        return False

def check_session_management():
    """Test session management"""
    print("\nüîß Testing session management...")
    
    try:
        from modules.sources.cloud_auth import CloudAuthManager
        
        auth_manager = CloudAuthManager('google_drive')
        
        # Test OAuth initiation
        redirect_uri = 'http://localhost:8080/api/cloud/oauth/callback'
        result = auth_manager.initiate_oauth_flow(redirect_uri)
        
        if result['success']:
            print("‚úÖ OAuth initiation successful")
            
            session_id = result['session_id']
            state = result['state']
            
            print(f"üìã Session ID: {session_id[:20]}...")
            print(f"üìã State: {state[:20]}...")
            
            # Check if session is stored
            if session_id in auth_manager.auth_sessions:
                print("‚úÖ Session stored successfully")
                return True
            else:
                print("‚ùå Session not found in storage")
                return False
        else:
            print(f"‚ùå OAuth initiation failed: {result['message']}")
            return False
            
    except Exception as e:
        print(f"‚ùå Session test error: {e}")
        return False

def check_google_credentials():
    """Check Google credentials redirect URI"""
    print("\nüîß Checking Google credentials...")
    
    creds_path = "modules/sources/credentials/google_drive_credentials.json"
    
    if not os.path.exists(creds_path):
        print(f"‚ùå Credentials file not found: {creds_path}")
        return False
    
    try:
        with open(creds_path, 'r') as f:
            creds = json.load(f)
        
        if 'installed' in creds:
            redirect_uris = creds['installed'].get('redirect_uris', [])
            
            print(f"üìç Configured redirect URIs:")
            for uri in redirect_uris:
                print(f"   ‚Ä¢ {uri}")
            
            # Check for required callback URI
            callback_uri = "http://localhost:8080/api/cloud/oauth/callback"
            
            if callback_uri in redirect_uris:
                print("‚úÖ Callback URI configured correctly")
                return True
            else:
                print(f"‚ùå Missing callback URI: {callback_uri}")
                print("üí° Add this URI to Google Cloud Console")
                return False
        else:
            print("‚ùå Invalid credentials format")
            return False
            
    except Exception as e:
        print(f"‚ùå Credentials check error: {e}")
        return False

def fix_redirect_uri():
    """Fix redirect URI in credentials"""
    print("\nüîß Fixing redirect URI...")
    
    creds_path = "modules/sources/credentials/google_drive_credentials.json"
    
    try:
        with open(creds_path, 'r') as f:
            creds = json.load(f)
        
        # Add callback URI
        callback_uri = "http://localhost:8080/api/cloud/oauth/callback"
        
        if 'installed' in creds:
            current_uris = creds['installed'].get('redirect_uris', [])
            
            if callback_uri not in current_uris:
                # Add callback URI
                new_uris = current_uris + [callback_uri]
                creds['installed']['redirect_uris'] = new_uris
                
                # Backup and save
                backup_path = creds_path + ".backup"
                with open(backup_path, 'w') as f:
                    json.dump(creds, f, indent=2)
                
                with open(creds_path, 'w') as f:
                    json.dump(creds, f, indent=2)
                
                print(f"‚úÖ Added callback URI: {callback_uri}")
                print(f"‚úÖ Backup saved: {backup_path}")
                return True
            else:
                print("‚úÖ Callback URI already configured")
                return True
        else:
            print("‚ùå Cannot fix - invalid credentials format")
            return False
            
    except Exception as e:
        print(f"‚ùå Fix failed: {e}")
        return False

def test_complete_flow():
    """Test complete OAuth flow simulation"""
    print("\nüîß Testing complete OAuth flow...")
    
    try:
        # Simulate auth request
        import requests
        
        auth_url = "http://localhost:8080/api/cloud/authenticate"
        auth_data = {
            "provider": "google_drive",
            "action": "initiate_auth"
        }
        
        auth_response = requests.post(auth_url, json=auth_data, timeout=10)
        
        print(f"üì° Auth response: {auth_response.status_code}")
        
        if auth_response.status_code == 200:
            auth_result = auth_response.json()
            
            if auth_result.get('success'):
                print("‚úÖ OAuth initiation successful")
                print(f"üîó Auth URL generated: {len(auth_result.get('auth_url', ''))} chars")
                return True
            else:
                print(f"‚ùå Auth failed: {auth_result.get('message')}")
                return False
        else:
            print(f"‚ùå Auth request failed: {auth_response.status_code}")
            return False
            
    except Exception as e:
        print(f"‚ùå Complete flow test error: {e}")
        return False

def main():
    """Main debug function"""
    print("=" * 60)
    print("üîß OAuth Callback Debug")
    print("=" * 60)
    
    tests = [
        ("Callback Endpoint", check_callback_endpoint),
        ("Session Management", check_session_management),
        ("Google Credentials", check_google_credentials),
        ("Complete Flow", test_complete_flow)
    ]
    
    passed = 0
    failed_tests = []
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            if test_func():
                passed += 1
                print(f"‚úÖ {test_name}: PASSED")
            else:
                print(f"‚ùå {test_name}: FAILED")
                failed_tests.append(test_name)
        except Exception as e:
            print(f"‚ùå {test_name}: CRASHED - {e}")
            failed_tests.append(test_name)
    
    # Summary
    print("\n" + "=" * 60)
    print(f"üìä DEBUG SUMMARY: {passed}/{len(tests)} tests passed")
    print("=" * 60)
    
    if "Google Credentials" in failed_tests:
        print("\nüîß QUICK FIX AVAILABLE:")
        response = input("Fix redirect URI in credentials file? (y/N): ")
        if response.lower() == 'y':
            fix_redirect_uri()
            print("\n‚úÖ Credentials fixed! Restart backend and try again.")
    
    if passed == len(tests):
        print("üéâ All tests passed! OAuth should work.")
    else:
        print("üîß Fix issues above and retry authentication.")

if __name__ == "__main__":
    main()
```
## üìÑ File: `fix_oauth_callback.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/fix_oauth_callback.py`

```python
#!/usr/bin/env python3
"""
Fix OAuth Callback Session Issues
Patch cloud_endpoints.py to handle session state validation more flexibly
"""

import os
import re

def fix_oauth_callback_validation():
    """Fix OAuth callback session validation"""
    
    endpoint_file = "modules/sources/cloud_endpoints.py"
    
    if not os.path.exists(endpoint_file):
        print(f"‚ùå File not found: {endpoint_file}")
        return False
    
    print("üîß Fixing OAuth callback session validation...")
    
    try:
        # Read current file
        with open(endpoint_file, 'r') as f:
            content = f.read()
        
        # Backup original
        backup_file = endpoint_file + ".backup"
        with open(backup_file, 'w') as f:
            f.write(content)
        print(f"‚úÖ Backup created: {backup_file}")
        
        # Find and replace the strict validation
        old_validation = """        # Get session info
        session_id = session.get('oauth_session_id')
        expected_state = session.get('oauth_state')
        
        if not session_id or state != expected_state:
            logger.error("‚ùå Invalid session or state mismatch")
            return f\"""
            <html>
                <head><title>VTrack - Authentication Failed</title></head>
                <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                    <h1 style="color: #dc3545;">‚ùå Authentication Failed</h1>
                    <p>Invalid session or security token mismatch.</p>
                    <p>Please close this window and try again.</p>
                    <script>
                        setTimeout(function() {{
                            window.close();
                        }}, 3000);
                    </script>
                </body>
            </html>
            \""", 400"""
        
        # More flexible validation
        new_validation = """        # Get session info
        session_id = session.get('oauth_session_id')
        expected_state = session.get('oauth_state')
        
        # More flexible session validation
        if not session_id:
            logger.warning("‚ö†Ô∏è No session ID found, checking active sessions...")
            # Find any active session as fallback
            from modules.sources.cloud_auth import CloudAuthManager
            auth_manager = CloudAuthManager(provider='google_drive')
            if auth_manager.auth_sessions:
                session_id = list(auth_manager.auth_sessions.keys())[0]
                logger.info(f"‚úÖ Using fallback session: {session_id}")
            else:
                logger.error("‚ùå No active OAuth sessions found")
                return f\"""
                <html>
                    <head><title>VTrack - Authentication Failed</title></head>
                    <body style="font-family: Arial, sans-serif; text-align: center; padding: 50px;">
                        <h1 style="color: #dc3545;">‚ùå Authentication Failed</h1>
                        <p>No active OAuth session found.</p>
                        <p>Please close this window and try again.</p>
                        <script>
                            setTimeout(function() {{
                                window.close();
                            }}, 3000);
                        </script>
                    </body>
                </html>
                \""", 400
        
        # Relaxed state validation
        if expected_state and state != expected_state:
            logger.warning(f"‚ö†Ô∏è State mismatch: expected {expected_state[:10]}..., got {state[:10]}...")
            logger.warning("‚ö†Ô∏è Proceeding with relaxed validation...")"""
        
        # Apply the fix
        if old_validation in content:
            content = content.replace(old_validation, new_validation)
            print("‚úÖ Applied relaxed session validation")
        else:
            print("‚ö†Ô∏è Could not find exact validation code - applying alternative fix")
            
            # Alternative fix: comment out strict validation
            content = re.sub(
                r'if not session_id or state != expected_state:.*?return.*?, 400',
                '# Relaxed validation - session check disabled for development',
                content,
                flags=re.DOTALL
            )
        
        # Write updated file
        with open(endpoint_file, 'w') as f:
            f.write(content)
        
        print(f"‚úÖ OAuth callback validation fixed in: {endpoint_file}")
        return True
        
    except Exception as e:
        print(f"‚ùå Fix failed: {e}")
        return False

def add_debug_logging():
    """Add debug logging to OAuth callback"""
    
    endpoint_file = "modules/sources/cloud_endpoints.py"
    
    try:
        with open(endpoint_file, 'r') as f:
            content = f.read()
        
        # Add debug logging after parameter extraction
        debug_code = """        
        # üîß DEBUG: Log OAuth callback parameters
        logger.info(f"üîç OAuth callback debug:")
        logger.info(f"   Code: {code[:20] if code else 'None'}...")
        logger.info(f"   State: {state[:20] if state else 'None'}...")
        logger.info(f"   Session ID: {session.get('oauth_session_id', 'None')}")
        logger.info(f"   Expected State: {session.get('oauth_state', 'None')[:20] if session.get('oauth_state') else 'None'}...")
        """
        
        # Insert debug code after parameter extraction
        insertion_point = 'error = request.args.get(\'error\')'
        if insertion_point in content:
            content = content.replace(insertion_point, insertion_point + debug_code)
            
            with open(endpoint_file, 'w') as f:
                f.write(content)
            
            print("‚úÖ Added debug logging to OAuth callback")
            return True
        else:
            print("‚ö†Ô∏è Could not add debug logging - insertion point not found")
            return False
            
    except Exception as e:
        print(f"‚ùå Debug logging failed: {e}")
        return False

def main():
    """Main fix function"""
    print("üîß Fixing OAuth Callback Issues")
    print("=" * 40)
    
    # Fix 1: Relaxed session validation
    if fix_oauth_callback_validation():
        print("‚úÖ OAuth callback validation fixed")
    else:
        print("‚ùå OAuth callback validation fix failed")
    
    # Fix 2: Add debug logging
    if add_debug_logging():
        print("‚úÖ Debug logging added")
    else:
        print("‚ùå Debug logging failed")
    
    print("\nüöÄ Next steps:")
    print("1. Restart backend: python app.py")
    print("2. Test authentication in browser")
    print("3. Check backend logs for detailed OAuth flow")
    print("4. If still issues, check browser console for errors")

if __name__ == "__main__":
    main()
```
## üìÑ File: `test_hikvision_real.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/test_hikvision_real.py`

```python
#!/usr/bin/env python3
"""
Test Hikvision RTSP on port 8000
"""

print("üéØ HIKVISION PORT 8000 RTSP TEST")

import socket
import subprocess
from datetime import datetime
from pathlib import Path

def test_rtsp_on_port_8000():
    """Test RTSP on port 8000 with different URL patterns"""
    print("\n=== RTSP ON PORT 8000 TEST ===")
    
    host = "192.168.1.54"
    port = 8000
    username = "binhnguyen041280"
    password = "@Ezv024819"
    
    print(f"Testing RTSP on port {port}")
    
    # Different RTSP URL patterns for port 8000
    rtsp_patterns = [
        # Standard patterns on port 8000
        f"rtsp://{username}:{password}@{host}:{port}/h264/ch1/main/av_stream",
        f"rtsp://{username}:{password}@{host}:{port}/h264/ch1/sub/av_stream",
        f"rtsp://{username}:{password}@{host}:{port}/Streaming/Channels/101",
        f"rtsp://{username}:{password}@{host}:{port}/Streaming/Channels/102",
        f"rtsp://{username}:{password}@{host}:{port}/Streaming/Channels/1",
        f"rtsp://{username}:{password}@{host}:{port}/cam/realmonitor?channel=1&subtype=0",
        f"rtsp://{username}:{password}@{host}:{port}/cam/realmonitor?channel=1&subtype=1",
        f"rtsp://{username}:{password}@{host}:{port}/stream1",
        f"rtsp://{username}:{password}@{host}:{port}/stream2",
        f"rtsp://{username}:{password}@{host}:{port}/live/main",
        f"rtsp://{username}:{password}@{host}:{port}/live/sub",
        f"rtsp://{username}:{password}@{host}:{port}/ch1/main",
        f"rtsp://{username}:{password}@{host}:{port}/ch1/sub",
        f"rtsp://{username}:{password}@{host}:{port}/av_stream",
        f"rtsp://{username}:{password}@{host}:{port}/",
        
        # Try with different username formats
        f"rtsp://admin:{password}@{host}:{port}/h264/ch1/main/av_stream",
        f"rtsp://admin:{password}@{host}:{port}/Streaming/Channels/101",
        f"rtsp://user:{password}@{host}:{port}/h264/ch1/main/av_stream",
        
        # Try with email as username
        f"rtsp://binhnguyen041280@gmail.com:{password}@{host}:{port}/h264/ch1/main/av_stream",
        f"rtsp://binhnguyen041280@gmail.com:{password}@{host}:{port}/Streaming/Channels/101"
    ]
    
    # Create target directory
    target_dir = Path("/Users/annhu/vtrack_app/V_Track/nvr_downloads/nvr_localhost/Front_Door_Camera")
    target_dir.mkdir(parents=True, exist_ok=True)
    
    # Check ffmpeg
    try:
        ffmpeg_check = subprocess.run(['which', 'ffmpeg'], capture_output=True)
        if ffmpeg_check.returncode != 0:
            print("‚ùå ffmpeg not found. Install with: brew install ffmpeg")
            return False
        else:
            print("‚úÖ ffmpeg found")
    except Exception as e:
        print(f"‚ùå ffmpeg check error: {e}")
        return False
    
    # Test each RTSP pattern
    for i, rtsp_url in enumerate(rtsp_patterns, 1):
        try:
            print(f"\nüîç Test {i}/{len(rtsp_patterns)}: {rtsp_url.replace(password, '***')}")
            
            output_file = target_dir / f"hikvision_port8000_test{i}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
            
            # FFmpeg command with more options for troubleshooting
            cmd = [
                'ffmpeg',
                '-rtsp_transport', 'tcp',
                '-i', rtsp_url,
                '-t', '3',  # 3 seconds for faster testing
                '-c', 'copy',
                '-avoid_negative_ts', 'make_zero',
                '-y',
                str(output_file)
            ]
            
            print(f"   üé¨ Attempting 3-second capture...")
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=15
            )
            
            if result.returncode == 0:
                if output_file.exists():
                    file_size = output_file.stat().st_size
                    if file_size > 0:
                        print(f"   üéâ SUCCESS! RTSP stream working!")
                        print(f"   üìÅ File: {output_file}")
                        print(f"   üìä Size: {file_size} bytes")
                        print(f"   ‚úÖ Working RTSP URL: {rtsp_url.replace(password, '***')}")
                        
                        # Continue testing other patterns to find all working ones
                        continue
                    else:
                        print(f"   ‚ö†Ô∏è File created but empty")
                        output_file.unlink()  # Remove empty file
                else:
                    print(f"   ‚ùå No output file created")
            else:
                print(f"   ‚ùå FFmpeg failed (return code: {result.returncode})")
                
                # Show specific error for debugging
                if result.stderr:
                    error_lines = result.stderr.strip().split('\n')
                    # Show last few lines of error
                    relevant_errors = [line for line in error_lines if any(keyword in line.lower() for keyword in ['error', 'failed', 'connection', 'refused', 'timeout'])]
                    if relevant_errors:
                        print(f"   üìù Error: {relevant_errors[-1][:100]}...")
                
        except subprocess.TimeoutExpired:
            print(f"   ‚è∞ Timeout after 15 seconds")
            
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            
    # Check results
    files = list(target_dir.glob('hikvision_port8000_test*.mp4'))
    working_files = [f for f in files if f.stat().st_size > 0]
    
    if working_files:
        print(f"\nüéâ SUCCESS! Found {len(working_files)} working RTSP streams!")
        print(f"üìÅ Files saved to: {target_dir}")
        for file in working_files:
            print(f"   - {file.name} ({file.stat().st_size} bytes)")
        return True
    else:
        print(f"\n‚ùå No working RTSP streams found on port 8000")
        return False

def test_http_streaming():
    """Test HTTP streaming endpoints"""
    print("\n=== HTTP STREAMING TEST ===")
    
    host = "192.168.1.54"
    port = 8000
    username = "binhnguyen041280"
    password = "@Ezv024819"
    
    # HTTP streaming endpoints
    http_endpoints = [
        f"http://{host}:{port}/ISAPI/Streaming/channels/101/httppreview",
        f"http://{host}:{port}/ISAPI/Streaming/channels/102/httppreview",
        f"http://{host}:{port}/ISAPI/Streaming/channels/1/httppreview",
        f"http://{host}:{port}/cgi-bin/snapshot.cgi",
        f"http://{host}:{port}/snapshot.cgi",
        f"http://{host}:{port}/video.cgi",
        f"http://{host}:{port}/videostream.cgi",
        f"http://{host}:{port}/axis-cgi/mjpg/video.cgi",
        f"http://{host}:{port}/mjpg/video.mjpg"
    ]
    
    import requests
    
    for endpoint in http_endpoints:
        try:
            print(f"üîç Testing HTTP: {endpoint}")
            
            response = requests.get(
                endpoint,
                auth=(username, password),
                timeout=5,
                stream=True
            )
            
            if response.status_code == 200:
                print(f"   ‚úÖ HTTP endpoint accessible")
                print(f"   üìù Content-Type: {response.headers.get('content-type', 'unknown')}")
                
                # If it's a video stream, try to save some data
                if 'video' in response.headers.get('content-type', '').lower():
                    target_dir = Path("/Users/annhu/vtrack_app/V_Track/nvr_downloads/nvr_localhost/Front_Door_Camera")
                    target_dir.mkdir(parents=True, exist_ok=True)
                    
                    output_file = target_dir / f"http_stream_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
                    
                    try:
                        with open(output_file, 'wb') as f:
                            for chunk in response.iter_content(chunk_size=8192):
                                f.write(chunk)
                                # Just get first few chunks for testing
                                if f.tell() > 1024 * 1024:  # 1MB
                                    break
                        
                        if output_file.exists() and output_file.stat().st_size > 0:
                            print(f"   üéâ HTTP stream data saved: {output_file}")
                            print(f"   üìä Size: {output_file.stat().st_size} bytes")
                            
                    except Exception as save_error:
                        print(f"   ‚ùå Save error: {save_error}")
                        
            else:
                print(f"   ‚ùå Status: {response.status_code}")
                
        except Exception as e:
            print(f"   ‚ùå Error: {e}")

if __name__ == "__main__":
    print("=" * 70)
    print("Device: 192.168.1.54:8000")
    print("Username: binhnguyen041280")
    print("Password: @Ezv024819")
    print("=" * 70)
    
    try:
        # Test RTSP on port 8000
        rtsp_success = test_rtsp_on_port_8000()
        
        # Test HTTP streaming
        test_http_streaming()
        
        if rtsp_success:
            print("\nüéâ HIKVISION STREAMING SUCCESSFUL!")
            print("‚úÖ Device can stream video via RTSP on port 8000")
            print("‚úÖ Can be integrated with VTrack")
            
            # Show VTrack configuration
            print(f"\nüìù VTRACK CONFIGURATION:")
            print(f"   Host: 192.168.1.54")
            print(f"   Port: 8000")
            print(f"   Username: binhnguyen041280")
            print(f"   Password: @Ezv024819")
            print(f"   Protocol: RTSP (Custom Port)")
            
        else:
            print("\n‚ö†Ô∏è RTSP streaming failed")
            print("‚ùå Device may not support RTSP streaming")
            print("‚ùå Check device configuration or credentials")
            
    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 70)
    print("Test completed")
```
## üìÑ File: `database.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/database.py`

```python
import sqlite3
import os
import json
from modules.db_utils import find_project_root
import time
from datetime import datetime, timedelta

# X√°c ƒë·ªãnh th∆∞ m·ª•c g·ªëc c·ªßa d·ª± √°n
BASE_DIR = find_project_root(os.path.abspath(__file__))

# ƒê∆∞·ªùng d·∫´n c∆° s·ªü d·ªØ li·ªáu
DB_DIR = os.path.join(BASE_DIR, "backend/database")
DB_PATH = os.path.join(DB_DIR, "events.db")

# ƒê∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh
INPUT_VIDEO_DIR = os.path.join(BASE_DIR, "resources/Inputvideo")
OUTPUT_CLIPS_DIR = os.path.join(BASE_DIR, "resources/output_clips")

def get_db_connection():
    """
    Get DB connection with retry logic for locked database and enhanced WAL config
    """
    for attempt in range(5):  # Retry t·ªëi ƒëa 5 l·∫ßn
        try:
            conn = sqlite3.connect(DB_PATH, timeout=60.0)  # TƒÉng timeout l√™n 60 gi√¢y
            conn.execute("PRAGMA busy_timeout = 60000")   # Busy timeout 60s
            conn.execute("PRAGMA journal_mode = WAL")     # WAL mode cho concurrent reads/writes
            conn.execute("PRAGMA synchronous = NORMAL")   # Balanced sync (nhanh h∆°n FULL)
            conn.execute("PRAGMA temp_store = MEMORY")    # Temp data in memory (tƒÉng speed)
            conn.execute("PRAGMA foreign_keys = ON")      # Enforce FK n·∫øu c·∫ßn
            print(f"‚úÖ DB connection success (attempt {attempt+1})")  # Debug log
            return conn
        except sqlite3.OperationalError as e:
            if "database is locked" in str(e) and attempt < 4:
                print(f"‚ö†Ô∏è DB locked, retrying in 2s... (attempt {attempt+1}/5)")
                time.sleep(2)  # Wait 2 gi√¢y tr∆∞·ªõc retry (tƒÉng t·ª´ 1s ƒë·ªÉ an to√†n)
                continue
            raise e  # Raise error n·∫øu h·∫øt retry
    raise sqlite3.OperationalError("Database locked after max retries")

def update_database():
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        # T·∫°o b·∫£ng file_list
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS file_list (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                program_type TEXT NOT NULL,
                days INTEGER,
                custom_path TEXT,
                file_path TEXT NOT NULL,
                ctime DATETIME,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                is_processed INTEGER DEFAULT 0,
                priority INTEGER DEFAULT 0,
                status TEXT DEFAULT 'ch∆∞a b·∫Øt ƒë·∫ßu',
                log_file_path TEXT,
                camera_name TEXT
            )
        """)

        # T·∫°o b·∫£ng program_status
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS program_status (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                key TEXT NOT NULL UNIQUE,
                value TEXT NOT NULL
            )
        """)
        cursor.execute("SELECT COUNT(*) FROM program_status WHERE key = 'first_run_completed'")
        if cursor.fetchone()[0] == 0:
            cursor.execute("INSERT INTO program_status (key, value) VALUES ('first_run_completed', 'false')")

        # T·∫°o b·∫£ng processing_config
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS processing_config (
                id INTEGER PRIMARY KEY,
                input_path TEXT,
                output_path TEXT,
                storage_duration INTEGER,
                min_packing_time INTEGER,
                max_packing_time INTEGER,
                frame_rate INTEGER,
                frame_interval INTEGER,
                video_buffer INTEGER,
                default_frame_mode TEXT,
                selected_cameras TEXT,
                db_path TEXT NOT NULL,
                run_default_on_start INTEGER DEFAULT 0,
                motion_threshold FLOAT DEFAULT 0.1,
                stable_duration_sec FLOAT DEFAULT 1
            )
        """)
        cursor.execute("UPDATE processing_config SET db_path = ?, run_default_on_start = 0 WHERE db_path IS NULL OR run_default_on_start IS NULL", (DB_PATH,))

        # üÜï PHASE 4: Add camera_paths column to processing_config
        try:
            cursor.execute("ALTER TABLE processing_config ADD COLUMN camera_paths TEXT DEFAULT '{}'")
            print("‚úÖ Added camera_paths column to processing_config")
        except sqlite3.OperationalError:
            pass  # Column already exists

        # Th√™m c·ªôt multiple_sources_enabled n·∫øu ch∆∞a c√≥
        try:
            cursor.execute("ALTER TABLE processing_config ADD COLUMN multiple_sources_enabled INTEGER DEFAULT 0")
        except sqlite3.OperationalError:
            pass  # C·ªôt ƒë√£ t·ªìn t·∫°i

        # Ch√®n d·ªØ li·ªáu m·∫∑c ƒë·ªãnh n·∫øu b·∫£ng processing_config r·ªóng
        cursor.execute("SELECT COUNT(*) FROM processing_config")
        if cursor.fetchone()[0] == 0:
            cursor.execute("""
                INSERT INTO processing_config (
                    id, input_path, output_path, storage_duration, min_packing_time, 
                    max_packing_time, frame_rate, frame_interval, video_buffer, default_frame_mode, 
                    selected_cameras, db_path, run_default_on_start, multiple_sources_enabled, camera_paths
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (1, INPUT_VIDEO_DIR, OUTPUT_CLIPS_DIR, 30, 10, 120, 30, 5, 2, "default", "[]", DB_PATH, 0, 0, "{}"))

        # üÜï PHASE 4: Create sync_status table for auto-sync management
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS sync_status (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_id INTEGER NOT NULL,
                sync_enabled INTEGER DEFAULT 1,
                last_sync_timestamp TEXT,
                next_sync_timestamp TEXT,
                sync_interval_minutes INTEGER DEFAULT 10,
                last_sync_status TEXT DEFAULT 'pending',
                last_sync_message TEXT,
                files_downloaded_count INTEGER DEFAULT 0,
                total_download_size_mb REAL DEFAULT 0.0,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (source_id) REFERENCES video_sources (id) ON DELETE CASCADE,
                UNIQUE(source_id)
            )
        """)
        print("‚úÖ Created sync_status table")

        # üÜï PHASE 4: Create downloaded_files table for tracking downloaded content
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS downloaded_files (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_id INTEGER NOT NULL,
                camera_name TEXT NOT NULL,
                original_filename TEXT,
                local_file_path TEXT NOT NULL,
                file_size_bytes INTEGER DEFAULT 0,
                download_timestamp TEXT DEFAULT CURRENT_TIMESTAMP,
                recording_start_time TEXT,
                recording_end_time TEXT,
                file_format TEXT,
                checksum TEXT,
                sync_batch_id TEXT,
                is_processed INTEGER DEFAULT 0,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (source_id) REFERENCES video_sources (id) ON DELETE CASCADE
            )
        """)
        print("‚úÖ Created downloaded_files table")

        # üÜï PHASE 4 OPTIMIZED: Create last_downloaded_file table for efficient tracking
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS last_downloaded_file (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_id INTEGER NOT NULL,
                camera_name TEXT NOT NULL,
                last_filename TEXT,
                last_file_timestamp TEXT,
                last_download_time TEXT DEFAULT CURRENT_TIMESTAMP,
                total_files_count INTEGER DEFAULT 0,
                total_size_mb REAL DEFAULT 0.0,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (source_id) REFERENCES video_sources (id) ON DELETE CASCADE,
                UNIQUE(source_id, camera_name)
            )
        """)
        print("‚úÖ Created last_downloaded_file table")

        # Create indexes for performance
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_sync_status_source_id ON sync_status(source_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_sync_status_next_sync ON sync_status(next_sync_timestamp)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_downloaded_files_source_camera ON downloaded_files(source_id, camera_name)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_downloaded_files_timestamp ON downloaded_files(download_timestamp)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_downloaded_files_processed ON downloaded_files(is_processed)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_last_downloaded_source_camera ON last_downloaded_file(source_id, camera_name)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_last_downloaded_timestamp ON last_downloaded_file(last_file_timestamp)")
   
        # T·∫°o b·∫£ng frame_settings
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS frame_settings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                mode TEXT NOT NULL,
                frame_rate INTEGER,
                frame_interval INTEGER,
                description TEXT
            )
        """)
        cursor.execute("SELECT COUNT(*) FROM frame_settings")
        if cursor.fetchone()[0] == 0:
            cursor.execute("""
                INSERT INTO frame_settings (mode, frame_rate, frame_interval, description)
                VALUES (?, ?, ?, ?)
            """, ("default", 30, 5, "Ch·∫ø ƒë·ªô m·∫∑c ƒë·ªãnh t·ª´ giao di·ªán"))

        # T·∫°o b·∫£ng general_info v·ªõi working_days d·∫°ng JSON ti·∫øng Anh
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS general_info (
                id INTEGER PRIMARY KEY,
                country TEXT,
                timezone TEXT,
                brand_name TEXT,
                working_days TEXT,
                from_time TEXT,
                to_time TEXT
            )
        """)
        cursor.execute("SELECT COUNT(*) FROM general_info")
        if cursor.fetchone()[0] == 0:
            working_days = json.dumps(["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"])
            cursor.execute("""
                INSERT INTO general_info (
                    id, country, timezone, brand_name, working_days, from_time, to_time
                ) VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (1, "Vi·ªát Nam", "UTC+7", "MyBrand", working_days, "07:00", "23:00"))

        # T·∫°o b·∫£ng events
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS events (
                event_id INTEGER PRIMARY KEY AUTOINCREMENT,
                ts INTEGER,
                te INTEGER,
                duration INTEGER,
                tracking_codes TEXT,
                video_file TEXT NOT NULL,
                buffer INTEGER NOT NULL,
                camera_name TEXT,
                packing_time_start INTEGER,
                packing_time_end INTEGER,
                is_processed INTEGER DEFAULT 0,
                processed_timestamp INTEGER,
                output_video_path TEXT,
                session_id TEXT,
                output_file TEXT
            )
        """)
        # T·∫°o ch·ªâ m·ª•c tr√™n te v√† event_id
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_events_te_event_id ON events(te, event_id)")

        # T·∫°o b·∫£ng processed_logs
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS processed_logs (
                log_file TEXT PRIMARY KEY,
                processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                is_processed INTEGER DEFAULT 0
            )
        """)

        # T·∫°o b·∫£ng packing_profiles
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS packing_profiles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                profile_name TEXT NOT NULL,
                qr_trigger_area TEXT,
                qr_motion_area TEXT,
                qr_mvd_area TEXT,
                packing_area TEXT,
                min_packing_time INTEGER,
                jump_time_ratio REAL,
                mvd_jump_ratio REAL,
                scan_mode TEXT,
                fixed_threshold INTEGER,
                margin INTEGER,
                additional_params TEXT
            )
        """)

        # T·∫°o b·∫£ng video_sources
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS video_sources (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_type TEXT NOT NULL,
                name TEXT NOT NULL,
                path TEXT NOT NULL,
                config TEXT,
                active INTEGER DEFAULT 1,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                folder_depth INTEGER DEFAULT 0,
                parent_folder_id TEXT
            )
        """)
        # üÜï PHASE 1: Add folder depth tracking columns
        try:
            cursor.execute("ALTER TABLE video_sources ADD COLUMN folder_depth INTEGER DEFAULT 0")
            print("‚úÖ Added folder_depth column to video_sources")
        except sqlite3.OperationalError:
            pass  # Column already exists

        try:
            cursor.execute("ALTER TABLE video_sources ADD COLUMN parent_folder_id TEXT")
            print("‚úÖ Added parent_folder_id column to video_sources")
        except sqlite3.OperationalError:
            pass  # Column already exists
        # üÜï PHASE 1: Create indexes for lazy folder tree (AFTER column migration)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_video_sources_folder_depth ON video_sources(folder_depth)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_video_sources_parent_folder ON video_sources(parent_folder_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_video_sources_source_type_active ON video_sources(source_type, active)")
        print("‚úÖ Created indexes for lazy folder tree performance")

        # T√≠ch h·ª£p migration Phase 3: Multiple Camera Support

        # 1. Update index cho video_sources
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_video_sources_active ON video_sources(active)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_video_sources_source_type ON video_sources(source_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_video_sources_created_at ON video_sources(created_at)")

        # 3. T·∫°o table camera_configurations
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS camera_configurations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                source_id INTEGER NOT NULL,
                camera_name TEXT NOT NULL,
                camera_config TEXT, -- JSON config specific to this camera
                is_selected INTEGER DEFAULT 1,
                folder_path TEXT, -- Local folder path for this camera
                stream_url TEXT, -- RTSP/stream URL if applicable
                resolution TEXT,
                codec TEXT,
                capabilities TEXT, -- JSON array of capabilities
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (source_id) REFERENCES video_sources (id) ON DELETE CASCADE,
                UNIQUE(source_id, camera_name)
            )
        """)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_camera_configurations_source_id ON camera_configurations(source_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_camera_configurations_selected ON camera_configurations(is_selected)")

        # 7. Create view active_cameras
        cursor.execute("""
            CREATE VIEW IF NOT EXISTS active_cameras AS
            SELECT 
                vs.id as source_id,
                vs.name as source_name,
                vs.source_type,
                vs.path as source_path,
                cc.camera_name,
                cc.folder_path,
                cc.stream_url,
                cc.resolution,
                cc.codec,
                cc.capabilities,
                cc.is_selected
            FROM video_sources vs
            LEFT JOIN camera_configurations cc ON vs.id = cc.source_id
            WHERE vs.active = 1 AND cc.is_selected = 1
        """)

        # 8. Create trigger update_camera_configurations_timestamp
        cursor.execute("""
            CREATE TRIGGER IF NOT EXISTS update_camera_configurations_timestamp
            AFTER UPDATE ON camera_configurations
            FOR EACH ROW
            BEGIN
                UPDATE camera_configurations SET updated_at = CURRENT_TIMESTAMP WHERE id = NEW.id;
            END
        """)

        # üÜï PHASE 4: Create trigger to update sync_status timestamp
        cursor.execute("""
            CREATE TRIGGER IF NOT EXISTS update_sync_status_timestamp
            AFTER UPDATE ON sync_status
            FOR EACH ROW
            BEGIN
                UPDATE sync_status SET updated_at = CURRENT_TIMESTAMP WHERE id = NEW.id;
            END
        """)

        # üÜï PHASE 4: Create trigger to update last_downloaded_file timestamp
        cursor.execute("""
            CREATE TRIGGER IF NOT EXISTS update_last_downloaded_file_timestamp
            AFTER UPDATE ON last_downloaded_file
            FOR EACH ROW
            BEGIN
                UPDATE last_downloaded_file SET updated_at = CURRENT_TIMESTAMP WHERE id = NEW.id;
            END
        """)

        # üÜï PHASE 4: Create view for sync dashboard
        cursor.execute("""
            CREATE VIEW IF NOT EXISTS sync_dashboard AS
            SELECT 
                vs.id as source_id,
                vs.name as source_name,
                vs.source_type,
                vs.path as source_path,
                ss.sync_enabled,
                ss.last_sync_timestamp,
                ss.next_sync_timestamp,
                ss.sync_interval_minutes,
                ss.last_sync_status,
                ss.last_sync_message,
                ss.files_downloaded_count,
                ss.total_download_size_mb,
                COUNT(df.id) as total_downloaded_files,
                SUM(df.file_size_bytes) / (1024*1024) as total_size_mb_calculated
            FROM video_sources vs
            LEFT JOIN sync_status ss ON vs.id = ss.source_id
            LEFT JOIN downloaded_files df ON vs.id = df.source_id
            WHERE vs.active = 1 AND vs.source_type IN ('nvr', 'cloud')
            GROUP BY vs.id, vs.name, vs.source_type, vs.path, ss.sync_enabled, 
                     ss.last_sync_timestamp, ss.next_sync_timestamp, ss.sync_interval_minutes,
                     ss.last_sync_status, ss.last_sync_message, ss.files_downloaded_count, ss.total_download_size_mb
        """)

        # üÜï PHASE 4 OPTIMIZED: Create view for efficient camera tracking
        cursor.execute("""
            CREATE VIEW IF NOT EXISTS camera_sync_status AS
            SELECT 
                vs.id as source_id,
                vs.name as source_name,
                vs.source_type,
                ldf.camera_name,
                ldf.last_filename,
                ldf.last_file_timestamp,
                ldf.last_download_time,
                ldf.total_files_count,
                ldf.total_size_mb,
                ss.sync_enabled,
                ss.sync_interval_minutes,
                ss.last_sync_status
            FROM video_sources vs
            LEFT JOIN last_downloaded_file ldf ON vs.id = ldf.source_id
            LEFT JOIN sync_status ss ON vs.id = ss.source_id
            WHERE vs.active = 1 AND vs.source_type IN ('nvr', 'cloud')
            ORDER BY vs.name, ldf.camera_name
        """)

        conn.commit()
        conn.close()
        print(f"üéâ PHASE 4 OPTIMIZED: Database updated successfully at {DB_PATH}")
        print("‚úÖ Added camera_paths column to processing_config")
        print("‚úÖ Created sync_status table for auto-sync management")
        print("‚úÖ Created downloaded_files table for file tracking")
        print("‚úÖ Created last_downloaded_file table for efficient tracking")
        print("‚úÖ Created indexes and views for performance")
        print(f"üéâ PHASE 1: Database updated successfully at {DB_PATH}")
        print("‚úÖ Added folder_depth and parent_folder_id columns to video_sources")
        print("‚úÖ Created indexes for lazy folder tree performance")
        print("‚úÖ Added helper functions for folder depth management")
        
    except Exception as e:
        print(f"Error updating database: {e}")
        raise

# üÜï PHASE 4: Helper functions for database operations

def update_camera_paths(source_id: int, camera_paths: dict):
    """Update camera_paths in processing_config for a source"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Update processing_config with camera paths
        camera_paths_json = json.dumps(camera_paths)
        cursor.execute("""
            UPDATE processing_config 
            SET camera_paths = ? 
            WHERE id = 1
        """, (camera_paths_json,))
        
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        print(f"Error updating camera paths: {e}")
        return False

def initialize_sync_status(source_id: int, sync_enabled: bool = True, interval_minutes: int = 10):
    """Initialize sync status for a new source"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        from datetime import datetime, timedelta
        
        now = datetime.now()
        next_sync = now + timedelta(minutes=interval_minutes)
        
        cursor.execute("""
            INSERT OR REPLACE INTO sync_status (
                source_id, sync_enabled, last_sync_timestamp, next_sync_timestamp,
                sync_interval_minutes, last_sync_status, last_sync_message
            ) VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            source_id, 
            1 if sync_enabled else 0,
            now.isoformat(),
            next_sync.isoformat(),
            interval_minutes,
            'initialized',
            'Auto-sync initialized'
        ))
        
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        print(f"Error initializing sync status: {e}")
        return False

def get_sync_status(source_id: int):
    """Get sync status for a source"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT * FROM sync_status WHERE source_id = ?
        """, (source_id,))
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            columns = [description[0] for description in cursor.description]
            return dict(zip(columns, result))
        return None
    except Exception as e:
        print(f"Error getting sync status: {e}")
        return None

# üÜï PHASE 4 OPTIMIZED: Helper functions for efficient file tracking

def update_last_downloaded_file(source_id: int, camera_name: str, latest_file_info: dict, total_count: int, total_size_mb: float):
    """Update last downloaded file info for a camera"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        from datetime import datetime
        
        cursor.execute("""
            INSERT OR REPLACE INTO last_downloaded_file (
                source_id, camera_name, last_filename, last_file_timestamp,
                last_download_time, total_files_count, total_size_mb
            ) VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            source_id,
            camera_name,
            latest_file_info['filename'],
            latest_file_info['timestamp'].isoformat(),
            datetime.now().isoformat(),
            total_count,
            total_size_mb
        ))
        
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        print(f"Error updating last downloaded file: {e}")
        return False

def get_last_downloaded_timestamp(source_id: int, camera_name: str):
    """Get last downloaded file timestamp for a camera"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT last_file_timestamp FROM last_downloaded_file 
            WHERE source_id = ? AND camera_name = ?
        """, (source_id, camera_name))
        
        result = cursor.fetchone()
        conn.close()
        
        return result[0] if result else "1970-01-01T00:00:00"
    except Exception as e:
        print(f"Error getting last downloaded timestamp: {e}")
        return "1970-01-01T00:00:00"

def get_camera_download_stats(source_id: int):
    """Get download statistics for all cameras of a source"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT camera_name, last_filename, last_file_timestamp,
                   total_files_count, total_size_mb, last_download_time
            FROM last_downloaded_file 
            WHERE source_id = ?
            ORDER BY camera_name
        """, (source_id,))
        
        results = cursor.fetchall()
        conn.close()
        
        camera_stats = {}
        total_files = 0
        total_size = 0
        
        for row in results:
            camera_name, last_filename, last_timestamp, files_count, size_mb, last_download = row
            camera_stats[camera_name] = {
                'last_filename': last_filename,
                'last_timestamp': last_timestamp,
                'files_count': files_count or 0,
                'size_mb': size_mb or 0.0,
                'last_download': last_download
            }
            total_files += files_count or 0
            total_size += size_mb or 0.0
        
        return {
            'camera_stats': camera_stats,
            'total_files': total_files,
            'total_size_mb': total_size,
            'cameras_count': len(camera_stats)
        }
    except Exception as e:
        print(f"Error getting camera download stats: {e}")
        return {
            'camera_stats': {},
            'total_files': 0,
            'total_size_mb': 0.0,
            'cameras_count': 0
        }
# üÜï PHASE 1: Helper functions for lazy folder tree

def create_source_with_folder_info(source_data, selected_folders=None):
    """Create video source with lazy folder tree information"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Prepare source data
        source_type = source_data.get('source_type')
        name = source_data.get('name')
        path = source_data.get('path')
        config = json.dumps(source_data.get('config', {}))
        
        # For cloud sources with lazy folder selection
        if source_type == 'cloud' and selected_folders:
            # Store selected folders in config
            config_dict = source_data.get('config', {})
            config_dict['selected_folders'] = selected_folders
            config_dict['lazy_loading_enabled'] = True
            config = json.dumps(config_dict)
            
            # Use depth from first selected folder (they should all be depth 4)
            folder_depth = selected_folders[0].get('depth', 4) if selected_folders else 4
            parent_folder_id = selected_folders[0].get('parent_id') if selected_folders else None
        else:
            folder_depth = 0
            parent_folder_id = None
        
        # Insert source
        cursor.execute("""
            INSERT INTO video_sources (
                source_type, name, path, config, active, 
                folder_depth, parent_folder_id
            ) VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (source_type, name, path, config, 1, folder_depth, parent_folder_id))
        
        source_id = cursor.lastrowid
        
        conn.commit()
        conn.close()
        
        print(f"‚úÖ Created source with lazy folder info: {name} (ID: {source_id})")
        return source_id
        
    except Exception as e:
        print(f"‚ùå Error creating source with folder info: {e}")
        return None

def get_sources_with_folder_info():
    """Get all sources with folder depth information"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id, source_type, name, path, config, active, 
                   folder_depth, parent_folder_id, created_at
            FROM video_sources 
            WHERE active = 1
            ORDER BY created_at DESC
        """)
        
        sources = []
        for row in cursor.fetchall():
            source = {
                'id': row[0],
                'source_type': row[1],
                'name': row[2],
                'path': row[3],
                'config': json.loads(row[4]) if row[4] else {},
                'active': row[5],
                'folder_depth': row[6],
                'parent_folder_id': row[7],
                'created_at': row[8]
            }
            sources.append(source)
        
        conn.close()
        return sources
        
    except Exception as e:
        print(f"‚ùå Error getting sources with folder info: {e}")
        return []

def update_source_folder_depth(source_id, folder_depth, parent_folder_id=None):
    """Update folder depth for existing source"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            UPDATE video_sources 
            SET folder_depth = ?, parent_folder_id = ?
            WHERE id = ?
        """, (folder_depth, parent_folder_id, source_id))
        
        conn.commit()
        conn.close()
        
        print(f"‚úÖ Updated folder depth for source {source_id}: depth={folder_depth}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error updating folder depth: {e}")
        return False

if __name__ == "__main__":
    os.makedirs(DB_DIR, exist_ok=True)
    update_database()
```
## üìÑ File: `debug_500_error.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/debug_500_error.py`

```python
#!/usr/bin/env python3
"""
Debug 500 Error - Test OAuth flow step by step
"""

import os
import sys
import traceback

def test_imports():
    """Test all required imports"""
    print("üîß Testing imports...")
    
    try:
        from google.auth.transport.requests import Request
        print("‚úÖ google.auth.transport.requests")
    except Exception as e:
        print(f"‚ùå google.auth.transport.requests: {e}")
        return False
    
    try:
        from google.oauth2.credentials import Credentials
        print("‚úÖ google.oauth2.credentials")
    except Exception as e:
        print(f"‚ùå google.oauth2.credentials: {e}")
        return False
    
    try:
        from google_auth_oauthlib.flow import Flow
        print("‚úÖ google_auth_oauthlib.flow")
    except Exception as e:
        print(f"‚ùå google_auth_oauthlib.flow: {e}")
        return False
    
    try:
        from googleapiclient.discovery import build
        print("‚úÖ googleapiclient.discovery")
    except Exception as e:
        print(f"‚ùå googleapiclient.discovery: {e}")
        return False
    
    return True

def test_credentials_file():
    """Test credentials file access"""
    print("\nüìÅ Testing credentials file...")
    
    creds_path = "modules/sources/credentials/google_drive_credentials.json"
    
    if not os.path.exists(creds_path):
        print(f"‚ùå File not found: {creds_path}")
        return False
    
    try:
        # Test file permissions
        with open(creds_path, 'r') as f:
            import json
            creds = json.load(f)
        
        print(f"‚úÖ File readable: {creds_path}")
        
        # Test OAuth flow creation
        from google_auth_oauthlib.flow import Flow
        
        flow = Flow.from_client_secrets_file(
            creds_path,
            scopes=['https://www.googleapis.com/auth/drive.readonly'],
            redirect_uri='http://localhost:8080/api/cloud/oauth/callback'
        )
        
        print("‚úÖ OAuth Flow created successfully")
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        traceback.print_exc()
        return False

def test_oauth_url_generation():
    """Test OAuth URL generation"""
    print("\nüåê Testing OAuth URL generation...")
    
    try:
        from modules.sources.cloud_auth import CloudAuthManager
        
        auth_manager = CloudAuthManager('google_drive')
        
        # Test OAuth flow
        redirect_uri = 'http://localhost:8080/api/cloud/oauth/callback'
        result = auth_manager.initiate_oauth_flow(redirect_uri)
        
        if result['success']:
            print("‚úÖ OAuth URL generated successfully")
            print(f"üîó Auth URL: {result['auth_url'][:80]}...")
            return True
        else:
            print(f"‚ùå OAuth failed: {result['message']}")
            return False
            
    except Exception as e:
        print(f"‚ùå OAuth error: {e}")
        traceback.print_exc()
        return False

def test_directory_structure():
    """Test directory structure"""
    print("\nüìÇ Testing directory structure...")
    
    required_dirs = [
        "modules/sources/credentials",
        "modules/sources/tokens"
    ]
    
    for dir_path in required_dirs:
        if os.path.exists(dir_path):
            print(f"‚úÖ {dir_path}")
        else:
            print(f"‚ùå {dir_path} - creating...")
            try:
                os.makedirs(dir_path, exist_ok=True)
                print(f"‚úÖ Created: {dir_path}")
            except Exception as e:
                print(f"‚ùå Failed to create {dir_path}: {e}")
                return False
    
    return True

def test_flask_endpoint():
    """Test Flask endpoint directly"""
    print("\nüåê Testing Flask endpoint...")
    
    try:
        # Import endpoint function directly
        from modules.sources.cloud_endpoints import cloud_authenticate
        
        # Create mock request
        class MockRequest:
            def get_json(self):
                return {
                    "provider": "google_drive",
                    "action": "initiate_auth"
                }
            
            @property
            def host_url(self):
                return "http://localhost:8080/"
        
        # Test endpoint function
        from flask import Flask
        app = Flask(__name__)
        
        with app.test_request_context():
            # Mock request object
            import modules.sources.cloud_endpoints
            original_request = modules.sources.cloud_endpoints.request
            modules.sources.cloud_endpoints.request = MockRequest()
            
            try:
                response = cloud_authenticate()
                print(f"‚úÖ Endpoint response: {response}")
                return True
            except Exception as e:
                print(f"‚ùå Endpoint error: {e}")
                traceback.print_exc()
                return False
            finally:
                modules.sources.cloud_endpoints.request = original_request
                
    except Exception as e:
        print(f"‚ùå Flask test error: {e}")
        traceback.print_exc()
        return False

def main():
    """Main debug function"""
    print("=" * 70)
    print("üîß DEBUG 500 ERROR - Google Drive Authentication")
    print("=" * 70)
    
    tests = [
        ("Imports", test_imports),
        ("Directory Structure", test_directory_structure),
        ("Credentials File", test_credentials_file),
        ("OAuth URL Generation", test_oauth_url_generation),
        ("Flask Endpoint", test_flask_endpoint)
    ]
    
    passed = 0
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            if test_func():
                passed += 1
                print(f"‚úÖ {test_name} PASSED")
            else:
                print(f"‚ùå {test_name} FAILED")
        except Exception as e:
            print(f"‚ùå {test_name} CRASHED: {e}")
            traceback.print_exc()
    
    print("\n" + "=" * 70)
    print(f"üìä SUMMARY: {passed}/{len(tests)} tests passed")
    print("=" * 70)
    
    if passed < len(tests):
        print("\nüí° RECOMMENDATIONS:")
        if passed == 0:
            print("1. Check Python dependencies")
            print("2. Verify file permissions")
            print("3. Restart backend server")
        else:
            print("1. Check failed test details above")
            print("2. Fix specific issues")
            print("3. Check backend logs for more details")

if __name__ == "__main__":
    main()
```
## üìÑ File: `final_hikvision_test.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/final_hikvision_test.py`

```python
#!/usr/bin/env python3
"""
Final comprehensive Hikvision test
Try web interface access first
"""

import requests
import socket
from datetime import datetime

def test_web_interface_direct():
    """Test direct web interface access"""
    print("üåê TESTING WEB INTERFACE ACCESS")
    
    host = "192.168.1.54"
    port = 8000
    username = "binhnguyen041280"
    password = "@Ezv024819"
    
    base_url = f"http://{host}:{port}"
    
    # Test simple GET request
    try:
        print(f"üîç Testing: {base_url}/")
        
        response = requests.get(
            f"{base_url}/",
            auth=(username, password),
            timeout=10,
            verify=False
        )
        
        print(f"‚úÖ Status: {response.status_code}")
        print(f"üìù Headers: {dict(response.headers)}")
        
        if response.status_code == 200:
            print(f"üéâ WEB INTERFACE ACCESSIBLE!")
            print(f"üìÑ Content preview: {response.text[:200]}...")
            
            # Look for video/stream links
            if 'video' in response.text.lower() or 'stream' in response.text.lower():
                print("üé¨ Video/streaming content detected in page")
                
            return True
        else:
            print(f"‚ùå Web interface not accessible")
            return False
            
    except Exception as e:
        print(f"‚ùå Web interface error: {e}")
        return False

def test_device_capabilities():
    """Test device capabilities via web"""
    print("\nüîß TESTING DEVICE CAPABILITIES")
    
    host = "192.168.1.54"
    port = 8000
    username = "binhnguyen041280"
    password = "@Ezv024819"
    
    # Try to access device info page
    info_urls = [
        f"http://{host}:{port}/device_info",
        f"http://{host}:{port}/system_info",
        f"http://{host}:{port}/status",
        f"http://{host}:{port}/info"
    ]
    
    for url in info_urls:
        try:
            print(f"üîç Testing: {url}")
            
            response = requests.get(
                url,
                auth=(username, password),
                timeout=5
            )
            
            if response.status_code == 200:
                print(f"‚úÖ Device info accessible")
                print(f"üìÑ Content: {response.text[:300]}...")
                
        except Exception as e:
            continue

def conclusion():
    """Final conclusion and recommendations"""
    print("\n" + "="*60)
    print("üéØ FINAL CONCLUSION")
    print("="*60)
    
    print("‚ùå RTSP STREAMING: Not supported on this device")
    print("‚ùå HTTP STREAMING: Not accessible with current credentials")
    print("‚ùå ONVIF PROTOCOL: Not supported")
    
    print("\nüîß DEVICE ANALYSIS:")
    print("‚úÖ Device is online and accessible on port 8000")
    print("‚úÖ TCP connection successful")
    print("‚ùå Authentication failing or protocol mismatch")
    print("‚ùå May not be a standard IP camera")
    
    print("\nüí° RECOMMENDATIONS:")
    print("1. Check device manual for correct credentials")
    print("2. Try accessing web interface directly in browser:")
    print("   http://192.168.1.54:8000")
    print("3. Check if device requires HTTPS instead of HTTP")
    print("4. Verify device model supports video streaming")
    print("5. Contact device manufacturer for protocol documentation")
    
    print("\nüöÄ ALTERNATIVE SOLUTIONS:")
    print("1. Use mock ONVIF containers for VTrack development")
    print("2. Test with different IP camera if available")
    print("3. Focus on VTrack integration with working devices")

if __name__ == "__main__":
    print("üéØ FINAL HIKVISION COMPREHENSIVE TEST")
    print("="*60)
    
    # Final web interface test
    web_success = test_web_interface_direct()
    
    # Device capabilities test
    test_device_capabilities()
    
    # Final conclusion
    conclusion()
    
    print("\n" + "="*60)
    print("‚úÖ COMPREHENSIVE TEST COMPLETED")
    print("üìù See recommendations above for next steps")

```
## üìÑ File: `simple_hikvision_test.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/simple_hikvision_test.py`

```python
#!/usr/bin/env python3
"""
Simple Hikvision test
"""

print("üéØ SIMPLE HIKVISION TEST STARTING...")

import socket
import subprocess
from datetime import datetime
from pathlib import Path

def test_rtsp_direct():
    """Test direct RTSP access"""
    print("\n=== DIRECT RTSP TEST ===")
    
    host = "192.168.1.54"
    rtsp_port = 554
    username = "binhnguyen041280"
    password = "@Ezv024819"
    
    print(f"Testing RTSP connection to {host}:{rtsp_port}")
    
    # Test RTSP port
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(5)
        result = sock.connect_ex((host, rtsp_port))
        sock.close()
        
        if result == 0:
            print(f"‚úÖ RTSP port {rtsp_port} accessible")
            
            # Try RTSP URL
            rtsp_url = f"rtsp://{username}:{password}@{host}:{rtsp_port}/h264/ch1/main/av_stream"
            print(f"üîç Testing RTSP URL: {rtsp_url.replace(password, '***')}")
            
            # Check ffmpeg
            try:
                ffmpeg_check = subprocess.run(['which', 'ffmpeg'], capture_output=True)
                if ffmpeg_check.returncode == 0:
                    print("‚úÖ ffmpeg found")
                    
                    # Create target directory
                    target_dir = Path("/Users/annhu/vtrack_app/V_Track/nvr_downloads/nvr_localhost/Front_Door_Camera")
                    target_dir.mkdir(parents=True, exist_ok=True)
                    print(f"‚úÖ Target directory: {target_dir}")
                    
                    # Try capture
                    output_file = target_dir / f"hikvision_simple_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
                    
                    cmd = [
                        'ffmpeg',
                        '-rtsp_transport', 'tcp',
                        '-i', rtsp_url,
                        '-t', '5',  # 5 seconds
                        '-c', 'copy',
                        '-y',
                        str(output_file)
                    ]
                    
                    print("üé¨ Attempting 5-second RTSP capture...")
                    print(f"Command: {' '.join(cmd[:3])} [URL] {' '.join(cmd[4:])}")
                    
                    result = subprocess.run(
                        cmd,
                        capture_output=True,
                        text=True,
                        timeout=30
                    )
                    
                    print(f"FFmpeg return code: {result.returncode}")
                    
                    if result.returncode == 0:
                        if output_file.exists():
                            file_size = output_file.stat().st_size
                            print(f"üéâ SUCCESS! RTSP capture working!")
                            print(f"File: {output_file}")
                            print(f"Size: {file_size} bytes")
                            
                            if file_size > 0:
                                print("‚úÖ Video file has content")
                                return True
                            else:
                                print("‚ö†Ô∏è Video file is empty")
                                return False
                        else:
                            print("‚ùå Output file not created")
                            return False
                    else:
                        print(f"‚ùå FFmpeg failed")
                        if result.stderr:
                            print(f"Error: {result.stderr[:300]}...")
                        return False
                        
                else:
                    print("‚ùå ffmpeg not found")
                    print("Install with: brew install ffmpeg")
                    return False
                    
            except Exception as ffmpeg_error:
                print(f"‚ùå ffmpeg error: {ffmpeg_error}")
                return False
                
        else:
            print(f"‚ùå RTSP port {rtsp_port} not accessible")
            
            # Try alternative ports
            alt_ports = [8554, 1935, 8000]
            for alt_port in alt_ports:
                try:
                    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                    sock.settimeout(3)
                    result = sock.connect_ex((host, alt_port))
                    sock.close()
                    
                    if result == 0:
                        print(f"‚úÖ Alternative port {alt_port} accessible")
                    else:
                        print(f"‚ùå Alternative port {alt_port} not accessible")
                        
                except Exception as e:
                    print(f"‚ùå Port {alt_port} error: {e}")
                    
            return False
            
    except Exception as e:
        print(f"‚ùå RTSP test error: {e}")
        return False

if __name__ == "__main__":
    print("üéØ SIMPLE HIKVISION RTSP TEST")
    print("=" * 60)
    print("Device: 192.168.1.54")
    print("Username: binhnguyen041280")
    print("Password: @Ezv024819")
    print("=" * 60)
    
    try:
        success = test_rtsp_direct()
        
        if success:
            print("\nÔøΩÔøΩ HIKVISION RTSP ACCESS SUCCESSFUL!")
            print("‚úÖ Device can be used with VTrack")
            print("‚úÖ Video file downloaded successfully")
        else:
            print("\n‚ö†Ô∏è RTSP access failed")
            print("‚ùå Check credentials or device configuration")
            print("‚ùå Try different RTSP URLs or ports")
            
    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)
    print("Test completed")

```
## üìÑ File: `rtsp_client.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/rtsp_client.py`

```python
#!/usr/bin/env python3
"""
RTSP Client Implementation for VTrack
Based on successful onvif-mock-fixed container test
"""

import subprocess
import os
import time
import logging
from datetime import datetime

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RTSPClient:
    """
    RTSP Client for VTrack - Based on working onvif-mock-fixed container
    """
    
    def __init__(self, rtsp_url, camera_name="Camera", output_dir="./downloads"):
        """
        Initialize RTSP client
        
        Args:
            rtsp_url (str): RTSP URL (e.g., rtsp://172.17.0.2:8554/stream1)
            camera_name (str): Camera name for file naming
            output_dir (str): Directory to save recordings
        """
        self.rtsp_url = rtsp_url
        self.camera_name = camera_name
        self.output_dir = output_dir
        
        # Create output directory if not exists
        os.makedirs(output_dir, exist_ok=True)
        
        logger.info(f"RTSP Client initialized for {camera_name}")
        logger.info(f"Stream URL: {rtsp_url}")
        logger.info(f"Output directory: {output_dir}")
    
    def test_connection(self, timeout=10):
        """
        Test RTSP connection using FFmpeg
        
        Args:
            timeout (int): Connection timeout in seconds
            
        Returns:
            dict: Connection test result
        """
        try:
            logger.info(f"Testing RTSP connection to {self.rtsp_url}")
            
            # Test connection with FFmpeg
            cmd = [
                'ffmpeg',
                '-i', self.rtsp_url,
                '-t', '1',  # 1 second test
                '-f', 'null',
                '-'
            ]
            
            result = subprocess.run(cmd, 
                                  capture_output=True, 
                                  text=True, 
                                  timeout=timeout)
            
            if result.returncode == 0:
                logger.info("‚úÖ RTSP connection successful")
                return {
                    "success": True,
                    "message": f"RTSP connection to {self.camera_name} successful",
                    "stream_url": self.rtsp_url
                }
            else:
                logger.warning(f"‚ùå RTSP connection failed: {result.stderr}")
                return {
                    "success": False,
                    "message": f"RTSP connection failed: {result.stderr}",
                    "stream_url": self.rtsp_url
                }
                
        except subprocess.TimeoutExpired:
            logger.error("‚ùå RTSP connection timeout")
            return {
                "success": False,
                "message": "RTSP connection timeout",
                "stream_url": self.rtsp_url
            }
        except Exception as e:
            logger.error(f"‚ùå RTSP connection error: {e}")
            return {
                "success": False,
                "message": f"RTSP connection error: {str(e)}",
                "stream_url": self.rtsp_url
            }
    
    def download_video(self, duration=10):
        """
        Download video from RTSP stream using FFmpeg
        
        Args:
            duration (int): Recording duration in seconds
            
        Returns:
            dict: Download result with file path and metadata
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.camera_name}_{timestamp}.mp4"
        output_path = os.path.join(self.output_dir, filename)
        
        try:
            logger.info(f"Starting video download: {duration} seconds")
            
            # FFmpeg command based on successful test
            cmd = [
                'ffmpeg',
                '-i', self.rtsp_url,
                '-t', str(duration),
                '-c', 'copy',  # Copy without re-encoding
                '-avoid_negative_ts', 'make_zero',
                output_path,
                '-y'  # Overwrite output file
            ]
            
            logger.info(f"FFmpeg command: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, 
                                  capture_output=True, 
                                  text=True, 
                                  timeout=duration+30)
            
            if result.returncode == 0 and os.path.exists(output_path):
                file_size = os.path.getsize(output_path)
                logger.info(f"‚úÖ Download successful: {output_path} ({file_size} bytes)")
                
                # Get video info
                video_info = self._get_video_info(output_path)
                
                return {
                    "success": True,
                    "message": f"Video downloaded successfully",
                    "output_path": output_path,
                    "file_size": file_size,
                    "duration": duration,
                    "video_info": video_info
                }
            else:
                logger.error(f"FFmpeg failed: {result.stderr}")
                return {
                    "success": False,
                    "message": f"FFmpeg download failed: {result.stderr}",
                    "output_path": output_path
                }
                
        except subprocess.TimeoutExpired:
            logger.error("FFmpeg download timed out")
            return {
                "success": False,
                "message": "Download timed out",
                "output_path": output_path
            }
        except Exception as e:
            logger.error(f"Download error: {e}")
            return {
                "success": False,
                "message": f"Download failed: {str(e)}",
                "output_path": output_path
            }
    
    def _get_video_info(self, video_path):
        """
        Get video information using FFprobe
        
        Args:
            video_path (str): Path to video file
            
        Returns:
            dict: Video information
        """
        try:
            cmd = [
                'ffprobe',
                '-v', 'quiet',
                '-print_format', 'json',
                '-show_format',
                '-show_streams',
                video_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                import json
                probe_data = json.loads(result.stdout)
                
                # Extract video stream info
                video_stream = None
                for stream in probe_data.get('streams', []):
                    if stream.get('codec_type') == 'video':
                        video_stream = stream
                        break
                
                if video_stream:
                    return {
                        "codec": video_stream.get('codec_name'),
                        "width": video_stream.get('width'),
                        "height": video_stream.get('height'),
                        "duration": float(probe_data.get('format', {}).get('duration', 0)),
                        "bitrate": video_stream.get('bit_rate'),
                        "fps": eval(video_stream.get('r_frame_rate', '0/1'))
                    }
                    
            return {"error": "Could not get video info"}
            
        except Exception as e:
            logger.error(f"Error getting video info: {e}")
            return {"error": str(e)}


def test_rtsp_cameras():
    """
    Test RTSP client with known working containers
    """
    print("üé• Testing RTSP Cameras...")
    
    # Test cameras based on successful documentation
    cameras = [
        {
            "name": "ONVIF_Mock_Camera",
            "url": "rtsp://172.17.0.2:8554/stream1",
            "output_dir": "./downloads/onvif_mock"
        }
    ]
    
    for camera in cameras:
        print(f"\nüì∑ Testing {camera['name']}...")
        
        # Initialize client
        client = RTSPClient(
            rtsp_url=camera['url'],
            camera_name=camera['name'],
            output_dir=camera['output_dir']
        )
        
        # Test connection
        conn_result = client.test_connection(timeout=10)
        print(f"Connection: {'‚úÖ' if conn_result['success'] else '‚ùå'} {conn_result['message']}")
        
        if conn_result['success']:
            # Download 5 seconds video
            download_result = client.download_video(duration=5)
            print(f"Download: {'‚úÖ' if download_result['success'] else '‚ùå'} {download_result['message']}")
            
            if download_result['success']:
                print(f"  üìÅ File: {download_result['output_path']}")
                print(f"  üìä Size: {download_result['file_size']} bytes")
                
                video_info = download_result.get('video_info', {})
                if 'error' not in video_info:
                    print(f"  üé¨ Resolution: {video_info.get('width')}x{video_info.get('height')}")
                    print(f"  ‚è±Ô∏è Duration: {video_info.get('duration')} seconds")
                    print(f"  üé≠ Codec: {video_info.get('codec')}")
                    print(f"  üìà FPS: {video_info.get('fps')}")
        
        print("  " + "="*50)


if __name__ == "__main__":
    test_rtsp_cameras()
```
## üìÑ File: `app.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/app.py`

```python
import os
import sys
from flask_cors import CORS

# ==================== T·∫ÆT T·∫§T C·∫¢ LOGS TR∆Ø·ªöC KHI IMPORT ====================
# TensorFlow logs
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['TF_LOGGING'] = 'ERROR'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

# Google/Abseil logs (MediaPipe)
os.environ['GLOG_minloglevel'] = '3'
os.environ['GLOG_logtostderr'] = '0'
os.environ['GLOG_stderrthreshold'] = '3'
os.environ['GLOG_v'] = '0'

# MediaPipe logs
os.environ['MEDIAPIPE_DISABLE_GPU'] = '1'
os.environ['MEDIAPIPE_LOG_LEVEL'] = '3'

# OpenCV logs
os.environ['OPENCV_LOG_LEVEL'] = 'ERROR'

# T·∫Øt C++ warnings
os.environ['PYTHONWARNINGS'] = 'ignore'

# Redirect stderr ƒë·ªÉ t·∫Øt ho√†n to√†n C++ logs
import warnings
warnings.filterwarnings('ignore')

# T·∫Øt absl logging
try:
    import absl.logging
    absl.logging.set_verbosity(absl.logging.ERROR)
    absl.logging.set_stderrthreshold(absl.logging.ERROR)
except ImportError:
    pass

# ==================== IMPORT MODULES ====================
from modules.config.logging_config import setup_logging, get_logger
from datetime import datetime
import logging
import signal
import threading
import socket
import atexit
import sqlite3
from datetime import datetime, timedelta, timezone

# Thi·∫øt l·∫≠p logging t·ª´ logging_config
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
setup_logging(BASE_DIR, app_name="app", log_level=logging.DEBUG)
logger = logging.getLogger("app")

# Import c√°c modules kh√°c
from modules.config.config import config_bp, init_app_and_config
from modules.scheduler.program import program_bp
from modules.query.query import query_bp
from blueprints.cutter_bp import cutter_bp
from blueprints.hand_detection_bp import hand_detection_bp
from blueprints.qr_detection_bp import qr_detection_bp
from blueprints.roi_bp import roi_bp
from modules.scheduler.program import scheduler  # Import BatchScheduler

# üÜï NEW: Import cloud endpoints blueprint
from modules.sources.cloud_endpoints import cloud_bp

# Kh·ªüi t·∫°o Flask app v√† DB path t·ª´ config
app, DB_PATH, logger = init_app_and_config()
from flask_session import Session

# üîß FIXED: OAuth-Compatible Session Configuration
import secrets
app.config.update(
    # OAuth Session Fix - CRITICAL for Google OAuth
    SECRET_KEY=os.environ.get('SECRET_KEY', secrets.token_urlsafe(32)),
    SESSION_COOKIE_NAME='vtrack_session',
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SECURE=False,  # Set to True in production with HTTPS
    SESSION_COOKIE_SAMESITE='Lax',  # CRITICAL for OAuth redirects
    PERMANENT_SESSION_LIFETIME=timedelta(hours=24),  # Longer for OAuth
    
    # Session storage
    SESSION_TYPE='filesystem',
    SESSION_FILE_DIR=os.path.join(BASE_DIR, 'flask_session'),
    
    # OAuth specific
    OAUTH_INSECURE_TRANSPORT=True,  # Only for development
)

# Initialize session
Session(app)

# üîß CORS Configuration for OAuth
CORS(app, 
     origins=['http://localhost:3000', 'http://127.0.0.1:3000'],
     supports_credentials=True,
     allow_headers=['Content-Type', 'Authorization'],
     methods=['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'])

logger.info("‚úÖ CORS configured for OAuth with credentials")

# üîß CRITICAL: Make sessions permanent for OAuth
@app.before_request
def make_session_permanent():
    from flask import session
    session.permanent = True

logger.info("üîë OAuth-compatible session configuration applied")

# ƒêƒÉng k√Ω c√°c Blueprint
app.register_blueprint(program_bp)
app.register_blueprint(config_bp)
app.register_blueprint(query_bp)
app.register_blueprint(cutter_bp)
app.register_blueprint(hand_detection_bp)
app.register_blueprint(qr_detection_bp)
app.register_blueprint(roi_bp)

# üÜï NEW: Register cloud endpoints blueprint with error handling
try:
    app.register_blueprint(cloud_bp, name='cloud_endpoints')
    logger.info("‚úÖ Cloud endpoints registered: /api/cloud/*")
except ValueError as e:
    logger.warning(f"‚ö†Ô∏è Cloud blueprint already registered: {e}")
    # If already registered, skip (could be from config.py)
    pass

# H√†m ghi last_stop_time khi ·ª©ng d·ª•ng d·ª´ng
def exit_handler():
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        last_stop_time = datetime.now(tz=timezone(timedelta(hours=7))).strftime('%Y-%m-%d %H:%M:%S')
        cursor.execute("""
            INSERT OR REPLACE INTO program_status (key, value)
            VALUES ('last_stop_time', ?)
        """, (last_stop_time,))
        conn.commit()
        conn.close()
        logger.info("Application stopped gracefully")
    except Exception as e:
        logger.error(f"Error saving last_stop_time: {e}")

# ƒêƒÉng k√Ω exit_handler
atexit.register(exit_handler)

def is_port_in_use(port):
    """Ki·ªÉm tra xem c·ªïng c√≥ ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng hay kh√¥ng."""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        try:
            s.bind(("localhost", port))
            return False
        except OSError:
            return True

# Global flag ƒë·ªÉ tr√°nh multiple shutdown
_shutdown_in_progress = False

def signal_handler(sig, frame):
    """X·ª≠ l√Ω t√≠n hi·ªáu d·ª´ng ·ª©ng d·ª•ng m·ªôt c√°ch graceful"""
    global _shutdown_in_progress
    
    # Tr√°nh multiple shutdown
    if _shutdown_in_progress:
        print("\nForced shutdown...")
        os._exit(1)  # Force exit n·∫øu ƒë√£ shutdown r·ªìi
    
    _shutdown_in_progress = True
    print("\nShutting down gracefully... (Press Ctrl+C again to force)")
    
    try:
        logger.info("Received shutdown signal, stopping application...")
        
        # D·ª´ng scheduler
        if 'scheduler' in globals():
            scheduler.stop()
            logger.info("Scheduler stopped")
        
        # ƒê·ª£i c√°c thread k·∫øt th√∫c v·ªõi timeout ng·∫Øn h∆°n
        main_thread = threading.current_thread()
        for t in threading.enumerate():
            if t != main_thread and t.is_alive():
                try:
                    t.join(timeout=2)  # Gi·∫£m timeout xu·ªëng 2 gi√¢y
                    if t.is_alive():
                        logger.warning(f"Thread {t.name} did not stop gracefully")
                except:
                    pass  # Ignore errors during shutdown
        
        logger.info("Application shutdown complete")
        
    except Exception as e:
        logger.error(f"Error during shutdown: {e}")
    finally:
        os._exit(0)  # Force exit

# ƒêƒÉng k√Ω signal handler
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# üîß Debug: List all registered endpoints on startup
def log_registered_routes():
    """Log all registered Flask routes for debugging"""
    logger.info("üìã Registered Flask Routes:")
    for rule in app.url_map.iter_rules():
        methods = ', '.join(rule.methods - {'HEAD', 'OPTIONS'})
        logger.info(f"   {methods:15} {rule.rule}")

# Kh·ªüi ch·∫°y ·ª©ng d·ª•ng
if __name__ == "__main__":
    port = 8080
    
    # Ki·ªÉm tra port tr∆∞·ªõc khi kh·ªüi ch·∫°y
    if is_port_in_use(port):
        logger.error(f"Port {port} is already in use!")
        sys.exit(1)
    
    logger.info(f"Starting VTrack application on port {port}")
    logger.info(f"üîë OAuth session security: ‚úÖ Enabled")
    
    # üîß Debug: Log registered routes
    log_registered_routes()
    
    try:
        app.run(
            host='0.0.0.0',
            port=port,
            debug=False,
            use_reloader=False,
            threaded=True
        )
    except KeyboardInterrupt:
        logger.info("Application interrupted by user")
    except Exception as e:
        logger.error(f"Application error: {e}")
    finally:
        logger.info("Application terminated")
```
## üìÑ File: `test_onvif_download.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/test_onvif_download.py`

```python
#!/usr/bin/env python3
"""
Test NVRDownloader with actual ONVIF containers
Run this to verify download functionality
"""

import sys
import os
import json
from datetime import datetime, timedelta

# Add backend to path
sys.path.append('/Users/annhu/vtrack_app/V_Track/backend')

def test_onvif_download():
    """Test NVRDownloader with actual ONVIF containers"""
    print("üß™ Testing NVRDownloader with ONVIF containers...")
    
    try:
        # Import required modules
        from modules.sources.nvr_downloader import NVRDownloader
        from modules.db_utils import get_db_connection
        
        # Create downloader instance
        downloader = NVRDownloader()
        
        # Get real source config from database
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            SELECT id, config, path FROM video_sources 
            WHERE source_type = 'nvr' AND active = 1 
            LIMIT 1
        """)
        result = cursor.fetchone()
        
        if not result:
            print("‚ùå No active NVR source found in database")
            return False
        
        source_id, config_json, path = result
        config = json.loads(config_json)
        
        print(f"‚úÖ Using source ID: {source_id}")
        print(f"‚úÖ Config: {json.dumps(config, indent=2)}")
        
        # Build source config for downloader
        source_config = {
            'id': source_id,
            'selected_cameras': config.get('selected_cameras', []),
            'url': config.get('url', 'localhost'),
            'port': config.get('port', 1000),
            'username': config.get('username', 'admin'),
            'password': config.get('password', 'admin')
        }
        
        print(f"‚úÖ Source config ready: {json.dumps(source_config, indent=2)}")
        
        # Test 1: Check ONVIF container connectivity
        print("\n=== TEST 1: ONVIF Container Connectivity ===")
        import socket
        
        # Test multiple ports (our docker-compose setup)
        test_ports = [1000, 1001, 1002]
        accessible_ports = []
        
        for port in test_ports:
            try:
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(3)
                result = sock.connect_ex(('localhost', port))
                sock.close()
                
                if result == 0:
                    accessible_ports.append(port)
                    print(f"‚úÖ Port {port} accessible")
                else:
                    print(f"‚ùå Port {port} not accessible")
            except Exception as e:
                print(f"‚ùå Port {port} error: {e}")
        
        if not accessible_ports:
            print("‚ùå No ONVIF containers accessible. Please start containers first:")
            print("   cd /Users/annhu/vtrack_app/V_Track/service/onvif-multiple-cameras")
            print("   docker-compose up -d")
            return False
        
        print(f"‚úÖ {len(accessible_ports)} ONVIF containers accessible")
        
        # Test 2: Test ONVIF GetRecordings request
        print("\n=== TEST 2: ONVIF GetRecordings Request ===")
        
        # Use first accessible port
        test_port = accessible_ports[0]
        test_camera = source_config['selected_cameras'][0] if source_config['selected_cameras'] else 'Camera1'
        
        print(f"Testing with port {test_port}, camera: {test_camera}")
        
        # Build test config
        test_config = {
            'url': 'localhost',
            'port': test_port,
            'username': source_config['username'],
            'password': source_config['password']
        }
        
        # Define time range (last 24 hours)
        time_range = {
            'from': datetime.now() - timedelta(hours=24),
            'to': datetime.now()
        }
        
        print(f"Time range: {time_range['from']} to {time_range['to']}")
        
        # Test _get_onvif_recordings method
        try:
            recordings = downloader._get_onvif_recordings(test_config, test_camera, time_range)
            print(f"‚úÖ GetRecordings response: {len(recordings)} recordings found")
            
            if recordings:
                print("Sample recording:")
                print(json.dumps(recordings[0], indent=2, default=str))
            else:
                print("‚ö†Ô∏è No recordings found (expected for mock containers)")
                
        except Exception as e:
            print(f"‚ùå GetRecordings failed: {e}")
            print("This is expected for mock containers that don't support recording API")
        
        # Test 3: Test download_latest_recordings method
        print("\n=== TEST 3: Download Latest Recordings ===")
        
        try:
            # Call download_latest_recordings
            result = downloader.download_latest_recordings(source_config, hours_back=24)
            
            print(f"Download result: {json.dumps(result, indent=2)}")
            
            if result['success']:
                print(f"‚úÖ Download successful: {result['files_downloaded']} files, {result['total_size_mb']:.2f} MB")
            else:
                print(f"‚ö†Ô∏è Download failed: {result['message']}")
                print("This is expected for mock containers without recording support")
                
        except Exception as e:
            print(f"‚ùå Download method failed: {e}")
            import traceback
            traceback.print_exc()
        
        # Test 4: Check database entries
        print("\n=== TEST 4: Database Entries ===")
        
        try:
            cursor.execute("""
                SELECT COUNT(*) FROM downloaded_files 
                WHERE source_id = ?
            """, (source_id,))
            
            file_count = cursor.fetchone()[0]
            print(f"Downloaded files in database: {file_count}")
            
            if file_count > 0:
                cursor.execute("""
                    SELECT camera_name, local_file_path, file_size_bytes, download_timestamp 
                    FROM downloaded_files 
                    WHERE source_id = ? 
                    ORDER BY download_timestamp DESC 
                    LIMIT 3
                """, (source_id,))
                
                recent_files = cursor.fetchall()
                print("Recent downloads:")
                for row in recent_files:
                    print(f"  - {row[0]}: {row[1]} ({row[2]} bytes, {row[3]})")
        
        except Exception as e:
            print(f"‚ùå Database check failed: {e}")
        
        conn.close()
        
        print("\n‚úÖ ONVIF download test completed")
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_containers():
    """Check if ONVIF containers are running"""
    print("üê≥ Checking ONVIF containers...")
    
    import subprocess
    
    try:
        # Check docker-compose status
        result = subprocess.run(
            ['docker', 'ps', '--filter', 'name=onvif', '--format', 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'],
            capture_output=True,
            text=True,
            cwd='/Users/annhu/vtrack_app/V_Track/service/onvif-multiple-cameras'
        )
        
        if result.returncode == 0:
            print("Docker containers:")
            print(result.stdout)
            return 'onvif' in result.stdout
        else:
            print(f"‚ùå Docker command failed: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"‚ùå Container check failed: {e}")
        return False

if __name__ == "__main__":
    print("üß™ NVRDownloader ONVIF Container Test")
    print("=" * 60)
    
    # Check containers first
    if check_containers():
        print("‚úÖ ONVIF containers detected")
    else:
        print("‚ö†Ô∏è ONVIF containers not detected. Starting them...")
        print("Please run:")
        print("  cd /Users/annhu/vtrack_app/V_Track/service/onvif-multiple-cameras")
        print("  docker-compose up -d")
        print("  Then run this test again")
        sys.exit(1)
    
    print("\n" + "=" * 60)
    
    # Run download test
    success = test_onvif_download()
    
    print("\n" + "=" * 60)
    print(f"üéØ Overall result: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
    
    if success:
        print("\nüéâ NVRDownloader is ready for integration!")
        print("Next steps:")
        print("1. Integrate with auto_sync_service.py")
        print("2. Add API endpoints in app.py")
        print("3. Add UI status display")
    else:
        print("\nüîß Issues found. Please fix before proceeding.")
```
## üìÑ File: `test_google_credentials.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/test_google_credentials.py`

```python
#!/usr/bin/env python3
"""
Test Google Drive Credentials
Quick test to verify credentials file and OAuth setup
"""

import os
import json
from pathlib import Path

def test_credentials():
    """Test Google Drive credentials file"""
    
    print("üîç Testing Google Drive credentials...")
    
    # Check credentials file
    creds_path = "modules/sources/credentials/google_drive_credentials.json"
    
    if not os.path.exists(creds_path):
        print(f"‚ùå Credentials file not found: {creds_path}")
        
        # Check alternative locations
        alt_paths = [
            "modules/sources/google_drive_credentials.json",
            "google_drive_credentials.json"
        ]
        
        for alt_path in alt_paths:
            if os.path.exists(alt_path):
                print(f"‚úÖ Found credentials at: {alt_path}")
                creds_path = alt_path
                break
        else:
            print("‚ùå No credentials file found anywhere")
            return False
    else:
        print(f"‚úÖ Credentials file found: {creds_path}")
    
    # Test credentials content
    try:
        with open(creds_path, 'r') as f:
            creds = json.load(f)
        
        if 'installed' in creds:
            installed = creds['installed']
            
            # Check required fields
            required_fields = ['client_id', 'client_secret', 'auth_uri', 'token_uri']
            missing_fields = []
            
            for field in required_fields:
                if field not in installed:
                    missing_fields.append(field)
                else:
                    # Show partial values for verification
                    value = installed[field]
                    if field == 'client_secret':
                        display_value = value[:8] + "..." if len(value) > 8 else "***"
                    elif field == 'client_id':
                        display_value = value[:20] + "..." if len(value) > 20 else value
                    else:
                        display_value = value
                    
                    print(f"‚úÖ {field}: {display_value}")
            
            if missing_fields:
                print(f"‚ùå Missing required fields: {missing_fields}")
                return False
            
            # Check redirect URIs
            if 'redirect_uris' in installed:
                redirect_uris = installed['redirect_uris']
                print(f"üìç Redirect URIs: {redirect_uris}")
                
                # Check if localhost is included
                localhost_found = any('localhost' in uri for uri in redirect_uris)
                if not localhost_found:
                    print("‚ö†Ô∏è No localhost redirect URI found - this might cause issues")
            
            print("‚úÖ Credentials file structure is valid")
            return True
            
        else:
            print("‚ùå Invalid credentials format - missing 'installed' key")
            return False
            
    except json.JSONDecodeError as e:
        print(f"‚ùå JSON decode error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Error reading credentials: {e}")
        return False

def test_oauth_flow():
    """Test OAuth flow initialization"""
    
    print("\nüîß Testing OAuth flow...")
    
    try:
        from modules.sources.cloud_auth import CloudAuthManager
        
        # Initialize auth manager
        auth_manager = CloudAuthManager('google_drive')
        print("‚úÖ CloudAuthManager initialized")
        
        # Test OAuth flow initiation (without actual redirect)
        redirect_uri = 'http://localhost:8080/api/cloud/oauth/callback'
        
        # This will fail with real OAuth but we can catch the specific error
        oauth_result = auth_manager.initiate_oauth_flow(redirect_uri)
        
        if oauth_result['success']:
            print("‚úÖ OAuth flow initialized successfully")
            print(f"üìç Auth URL: {oauth_result['auth_url'][:50]}...")
            return True
        else:
            print(f"‚ùå OAuth flow failed: {oauth_result['message']}")
            
            # Common OAuth errors
            error_msg = oauth_result['message'].lower()
            if 'not found' in error_msg or 'file' in error_msg:
                print("üí° Solution: Check credentials file location")
            elif 'redirect' in error_msg:
                print("üí° Solution: Update redirect URIs in Google Cloud Console")
            elif 'client' in error_msg:
                print("üí° Solution: Verify client_id and client_secret")
            
            return False
            
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå OAuth test error: {e}")
        return False

def test_api_endpoint():
    """Test API endpoint directly"""
    
    print("\nüåê Testing API endpoint...")
    
    try:
        import requests
        
        url = "http://localhost:8080/api/cloud/authenticate"
        data = {
            "provider": "google_drive",
            "action": "initiate_auth"
        }
        
        response = requests.post(url, json=data, timeout=5)
        
        print(f"üì° API Response: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            print("‚úÖ API endpoint working")
            if 'auth_url' in result:
                print("‚úÖ OAuth URL generated successfully")
            return True
        else:
            print(f"‚ùå API error: {response.status_code}")
            try:
                error_data = response.json()
                print(f"Error details: {error_data}")
            except:
                print(f"Raw response: {response.text}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("‚ùå Cannot connect to backend - is it running on port 8080?")
        return False
    except ImportError:
        print("‚ö†Ô∏è Requests library not available - skipping API test")
        return True
    except Exception as e:
        print(f"‚ùå API test error: {e}")
        return False

def main():
    """Main test function"""
    
    print("=" * 60)
    print("üîß Google Drive Integration Test")
    print("=" * 60)
    
    tests_passed = 0
    total_tests = 3
    
    # Test 1: Credentials file
    if test_credentials():
        tests_passed += 1
    
    # Test 2: OAuth flow
    if test_oauth_flow():
        tests_passed += 1
    
    # Test 3: API endpoint
    if test_api_endpoint():
        tests_passed += 1
    
    # Summary
    print("\n" + "=" * 60)
    print(f"üìä TEST SUMMARY: {tests_passed}/{total_tests} passed")
    print("=" * 60)
    
    if tests_passed == total_tests:
        print("üéâ All tests passed! Google Drive integration should work.")
    elif tests_passed >= 1:
        print("‚ö†Ô∏è Some tests failed. Check the issues above.")
    else:
        print("‚ùå All tests failed. Google Drive integration needs setup.")
    
    # Recommendations
    print("\nüí° NEXT STEPS:")
    
    if tests_passed == 0:
        print("1. ‚úÖ Download Google Cloud Console credentials")
        print("2. ‚úÖ Place in modules/sources/credentials/google_drive_credentials.json")
        print("3. ‚úÖ Restart backend server")
    elif tests_passed < total_tests:
        print("1. ‚úÖ Check backend logs for detailed errors")
        print("2. ‚úÖ Verify Google Cloud Console OAuth setup")
        print("3. ‚úÖ Ensure redirect URIs include localhost")
    else:
        print("1. üéØ Try authentication again in browser")
        print("2. üéØ Should see Google OAuth popup")

if __name__ == "__main__":
    main()
```
## üìÑ File: `test_nvr_downloader.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/test_nvr_downloader.py`

```python
#!/usr/bin/env python3
"""
Test script for nvr_downloader.py
Run this to verify NVRDownloader functionality
"""

import sys
import os
import json
from datetime import datetime, timedelta

# Add backend to path
sys.path.append('/Users/annhu/vtrack_app/V_Track/backend')

def test_nvr_downloader():
    """Test NVRDownloader with mock data"""
    print("üß™ Testing NVRDownloader...")
    
    try:
        # Import NVRDownloader
        from modules.sources.nvr_downloader import NVRDownloader
        print("‚úÖ Successfully imported NVRDownloader")
        
        # Create instance
        downloader = NVRDownloader()
        print("‚úÖ NVRDownloader instance created")
        
        # Test 1: Basic initialization
        print("\n=== TEST 1: Basic Initialization ===")
        print(f"Download progress storage: {type(downloader.download_progress)}")
        print(f"Download progress empty: {len(downloader.download_progress) == 0}")
        
        # Test 2: Mock source config
        print("\n=== TEST 2: Mock Source Config ===")
        mock_source_config = {
            'id': 36,  # From database
            'selected_cameras': ['Front Door Camera', 'Parking Lot Camera'],
            'url': 'localhost',
            'port': 1000,
            'username': 'admin',
            'password': 'admin',
            'path': '/Users/annhu/vtrack_app/V_Track/nvr_downloads/nvr_localhost'
        }
        
        print(f"Mock config: {json.dumps(mock_source_config, indent=2)}")
        
        # Test 3: Test path validation integration
        print("\n=== TEST 3: Path Validation Integration ===")
        try:
            from modules.utils.path_validator import path_validator
            print("‚úÖ PathValidator imported successfully")
            
            # Test get_camera_paths
            camera_paths = path_validator.get_camera_paths(
                mock_source_config['path'], 
                mock_source_config['selected_cameras']
            )
            print(f"Camera paths result: {camera_paths}")
            
        except Exception as e:
            print(f"‚ùå PathValidator error: {e}")
        
        # Test 4: Test database connection
        print("\n=== TEST 4: Database Connection ===")
        try:
            from modules.db_utils import get_db_connection
            conn = get_db_connection()
            cursor = conn.cursor()
            
            # Test sync_status table
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='sync_status'")
            if cursor.fetchone():
                print("‚úÖ sync_status table exists")
            else:
                print("‚ùå sync_status table missing")
            
            # Test downloaded_files table
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='downloaded_files'")
            if cursor.fetchone():
                print("‚úÖ downloaded_files table exists")
            else:
                print("‚ùå downloaded_files table missing")
            
            conn.close()
            
        except Exception as e:
            print(f"‚ùå Database error: {e}")
        
        # Test 5: Test SOAP envelope generation
        print("\n=== TEST 5: SOAP Envelope Generation ===")
        try:
            test_body = "<TestRequest>Hello</TestRequest>"
            soap_envelope = downloader._wrap_soap_envelope(test_body)
            print("‚úÖ SOAP envelope generated:")
            print(soap_envelope[:200] + "..." if len(soap_envelope) > 200 else soap_envelope)
            
        except Exception as e:
            print(f"‚ùå SOAP envelope error: {e}")
        
        # Test 6: Test with real source config (dry run)
        print("\n=== TEST 6: Real Source Config (Dry Run) ===")
        try:
            # Get actual source from database
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
                SELECT id, config, path FROM video_sources 
                WHERE source_type = 'nvr' AND active = 1 
                LIMIT 1
            """)
            result = cursor.fetchone()
            
            if result:
                source_id, config_json, path = result
                config = json.loads(config_json)
                
                print(f"Real source found: ID={source_id}")
                print(f"Config: {json.dumps(config, indent=2)}")
                print(f"Path: {path}")
                
                # Build real config for downloader
                real_config = {
                    'id': source_id,
                    'selected_cameras': config.get('selected_cameras', []),
                    'url': config.get('url', 'localhost'),
                    'port': config.get('port', 1000),
                    'username': config.get('username', 'admin'),
                    'password': config.get('password', 'admin'),
                    'path': f'/Users/annhu/vtrack_app/V_Track/nvr_downloads/nvr_{config.get("url", "localhost")}'
                }
                
                print(f"Real config for downloader: {json.dumps(real_config, indent=2)}")
                
                # Test download_latest_recordings (without actual HTTP calls)
                print("\nüì• Testing download_latest_recordings (mock)...")
                
                # This would actually call ONVIF - let's skip for now
                print("‚ö†Ô∏è Skipping actual HTTP calls to avoid container dependency")
                
            else:
                print("‚ùå No NVR source found in database")
            
            conn.close()
            
        except Exception as e:
            print(f"‚ùå Real config test error: {e}")
        
        print("\n‚úÖ NVRDownloader basic tests completed")
        return True
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_dependencies():
    """Test required dependencies"""
    print("üîç Testing dependencies...")
    
    required_modules = [
        'requests',
        'logging', 
        'os',
        'datetime',
        'xml.etree.ElementTree',
        'typing'
    ]
    
    for module in required_modules:
        try:
            __import__(module)
            print(f"‚úÖ {module}")
        except ImportError:
            print(f"‚ùå {module} - MISSING")
    
    # Test custom modules
    custom_modules = [
        'modules.db_utils',
        'modules.utils.path_validator'
    ]
    
    for module in custom_modules:
        try:
            __import__(module)
            print(f"‚úÖ {module}")
        except ImportError as e:
            print(f"‚ùå {module} - MISSING: {e}")

if __name__ == "__main__":
    print("üß™ NVRDownloader Test Suite")
    print("=" * 50)
    
    # Test 1: Dependencies
    test_dependencies()
    
    print("\n" + "=" * 50)
    
    # Test 2: NVRDownloader functionality
    success = test_nvr_downloader()
    
    print("\n" + "=" * 50)
    print(f"üéØ Overall result: {'‚úÖ PASSED' if success else '‚ùå FAILED'}")
```
## üìÑ File: `cutter_bp.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/blueprints/cutter_bp.py`

```python
import sqlite3
import os
from datetime import datetime
import subprocess
from flask import Blueprint, request, jsonify
from modules.db_utils import get_db_connection
import ast
from modules.technician.cutter.cutter_complete import cut_complete_event
from modules.technician.cutter.cutter_incomplete import cut_incomplete_event, merge_incomplete_events
from modules.technician.cutter.cutter_utils import generate_output_filename, update_event_in_db
from modules.scheduler.db_sync import db_rwlock

cutter_bp = Blueprint('cutter', __name__)

with db_rwlock.gen_rlock():
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT output_path FROM processing_config LIMIT 1")
    result = cursor.fetchone()
    output_dir = result[0] if result else os.path.join(os.path.dirname(os.path.abspath(__file__)), "../../resources/output_clips")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    conn.close()

def get_video_duration(video_file):
    try:
        cmd = ["ffprobe", "-v", "error", "-show_entries", "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", video_file]
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        return float(result.stdout.strip())
    except Exception:
        return None

def cut_and_update_events(selected_events, tracking_codes_filter, brand_name="Alan"):
    with db_rwlock.gen_wlock():
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT video_buffer, max_packing_time FROM processing_config LIMIT 1")
        result = cursor.fetchone()
        video_buffer = result[0] if result else 5
        max_packing_time = result[1] if result else 120
        cut_files = []

        for event in selected_events:
            event_id = event.get("event_id")
            ts = event.get("ts")
            te = event.get("te")
            video_file = event.get("video_file")
            cursor.execute("SELECT is_processed FROM events WHERE event_id = ?", (event_id,))
            is_processed = cursor.fetchone()[0]
            if is_processed:
                print(f"B·ªè qua: S·ª± ki·ªán {event_id} ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω tr∆∞·ªõc ƒë√≥")
                continue

            has_ts = ts is not None
            has_te = te is not None
            is_incomplete = (has_ts and not has_te) or (not has_ts and has_te)

            if is_incomplete:
                next_event = None
                if has_ts and not has_te:
                    cursor.execute("SELECT event_id, ts, te, video_file, packing_time_start, packing_time_end, tracking_codes, is_processed FROM events WHERE event_id = ? AND is_processed = 0", (event_id + 1,))
                    next_event_row = cursor.fetchone()
                    if next_event_row:
                        next_event = {
                            "event_id": next_event_row[0],
                            "ts": next_event_row[1],
                            "te": next_event_row[2],
                            "video_file": next_event_row[3],
                            "packing_time_start": next_event_row[4],
                            "packing_time_end": next_event_row[5],
                            "tracking_codes": next_event_row[6],
                            "is_processed": next_event_row[7]
                        }
                elif not has_ts and has_te:
                    cursor.execute("SELECT event_id, ts, te, video_file, packing_time_start, packing_time_end, tracking_codes, is_processed FROM events WHERE event_id = ? AND is_processed = 0", (event_id - 1,))
                    prev_event_row = cursor.fetchone()
                    if prev_event_row:
                        next_event = {
                            "event_id": prev_event_row[0],
                            "ts": prev_event_row[1],
                            "te": prev_event_row[2],
                            "video_file": prev_event_row[3],
                            "packing_time_start": prev_event_row[4],
                            "packing_time_end": prev_event_row[5],
                            "tracking_codes": prev_event_row[6],
                            "is_processed": prev_event_row[7]
                        }

                if next_event:
                    next_event_id = next_event.get("event_id")
                    next_ts = next_event.get("ts")
                    next_te = next_event.get("te")
                    next_video_file = next_event.get("video_file")
                    next_has_ts = next_ts is not None
                    next_has_te = next_te is not None
                    can_merge = (has_ts and not has_te and not next_has_ts and next_has_te) or (not has_ts and has_te and next_has_ts and not next_has_te)

                    if can_merge:
                        video_length_a = get_video_duration(video_file)
                        video_length_b = get_video_duration(next_video_file)
                        if video_length_a is None or video_length_b is None:
                            print(f"L·ªói: Kh√¥ng th·ªÉ l·∫•y ƒë·ªô d√†i video {video_file} ho·∫∑c {next_video_file}")
                            continue

                        output_file_a = generate_output_filename(event, tracking_codes_filter, output_dir, brand_name)
                        print(f"ƒêang x·ª≠ l√Ω s·ª± ki·ªán {event_id}: output_file={output_file_a}, packing_time_start={event.get('packing_time_start')}, packing_time_end={event.get('packing_time_end')}")
                        if cut_incomplete_event(event, video_buffer, video_length_a, output_file_a):
                            update_event_in_db(cursor, event_id, output_file_a)

                        output_file_b = generate_output_filename(next_event, tracking_codes_filter, output_dir, brand_name)
                        print(f"ƒêang x·ª≠ l√Ω s·ª± ki·ªán {next_event_id}: output_file={output_file_b}, packing_time_start={next_event.get('packing_time_start')}, packing_time_end={next_event.get('packing_time_end')}")
                        if cut_incomplete_event(next_event, video_buffer, video_length_b, output_file_b):
                            update_event_in_db(cursor, next_event_id, output_file_b)

                        if has_ts and not has_te:
                            event_a = event
                            event_b = next_event
                            video_length_event_a = video_length_a
                            video_length_event_b = video_length_b
                        else:
                            event_a = next_event
                            event_b = event
                            video_length_event_a = video_length_b
                            video_length_event_b = video_length_a

                        print(f"G·ªçi merge_incomplete_events: event_a (ID: {event_a.get('event_id')}, ts: {event_a.get('ts')}, te: {event_a.get('te')}), event_b (ID: {event_b.get('event_id')}, ts: {event_b.get('ts')}, te: {event_b.get('te')})")

                        merged_file = merge_incomplete_events(event_a, event_b, video_buffer, video_length_event_a, video_length_event_b, output_dir, max_packing_time, brand_name)
                        if merged_file:
                            update_event_in_db(cursor, event_id, merged_file)
                            update_event_in_db(cursor, next_event_id, merged_file)
                            cut_files.append(merged_file)
                        continue

            video_length = get_video_duration(video_file)
            if video_length is None:
                print(f"L·ªói: Kh√¥ng th·ªÉ l·∫•y ƒë·ªô d√†i video {video_file}")
                continue

            output_file = generate_output_filename(event, tracking_codes_filter, output_dir, brand_name)
            print(f"ƒêang x·ª≠ l√Ω s·ª± ki·ªán {event_id}: output_file={output_file}, packing_time_start={event.get('packing_time_start')}, packing_time_end={event.get('packing_time_end')}")

            if has_ts and has_te:
                if cut_complete_event(event, video_buffer, video_length, output_file):
                    update_event_in_db(cursor, event_id, output_file)
                    cut_files.append(output_file)
            elif is_incomplete:
                if cut_incomplete_event(event, video_buffer, video_length, output_file):
                    update_event_in_db(cursor, event_id, output_file)
                    cut_files.append(output_file)
            else:
                print(f"B·ªè qua: S·ª± ki·ªán {event_id} kh√¥ng c√≥ ts ho·∫∑c te")
                continue

        conn.commit()
        conn.close()
    return cut_files

@cutter_bp.route('/cut-videos', methods=['POST'])
def cut_videos():
    data = request.get_json()
    selected_events = data.get('selected_events', [])
    tracking_codes_filter = data.get('tracking_codes_filter', [])

    if not selected_events:
        return jsonify({"error": "No selected events provided"}), 400

    try:
        cut_files = cut_and_update_events(selected_events, tracking_codes_filter)
        return jsonify({"message": "Videos cut successfully", "cut_files": cut_files}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500
```
## üìÑ File: `__init__.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/blueprints/__init__.py`

```python

```
## üìÑ File: `hand_detection_bp.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/blueprints/hand_detection_bp.py`

```python
from flask import Blueprint, request, jsonify
from modules.technician.hand_detection import select_roi
import subprocess
import os
import json
import logging

hand_detection_bp = Blueprint('hand_detection', __name__)

logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

@hand_detection_bp.route('/select-roi', methods=['POST'])
def select_roi_endpoint():
    try:
        data = request.get_json()
        video_path = data.get('videoPath')
        camera_id = data.get('cameraId')
        step = data.get('step', 'packing')
        
        logging.debug(f"Received request for select-roi with step: {step}, video_path: {video_path}, camera_id: {camera_id}")
        
        if not video_path or not camera_id:
            logging.error("Missing videoPath or cameraId")
            return jsonify({"success": False, "error": "Thi·∫øu videoPath ho·∫∑c cameraId."}), 400
        
        if not os.path.exists(video_path):
            logging.error(f"Video path does not exist: {video_path}")
            return jsonify({"success": False, "error": "ƒê∆∞·ªùng d·∫´n video kh√¥ng t·ªìn t·∫°i."}), 404
        
        if os.path.exists("/tmp/roi.json"):
            os.remove("/tmp/roi.json")
            logging.info("ƒê√£ x√≥a file /tmp/roi.json ƒë·ªÉ b·∫Øt ƒë·∫ßu quy tr√¨nh m·ªõi")
        
        result = select_roi(video_path, camera_id, step)
        logging.debug(f"Result from select_roi: {result}")
        return jsonify(result), 200 if result["success"] else 400
    
    except Exception as e:
        logging.error(f"Exception in select_roi_endpoint: {str(e)}")
        return jsonify({"success": False, "error": f"L·ªói h·ªá th·ªëng: {str(e)}"}), 500

@hand_detection_bp.route('/run-select-roi', methods=['POST'])
def run_select_roi_endpoint():
    try:
        data = request.get_json()
        video_path = data.get('videoPath')
        camera_id = data.get('cameraId', 'default_camera')
        
        if not video_path:
            return jsonify({"success": False, "error": "Thi·∫øu videoPath."}), 400
        
        logging.info(f"Running hand_detection.py with video_path: {video_path}, camera_id: {camera_id}")
        
        if not os.path.exists(video_path):
            return jsonify({"success": False, "error": "ƒê∆∞·ªùng d·∫´n video kh√¥ng t·ªìn t·∫°i."}), 404
        
        if os.path.exists("/tmp/roi.json"):
            os.remove("/tmp/roi.json")
        
        result = subprocess.run(
            ["python3", "modules/technician/hand_detection.py", video_path, camera_id],
            capture_output=True,
            text=True,
            timeout=300
        )
        
        if result.returncode != 0:
            error_message = f"L·ªói khi ch·∫°y script: {result.stderr}"
            logging.error(error_message)
            return jsonify({"success": False, "error": error_message}), 500
        
        if not os.path.exists("/tmp/roi.json"):
            return jsonify({"success": False, "error": "Kh√¥ng t√¨m th·∫•y file k·∫øt qu·∫£ ROI."}), 500
        
        with open("/tmp/roi.json", "r") as f:
            roi_result = json.load(f)
        
        logging.info(f"ROI result from /tmp/roi.json: {roi_result}")
        return jsonify(roi_result), 200 if roi_result["success"] else 400
    
    except subprocess.TimeoutExpired:
        return jsonify({"success": False, "error": "H·∫øt th·ªùi gian ch·ªù khi ch·∫°y script."}), 500
    except Exception as e:
        logging.error(f"Unexpected error in run-select-roi: {str(e)}")
        return jsonify({"success": False, "error": f"L·ªói h·ªá th·ªëng: {str(e)}"}), 500

```
## üìÑ File: `roi_bp.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/blueprints/roi_bp.py`

```python
from flask import Blueprint, request, jsonify, send_file
from modules.technician.hand_detection import finalize_roi
import os
import glob
import json
import sqlite3
from datetime import datetime
import logging

roi_bp = Blueprint('roi', __name__)

logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "..", "database", "events.db")
CAMERA_ROI_DIR = os.path.join(BASE_DIR, "..", "..", "resources/output_clips/CameraROI")

@roi_bp.route('/finalize-roi', methods=['POST'])
def finalize_roi_endpoint():
    try:
        data = request.get_json()
        video_path = data.get('videoPath')
        camera_id = data.get('cameraId')
        rois = data.get('rois')

        if not video_path or not camera_id or not rois:
            return jsonify({"success": False, "error": "Thi·∫øu videoPath, cameraId ho·∫∑c rois."}), 400

        if not os.path.exists(video_path):
            return jsonify({"success": False, "error": "ƒê∆∞·ªùng d·∫´n video kh√¥ng t·ªìn t·∫°i."}), 404

        packing_roi = [0, 0, 0, 0]
        if os.path.exists("/tmp/roi.json"):
            with open("/tmp/roi.json", "r") as f:
                roi_data = json.load(f)
                if roi_data.get("success") and "roi" in roi_data:
                    packing_roi = [roi_data["roi"]["x"], roi_data["roi"]["y"], roi_data["roi"]["w"], roi_data["roi"]["h"]]
        
        qr_mvd_area = [0, 0, 0, 0]
        qr_trigger_area = [0, 0, 0, 0]
        table_type = None
        if os.path.exists("/tmp/qr_roi.json"):
            with open("/tmp/qr_roi.json", "r") as f:
                qr_roi_data = json.load(f)
                table_type = qr_roi_data.get("table_type")
                for roi in rois:
                    if roi["type"] == "mvd":
                        qr_mvd_area = [roi["x"], roi["y"], roi["w"], roi["h"]]
                    elif roi["type"] == "trigger" and table_type == "standard":
                        qr_trigger_area = [roi["x"], roi["y"], roi["w"], roi["h"]]

        profile_name = camera_id
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute("SELECT 1 FROM packing_profiles WHERE profile_name = ?", (profile_name,))
        exists = cursor.fetchone()
        
        if exists:
            cursor.execute('''
                UPDATE packing_profiles
                SET qr_trigger_area = ?, qr_mvd_area = ?, packing_area = ?,
                    min_packing_time = ?, jump_time_ratio = ?, scan_mode = ?, fixed_threshold = ?, margin = ?, additional_params = ?
                WHERE profile_name = ?
            ''', (
                json.dumps(qr_trigger_area),
                json.dumps(qr_mvd_area),
                json.dumps(packing_roi),
                10, 0.5, "full", 20, 60, json.dumps({}),
                profile_name
            ))
        else:
            cursor.execute('''
                INSERT INTO packing_profiles (
                    profile_name, qr_trigger_area, qr_mvd_area, packing_area,
                    min_packing_time, jump_time_ratio, scan_mode, fixed_threshold, margin, additional_params
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                profile_name,
                json.dumps(qr_trigger_area),
                json.dumps(qr_mvd_area),
                json.dumps(packing_roi),
                10, 0.5, "full", 20, 60, json.dumps({})
            ))
        conn.commit()
        conn.close()
        logging.info(f"L∆∞u ROI v√†o packing_profiles v·ªõi profile_name: {profile_name}")

        result = finalize_roi(video_path, camera_id, rois)
        return jsonify(result), 200 if result["success"] else 400
    
    except Exception as e:
        logging.error(f"Exception in finalize_roi_endpoint: {str(e)}")
        return jsonify({"success": False, "error": f"L·ªói h·ªá th·ªëng: {str(e)}"}), 500

@roi_bp.route('/get-roi-frame', methods=['GET'])
def get_roi_frame():
    camera_id = request.args.get('camera_id')
    file = request.args.get('file')
    if not camera_id or not file:
        return jsonify({"success": False, "error": "Thi·∫øu camera_id ho·∫∑c file."}), 400

    file_path = os.path.join(CAMERA_ROI_DIR, f"camera_{camera_id}_{file}")
    logging.info(f"Attempting to fetch file: {file_path}")

    if not os.path.exists(file_path):
        logging.error(f"File kh√¥ng t·ªìn t·∫°i: {file_path}")
        return jsonify({"success": False, "error": "Kh√¥ng t√¨m th·∫•y ·∫£nh."}), 404

    return send_file(file_path, mimetype='image/jpeg')

@roi_bp.route('/get-final-roi-frame', methods=['GET'])
def get_final_roi_frame():
    camera_id = request.args.get('camera_id')
    if not camera_id:
        return jsonify({"success": False, "error": "Thi·∫øu camera_id."}), 400
    
    final_pattern = os.path.join(CAMERA_ROI_DIR, f"camera_{camera_id}_roi_final_*.jpg")
    final_files = glob.glob(final_pattern)
    logging.info(f"Files found for camera_id={camera_id}: {final_files}")

    if not final_files:
        logging.error(f"Kh√¥ng t√¨m th·∫•y file t·ªïng h·ª£p n√†o trong {CAMERA_ROI_DIR} v·ªõi pattern {final_pattern}")
        return jsonify({"success": False, "error": "Kh√¥ng t√¨m th·∫•y ·∫£nh t·ªïng h·ª£p."}), 404

    latest_file = max(final_files, key=os.path.getmtime)
    logging.info(f"Latest file selected: {latest_file}")

    if not os.path.exists(latest_file):
        logging.error(f"File m·ªõi nh·∫•t {latest_file} kh√¥ng t·ªìn t·∫°i")
        return jsonify({"success": False, "error": "Kh√¥ng t√¨m th·∫•y ·∫£nh t·ªïng h·ª£p."}), 404

    return send_file(latest_file, mimetype='image/jpeg')
```
## üìÑ File: `qr_detection_bp.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/blueprints/qr_detection_bp.py`

```python
from flask import Blueprint, request, jsonify
from modules.technician.qr_detector import select_qr_roi
import subprocess
import os
import json
import logging

qr_detection_bp = Blueprint('qr_detection', __name__)

logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

CAMERA_ROI_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "..", "resources/output_clips/CameraROI")

@qr_detection_bp.route('/select-qr-roi', methods=['POST'])
def select_qr_roi_endpoint():
    try:
        data = request.get_json()
        video_path = data.get('videoPath')
        camera_id = data.get('cameraId')
        roi_frame_path = data.get('roiFramePath')
        step = data.get('step', 'mvd')
        
        logging.debug(f"[MVD] Received data: {data}")
        logging.debug(f"[MVD] Parameters - video_path: {video_path}, camera_id: {camera_id}, roi_frame_path: {roi_frame_path}, step: {step}")
        
        if not video_path or not camera_id or not roi_frame_path:
            logging.error("[MVD] Missing required parameters")
            return jsonify({"success": False, "error": "Thi·∫øu videoPath, cameraId ho·∫∑c roiFramePath."}), 400
        
        logging.debug(f"[MVD] Checking video path exists: {video_path}")
        if not os.path.exists(video_path):
            logging.error(f"[MVD] Video path does not exist: {video_path}")
            return jsonify({"success": False, "error": "ƒê∆∞·ªùng d·∫´n video kh√¥ng t·ªìn t·∫°i."}), 404
        
        logging.debug(f"[MVD] Checking ROI frame path exists: {roi_frame_path}")
        if not os.path.exists(roi_frame_path):
            logging.error(f"[MVD] ROI frame path does not exist: {roi_frame_path}")
            return jsonify({"success": False, "error": "ƒê∆∞·ªùng d·∫´n ·∫£nh t·∫°m kh√¥ng t·ªìn t·∫°i."}), 404
        
        if os.path.exists("/tmp/qr_roi.json"):
            logging.debug("[MVD] Removing existing /tmp/qr_roi.json")
            os.remove("/tmp/qr_roi.json")
            logging.info("[MVD] ƒê√£ x√≥a file /tmp/qr_roi.json ƒë·ªÉ b·∫Øt ƒë·∫ßu quy tr√¨nh m·ªõi")
        
        logging.debug(f"[MVD] Calling select_qr_roi with video_path: {video_path}, camera_id: {camera_id}, roi_frame_path: {roi_frame_path}, step: {step}")
        result = select_qr_roi(video_path, camera_id, roi_frame_path, step)
        logging.debug(f"[MVD] select_qr_roi result: {result}")
        logging.info(f"[MVD] Completed MVD step for camera_id: {camera_id}")
        
        return jsonify(result), 200 if result["success"] else 400
    
    except Exception as e:
        logging.error(f"[MVD] Exception in select_qr_roi_endpoint: {str(e)}")
        return jsonify({"success": False, "error": f"L·ªói h·ªá th·ªëng: {str(e)}"}), 500

@qr_detection_bp.route('/run-qr-detector', methods=['POST'])
def run_qr_detector_endpoint():
    try:
        data = request.get_json()
        video_path = data.get('videoPath')
        camera_id = data.get('cameraId', 'default_camera')
        
        if not video_path:
            return jsonify({"success": False, "error": "Thi·∫øu videoPath."}), 400
        
        absolute_roi_frame_path = os.path.join(CAMERA_ROI_DIR, f"camera_{camera_id}_roi_packing.jpg")
        
        logging.info(f"Running qr_detector.py with video_path: {video_path}, camera_id: {camera_id}, roi_frame_path: {absolute_roi_frame_path}")
        
        if not os.path.exists(video_path):
            return jsonify({"success": False, "error": "ƒê∆∞·ªùng d·∫´n video kh√¥ng t·ªìn t·∫°i."}), 404
        if not os.path.exists(absolute_roi_frame_path):
            return jsonify({"success": False, "error": "ƒê∆∞·ªùng d·∫´n ·∫£nh packing kh√¥ng t·ªìn t·∫°i."}), 404
        
        if os.path.exists("/tmp/qr_roi.json"):
            os.remove("/tmp/qr_roi.json")
        
        result = subprocess.run(
            ["python3", "modules/technician/qr_detector.py", video_path, camera_id, absolute_roi_frame_path],
            capture_output=True,
            text=True,
            timeout=300
        )
        
        if result.returncode != 0:
            error_message = f"L·ªói khi ch·∫°y script: {result.stderr}"
            logging.error(error_message)
            return jsonify({"success": False, "error": error_message}), 500
        
        if not os.path.exists("/tmp/qr_roi.json"):
            return jsonify({"success": False, "error": "Kh√¥ng t√¨m th·∫•y file k·∫øt qu·∫£ ROI."}), 500
        
        with open("/tmp/qr_roi.json", "r") as f:
            qr_roi_result = json.load(f)
        
        logging.info(f"QR ROI result from /tmp/qr_roi.json: {qr_roi_result}")
        return jsonify(qr_roi_result), 200 if qr_roi_result["success"] else 400
    
    except subprocess.TimeoutExpired:
        return jsonify({"success": False, "error": "H·∫øt th·ªùi gian ch·ªù khi ch·∫°y script."}), 500
    except Exception as e:
        logging.error(f"Unexpected error in run-qr-detector: {str(e)}")
        return jsonify({"success": False, "error": f"L·ªói h·ªá th·ªëng: {str(e)}"}), 500
```
## üìÑ File: `config_loader.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/config_loader.py`

```python
import sqlite3
import os
from modules.path_utils import get_paths


def get_processing_config():
    """
    Tr·∫£ v·ªÅ INPUT_VIDEO_DIR v√† LOG_DIR t·ª´ b·∫£ng processing_config.
    N·∫øu thi·∫øu, fallback v·ªÅ path m·∫∑c ƒë·ªãnh.
    """
    paths = get_paths()
    db_path = paths["DB_PATH"]

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT input_path, output_path FROM processing_config LIMIT 1")
        row = cursor.fetchone()
        conn.close()

        if row:
            return {
                "INPUT_VIDEO_DIR": row[0],
                "LOG_DIR": row[1],
            }
    except Exception as e:
        print(f"[!] L·ªói ƒë·ªçc c·∫•u h√¨nh DB: {e}")

    # fallback n·∫øu l·ªói ho·∫∑c DB tr·ªëng
    return {
        "INPUT_VIDEO_DIR": os.path.join(paths["BASE_DIR"], "resources/Inputvideo"),
        "LOG_DIR": os.path.join(paths["BASE_DIR"], "resources/output_clips/LOG"),
    }


def get_log_path(file_name: str) -> str:
    """Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file trong LOG_DIR."""
    log_dir = get_processing_config()["LOG_DIR"]
    return os.path.join(log_dir, file_name)


def get_input_path(file_name: str) -> str:
    """Tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file trong INPUT_VIDEO_DIR."""
    input_dir = get_processing_config()["INPUT_VIDEO_DIR"]
    return os.path.join(input_dir, file_name)
```
## üìÑ File: `__init__.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/__init__.py`

```python

```
## üìÑ File: `path_utils.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/path_utils.py`

```python
import os


def find_project_root(file_path):
    """T√¨m th∆∞ m·ª•c g·ªëc c·ªßa d·ª± √°n b·∫Øt ƒë·∫ßu t·ª´ file_path."""
    current_path = os.path.dirname(os.path.abspath(file_path))
    while current_path != os.path.dirname(current_path):
        if "backend" in os.listdir(current_path):
            return current_path
        current_path = os.path.dirname(current_path)
    raise RuntimeError("Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c g·ªëc d·ª± √°n.")


def get_paths():
    base_dir = find_project_root(__file__)
    return {
        "BASE_DIR": base_dir,
        "DB_PATH": os.path.join(base_dir, "backend/database/events.db"),
        "BACKEND_DIR": os.path.join(base_dir, "backend"),
        "FRONTEND_DIR": os.path.join(base_dir, "frontend"),
        "CAMERA_ROI_DIR": os.path.join(base_dir, "resources", "output_clips", "CameraROI")
    }

```
## üìÑ File: `config.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/config/config.py`

```python
from datetime import datetime
from flask import Blueprint, request, jsonify, Flask
from flask_cors import CORS
import os
import json
import sqlite3
import logging
import time
from modules.db_utils import find_project_root, get_db_connection
from modules.scheduler.db_sync import db_rwlock
from modules.sources.path_manager import PathManager
from modules.sources.nvr_client import NVRClient
from database import update_database, DB_PATH, initialize_sync_status
from modules.sources.nvr_downloader import NVRDownloader
from modules.sources.auto_sync_service import AutoSyncService
# üÜï NEW: Cloud endpoints module
from modules.sources.cloud_endpoints import cloud_bp

config_bp = Blueprint('config', __name__)

# X√°c ƒë·ªãnh th∆∞ m·ª•c g·ªëc c·ªßa d·ª± √°n
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
CONFIG_FILE = os.path.join(BASE_DIR, "config.json")

def init_app_and_config():
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        handlers=[
            logging.StreamHandler()
        ]
    )
    logger = logging.getLogger(__name__)

    app = Flask(__name__)
    CORS(app, resources={r"/*": {"origins": "http://localhost:3000"}})

    DB_PATH = os.path.join(BASE_DIR, "database", "events.db")
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)

    # G·ªçi update_database ƒë·ªÉ t·∫°o b·∫£ng tr∆∞·ªõc khi truy v·∫•n
    update_database()

    def get_db_path():
        default_db_path = DB_PATH
        try:
            with db_rwlock.gen_rlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("SELECT db_path FROM processing_config WHERE id = 1")
                result = cursor.fetchone()
                conn.close()
            return result[0] if result else default_db_path
        except Exception as e:
            logger.error(f"Error getting DB_PATH from database: {e}")
            return default_db_path

    final_db_path = get_db_path()
    logger.info(f"Using DB_PATH: {final_db_path}")

    # Truy v·∫•n c·∫•u h√¨nh t·ª´ processing_config
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT input_path, output_path, frame_rate, frame_interval FROM processing_config WHERE id = 1")
        result = cursor.fetchone()
        conn.close()
        if result:
            INPUT_PATH, OUTPUT_PATH, FRAME_RATE, FRAME_INTERVAL = result
        else:
            INPUT_PATH = os.path.join(BASE_DIR, "Inputvideo")
            OUTPUT_PATH = os.path.join(BASE_DIR, "output_clips")
            FRAME_RATE = 30
            FRAME_INTERVAL = 6
    except Exception as e:
        logger.error(f"Error querying processing_config: {e}")
        INPUT_PATH = os.path.join(BASE_DIR, "Inputvideo")
        OUTPUT_PATH = os.path.join(BASE_DIR, "output_clips")
        FRAME_RATE = 30
        FRAME_INTERVAL = 6

    return app, final_db_path, logger

# H√†m ƒë·ªçc c·∫•u h√¨nh t·ª´ file ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng
def load_config():
    default_config = {
        "db_path": os.path.join(BASE_DIR, "database", "events.db"),
        "input_path": os.path.join(BASE_DIR, "Inputvideo"),
        "output_path": os.path.join(BASE_DIR, "output_clips")
    }
    
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"Error loading config file: {e}")
            return default_config
    
    return {
        "db_path": os.getenv("DB_PATH", default_config["db_path"]),
        "input_path": os.getenv("INPUT_PATH", default_config["input_path"]),
        "output_path": os.getenv("OUTPUT_PATH", default_config["output_path"])
    }

# Load c·∫•u h√¨nh t·ª´ processing_config thay v√¨ config.json
config = load_config()

def detect_camera_folders(path):
    """Detect camera folders in the given path"""
    cameras = []
    
    if not os.path.exists(path):
        return cameras
    
    try:
        for item in os.listdir(path):
            item_path = os.path.join(path, item)
            if os.path.isdir(item_path):
                # Check if this looks like a camera folder
                # Common camera folder patterns: Cam*, Camera*, Channel*, etc.
                item_lower = item.lower()
                if any(pattern in item_lower for pattern in ['cam', 'camera', 'channel', 'ch']):
                    cameras.append(item)
                # Also include any directory that contains video files
                elif has_video_files(item_path):
                    cameras.append(item)
        
        cameras.sort()  # Sort alphabetically
        return cameras
    except Exception as e:
        print(f"Error detecting cameras in {path}: {e}")
        return cameras

def has_video_files(path, max_depth=2):
    """Check if directory contains video files (recursive up to max_depth)"""
    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv', '.m4v', '.mpg', '.mpeg')
    
    def check_directory(dir_path, depth):
        if depth > max_depth:
            return False
        
        try:
            for item in os.listdir(dir_path):
                item_path = os.path.join(dir_path, item)
                if os.path.isfile(item_path) and item.lower().endswith(video_extensions):
                    return True
                elif os.path.isdir(item_path) and depth < max_depth:
                    if check_directory(item_path, depth + 1):
                        return True
        except (PermissionError, OSError):
            pass
        
        return False
    
    return check_directory(path, 0)

# ‚úÖ FIX: Helper function ƒë·ªÉ map path cho c√°c source type kh√°c nhau
def get_working_path_for_source(source_type, source_name, source_path):
    """Map source connection info to actual working directory"""
    if source_type == 'nvr':
        # NVR: source_path is connection URL, working path is download directory
        working_path = os.path.join(BASE_DIR, "nvr_downloads", source_name)
        print(f"üîó NVR Path Mapping: {source_path} ‚Üí {working_path}")
        
        # Create directory if it doesn't exist
        try:
            os.makedirs(working_path, exist_ok=True)
            print(f"üìÅ Created/verified NVR directory: {working_path}")
        except Exception as e:
            print(f"‚ùå Failed to create NVR directory {working_path}: {e}")
            
        return working_path
        
    elif source_type == 'local':
        # Local: source_path is actual file system path
        working_path = source_path
        print(f"üìÅ Local Path Mapping: {source_path} ‚Üí {working_path}")
        return working_path
        
    elif source_type == 'cloud':
        # Cloud: source_path is cloud URL, working path is sync directory
        working_path = os.path.join(BASE_DIR, "cloud_sync", source_name)
        print(f"‚òÅÔ∏è Cloud Path Mapping: {source_path} ‚Üí {working_path}")
        
        # Create directory if it doesn't exist
        try:
            os.makedirs(working_path, exist_ok=True)
            print(f"üìÅ Created/verified Cloud directory: {working_path}")
        except Exception as e:
            print(f"‚ùå Failed to create Cloud directory {working_path}: {e}")
            
        return working_path
        
    else:
        # Unknown source type: use as-is
        print(f"‚ùì Unknown source type '{source_type}', using path as-is: {source_path}")
        return source_path

@config_bp.route('/detect-cameras', methods=['POST'])
def detect_cameras():
    """Detect camera folders in the specified path"""
    try:
        data = request.json
        path = data.get('path')
        
        if not path:
            return jsonify({"error": "Path is required"}), 400
        
        if not os.path.exists(path):
            return jsonify({"error": f"Path does not exist: {path}"}), 400
        
        # Detect camera folders
        cameras = detect_camera_folders(path)
        
        # Get current selected cameras from processing_config
        selected_cameras = []
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT selected_cameras FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            if result and result[0]:
                selected_cameras = json.loads(result[0])
            conn.close()
        except Exception as e:
            print(f"Error getting selected cameras: {e}")
        
        return jsonify({
            "cameras": cameras,
            "selected_cameras": selected_cameras,
            "path": path,
            "count": len(cameras)
        }), 200
        
    except Exception as e:
        return jsonify({"error": f"Failed to detect cameras: {str(e)}"}), 500

@config_bp.route('/update-source-cameras', methods=['POST'])
def update_source_cameras():
    """üîß Update selected cameras for a source in processing_config (Simple Update)"""
    try:
        data = request.json
        source_id = data.get('source_id')
        selected_cameras = data.get('selected_cameras', [])
        
        # Update processing_config with selected cameras
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            UPDATE processing_config 
            SET selected_cameras = ? 
            WHERE id = 1
        """, (json.dumps(selected_cameras),))
        
        conn.commit()
        conn.close()
        
        return jsonify({
            "message": "Camera selection updated successfully",
            "selected_cameras": selected_cameras,
            "count": len(selected_cameras)
        }), 200
        
    except Exception as e:
        return jsonify({"error": f"Failed to update camera selection: {str(e)}"}), 500

@config_bp.route('/get-cameras', methods=['GET'])
def get_cameras():
    try:
        path_manager = PathManager()
        sources = path_manager.get_all_active_sources()
        
        cameras = []
        
        if sources:
            # Use active source
            active_source = sources[0]  # Single active source
            source_type = active_source['source_type']
            
            if source_type == 'local':
                # Local directory scanning
                video_root = active_source['path']
                if not os.path.exists(video_root):
                    return jsonify({"error": f"Directory {video_root} does not exist. Ensure the path is correct or create the directory."}), 400
                
                # Detect camera folders
                detected_cameras = detect_camera_folders(video_root)
                for camera in detected_cameras:
                    cameras.append({"name": camera, "path": os.path.join(video_root, camera)})
            
            elif source_type in ['network', 'cloud', 'camera']:
                # For other source types, use source name as camera
                cameras.append({"name": active_source['name'], "path": active_source['path']})
        else:
            # Fallback to legacy behavior
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT input_path FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            conn.close()

            if not result:
                return jsonify({"error": "video_root not found in configuration. Please update via /save-config endpoint."}), 400

            video_root = result[0]
            if not os.path.exists(video_root):
                return jsonify({"error": f"Directory {video_root} does not exist. Ensure the path is correct or create the directory."}), 400

            detected_cameras = detect_camera_folders(video_root)
            for camera in detected_cameras:
                cameras.append({"name": camera, "path": os.path.join(video_root, camera)})

        return jsonify({"cameras": cameras}), 200
    except Exception as e:
        return jsonify({"error": f"Failed to retrieve cameras: {str(e)}"}), 500

@config_bp.route('/save-config', methods=['POST'])
def save_config():
    """Fixed save_config without frame_settings table dependency"""
    try:
        data = request.json
        if not data:
            return jsonify({"error": "No data provided"}), 400
            
        video_root = data.get('video_root')
        output_path = data.get('output_path', config.get("output_path", "/default/output"))
        default_days = data.get('default_days', 30)
        min_packing_time = data.get('min_packing_time', 10)
        max_packing_time = data.get('max_packing_time', 120)
        frame_rate = data.get('frame_rate', 30)
        frame_interval = data.get('frame_interval', 5)
        video_buffer = data.get('video_buffer', 2)
        selected_cameras = data.get('selected_cameras', [])
        run_default_on_start = data.get('run_default_on_start', 1)

        print(f"=== SAVE CONFIG REQUEST ===")
        print(f"Raw video_root from frontend: {video_root}")
        print(f"Selected cameras: {selected_cameras}")

        # ‚úÖ FIX: Enhanced path mapping with better error handling
        try:
            # Try to get active source for path mapping
            try:
                from modules.sources.path_manager import PathManager
                path_manager = PathManager()
                active_sources = path_manager.get_all_active_sources()
                
                if active_sources:
                    active_source = active_sources[0]  # Single active source
                    source_type = active_source['source_type']
                    source_name = active_source['name']
                    source_path = active_source['path']
                    
                    print(f"Found active source: {source_name} ({source_type})")
                    
                    # Apply proper path mapping
                    correct_working_path = get_working_path_for_source(source_type, source_name, source_path)
                    
                    if video_root != correct_working_path:
                        print(f"üîÑ Correcting video_root: {video_root} ‚Üí {correct_working_path}")
                        video_root = correct_working_path
                    else:
                        print(f"‚úÖ video_root already correct: {video_root}")
                else:
                    print("‚ö†Ô∏è No active video source found, using video_root as-is")
                    
            except ImportError:
                print("‚ö†Ô∏è PathManager not available, using video_root as-is")
            except Exception as pm_error:
                print(f"‚ö†Ô∏è PathManager error: {pm_error}, using video_root as-is")
                
        except Exception as path_error:
            print(f"‚ùå Error in path mapping: {path_error}")

        # ‚úÖ Final validation
        if not video_root or video_root.strip() == "":
            error_msg = "‚ùå video_root cannot be empty"
            print(error_msg)
            return jsonify({"error": error_msg}), 400

        # Basic URL validation
        if '://' in video_root or 'localhost:' in video_root:
            error_msg = f"‚ùå video_root cannot be a URL: {video_root}"
            print(error_msg)
            return jsonify({"error": error_msg}), 400

        print(f"üìù Final video_root for database: {video_root}")

        # ‚úÖ FIXED: Database operations - only processing_config table
        try:
            conn = get_db_connection()
            if not conn:
                return jsonify({"error": "Database connection failed"}), 500
                
            cursor = conn.cursor()
            
            # Check if processing_config table exists
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name='processing_config'
            """)
            if not cursor.fetchone():
                return jsonify({"error": "processing_config table not found"}), 500
            
            # Add column if not exists (safe operation)
            try:
                cursor.execute("ALTER TABLE processing_config ADD COLUMN run_default_on_start INTEGER DEFAULT 1")
                print("‚úÖ Added run_default_on_start column")
            except sqlite3.OperationalError:
                pass  # Column already exists
            
            # ‚úÖ MAIN FIX: Only insert into processing_config (no frame_settings)
            cursor.execute("""
                INSERT OR REPLACE INTO processing_config (
                    id, input_path, output_path, storage_duration, min_packing_time, 
                    max_packing_time, frame_rate, frame_interval, video_buffer, default_frame_mode, 
                    selected_cameras, db_path, run_default_on_start
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (1, video_root, output_path, default_days, min_packing_time, max_packing_time, 
                  frame_rate, frame_interval, video_buffer, "default", json.dumps(selected_cameras), 
                  DB_PATH, run_default_on_start))

            print("‚úÖ processing_config updated successfully")

            # ‚úÖ REMOVED: No more frame_settings table insert
            # Frame data is now stored in processing_config table only

            conn.commit()
            
            # ‚úÖ Verify what was saved
            cursor.execute("SELECT input_path, selected_cameras, frame_rate, frame_interval FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            if result:
                saved_path, saved_cameras, saved_fr, saved_fi = result
                print(f"‚úÖ Verified saved input_path: {saved_path}")
                print(f"‚úÖ Verified saved cameras: {saved_cameras}")
                print(f"‚úÖ Verified saved frame_rate: {saved_fr}, frame_interval: {saved_fi}")
            
            conn.close()
            
            print("‚úÖ Config saved successfully")
            return jsonify({
                "message": "Configuration saved successfully",
                "saved_path": video_root,
                "saved_cameras": selected_cameras,
                "frame_settings": {
                    "frame_rate": frame_rate,
                    "frame_interval": frame_interval
                }
            }), 200
            
        except sqlite3.PermissionError as e:
            error_msg = f"Database permission denied: {str(e)}"
            print(f"‚ùå {error_msg}")
            return jsonify({"error": error_msg}), 403
        except sqlite3.Error as e:
            error_msg = f"Database error: {str(e)}"
            print(f"‚ùå {error_msg}")
            return jsonify({"error": error_msg}), 500
        except Exception as e:
            error_msg = f"Database operation failed: {str(e)}"
            print(f"‚ùå {error_msg}")
            return jsonify({"error": error_msg}), 500

    except Exception as e:
        # ‚úÖ Catch-all error handler to ensure JSON response
        error_msg = f"Unexpected error: {str(e)}"
        print(f"‚ùå CRITICAL ERROR in save_config: {error_msg}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": error_msg}), 500

@config_bp.route('/save-general-info', methods=['POST'])
def save_general_info():
    data = request.json
    country = data.get('country')
    timezone = data.get('timezone')
    brand_name = data.get('brand_name')
    working_days = data.get('working_days', ["Th·ª© Hai", "Th·ª© Ba", "Th·ª© T∆∞", "Th·ª© NƒÉm", "Th·ª© S√°u", "Th·ª© B·∫£y", "Ch·ªß Nh·∫≠t"])
    
    # B·∫£n ƒë·ªì ng√†y ti·∫øng Vi·ªát sang ti·∫øng Anh
    day_map = {
        'Th·ª© Hai': 'Monday', 'Th·ª© Ba': 'Tuesday', 'Th·ª© T∆∞': 'Wednesday',
        'Th·ª© NƒÉm': 'Thursday', 'Th·ª© S√°u': 'Friday', 'Th·ª© B·∫£y': 'Saturday',
        'Ch·ªß Nh·∫≠t': 'Sunday'
    }
    
    # Chuy·ªÉn ƒë·ªïi working_days sang ti·∫øng Anh
    working_days_en = [day_map.get(day, day) for day in working_days]
    
    from_time = data.get('from_time', "07:00")
    to_time = data.get('to_time', "23:00")

    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            INSERT OR REPLACE INTO general_info (
                id, country, timezone, brand_name, working_days, from_time, to_time
            ) VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (1, country, timezone, brand_name, json.dumps(working_days_en), from_time, to_time))

        conn.commit()
        conn.close()
    except PermissionError as e:
        return jsonify({"error": f"Permission denied: {str(e)}. Check database file permissions."}), 403
    except Exception as e:
        return jsonify({"error": f"Database error: {str(e)}. Ensure the database is accessible."}), 500

    print("General info saved:", data)
    return jsonify({"message": "General info saved"}), 200

@config_bp.route('/save-sources', methods=['POST'])
def save_video_sources():
    """Save single active video source - Enhanced with auto-sync for NVR"""
    data = request.json
    sources = data.get('sources', [])
    
    if not sources:
        return jsonify({"error": "No sources provided"}), 400
    
    # Single Active Source: only process the first source
    source = sources[0]
    source_type = source.get('source_type')
    name = source.get('name')
    path = source.get('path')
    config_data = source.get('config', {})
    
    print(f"=== SAVE SOURCE: {name} ({source_type}) ===")
    print(f"Connection path: {path}")
    print(f"Config data: {config_data}")
    
    if not all([source_type, name, path]):
        return jsonify({"error": "Source missing required fields"}), 400
    
    path_manager = PathManager()
    
    try:
        # Disable all existing sources first
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("UPDATE video_sources SET active = 0")
        conn.commit()
        conn.close()
        
        # Add new source as active
        success, message = path_manager.add_source(source_type, name, path, config_data)
        
        if success:
            # Get source ID for database operations
            source_id = path_manager.get_source_id_by_name(name)
            
            # ‚úÖ FIX: Calculate correct working path and update processing_config
            working_path = get_working_path_for_source(source_type, name, path)
            
            # Update processing_config.input_path to point to working path
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE processing_config 
                SET input_path = ? 
                WHERE id = 1
            """, (working_path,))
            
            print(f"‚úÖ Updated processing_config.input_path to: {working_path}")
            
            # üÜï ENHANCED NVR PROCESSING WITH AUTO-SYNC
            if source_type == 'nvr':
                print(f"üéØ PROCESSING NVR SOURCE WITH AUTO-SYNC...")
                
                selected_cameras = config_data.get('selected_cameras', [])
                
                if selected_cameras:
                    # 1. Path validation and directory creation
                    print(f"üìÅ Creating directories for {len(selected_cameras)} cameras...")
                    try:
                        from modules.utils.path_validator import PathValidator
                        path_validator = PathValidator()
                        
                        # Validate source path
                        path_result = path_validator.validate_source_path(source_type, working_path)
                        if not path_result['success']:
                            print(f"‚ö†Ô∏è Path validation warning: {path_result['message']}")
                        
                        # Create camera directories
                        camera_result = path_validator.create_camera_directories(working_path, selected_cameras)
                        if camera_result['success']:
                            print(f"‚úÖ Created {len(camera_result['created_directories'])} camera directories")
                        else:
                            print(f"‚ùå Directory creation failed: {camera_result['message']}")
                            
                    except ImportError:
                        print("‚ö†Ô∏è PathValidator not available, using basic directory creation")
                        for camera in selected_cameras:
                            camera_dir = os.path.join(working_path, camera.replace(' ', '_'))
                            os.makedirs(camera_dir, exist_ok=True)
                            print(f"üìÅ Created: {camera_dir}")
                    
                    # 2. Initialize sync status (always enabled for NVR)
                    print(f"üîÑ Initializing auto-sync for source ID: {source_id}")
                    #try:
                    #    sync_result = initialize_sync_status(
                    #       source_id, 
                    #        sync_enabled=True, 
                    #        interval_minutes=2  # 2 minutes for testing
                    #   )
                    #    if sync_result:
                    #        print(f"‚úÖ Auto-sync enabled (2-minute intervals)")
                    #    else:
                    #        print(f"‚ö†Ô∏è Auto-sync initialization failed")
                    #except Exception as sync_error:
                    #    print(f"‚ùå Auto-sync initialization error: {sync_error}")
                    
                    # 3. Update camera paths in processing_config
                    print(f"üó∫Ô∏è Updating camera paths mapping...")
                    #try:
                    #    camera_paths = {}
                    #    for camera in selected_cameras:
                    #        camera_dir = os.path.join(working_path, camera.replace(' ', '_'))
                    #        camera_paths[camera] = camera_dir
                        
                    #    update_camera_paths(camera_paths)
                    #    print(f"‚úÖ Updated camera paths for {len(camera_paths)} cameras")
                        
                    #except Exception as path_error:
                    #    print(f"‚ùå Camera paths update error: {path_error}")
                    
                    # 4. üé¨ INITIAL MOCK DOWNLOAD - Key Feature!
                    print(f"üé¨ Starting initial mock download...")
                    try:
                        # Initialize NVRDownloader in mock mode with testing intervals
                        downloader = NVRDownloader(mock_mode=True, testing_intervals=True)
                        
                        download_config = {
                            'source_id': source_id,
                            'name': name,
                            'selected_cameras': selected_cameras,
                            'working_path': working_path
                        }
                        
                        # Perform initial download
                        download_results = downloader.download_recordings(download_config)
                        
                        if download_results['success']:
                            total_files = len(download_results['downloaded_files'])
                            total_size_kb = download_results['total_size'] / 1024
                            cameras_count = len(download_results['cameras_processed'])
                            
                            print(f"üéâ INITIAL DOWNLOAD SUCCESS:")
                            print(f"   üìä Files created: {total_files}")
                            print(f"   üìÅ Total size: {total_size_kb:.1f} KB")
                            print(f"   üé• Cameras processed: {cameras_count}")
                            
                            # Store download stats for response
                            initial_download_stats = {
                                'files_created': total_files,
                                'total_size_kb': round(total_size_kb, 1),
                                'cameras_processed': cameras_count
                            }
                        else:
                            print(f"‚ùå Initial download failed: {download_results.get('error', 'Unknown error')}")
                            initial_download_stats = {
                                'files_created': 0,
                                'total_size_kb': 0,
                                'cameras_processed': 0,
                                'error': download_results.get('error')
                            }
                            
                    except Exception as download_error:
                        print(f"‚ùå Initial download error: {download_error}")
                        initial_download_stats = {
                            'files_created': 0,
                            'total_size_kb': 0,
                            'cameras_processed': 0,
                            'error': str(download_error)
                        }
                    
                    # 5. üöÄ START BACKGROUND AUTO-SYNC SERVICE
                    print(f"üöÄ Starting background auto-sync service...")
                    try:
                        # Note: AutoSyncService implementation will be in next phase
                        # For now, just log that it would start
                        auto_sync_config = {
                            'source_id': source_id,
                            'source_name': name,
                            'selected_cameras': selected_cameras,
                            'working_path': working_path,
                            'sync_interval_minutes': 2,  # Testing interval
                            'mock_mode': True
                        }
                        
                        print(f"‚úÖ Auto-sync service ready with config: {auto_sync_config}")
                        # TODO: auto_sync_service.start_auto_sync(auto_sync_config)
                        
                    except Exception as service_error:
                        print(f"‚ùå Auto-sync service error: {service_error}")
                    
                    # Sync cameras to processing_config
                    cursor.execute("""
                        UPDATE processing_config 
                        SET selected_cameras = ? 
                        WHERE id = 1
                    """, (json.dumps(selected_cameras),))
                    print(f"‚úÖ Synced {len(selected_cameras)} cameras to processing_config")
                    
                else:
                    print("‚ö†Ô∏è No cameras selected for NVR source")
                    initial_download_stats = {'files_created': 0, 'cameras_processed': 0}
                    cursor.execute("""
                        UPDATE processing_config 
                        SET selected_cameras = '[]' 
                        WHERE id = 1
                    """)
            
            # Handle other source types (existing logic)
            elif source_type == 'local':
                # Local source: Auto-detect cameras from file system
                try:
                    cameras = detect_camera_folders(working_path)
                    if cameras:
                        cursor.execute("""
                            UPDATE processing_config 
                            SET selected_cameras = ? 
                            WHERE id = 1
                        """, (json.dumps(cameras),))
                        print(f"‚úÖ Local cameras auto-selected: {cameras}")
                except Exception as camera_error:
                    print(f"Camera detection failed: {camera_error}")
                    cursor.execute("""
                        UPDATE processing_config 
                        SET selected_cameras = '[]' 
                        WHERE id = 1
                    """)
                    
            elif source_type == 'cloud':
                # Cloud source: use cameras from config (similar to NVR)
                selected_cameras = config_data.get('selected_cameras', [])
                if selected_cameras:
                    cursor.execute("""
                        UPDATE processing_config 
                        SET selected_cameras = ? 
                        WHERE id = 1
                    """, (json.dumps(selected_cameras),))
                    print(f"‚úÖ Cloud cameras synced to processing_config: {selected_cameras}")
                else:
                    cursor.execute("""
                        UPDATE processing_config 
                        SET selected_cameras = '[]' 
                        WHERE id = 1
                    """)
            else:
                # Unknown source type: clear cameras
                cursor.execute("""
                    UPDATE processing_config 
                    SET selected_cameras = '[]' 
                    WHERE id = 1
                """)
                print(f"‚ö†Ô∏è Unknown source type '{source_type}', cleared cameras")
            
            conn.commit()
            conn.close()
            
            # üéâ ENHANCED RESPONSE WITH DOWNLOAD STATS
            response_data = {
                "message": f"Source '{name}' set as active",
                "source_type": source_type,
                "connection_path": path,
                "working_path": working_path,
                "cameras_synced": config_data.get('selected_cameras', []) if source_type in ['nvr', 'cloud'] else detect_camera_folders(working_path) if source_type == 'local' else []
            }
            
            # Add NVR-specific response data
            if source_type == 'nvr' and 'initial_download_stats' in locals():
                response_data.update({
                    "auto_sync_enabled": True,
                    "initial_download": initial_download_stats,
                    "sync_interval_minutes": 2
                })
                
                # Enhanced success message
                if initial_download_stats['files_created'] > 0:
                    response_data["message"] = f"NVR source '{name}' activated with auto-sync. {initial_download_stats['files_created']} recordings downloaded immediately."
            
            return jsonify(response_data), 200
        else:
            return jsonify({"error": f"Failed to save source: {message}"}), 400
            
    except Exception as e:
        print(f"Failed to save sources: {str(e)}")
        return jsonify({"error": f"Failed to save sources: {str(e)}"}), 500

# üÜï HELPER FUNCTIONS TO ADD TO config.py

def update_camera_paths(camera_paths_dict):
    """
    Update camera paths mapping in processing_config
    
    Args:
        camera_paths_dict (dict): Camera name -> directory path mapping
    """
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Update camera_paths column in processing_config
        cursor.execute("""
            UPDATE processing_config 
            SET camera_paths = ? 
            WHERE id = 1
        """, (json.dumps(camera_paths_dict),))
        
        conn.commit()
        conn.close()
        
        print(f"‚úÖ Camera paths updated: {camera_paths_dict}")
        
    except Exception as e:
        print(f"‚ùå Failed to update camera paths: {e}")

def get_nvr_download_status(source_id):
    """
    Get current download status for NVR source
    
    Args:
        source_id (int): Source database ID
        
    Returns:
        dict: Download status information
    """
    try:
        downloader = NVRDownloader(mock_mode=True)
        stats = downloader.get_download_statistics(source_id)
        
        # Get sync status
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            SELECT sync_enabled, sync_interval_minutes, last_sync_time, last_sync_status
            FROM sync_status WHERE source_id = ?
        """, (source_id,))
        
        sync_row = cursor.fetchone()
        conn.close()
        
        if sync_row:
            sync_enabled, interval, last_sync, last_status = sync_row
            stats['sync_status'] = {
                'enabled': bool(sync_enabled),
                'interval_minutes': interval,
                'last_sync_time': last_sync,
                'last_sync_status': last_status
            }
        else:
            stats['sync_status'] = {
                'enabled': False,
                'interval_minutes': None,
                'last_sync_time': None,
                'last_sync_status': None
            }
        
        return stats
        
    except Exception as e:
        print(f"‚ùå Failed to get NVR download status: {e}")
        return {
            'total_files': 0,
            'total_size': 0,
            'cameras_count': 0,
            'sync_status': {'enabled': False}
        }

# üÜï NEW API ENDPOINT TO ADD TO config.py

@config_bp.route('/get-nvr-status/<int:source_id>', methods=['GET'])
def get_nvr_status(source_id):
    """
    Get NVR source download status and statistics
    
    Args:
        source_id (int): Source database ID via URL parameter
        
    Returns:
        JSON: NVR status information
    """
    try:
        status = get_nvr_download_status(source_id)
        
        return jsonify({
            "source_id": source_id,
            "download_stats": status,
            "timestamp": datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        return jsonify({
            "error": f"Failed to get NVR status: {str(e)}",
            "source_id": source_id
        }), 500

@config_bp.route('/trigger-nvr-sync/<int:source_id>', methods=['POST'])
def trigger_manual_nvr_sync(source_id):
    """
    Manually trigger NVR sync for testing/debugging
    
    Args:
        source_id (int): Source database ID via URL parameter
        
    Returns:
        JSON: Sync results
    """
    try:
        # Get source info
        path_manager = PathManager()
        source = path_manager.get_source_by_id(source_id)
        
        if not source or source['source_type'] != 'nvr':
            return jsonify({
                "error": f"NVR source {source_id} not found"
            }), 404
        
        # Get working path and cameras
        working_path = get_working_path_for_source(
            source['source_type'], 
            source['name'], 
            source['path']
        )
        
        selected_cameras = source['config'].get('selected_cameras', [])
        
        # Trigger download
        downloader = NVRDownloader(mock_mode=True, testing_intervals=True)
        
        download_config = {
            'source_id': source_id,
            'name': source['name'],
            'selected_cameras': selected_cameras,
            'working_path': working_path
        }
        
        results = downloader.download_recordings(download_config)
        
        # Update sync status
        if results['success']:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE sync_status 
                SET last_sync_time = ?, last_sync_status = ?
                WHERE source_id = ?
            """, (datetime.now().isoformat(), 'success', source_id))
            conn.commit()
            conn.close()
        
        return jsonify({
            "message": "Manual sync completed",
            "source_id": source_id,
            "results": results
        }), 200
        
    except Exception as e:
        return jsonify({
            "error": f"Manual sync failed: {str(e)}",
            "source_id": source_id
        }), 500

@config_bp.route('/test-source', methods=['POST'])  
def test_source_connection():
    """Test connectivity for all source types including NVR/DVR"""
    try:
        # Ensure we have valid JSON request
        if not request.is_json:
            return jsonify({
                "accessible": False,
                "message": "Invalid request format - JSON required",
                "source_type": "unknown"
            }), 400
        
        data = request.get_json()
        if not data:
            return jsonify({
                "accessible": False,
                "message": "No data provided",
                "source_type": "unknown"
            }), 400
        
        source_type = data.get('source_type')
        
        if not source_type:
            return jsonify({
                "accessible": False,
                "message": "source_type is required",
                "source_type": "unknown"
            }), 400
        
        # Handle different source types
        if source_type == 'local':
            # Existing local path validation
            source_config = {
                'source_type': source_type,
                'path': data.get('path'),
                'config': data.get('config', {})
            }
            
            if not source_config['path']:
                return jsonify({
                    "accessible": False,
                    "message": "path is required for local sources",
                    "source_type": source_type
                }), 400
            
            path_manager = PathManager()
            is_accessible, message = path_manager.validate_source_accessibility(source_config)
            
            return jsonify({
                "accessible": is_accessible,
                "message": message,
                "source_type": source_type
            }), 200
            
        elif source_type == 'nvr':
            # üÜï NEW: NVR connection testing + camera discovery
            from modules.sources.nvr_client import NVRClient
            
            nvr_client = NVRClient()
            result = nvr_client.test_connection_and_discover_cameras(data)
            
            return jsonify(result), 200
            
        elif source_type == 'cloud':
            # üÜï NEW: Cloud connection testing + folder discovery
            from modules.sources.cloud_manager import CloudManager
            cloud_manager = CloudManager(provider='google_drive')
            result = cloud_manager.test_connection_and_discover_folders(data)
            return jsonify(result), 200
            
        else:
            return jsonify({
                "accessible": False,
                "message": f"Unknown source type: {source_type}",
                "source_type": source_type
            }), 400
        
    except ImportError as e:
        return jsonify({
            "accessible": False,
            "message": f"NVR module not available: {str(e)}",
            "source_type": data.get('source_type', 'unknown')
        }), 500
        
    except json.JSONDecodeError:
        return jsonify({
            "accessible": False,
            "message": "Invalid JSON format",
            "source_type": "unknown"
        }), 400
        
    except Exception as e:
        return jsonify({
            "accessible": False,
            "message": f"Test failed: {str(e)}",
            "source_type": data.get('source_type', 'unknown')
        }), 500

@config_bp.route('/get-sources', methods=['GET'])
def get_video_sources():
    """Get all video sources"""
    try:
        path_manager = PathManager()
        sources = path_manager.get_all_active_sources()
        
        return jsonify({"sources": sources}), 200
        
    except Exception as e:
        return jsonify({"error": f"Failed to retrieve sources: {str(e)}"}), 500

@config_bp.route('/update-source/<int:source_id>', methods=['PUT'])
def update_video_source(source_id):
    """üîß Simple update video source - same type only, mainly for camera selection"""
    try:
        data = request.json
        path_manager = PathManager()
        
        # Get current source for validation
        current_source = path_manager.get_source_by_id(source_id)
        if not current_source:
            return jsonify({"error": f"Source with id {source_id} not found"}), 404
        
        # For now, we only support updating the config (mainly for camera selection)
        # Path and source_type changes are handled by "Change" button workflow
        new_config = data.get('config', current_source['config'])
        
        # üîÑ Update source config only
        success, message = path_manager.update_source(source_id, config=new_config)
        
        if not success:
            return jsonify({"error": message}), 400
        
        return jsonify({
            "message": message,
            "source_id": source_id,
            "updated_fields": ["config"]
        }), 200
        
    except Exception as e:
        return jsonify({"error": f"Failed to update source: {str(e)}"}), 500

@config_bp.route('/delete-source/<int:source_id>', methods=['DELETE'])
def delete_video_source(source_id):
    """üîÑ Delete video source (used by Change button to reset workflow)"""
    path_manager = PathManager()
    
    try:
        # Get source info before deletion for logging
        source = path_manager.get_source_by_id(source_id)
        source_name = source.get('name', 'Unknown') if source else 'Unknown'
        
        success, message = path_manager.delete_source(source_id)
        
        if success:
            # üßπ Clean reset processing_config 
            try:
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    UPDATE processing_config 
                    SET input_path = '', selected_cameras = '[]' 
                    WHERE id = 1
                """)
                conn.commit()
                conn.close()
                
                print(f"Source '{source_name}' deleted and processing_config reset")
                
            except Exception as config_error:
                print(f"Failed to reset processing_config: {config_error}")
            
            return jsonify({
                "message": f"Source '{source_name}' removed successfully. You can now add a new source.",
                "reset": True
            }), 200
        else:
            return jsonify({"error": message}), 400
            
    except Exception as e:
        return jsonify({"error": f"Failed to delete source: {str(e)}"}), 500

@config_bp.route('/toggle-source/<int:source_id>', methods=['POST'])
def toggle_source_status(source_id):
    """Toggle source active status"""
    data = request.json
    active = data.get('active', True)
    path_manager = PathManager()
    
    try:
        if active:
            # Disable all other sources first (Single Active Source)
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("UPDATE video_sources SET active = 0")
            conn.commit()
            conn.close()
        
        success, message = path_manager.toggle_source_status(source_id, active)
        
        if success and active:
            # Update input_path to this source
            source = path_manager.get_source_by_id(source_id)
            if source:
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    UPDATE processing_config 
                    SET input_path = ? 
                    WHERE id = 1
                """, (source['path'],))
                
                # Auto-detect cameras for local sources
                if source['source_type'] == 'local':
                    try:
                        cameras = detect_camera_folders(source['path'])
                        if cameras:
                            cursor.execute("""
                                UPDATE processing_config 
                                SET selected_cameras = ? 
                                WHERE id = 1
                            """, (json.dumps(cameras),))
                        else:
                            cursor.execute("""
                                UPDATE processing_config 
                                SET selected_cameras = '[]' 
                                WHERE id = 1
                            """)
                    except Exception as camera_error:
                        print(f"Camera detection failed: {camera_error}")
                        cursor.execute("""
                            UPDATE processing_config 
                            SET selected_cameras = '[]' 
                            WHERE id = 1
                        """)
                else:
                    # Clear cameras for non-local sources
                    cursor.execute("""
                        UPDATE processing_config 
                        SET selected_cameras = '[]' 
                        WHERE id = 1
                    """)
                
                conn.commit()
                conn.close()
        
        if success:
            return jsonify({"message": message}), 200
        else:
            return jsonify({"error": message}), 400
            
    except Exception as e:
        return jsonify({"error": f"Failed to toggle source status: {str(e)}"}), 500
    
@config_bp.route('/get-processing-cameras', methods=['GET'])
def get_processing_cameras():
    """Get selected cameras from processing_config"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT selected_cameras FROM processing_config WHERE id = 1")
        result = cursor.fetchone()
        conn.close()
        
        if result and result[0]:
            selected_cameras = json.loads(result[0])
            return jsonify({
                "selected_cameras": selected_cameras,
                "count": len(selected_cameras)
            }), 200
        else:
            return jsonify({
                "selected_cameras": [],
                "count": 0
            }), 200
            
    except Exception as e:
        return jsonify({"error": f"Failed to get processing cameras: {str(e)}"}), 500    
```
## üìÑ File: `logging_config.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/config/logging_config.py`

```python
import logging
import os
import sys
from datetime import datetime
from logging.handlers import RotatingFileHandler

class LogSizeFilter(logging.Filter):
    def __init__(self, log_file, max_size=10*1024*1024):
        super().__init__()
        self.log_file = log_file
        self.max_size = max_size
    
    def filter(self, record):
        if os.path.exists(self.log_file) and os.path.getsize(self.log_file) > self.max_size:
            if record.levelno < logging.INFO:
                return False
            print("Log file size exceeds 10MB, switching to INFO level", file=sys.stderr)
            return True
        return True

class ContextAdapter(logging.LoggerAdapter):
    def process(self, msg, kwargs):
        context = " ".join(f"{k}={v}" for k, v in self.extra.items())
        return f"[{context}] {msg}", kwargs

def setup_logging(base_dir, app_name="app", log_level=logging.INFO):
    log_dir = os.path.join(base_dir, "resources", "output_clips", "LOG")
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"{app_name}_{datetime.now().strftime('%Y-%m-%d')}.log")
    
    handler = RotatingFileHandler(log_file, maxBytes=10*1024*1024, backupCount=5)
    handler.setFormatter(logging.Formatter(
        '%(asctime)sZ [%(levelname)s] %(name)s: %(message)s',
        datefmt='%Y-%m-%dT%H:%M:%S'
    ))
    handler.addFilter(LogSizeFilter(log_file))
    
    logging.basicConfig(level=log_level, handlers=[handler])

def get_logger(module_name, context=None, separate_log=None):
    logger = logging.getLogger("app")
    if separate_log:
        log_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "resources", "output_clips", "LOG")
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, f"{separate_log}_{datetime.now().strftime('%Y-%m-%d')}.log")
        file_handler = RotatingFileHandler(log_file, maxBytes=10*1024*1024, backupCount=5)
        file_handler.setFormatter(logging.Formatter(
            '%(asctime)s,%(msecs)03d - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        ))
        file_handler.setLevel(logging.INFO)
        logger.addHandler(file_handler)
    return ContextAdapter(logger, context or {})
```
## üìÑ File: `__init__.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/config/__init__.py`

```python

```
## üìÑ File: `file_lister.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/scheduler/file_lister.py`

```python
import os
import sqlite3
import json
import logging
from datetime import datetime, timedelta
from statistics import median
from modules.db_utils import find_project_root, get_db_connection
from .db_sync import db_rwlock
import subprocess
import pytz

# C·∫•u h√¨nh m√∫i gi·ªù Vi·ªát Nam
VIETNAM_TZ = pytz.timezone('Asia/Ho_Chi_Minh')

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

logger = logging.getLogger("app")
logger.info("Logging initialized")

# H·∫±ng s·ªë cho qu√©t ƒë·ªông
BUFFER_SECONDS = 6 * 60
N_FILES_FOR_ESTIMATE = 3
DEFAULT_DAYS = 7

DB_PATH = os.path.join(BASE_DIR, "database", "events.db")
os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)

def get_db_path():
    try:
        with db_rwlock.gen_rlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT db_path FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            conn.close()
            return result[0] if result else DB_PATH
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y DB_PATH: {e}")
        return DB_PATH

DB_PATH = get_db_path()
logger.info(f"S·ª≠ d·ª•ng DB_PATH: {DB_PATH}")

def get_file_creation_time(file_path):
    """L·∫•y th·ªùi gian t·∫°o t·ªáp b·∫±ng FFmpeg, chu·∫©n h√≥a theo m√∫i gi·ªù Vi·ªát Nam."""
    if not os.path.isfile(file_path) or not file_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv')):
        return datetime.fromtimestamp(os.path.getctime(file_path), tz=VIETNAM_TZ)
    try:
        cmd = [
            "ffprobe",
            "-v", "quiet",
            "-print_format", "json",
            "-show_entries", "format_tags=creation_time:format=creation_time",
            file_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        metadata = json.loads(result.stdout)
        creation_time = (
            metadata.get("format", {})
                    .get("tags", {})
                    .get("creation_time")
            or metadata.get("format", {}).get("creation_time")  
        )  
        if creation_time:
            utc_time = datetime.strptime(creation_time, "%Y-%m-%dT%H:%M:%S.%fZ")
            utc_time = pytz.utc.localize(utc_time)
            return utc_time.astimezone(VIETNAM_TZ)
        else:
            logger.warning(f"Kh√¥ng t√¨m th·∫•y creation_time cho {file_path}, d√πng gi·ªù h·ªá th·ªëng")
            return datetime.fromtimestamp(os.path.getctime(file_path), tz=VIETNAM_TZ)
    except (subprocess.CalledProcessError, json.JSONDecodeError, ValueError) as e:
        logger.error(f"L·ªói khi l·∫•y creation_time cho {file_path}: {e}")
        return datetime.fromtimestamp(os.path.getctime(file_path), tz=VIETNAM_TZ)

def compute_chunk_interval(ctimes):
    ctimes = sorted(ctimes)[-N_FILES_FOR_ESTIMATE:]
    if len(ctimes) < 2:
        return 30
    intervals = [(ctimes[i+1] - ctimes[i]) / 60 for i in range(len(ctimes)-1)]
    return round(median(intervals))

def scan_files(root_path, video_root, time_threshold, max_ctime, restrict_to_current_date=False, camera_ctime_map=None, working_days=None, from_time=None, to_time=None, selected_cameras=None, strict_date_match=False):
    video_files = []
    file_ctimes = []
    video_extensions = ('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv')
    current_date = datetime.now(VIETNAM_TZ).date()
    skipped_by_ctime = 0
    skipped_by_camera = 0
    ffprobe_errors = 0

    for root, dirs, files in os.walk(root_path):
        relative_path = os.path.relpath(root, video_root)
        camera_name = relative_path.split(os.sep)[0] if relative_path != "." else os.path.basename(video_root)
        if selected_cameras and camera_name not in selected_cameras:
            skipped_by_camera += len([f for f in files if f.lower().endswith(video_extensions)])
            continue

        for file in files:
            if file.lower().endswith(video_extensions):
                file_path = os.path.join(root, file)
                try:
                    file_ctime = get_file_creation_time(file_path)
                except Exception:
                    ffprobe_errors += 1
                    file_ctime = datetime.fromtimestamp(os.path.getctime(file_path), tz=VIETNAM_TZ)

                logger.debug(f"Checking file {file_path}, ctime={file_ctime}, max_ctime={max_ctime}")
                if time_threshold and file_ctime < time_threshold:
                    skipped_by_ctime += 1
                    continue

                if max_ctime and file_ctime <= max_ctime:
                    skipped_by_ctime += 1
                    continue

                weekday = file_ctime.strftime('%A')
                if working_days and weekday not in working_days:
                    skipped_by_ctime += 1
                    logger.debug(f"Skipped file {file_path} due to non-working day: {weekday}")
                    continue

                file_time = file_ctime.time()
                if from_time and to_time and not (from_time <= file_time <= to_time):
                    skipped_by_ctime += 1
                    logger.debug(f"Skipped file {file_path} due to time outside working hours: {file_time}")
                    continue

                relative_path = os.path.relpath(file_path, video_root)
                video_files.append(relative_path)
                file_ctimes.append(file_ctime.timestamp())
                logger.info(f"T√¨m th·∫•y t·ªáp: {file_path}")

        if camera_ctime_map is not None:
            dir_ctime = datetime.fromtimestamp(os.path.getctime(root), tz=VIETNAM_TZ)
            camera_ctime_map[camera_name] = max(camera_ctime_map.get(camera_name, 0), dir_ctime.timestamp())

    logger.info(f"Th·ªëng k√™ qu√©t: {skipped_by_ctime} t·ªáp b·ªè qua do ctime, {skipped_by_camera} t·ªáp b·ªè qua do camera, {ffprobe_errors} l·ªói ffprobe")
    return video_files, file_ctimes

def save_files_to_db(conn, video_files, file_ctimes, scan_action, days, custom_path, video_root):
    if not video_files:
        return

    insert_data = []
    days_val = len(days) if isinstance(days, list) else days if days is not None else None
    for file_path, file_ctime in zip(video_files, file_ctimes):
        absolute_path = os.path.join(video_root, file_path) if scan_action != "custom" or not os.path.isfile(custom_path) else custom_path
        file_ctime_dt = datetime.fromtimestamp(file_ctime, tz=VIETNAM_TZ)
        priority = 1 if scan_action == "custom" else 0
        relative_path = os.path.relpath(absolute_path, video_root) if scan_action != "custom" else os.path.dirname(absolute_path)
        camera_name = relative_path.split(os.sep)[0] if relative_path != "." else os.path.basename(video_root)
        insert_data.append((
            scan_action, days_val, custom_path, absolute_path, datetime.now(VIETNAM_TZ), file_ctime_dt, priority, camera_name, 'pending', 0
        ))

    with conn:
        cursor = conn.cursor()
        cursor.executemany('''
            INSERT INTO file_list (program_type, days, custom_path, file_path, created_at, ctime, priority, camera_name, status, is_processed)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', insert_data)
        logger.info(f"ƒê√£ ch√®n {len(insert_data)} t·ªáp v√†o file_list")

def list_files(video_root, scan_action, custom_path, days, db_path, default_scan_days=7, camera_ctime_map=None, is_initial_scan=False):
    try:
        with db_rwlock.gen_wlock():
            conn = get_db_connection()
            cursor = conn.cursor()

            if not os.path.exists(video_root):
                try:
                    os.makedirs(video_root, exist_ok=True)
                    logger.info(f"ƒê√£ t·∫°o th∆∞ m·ª•c video root: {video_root}")
                except Exception as e:
                    logger.error(f"Kh√¥ng th·ªÉ t·∫°o th∆∞ m·ª•c video root: {video_root}, l·ªói: {str(e)}")
                    raise Exception(f"Kh√¥ng th·ªÉ t·∫°o th∆∞ m·ª•c video root: {str(e)}")

            cursor.execute('SELECT MAX(ctime) FROM file_list')
            last_ctime = cursor.fetchone()[0]
            max_ctime = datetime.fromisoformat(last_ctime.replace('Z', '+00:00')) if last_ctime else datetime.min.replace(tzinfo=VIETNAM_TZ)

            cursor.execute("SELECT input_path, selected_cameras FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            if result:
                video_root = result[0]
                selected_cameras = json.loads(result[1]) if result[1] else []
            else:
                selected_cameras = []
            logger.info(f"S·ª≠ d·ª•ng video_root: {video_root}, Camera ƒë∆∞·ª£c ch·ªçn: {selected_cameras}")

            cursor.execute("SELECT working_days, from_time, to_time FROM general_info WHERE id = 1")
            general_info = cursor.fetchone()
            if general_info:
                try:
                    working_days_raw = general_info[0].encode('utf-8').decode('utf-8') if general_info[0] else ''
                    working_days = json.loads(working_days_raw) if working_days_raw else []
                except json.JSONDecodeError as e:
                    logger.error(f"JSON kh√¥ng h·ª£p l·ªá trong working_days: {general_info[0]}, l·ªói: {e}")
                    working_days = []
                from_time = datetime.strptime(general_info[1], '%H:%M').time() if general_info[1] else None
                to_time = datetime.strptime(general_info[2], '%H:%M').time() if general_info[2] else None
            else:
                working_days, from_time, to_time = [], None, None
            logger.info(f"Ng√†y l√†m vi·ªác: {working_days}, from_time: {from_time}, to_time: {to_time}")

            video_files = []
            file_ctimes = []

            if scan_action == "custom" and custom_path:
                if not os.path.exists(custom_path):
                    raise Exception(f"ƒê∆∞·ªùng d·∫´n kh√¥ng t·ªìn t·∫°i: {custom_path}")
                if os.path.isfile(custom_path) and custom_path.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv')):
                    file_name = os.path.basename(custom_path)
                    file_ctime = get_file_creation_time(custom_path)
                    video_files.append(file_name)
                    file_ctimes.append(file_ctime.timestamp())
                    logger.info(f"T√¨m th·∫•y t·ªáp: {custom_path}")
                else:
                    video_files, file_ctimes = scan_files(
                        custom_path, video_root, None, None, False, None,
                        working_days, from_time, to_time, selected_cameras, strict_date_match=False
                    )
            elif scan_action == "first" and days:
                time_threshold = datetime.now(VIETNAM_TZ) - timedelta(days=days)
                video_files, file_ctimes = scan_files(
                    video_root, video_root, time_threshold, None, False, None,
                    working_days, from_time, to_time, selected_cameras, strict_date_match=False
                )
                cursor.execute('''
                    INSERT OR REPLACE INTO program_status (id, key, value)
                    VALUES ((SELECT id FROM program_status WHERE key = 'first_run_completed'), 'first_run_completed', 'true')
                ''')
                conn.commit()
            else:  # default
                time_threshold = datetime.now(VIETNAM_TZ) - timedelta(days=default_scan_days) if is_initial_scan else datetime.now(VIETNAM_TZ) - timedelta(days=1)
                restrict_to_current_date = not is_initial_scan
                video_files, file_ctimes = scan_files(
                    video_root, video_root, time_threshold, max_ctime, restrict_to_current_date, camera_ctime_map,
                    working_days, from_time, to_time, selected_cameras, strict_date_match=True
                )

            save_files_to_db(conn, video_files, file_ctimes, scan_action, days, custom_path, video_root)
            conn.close()
        logger.info(f"T√¨m th·∫•y {len(video_files)} t·ªáp video")
        return video_files, file_ctimes
    except Exception as e:
        logger.error(f"L·ªói trong list_files: {e}")
        raise Exception(f"L·ªói trong list_files: {str(e)}")

def cleanup_stale_jobs():
    try:
        with db_rwlock.gen_wlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE file_list 
                SET status = 'pending'
                WHERE status = 'ƒëang frame sampler ...'
                AND created_at < datetime('now', '-59 minutes')
            """)
            affected = cursor.rowcount
            conn.commit()
            conn.close()
            if affected > 0:
                logger.info(f"Reset {affected} stale jobs to pending")
    except Exception as e:
        logger.error(f"Error cleaning up stale jobs: {e}")

def run_file_scan(scan_action="default", days=None, custom_path=None):
    db_path = get_db_path()
    cleanup_stale_jobs()
    try:
        with db_rwlock.gen_rlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT input_path FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            conn.close()
            video_root = result[0] if result else ""
        if not video_root:
            raise Exception("Kh√¥ng t√¨m th·∫•y video_root trong processing_config")
        camera_ctime_map = {}
        is_initial_scan = scan_action == "default" and days is not None  # ƒê·∫∑t is_initial_scan=True cho l·∫ßn qu√©t ƒë·∫ßu ti√™n
        files, _ = list_files(video_root, scan_action, custom_path, days, db_path, camera_ctime_map=camera_ctime_map, is_initial_scan=is_initial_scan)
        return files
    except Exception as e:
        logger.error(f"L·ªói trong run_file_scan: {e}")
        raise

```
## üìÑ File: `db_sync.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/scheduler/db_sync.py`

```python
from readerwriterlock import rwlock
import threading

db_rwlock = rwlock.RWLockFairD()  # S·ª≠ d·ª•ng RWLockFairD ƒë·ªÉ tr√°nh deadlock
frame_sampler_event = threading.Event()
event_detector_event = threading.Event()
event_detector_done = threading.Event()
event_detector_done.set()  # Ban ƒë·∫ßu cho ph√©p Frame Sampler ch·∫°y

```
## üìÑ File: `system_monitor.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/scheduler/system_monitor.py`

```python
import psutil
import logging
import os
from datetime import datetime
from modules.config.logging_config import get_logger


# ƒê∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi t·ª´ project root
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class SystemMonitor:
    def __init__(self):
        self.min_batch_size = 2
        self.max_batch_size = 6
        self.cpu_threshold_low = 70  # TƒÉng batch_size n·∫øu CPU < 70%
        self.cpu_threshold_high = 90  # Gi·∫£m batch_size n·∫øu CPU > 90%
        self.setup_logging()

    def setup_logging(self):
        self.logger = get_logger(__name__, {"module": "system_monitor"})
        self.logger.info("SystemMonitor logging initialized")

    def get_system_metrics(self):
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            logging.info(f"System metrics retrieved: CPU={cpu_percent}%, Memory={memory_percent}%")
            return cpu_percent, memory_percent
        except Exception as e:
            logging.error(f"Error getting system metrics: {str(e)}")
            return 50.0, 50.0  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh n·∫øu l·ªói

    def get_batch_size(self, current_batch_size=2):
        logging.info(f"Calculating batch size, current={current_batch_size}")
        cpu_percent, memory_percent = self.get_system_metrics()
        if cpu_percent < self.cpu_threshold_low and memory_percent < self.cpu_threshold_low:
            new_batch_size = min(current_batch_size + 1, self.max_batch_size)
        elif cpu_percent > self.cpu_threshold_high or memory_percent > self.cpu_threshold_high:
            new_batch_size = max(current_batch_size - 1, self.min_batch_size)
        else:
            new_batch_size = current_batch_size
        logging.info(f"Calculated batch_size: {new_batch_size}")
        return new_batch_size

    def log_timeout_warning(self, timeout_files, total_files):
        logging.info(f"Checking timeout: {timeout_files}/{total_files} files")
        if timeout_files > total_files * 0.1:
            logging.warning(f"Warning: {timeout_files}/{total_files} files timed out, consider increasing resources")
        else:
            logging.info("No timeout warning triggered")

```
## üìÑ File: `program_runner.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/scheduler/program_runner.py`

```python
import threading
import time
import os
import logging
from datetime import datetime
from modules.db_utils.db_utils import get_db_connection
from modules.technician.frame_sampler_trigger import FrameSamplerTrigger
from modules.technician.frame_sampler_no_trigger import FrameSamplerNoTrigger
from modules.technician.IdleMonitor import IdleMonitor
from modules.technician.event_detector import process_single_log
from .db_sync import db_rwlock, frame_sampler_event, event_detector_event, event_detector_done
import json
from modules.config.logging_config import  get_logger
import logging

logging.info("Logging initialized for program_runner")

# Bi·∫øn t·∫°m ƒë·ªÉ l∆∞u tr·∫°ng th√°i ch·∫°y v√† s·ªë ng√†y
running_state = {"current_running": None, "days": None, "custom_path": None, "files": []}
# Dictionary l∆∞u kh√≥a cho t·ª´ng nh√≥m video
video_locks = {}

def start_frame_sampler_thread(batch_size=1):
    logging.info(f"Starting {batch_size} frame sampler threads")
    threads = []
    for _ in range(batch_size):
        frame_sampler_thread = threading.Thread(target=run_frame_sampler)
        frame_sampler_thread.start()
        threads.append(frame_sampler_thread)
    return threads

def run_frame_sampler():
    logging.info("Frame sampler thread started")
    while True:  # V√≤ng l·∫∑p v√¥ h·∫°n ƒë·ªÉ thread lu√¥n ch·∫°y
        frame_sampler_event.wait()  # Ch·ªù th√¥ng b√°o t·ª´ event
        logging.debug("Frame sampler event received")
        try:
            with db_rwlock.gen_rlock():  # ƒê·ªìng b·ªô h√≥a truy c·∫≠p database
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("SELECT file_path, camera_name FROM file_list WHERE is_processed = 0 ORDER BY priority DESC, created_at ASC")
                video_files = [(row[0], row[1]) for row in cursor.fetchall()]
                conn.close()
                logging.info(f"Found {len(video_files)} unprocessed video files")

            if not video_files:
                logging.info("No video files to process, clearing event")
                frame_sampler_event.clear()  # X√≥a event v√† ti·∫øp t·ª•c ch·ªù
                continue

            for video_file, camera_name in video_files:
                # Ki·ªÉm tra tr·∫°ng th√°i video tr∆∞·ªõc khi x·ª≠ l√Ω
                with db_rwlock.gen_rlock():
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("SELECT status, is_processed FROM file_list WHERE file_path = ?", (video_file,))
                    result = cursor.fetchone()
                    conn.close()
                    if result and (result[0] == "ƒëang frame sampler ..." or result[1] == 1):
                        logging.info(f"Skipping video {video_file}: already being processed or completed")
                        continue

                # Kh√≥a theo video
                with db_rwlock.gen_wlock():
                    if video_file not in video_locks:
                        video_locks[video_file] = threading.Lock()
                video_lock = video_locks[video_file]
                if not video_lock.acquire(blocking=False):
                    logging.info(f"Skipping video {video_file}: locked by another thread")
                    continue

                try:
                    logging.info(f"Processing video: {video_file}")
                    # Ki·ªÉm tra qr_trigger_area v√† packing_area t·ª´ packing_profiles
                    with db_rwlock.gen_rlock():
                        conn = get_db_connection()
                        cursor = conn.cursor()
                        search_name = camera_name if camera_name else "CamTest"
                        if not camera_name:
                            logging.warning(f"No camera_name for {video_file}, falling back to CamTest")
                        cursor.execute("SELECT id, profile_name, qr_trigger_area, packing_area FROM packing_profiles WHERE profile_name LIKE ?", (f'%{search_name}%',))
                        profiles = cursor.fetchall()
                        conn.close()
                    
                    # Ch·ªçn profile c√≥ id l·ªõn nh·∫•t
                    trigger = [0, 0, 0, 0]
                    packing_area = None
                    selected_profile = None
                    if profiles:
                        selected_profile = max(profiles, key=lambda x: x[0])  # Ch·ªçn id l·ªõn nh·∫•t
                        profile_id, profile_name, qr_trigger_area, packing_area_raw = selected_profile
                        # Parse qr_trigger_area
                        try:
                            trigger = json.loads(qr_trigger_area) if qr_trigger_area else [0, 0, 0, 0]
                            if not isinstance(trigger, list) or len(trigger) != 4:
                                logging.error(f"Invalid qr_trigger_area for {profile_name}: {qr_trigger_area}, using default [0, 0, 0, 0]")
                                trigger = [0, 0, 0, 0]
                        except json.JSONDecodeError as e:
                            logging.error(f"Failed to parse qr_trigger_area for {profile_name}: {e}, using default [0, 0, 0, 0]")
                            trigger = [0, 0, 0, 0]
                        # Parse packing_area
                        try:
                            if packing_area_raw:
                                parsed = json.loads(packing_area_raw)
                                if isinstance(parsed, list) and len(parsed) == 4:
                                    packing_area = tuple(parsed)
                                else:
                                    logging.error(f"Invalid packing_area format for {profile_name}: {packing_area_raw}, using default None")
                                    packing_area = None
                            logging.info(f"Selected profile id={profile_id}, profile_name={profile_name}, qr_trigger_area={trigger}, packing_area={packing_area}")
                        except (ValueError, json.JSONDecodeError, KeyError, TypeError) as e:
                            logging.error(f"Failed to parse packing_area for {profile_name}: {e}, using default None")
                            packing_area = None
                    else:
                        logging.warning(f"No profile found for camera {search_name}, using default qr_trigger_area=[0, 0, 0, 0], packing_area=None")
                    
                    # Ch·∫°y IdleMonitor tr∆∞·ªõc FrameSampler, truy·ªÅn packing_area
                    idle_monitor = IdleMonitor()
                    logging.info(f"Running IdleMonitor for {video_file}")
                    idle_monitor.process_video(video_file, camera_name, packing_area)
                    work_block_queue = idle_monitor.get_work_block_queue()

                    # b·ªè qua file kh√¥ng c√≥ work block
                    if work_block_queue.empty():
                        logging.info(f"No work blocks found for {video_file}, skipping FrameSampler and log file creation")
                        with db_rwlock.gen_wlock():
                            conn = get_db_connection()
                            cursor = conn.cursor()
                            cursor.execute("UPDATE file_list SET status = ?, is_processed = 1 WHERE file_path = ?", ("xong", video_file))
                            conn.commit()
                            conn.close()
                        continue  # B·ªè qua FrameSampler v√† chuy·ªÉn sang video ti·∫øp theo
                    # Ch·ªçn FrameSampler d·ª±a tr√™n trigger
                    if trigger != [0, 0, 0, 0]:
                        frame_sampler = FrameSamplerTrigger()
                        logging.info(f"Using FrameSamplerTrigger for {video_file}")
                    else:
                        frame_sampler = FrameSamplerNoTrigger()
                        logging.info(f"Using FrameSamplerNoTrigger for {video_file}")

                    with db_rwlock.gen_wlock():  # Kh√≥a khi c·∫≠p nh·∫≠t tr·∫°ng th√°i
                        conn = get_db_connection()
                        cursor = conn.cursor()
                        cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("ƒëang frame sampler ...", video_file))
                        conn.commit()
                        conn.close()
                        logging.debug(f"Updated status for {video_file} to 'ƒëang frame sampler ...'")
                    
                    # G·ªçi process_video v·ªõi work block t·ª´ queue
                    log_file = None
                    while not work_block_queue.empty():
                        work_block = work_block_queue.get()
                        start_time = work_block['start_time']
                        end_time = work_block['end_time']
                        logging.info(f"Processing video block: start_time={start_time}, end_time={end_time}")
                        log_file = frame_sampler.process_video(
                            video_file,
                            video_lock=frame_sampler.video_lock,
                            get_packing_area_func=frame_sampler.get_packing_area,
                            process_frame_func=frame_sampler.process_frame,
                            frame_interval=frame_sampler.frame_interval,
                            start_time=start_time,
                            end_time=end_time
                        )
                    
                    with db_rwlock.gen_wlock():  # Kh√≥a khi c·∫≠p nh·∫≠t tr·∫°ng th√°i cu·ªëi
                        conn = get_db_connection()
                        cursor = conn.cursor()
                        if log_file:
                            cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("xong", video_file))
                            event_detector_event.set()  # K√≠ch ho·∫°t Event Detector sau m·ªói video
                            logging.info(f"Video {video_file} processed successfully, log file: {log_file}")
                        else:
                            cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("l·ªói", video_file))
                            logging.error(f"Failed to process video {video_file}")
                        conn.commit()
                        conn.close()
                    
                    # T·∫°m d·ª´ng sau khi x·ª≠ l√Ω xong m·ªôt video
                    logging.info(f"Frame Sampler pausing after processing {video_file}, waiting for Event Detector...")
                    while not event_detector_done.is_set():
                        time.sleep(1)  # Ch·ªù Event Detector ho√†n t·∫•t

                finally:
                    video_lock.release()
                    with db_rwlock.gen_wlock():
                        video_locks.pop(video_file, None)  # X√≥a kh√≥a sau khi x·ª≠ l√Ω xong
                    logging.debug(f"Released lock for {video_file}")

            frame_sampler_event.clear()  # X√≥a event sau khi x·ª≠ l√Ω h·∫øt file
            logging.info("All video files processed, clearing frame sampler event")
        except Exception as e:
            logging.error(f"Error in Frame Sampler thread: {str(e)}")
            frame_sampler_event.clear()  # ƒê·∫£m b·∫£o thread "ng·ªß" l·∫°i n·∫øu c√≥ l·ªói

def start_event_detector_thread():
    logging.info("Starting event detector thread")
    event_detector_thread = threading.Thread(target=run_event_detector)
    event_detector_thread.start()
    return event_detector_thread

def run_event_detector():
    logging.info("Event detector thread started")
    while True:
        event_detector_event.wait()
        logging.debug("Event detector event received")
        try:
            with db_rwlock.gen_rlock():  # ƒê·ªìng b·ªô h√≥a truy c·∫≠p database
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("SELECT log_file FROM processed_logs WHERE is_processed = 0")
                log_files = [row[0] for row in cursor.fetchall()]
                conn.close()
                logging.info(f"Found {len(log_files)} unprocessed log files")

            if not log_files:
                event_detector_event.clear()
                event_detector_done.set()  # B√°o hi·ªáu Frame Sampler ti·∫øp t·ª•c
                logging.info("No log files to process, clearing event and signaling done")
                continue

            for log_file in log_files:
                logging.info(f"Event Detector processing: {log_file}")
                process_single_log(log_file)
            event_detector_event.clear()
            event_detector_done.set()  # B√°o hi·ªáu Frame Sampler ti·∫øp t·ª•c sau khi x·ª≠ l√Ω h·∫øt log
            logging.info("All log files processed, clearing event and signaling done")
        except Exception as e:
            logging.error(f"Error in Event Detector thread: {str(e)}")
            event_detector_event.clear()
            event_detector_done.set()  # V·∫´n b√°o hi·ªáu Frame Sampler ti·∫øp t·ª•c n·∫øu c√≥ l·ªói

```
## üìÑ File: `program.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/scheduler/program.py`

```python
from flask import Blueprint, request, jsonify
import os
import json
import threading
import pytz
from datetime import datetime, timedelta
import logging
from modules.db_utils import find_project_root, get_db_connection
from .file_lister import run_file_scan, get_db_path
from .batch_scheduler import BatchScheduler
from .db_sync import frame_sampler_event, event_detector_event
import logging

VIETNAM_TZ = pytz.timezone('Asia/Ho_Chi_Minh')

program_bp = Blueprint('program', __name__)

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DB_PATH = os.path.join(BASE_DIR, "database", "events.db")
os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)

DB_PATH = get_db_path()
LOG_DIR = os.path.join(BASE_DIR, "../../resources/output_clips/LOG")
os.makedirs(LOG_DIR, exist_ok=True)

logger = logging.getLogger("app")
logger.info("Program logging initialized")

db_rwlock = threading.RLock()
running_state = {
    "days": None,
    "custom_path": None,
    "current_running": None,
    "files": []
}

scheduler = BatchScheduler()

def init_default_program():
    logger.info("Initializing default program")
    try:
        with db_rwlock:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute('SELECT value FROM program_status WHERE key = "first_run_completed"')
            result = cursor.fetchone()
            conn.close()
        first_run_completed = result[0] == 'true' if result else False
        logger.info(f"First run completed: {first_run_completed}, Scheduler running: {scheduler.running}")
        if first_run_completed and not scheduler.running:
            logger.info("Chuy·ªÉn sang ch·∫ø ƒë·ªô ch·∫°y m·∫∑c ƒë·ªãnh (qu√©t l·∫∑p)")
            running_state["current_running"] = "M·∫∑c ƒë·ªãnh"
            scheduler.start()
    except Exception as e:
        logger.error(f"Error initializing default program: {e}")

init_default_program()

@program_bp.route('/program', methods=['POST'])
def program():
    logger.info(f"POST /program called, Current state before action: scheduler_running={scheduler.running}, running_state={running_state}")
    data = request.json
    card = data.get('card')
    action = data.get('action')
    custom_path = data.get('custom_path', '')
    days = data.get('days')

    if card == "L·∫ßn ƒë·∫ßu" and action == "run":
        try:
            with db_rwlock:
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute('SELECT value FROM program_status WHERE key = "first_run_completed"')
                result = cursor.fetchone()
                first_run_completed = result[0] == 'true' if result else False
                conn.close()
            if first_run_completed:
                logger.warning("First run already completed")
                return jsonify({"error": "L·∫ßn ƒë·∫ßu ƒë√£ ch·∫°y tr∆∞·ªõc ƒë√≥, kh√¥ng th·ªÉ ch·∫°y l·∫°i"}), 400
        except Exception as e:
            logger.error(f"Failed to check first run status: {str(e)}")
            return jsonify({"error": f"Failed to check first run status: {str(e)}"}), 500

    if action == "run":
        logger.info(f"Action run for card: {card}, scheduler_running={scheduler.running}")
        if scheduler.running and card == "Ch·ªâ ƒë·ªãnh":
            scheduler.pause()
            running_state["current_running"] = None
            running_state["files"] = []
        if card == "L·∫ßn ƒë·∫ßu":
            if not days:
                logger.error("Days required for L·∫ßn ƒë·∫ßu")
                return jsonify({"error": "Days required for L·∫ßn ƒë·∫ßu"}), 400
            running_state["days"] = days
            running_state["custom_path"] = None
            try:
                run_file_scan(scan_action="first", days=days)
            except Exception as e:
                logger.error(f"Failed to run first scan: {str(e)}")
                return jsonify({"error": f"Failed to run first scan: {str(e)}"}), 500
        elif card == "Ch·ªâ ƒë·ªãnh":
            if not custom_path:
                logger.error("Custom path required for Ch·ªâ ƒë·ªãnh")
                return jsonify({"error": "Custom path required cho Ch·ªâ ƒë·ªãnh"}), 400
            abs_path = os.path.abspath(custom_path)
            if not os.path.exists(abs_path):
                logger.error(f"Custom path {abs_path} does not exist")
                return jsonify({"error": f"Custom path {abs_path} does not exist"}), 400
            try:
                with db_rwlock:
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("SELECT status, is_processed FROM file_list WHERE file_path = ? AND (status = 'xong' OR is_processed = 1)", (abs_path,))
                    result = cursor.fetchone()
                    conn.close()
                    if result:
                        logger.warning(f"File {abs_path} already processed with status {result[0]}")
                        return jsonify({"error": "File ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω"}), 400
            except Exception as e:
                logger.error(f"Error checking file status: {str(e)}")
                return jsonify({"error": f"Error checking file status: {str(e)}"}), 500
            running_state["custom_path"] = abs_path
            running_state["days"] = None
            try:
                scheduler.pause()
                run_file_scan(scan_action="custom", custom_path=abs_path)
                with db_rwlock:
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("SELECT file_path FROM file_list WHERE custom_path = ? AND status = 'pending' ORDER BY created_at DESC LIMIT 1", (abs_path,))
                    result = cursor.fetchone()
                    conn.close()
                if result:
                    from .program_runner import start_frame_sampler_thread, start_event_detector_thread
                    frame_sampler_event.set()
                    start_frame_sampler_thread()
                    start_event_detector_thread()
                    logger.info(f"[Ch·ªâ ƒë·ªãnh] Processing started: {result[0]}")
                    import time
                    while True:
                        with db_rwlock:
                            conn = get_db_connection()
                            cursor = conn.cursor()
                            cursor.execute("SELECT status FROM file_list WHERE file_path = ?", (result[0],))
                            status_result = cursor.fetchone()
                            conn.close()
                        if status_result and status_result[0] == 'xong':
                            break
                        time.sleep(2)
                    logger.info(f"[Ch·ªâ ƒë·ªãnh] Processing completed: {result[0]}")
                    scheduler.resume()
                    try:
                        if not scheduler.running:
                            scheduler.start()
                            logger.info("Restarted scheduler for default mode")
                        run_file_scan(scan_action="default")
                        frame_sampler_event.set()
                        event_detector_event.set()
                        logger.info(f"Completed Ch·ªâ ƒë·ªãnh, transitioning to default: scheduler_running={scheduler.running}, running_state={running_state}")
                    except Exception as e:
                        logger.error(f"Error triggering default scan: {str(e)}")
                else:
                    logger.error(f"[Ch·ªâ ƒë·ªãnh] No pending file found at: {abs_path}")
                    return jsonify({"error": "Kh√¥ng t√¨m th·∫•y file pending ƒë·ªÉ x·ª≠ l√Ω"}), 404
            except Exception as e:
                logger.error(f"[Ch·ªâ ƒë·ªãnh] Error: {str(e)}")
                scheduler.resume()
                return jsonify({"error": f"X·ª≠ l√Ω ch·ªâ ƒë·ªãnh th·∫•t b·∫°i: {str(e)}"}), 500
        else:
            running_state["days"] = None
            running_state["custom_path"] = None

        running_state["current_running"] = card
        if not scheduler.running:
            running_state["current_running"] = "M·∫∑c ƒë·ªãnh"
            scheduler.start()

        if card == "L·∫ßn ƒë·∫ßu":
            try:
                with db_rwlock:
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("UPDATE program_status SET value = ? WHERE key = ?", ("true", "first_run_completed"))
                    conn.commit()
                    conn.close()
                logger.info("Chuy·ªÉn sang ch·∫ø ƒë·ªô ch·∫°y m·∫∑c ƒë·ªãnh (qu√©t l·∫∑p) sau khi ho√†n th√†nh L·∫ßn ƒë·∫ßu")
            except Exception as e:
                logger.error(f"Error updating first_run_completed: {e}")

    elif action == "stop":
        logger.info(f"Action stop called, current_state={running_state}, scheduler_running={scheduler.running}")
        running_state["current_running"] = None
        running_state["days"] = None
        running_state["custom_path"] = None
        running_state["files"] = []
        if not scheduler.running:
            scheduler.start()
            logger.info("Scheduler restarted for default mode")
        logger.info(f"State after stop: running_state={running_state}, scheduler_running={scheduler.running}")

    logger.info(f"Program action completed: {card} {action}, final_state={running_state}, scheduler_running={scheduler.running}")
    return jsonify({
        "current_running": running_state["current_running"],
        "days": running_state.get("days"),
        "custom_path": running_state.get("custom_path")
    }), 200

@program_bp.route('/program', methods=['GET'])
def get_program_status():
    logger.info("GET /program called")
    return jsonify({
        "current_running": running_state["current_running"],
        "days": running_state.get("days"),
        "custom_path": running_state.get("custom_path")
    }), 200

@program_bp.route('/confirm-run', methods=['POST'])
def confirm_run():
    logger.info("POST /confirm-run called")
    data = request.json
    card = data.get('card')

    scan_action = "first" if card == "L·∫ßn ƒë·∫ßu" else "default" if card == "M·∫∑c ƒë·ªãnh" else "custom"
    days = running_state.get("days") if card == "L·∫ßn ƒë·∫ßu" else None
    custom_path = running_state.get("custom_path", '')
    try:
        run_file_scan(scan_action=scan_action, days=days, custom_path=custom_path)
        logger.info(f"Files queued for {scan_action}")
    except Exception as e:
        logger.error(f"Failed to list files: {str(e)}")
        return jsonify({"error": f"Failed to list files: {str(e)}"}), 500

    return jsonify({
        "program_type": scan_action
    }), 200

@program_bp.route('/program-progress', methods=['GET'])
def get_program_progress():
    logger.info("GET /program-progress called")
    try:
        with db_rwlock:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT file_path, status FROM file_list WHERE is_processed = 0 ORDER BY created_at DESC")
            files_status = [{"file": row[0], "status": row[1]} for row in cursor.fetchall()]
            conn.close()
        logger.info(f"Retrieved {len(files_status)} files for status")
        return jsonify({"files": files_status}), 200
    except Exception as e:
        logger.error(f"Failed to retrieve program progress: {str(e)}")
        return jsonify({"error": f"Failed to retrieve program progress: {str(e)}"}), 500

@program_bp.route('/check-first-run', methods=['GET'])
def check_first_run():
    logger.info("GET /check-first-run called")
    try:
        with db_rwlock:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute('SELECT value FROM program_status WHERE key = "first_run_completed"')
            result = cursor.fetchone()
            conn.close()
            first_run_completed = result[0] == 'true' if result else False
        logger.info(f"First run completed: {first_run_completed}")
        return jsonify({"first_run_completed": first_run_completed}), 200
    except Exception as e:
        logger.error(f"Failed to check first run status: {str(e)}")
        return jsonify({"error": f"Failed to check first run status: {str(e)}"}), 500

@program_bp.route('/get-cameras', methods=['GET'])
def get_cameras():
    logger.info("GET /get-cameras called")
    try:
        with db_rwlock:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT selected_cameras FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            conn.close()
            cameras = result[0] if result else "[]"
            cameras_list = json.loads(cameras) if cameras else []
        logger.info(f"Retrieved {len(cameras_list)} cameras")
        return jsonify({"cameras": cameras_list}), 200
    except Exception as e:
        logger.error(f"Failed to retrieve cameras: {str(e)}")
        return jsonify({"error": f"Failed to retrieve cameras: {str(e)}"}), 500

@program_bp.route('/get-camera-folders', methods=['GET'])
def get_camera_folders():
    logger.info("GET /get-camera-folders called")
    try:
        with db_rwlock:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT input_path FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            video_root = result[0] if result else os.path.join(BASE_DIR, "Inputvideo")
            conn.close()

        if not os.path.exists(video_root):
            logger.error(f"Directory {video_root} does not exist")
            return jsonify({"error": f"Directory {video_root} does not exist. Ensure the path is correct or create the directory."}), 400

        folders = []
        for folder_name in os.listdir(video_root):
            folder_path = os.path.join(video_root, folder_name)
            if os.path.isdir(folder_path):
                folders.append({"name": folder_name, "path": folder_path})
        logger.info(f"Retrieved {len(folders)} camera folders")
        return jsonify({"folders": folders}), 200
    except Exception as e:
        logger.error(f"Failed to retrieve camera folders: {str(e)}")
        return jsonify({"error": f"Failed to retrieve camera folders: {str(e)}"}), 500

if __name__ == "__main__":
    logger.info("Main program started")
    if not scheduler.running:
        running_state["current_running"] = "M·∫∑c ƒë·ªãnh"
        scheduler.start()

```
## üìÑ File: `batch_scheduler.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/scheduler/batch_scheduler.py`

```python
import os
import threading
import time
import logging
import sqlite3
import pytz
import psutil  # TH√äM IMPORT M·ªöI
from datetime import datetime, timedelta
from modules.db_utils import get_db_connection
from .db_sync import db_rwlock, frame_sampler_event, event_detector_event
from .file_lister import run_file_scan
from .program_runner import start_frame_sampler_thread, start_event_detector_thread
import logging

logger = logging.getLogger("app")
logger.info("BatchScheduler logging initialized")

# C·∫•u h√¨nh m√∫i gi·ªù Vi·ªát Nam
VIETNAM_TZ = pytz.timezone('Asia/Ho_Chi_Minh')

class SystemMonitor:
    """Theo d√µi t√†i nguy√™n h·ªá th·ªëng v√† t√≠nh batch_size ƒë·ªông."""
    def __init__(self):
        self.cpu_threshold_low = 70
        self.cpu_threshold_high = 90
        self.base_batch_size = 2
        self.max_batch_size = 6

    def get_cpu_usage(self):
        """L·∫•y CPU usage th·ª±c t·∫ø t·ª´ h·ªá th·ªëng"""
        try:
            # L·∫•y CPU usage trung b√¨nh trong 1 gi√¢y
            cpu_percent = psutil.cpu_percent(interval=1)
            logger.debug(f"Current CPU usage: {cpu_percent}%")
            return cpu_percent
        except Exception as e:
            logger.error(f"Error getting CPU usage: {e}")
            return 50  # Fallback value n·∫øu c√≥ l·ªói

    def get_memory_usage(self):
        """L·∫•y memory usage th·ª±c t·∫ø"""
        try:
            memory_percent = psutil.virtual_memory().percent
            logger.debug(f"Current memory usage: {memory_percent}%")
            return memory_percent
        except Exception as e:
            logger.error(f"Error getting memory usage: {e}")
            return 50  # Fallback value

    def get_batch_size(self, current_batch_size):
        cpu_usage = self.get_cpu_usage()
        memory_usage = self.get_memory_usage()
        
        logger.debug(f"Resource usage - CPU: {cpu_usage}%, Memory: {memory_usage}%")
        
        # Ki·ªÉm tra n·∫øu t√†i nguy√™n qu√° t·∫£i
        if cpu_usage > self.cpu_threshold_high or memory_usage > 85:
            if current_batch_size > self.base_batch_size:
                new_batch_size = current_batch_size - 1
                logger.warning(f"High resource usage (CPU: {cpu_usage}%, RAM: {memory_usage}%), reducing batch size: {current_batch_size} -> {new_batch_size}")
                return new_batch_size
        
        # Ki·ªÉm tra n·∫øu t√†i nguy√™n nh√†n r·ªói
        elif cpu_usage < self.cpu_threshold_low and memory_usage < 70:
            if current_batch_size < self.max_batch_size:
                new_batch_size = current_batch_size + 1
                logger.info(f"Low resource usage (CPU: {cpu_usage}%, RAM: {memory_usage}%), increasing batch size: {current_batch_size} -> {new_batch_size}")
                return new_batch_size
        
        # Gi·ªØ nguy√™n n·∫øu t√†i nguy√™n ·ªïn ƒë·ªãnh
        return current_batch_size

    def log_system_info(self):
        """Log th√¥ng tin h·ªá th·ªëng khi kh·ªüi ƒë·ªông"""
        try:
            cpu_count = psutil.cpu_count()
            memory_total = psutil.virtual_memory().total / (1024**3)  # GB
            logger.info(f"System info - CPU cores: {cpu_count}, Total RAM: {memory_total:.1f}GB")
            logger.info(f"Batch size config - Base: {self.base_batch_size}, Max: {self.max_batch_size}")
            logger.info(f"CPU thresholds - Low: {self.cpu_threshold_low}%, High: {self.cpu_threshold_high}%")
        except Exception as e:
            logger.error(f"Error logging system info: {e}")

class BatchScheduler:
    def __init__(self):
        self.batch_size = 2
        self.sys_monitor = SystemMonitor()
        self.scan_interval = 60
        self.timeout_seconds = 3600
        self.running = False
        self.queue_limit = 5
        self.sampler_threads = []
        self.detector_thread = None
        self.pause_event = threading.Event()
        self.pause_event.set()

    def pause(self):
        logger.info(f"BatchScheduler paused, current_batch_size={self.batch_size}")
        self.pause_event.clear()

    def resume(self):
        logger.info(f"BatchScheduler resumed, current_batch_size={self.batch_size}")
        self.pause_event.set()

    def get_pending_files(self):
        """L·∫•y danh s√°ch file ch∆∞a x·ª≠ l√Ω, gi·ªõi h·∫°n queue_limit."""
        try:
            with db_rwlock.gen_rlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("SELECT file_path, camera_name FROM file_list WHERE status = 'pending' AND is_processed = 0 ORDER BY priority DESC, created_at ASC LIMIT ?", 
                             (self.queue_limit,))
                files = [(row[0], row[1]) for row in cursor.fetchall()]
                conn.close()
            return files
        except Exception as e:
            logger.error(f"Error retrieving pending files: {e}")
            return []

    def update_file_status(self, file_path, status):
        """C·∫≠p nh·∫≠t tr·∫°ng th√°i file trong file_list."""
        try:
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("UPDATE file_list SET status = ?, is_processed = ? WHERE file_path = ?",
                             (status, 1 if status in ['xong', 'l·ªói', 'timeout'] else 0, file_path))
                conn.commit()
                conn.close()
        except Exception as e:
            logger.error(f"Error updating file status for {file_path}: {e}")

    def check_timeout(self):
        """Ki·ªÉm tra v√† c·∫≠p nh·∫≠t tr·∫°ng th√°i timeout cho file qu√° 900s."""
        try:
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("SELECT file_path, created_at FROM file_list WHERE status = 'ƒëang frame sampler ...'")
                for row in cursor.fetchall():
                    created_at = datetime.fromisoformat(row[1].replace('Z', '+00:00')) if row[1] else datetime.min.replace(tzinfo=VIETNAM_TZ)
                    if (datetime.now(VIETNAM_TZ) - created_at).total_seconds() > self.timeout_seconds:
                        cursor.execute("UPDATE file_list SET status = ?, is_processed = 1 WHERE file_path = ?", 
                                     ('timeout', row[0]))
                        logger.warning(f"Timeout processing {row[0]} after {self.timeout_seconds}s")
                conn.commit()
                conn.close()
        except Exception as e:
            logger.error(f"Error checking timeout: {e}")

    def scan_files(self):
        """Qu√©t file m·ªõi ƒë·ªãnh k·ª≥ (15 ph√∫t)."""
        logger.info("B·∫Øt ƒë·∫ßu qu√©t l·∫∑p")
        while self.running:
            try:
                logger.debug("Ki·ªÉm tra qu√©t l·∫∑p, running=%s, paused=%s", self.running, not self.pause_event.is_set())
                self.pause_event.wait()
                with db_rwlock.gen_rlock():
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("SELECT COUNT(*) FROM file_list WHERE status = 'pending' AND is_processed = 0")
                    pending_count = cursor.fetchone()[0]
                    conn.close()

                if pending_count >= self.queue_limit:
                    logger.warning(f"Queue full ({pending_count}/{self.queue_limit}), skipping file scan")
                else:
                    run_file_scan("default")
                    frame_sampler_event.set()
                time.sleep(self.scan_interval)
            except Exception as e:
                logger.error(f"Error in file scan: {e}")

    def run_batch(self):
        """Ch·∫°y batch x·ª≠ l√Ω file, s·ª≠ d·ª•ng run_frame_sampler."""
        while self.running:
            try:
                self.pause_event.wait()
                self.batch_size = self.sys_monitor.get_batch_size(self.batch_size)

                if not self.sampler_threads or len(self.sampler_threads) != self.batch_size:
                    for thread in self.sampler_threads:
                        if thread.is_alive():
                            thread.join(timeout=1)
                    self.sampler_threads = start_frame_sampler_thread(self.batch_size)
                    logger.info(f"Started {self.batch_size} frame sampler threads")

                if not self.detector_thread or not self.detector_thread.is_alive():
                    self.detector_thread = start_event_detector_thread()
                    logger.info("Started event detector thread")

                self.check_timeout()

                files = self.get_pending_files()
                if not files:
                    frame_sampler_event.clear()
                    frame_sampler_event.wait()
                    continue

                frame_sampler_event.set()
                event_detector_event.set()
                time.sleep(60)
            except Exception as e:
                logger.error(f"Error in batch processing: {e}")

    def start(self):
        """Kh·ªüi ƒë·ªông BatchScheduler."""
        if not self.running:
            # Log system info khi kh·ªüi ƒë·ªông
            self.sys_monitor.log_system_info()
            
            self.running = True
            days = [(datetime.now(VIETNAM_TZ) - timedelta(days=i)).date().isoformat() for i in range(6, -1, -1)]
            logger.info(f"Initial scan for days: {days}")
            try:
                run_file_scan("default", days=days)
                frame_sampler_event.set()
            except Exception as e:
                logger.error(f"Initial scan failed: {e}")

            scan_thread = threading.Thread(target=self.scan_files)
            batch_thread = threading.Thread(target=self.run_batch)
            scan_thread.start()
            batch_thread.start()
            logger.info(f"BatchScheduler started, batch_size={self.batch_size}, scan_interval={self.scan_interval}")

    def stop(self):
        """D·ª´ng BatchScheduler m·ªôt c√°ch an to√†n."""
        if not self.running:
            return  # ƒê√£ d·ª´ng r·ªìi
            
        logger.info("Stopping BatchScheduler...")
        self.running = False
        
        # Clear events ƒë·ªÉ c√°c thread c√≥ th·ªÉ tho√°t
        frame_sampler_event.clear()
        event_detector_event.clear()
        
        # ƒê·∫∑t pause_event ƒë·ªÉ c√°c thread kh√¥ng b·ªã block
        self.pause_event.set()
        
        # D·ª´ng sampler threads v·ªõi timeout ng·∫Øn
        for i, thread in enumerate(self.sampler_threads):
            if thread and thread.is_alive():
                try:
                    thread.join(timeout=0.5)  # Timeout ng·∫Øn
                    if thread.is_alive():
                        logger.warning(f"Sampler thread {i} did not stop gracefully")
                except Exception as e:
                    logger.warning(f"Error stopping sampler thread {i}: {e}")
        
        # D·ª´ng detector thread
        if self.detector_thread and self.detector_thread.is_alive():
            try:
                self.detector_thread.join(timeout=0.5)
                if self.detector_thread.is_alive():
                    logger.warning("Detector thread did not stop gracefully")
            except Exception as e:
                logger.warning(f"Error stopping detector thread: {e}")
        
        logger.info("BatchScheduler stopped")
```
## üìÑ File: `file_parser.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/utils/file_parser.py`

```python
import pandas as pd
import base64
import os
from io import BytesIO
import logging
import csv

# Thi·∫øt l·∫≠p logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def force_split_excel_text(df: pd.DataFrame) -> pd.DataFrame:
    if df.shape[1] == 1 and isinstance(df.columns[0], str) and "\t" in df.columns[0]:
        raw = df.to_csv(index=False, header=False)
        reader = csv.reader(raw.splitlines(), delimiter='\t')
        rows = list(reader)
        df_fixed = pd.DataFrame(rows[1:], columns=rows[0])
        logger.debug(f"[DEBUG] After force_split_excel_text - df.columns: {df_fixed.columns.tolist()}")
        logger.debug(f"[DEBUG] After force_split_excel_text - df.shape: {df_fixed.shape}")
        return df_fixed
    return df

def parse_uploaded_file(file_content: str = None, file_path: str = None, is_excel: bool = False) -> pd.DataFrame:
    """
    Decode base64-encoded file content or read from file path and return a pandas DataFrame.
    Supports both CSV and Excel formats.
    Raises detailed exceptions instead of falling back silently.
    """
    logger.debug(f"parse_uploaded_file called with is_excel={is_excel}, file_content={'provided' if file_content else 'not provided'}, file_path={file_path}")

    if not file_content and not file_path:
        raise ValueError("Either file_content or file_path must be provided.")

    if file_content:
        try:
            file_bytes = base64.b64decode(file_content)
        except Exception as e:
            raise ValueError(f"Failed to decode base64 content: {e}")
        buffer = BytesIO(file_bytes)
    elif file_path:
        if not os.path.exists(file_path):
            raise ValueError(f"File not found at path: {file_path}")
        buffer = file_path  # pandas can read directly from file path

    try:
        if is_excel:
            logger.debug("Reading file as Excel (pd.read_excel)")
            try:
                df = pd.read_excel(buffer, header=None, engine='openpyxl')  # X√≥a encoding
            except Exception as e:
                logger.debug(f"Failed to read Excel with pd.read_excel: {str(e)}")
                logger.debug("Falling back to pd.read_csv")
                buffer.seek(0)  # Reset con tr·ªè file ƒë·ªÉ ƒë·ªçc l·∫°i
                df = pd.read_csv(buffer, sep=",", encoding='utf-8-sig', engine='python')
            logger.debug(f"[DEBUG] Raw DataFrame before processing: {df.to_dict()}")
            logger.debug(f"[DEBUG] Raw first row (potential header): {df.iloc[0].tolist()}")
            if df.shape[0] > 1:
                df.columns = df.iloc[0].values.tolist()
                df = df[1:]
                df = force_split_excel_text(df)  # Fix n·∫øu d√≠nh l·ªói tab
            else:
                raise ValueError("Excel file missing header/data")
            logger.debug(f"[DEBUG] df.columns: {df.columns.tolist()}")
            logger.debug(f"[DEBUG] df.shape: {df.shape}")
            logger.debug(f"[DEBUG] df.head(2): {df.head(2).to_dict()}")
            return df
        else:
            logger.debug("Reading file as CSV (pd.read_csv)")
            try:
                df = pd.read_csv(buffer, sep=",", encoding='latin1', engine='python')  # Th·ª≠ d·∫•u ph·∫©y tr∆∞·ªõc
                # Ki·ªÉm tra n·∫øu ch·ªâ c√≥ 1 c·ªôt v√† c·ªôt ƒë√≥ ch·ª©a d·∫•u ;
                if len(df.columns) == 1 and df.columns[0] and isinstance(df.columns[0], str) and ";" in df.columns[0]:
                    logger.debug("Detected single column with semicolon, retrying with sep=';'")
                    if file_content:
                        buffer.seek(0)  # Reset con tr·ªè file ƒë·ªÉ ƒë·ªçc l·∫°i n·∫øu d√πng file_content
                    df = pd.read_csv(buffer, sep=";", encoding='latin1', engine='python')
                return df
            except pd.errors.ParserError:
                if file_content:
                    buffer.seek(0)  # Reset con tr·ªè file ƒë·ªÉ ƒë·ªçc l·∫°i n·∫øu d√πng file_content
                return pd.read_csv(buffer, sep=";", encoding='latin1', engine='python')  # N·∫øu l·ªói, th·ª≠ d·∫•u ch·∫•m ph·∫©y
    except Exception as e:
        file_type = 'Excel' if is_excel else 'CSV'
        raise ValueError(f"Failed to read {file_type} file: {e}")
```
## üìÑ File: `__init__.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/utils/__init__.py`

```python

```
## üìÑ File: `path_validator.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/utils/path_validator.py`

```python
# backend/modules/utils/path_validator.py
import os
import shutil
import json
import logging
from typing import Dict, List, Tuple
from pathlib import Path
import stat

logger = logging.getLogger(__name__)

class PathValidator:
    """
    Path validation and directory management for VTrack video sources
    Handles directory creation, permission checks, and disk space validation
    """
    
    def __init__(self, base_path: str = None):
        """
        Initialize PathValidator with base path for video storage
        
        Args:
            base_path: Base directory for all video sources (default: project root)
        """
        if base_path is None:
            # Default to project root + storage directories
            from modules.db_utils import find_project_root
            project_root = find_project_root(os.path.abspath(__file__))
            base_path = project_root
        
        self.base_path = Path(base_path)
        self.logger = logging.getLogger(__name__)
        
        # Default storage directories
        self.nvr_downloads_dir = self.base_path / "nvr_downloads"
        self.cloud_sync_dir = self.base_path / "cloud_sync"
        self.output_clips_dir = self.base_path / "output_clips"
        
        self.logger.info(f"PathValidator initialized with base_path: {self.base_path}")
    
    def validate_source_path(self, source_type: str, source_name: str) -> Dict:
        """
        Validate and prepare working path for a video source
        
        Args:
            source_type: Type of source ('nvr', 'local', 'cloud')
            source_name: Unique name for the source
            
        Returns:
            Dict with validation results and working path
        """
        try:
            self.logger.info(f"üîç Validating source path: {source_type}/{source_name}")
            
            # Determine working directory based on source type
            if source_type == 'nvr':
                working_path = self.nvr_downloads_dir / source_name
            elif source_type == 'cloud':
                working_path = self.cloud_sync_dir / source_name
            elif source_type == 'local':
                # Local sources use their own paths, no validation needed
                return {
                    'success': True,
                    'working_path': None,
                    'message': 'Local source uses existing path',
                    'disk_space_gb': self._get_disk_space_gb(str(self.base_path)),
                    'permissions': 'read-only'
                }
            else:
                return {
                    'success': False,
                    'message': f'Unknown source type: {source_type}',
                    'working_path': None
                }
            
            # Create working directory if it doesn't exist
            working_path.mkdir(parents=True, exist_ok=True)
            self.logger.info(f"‚úÖ Working directory ready: {working_path}")
            
            # Validate permissions and disk space
            permissions_check = self.check_permissions(str(working_path))
            disk_check = self.check_disk_space(str(working_path), required_gb=1.0)
            
            if not permissions_check['writable']:
                return {
                    'success': False,
                    'message': f'Directory not writable: {working_path}',
                    'working_path': str(working_path),
                    'permissions': permissions_check
                }
            
            if not disk_check['sufficient']:
                return {
                    'success': False,
                    'message': f'Insufficient disk space: {disk_check["available_gb"]:.1f} GB available',
                    'working_path': str(working_path),
                    'disk_space': disk_check
                }
            
            return {
                'success': True,
                'working_path': str(working_path),
                'message': f'Source path validated successfully',
                'disk_space_gb': disk_check['available_gb'],
                'permissions': 'read-write',
                'created_directories': [str(working_path)]
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Path validation failed: {e}")
            return {
                'success': False,
                'message': f'Path validation error: {str(e)}',
                'working_path': None
            }
    
    def create_camera_directories(self, source_path: str, camera_names: List[str]) -> Dict:
        """
        Create individual directories for each camera under source path
        
        Args:
            source_path: Working directory for the source
            camera_names: List of camera names to create directories for
            
        Returns:
            Dict with created directories and camera path mapping
        """
        try:
            self.logger.info(f"üìÅ Creating camera directories in: {source_path}")
            self.logger.info(f"üìπ Cameras: {camera_names}")
            
            if not camera_names:
                return {
                    'success': True,
                    'camera_paths': {},
                    'created_directories': [],
                    'message': 'No cameras to create directories for'
                }
            
            source_dir = Path(source_path)
            if not source_dir.exists():
                source_dir.mkdir(parents=True, exist_ok=True)
                self.logger.info(f"‚úÖ Created source directory: {source_dir}")
            
            camera_paths = {}
            created_directories = []
            
            for camera_name in camera_names:
                # Sanitize camera name for file system
                safe_name = self._sanitize_directory_name(camera_name)
                camera_dir = source_dir / safe_name
                
                # Create camera directory
                camera_dir.mkdir(parents=True, exist_ok=True)
                
                # Store mapping
                camera_paths[camera_name] = str(camera_dir)
                created_directories.append(str(camera_dir))
                
                self.logger.info(f"‚úÖ Created camera directory: {camera_name} ‚Üí {camera_dir}")
            
            return {
                'success': True,
                'camera_paths': camera_paths,
                'created_directories': created_directories,
                'message': f'Created {len(camera_paths)} camera directories',
                'total_cameras': len(camera_names)
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Camera directory creation failed: {e}")
            return {
                'success': False,
                'message': f'Camera directory creation error: {str(e)}',
                'camera_paths': {},
                'created_directories': []
            }
    
    def check_disk_space(self, path: str, required_gb: float = 1.0) -> Dict:
        """
        Check available disk space at given path
        
        Args:
            path: Path to check disk space for
            required_gb: Minimum required space in GB
            
        Returns:
            Dict with disk space information
        """
        try:
            # Get disk usage statistics
            statvfs = shutil.disk_usage(path)
            
            # Convert to GB
            total_gb = statvfs.total / (1024**3)
            used_gb = (statvfs.total - statvfs.free) / (1024**3)
            available_gb = statvfs.free / (1024**3)
            
            usage_percent = (used_gb / total_gb) * 100
            sufficient = available_gb >= required_gb
            
            return {
                'sufficient': sufficient,
                'available_gb': available_gb,
                'used_gb': used_gb,
                'total_gb': total_gb,
                'usage_percent': usage_percent,
                'required_gb': required_gb,
                'path': path
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Disk space check failed: {e}")
            return {
                'sufficient': False,
                'available_gb': 0,
                'error': str(e),
                'path': path
            }
    
    def check_permissions(self, path: str) -> Dict:
        """
        Check read/write permissions for given path
        
        Args:
            path: Path to check permissions for
            
        Returns:
            Dict with permission information
        """
        try:
            path_obj = Path(path)
            
            # Check if path exists
            if not path_obj.exists():
                # Try to create it to test permissions
                try:
                    path_obj.mkdir(parents=True, exist_ok=True)
                    created = True
                except Exception:
                    return {
                        'readable': False,
                        'writable': False,
                        'executable': False,
                        'error': 'Cannot create directory',
                        'path': path
                    }
            else:
                created = False
            
            # Test permissions
            readable = os.access(path, os.R_OK)
            writable = os.access(path, os.W_OK)
            executable = os.access(path, os.X_OK)
            
            # Get file mode
            try:
                stat_info = path_obj.stat()
                file_mode = stat.filemode(stat_info.st_mode)
            except Exception:
                file_mode = 'unknown'
            
            return {
                'readable': readable,
                'writable': writable,
                'executable': executable,
                'file_mode': file_mode,
                'created': created,
                'path': path
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Permission check failed: {e}")
            return {
                'readable': False,
                'writable': False,
                'executable': False,
                'error': str(e),
                'path': path
            }
    
    def get_camera_paths(self, source_path: str, camera_names: List[str]) -> Dict:
        """
        Get mapping of camera names to their directory paths
        
        Args:
            source_path: Working directory for the source
            camera_names: List of camera names
            
        Returns:
            Dict mapping camera names to directory paths
        """
        try:
            source_dir = Path(source_path)
            camera_paths = {}
            
            for camera_name in camera_names:
                safe_name = self._sanitize_directory_name(camera_name)
                camera_dir = source_dir / safe_name
                camera_paths[camera_name] = str(camera_dir)
            
            return {
                'success': True,
                'camera_paths': camera_paths,
                'source_path': source_path
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Get camera paths failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'camera_paths': {}
            }
    
    def cleanup_unused_directories(self, source_path: str, active_cameras: List[str]) -> Dict:
        """
        Remove directories for cameras that are no longer active
        
        Args:
            source_path: Working directory for the source
            active_cameras: List of currently active camera names
            
        Returns:
            Dict with cleanup results
        """
        try:
            self.logger.info(f"üßπ Cleaning up unused directories in: {source_path}")
            
            source_dir = Path(source_path)
            if not source_dir.exists():
                return {
                    'success': True,
                    'removed_directories': [],
                    'message': 'Source directory does not exist'
                }
            
            # Get all existing directories
            existing_dirs = [d for d in source_dir.iterdir() if d.is_dir()]
            
            # Sanitize active camera names
            active_safe_names = [self._sanitize_directory_name(name) for name in active_cameras]
            
            removed_directories = []
            
            for dir_path in existing_dirs:
                if dir_path.name not in active_safe_names:
                    try:
                        shutil.rmtree(dir_path)
                        removed_directories.append(str(dir_path))
                        self.logger.info(f"üóëÔ∏è Removed unused directory: {dir_path}")
                    except Exception as e:
                        self.logger.warning(f"‚ö†Ô∏è Failed to remove directory {dir_path}: {e}")
            
            return {
                'success': True,
                'removed_directories': removed_directories,
                'message': f'Cleaned up {len(removed_directories)} unused directories',
                'active_cameras': active_cameras,
                'remaining_directories': len(existing_dirs) - len(removed_directories)
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Directory cleanup failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'removed_directories': []
            }
    
    def get_directory_health_status(self, path: str) -> Dict:
        """
        Get comprehensive health status of a directory
        
        Args:
            path: Directory path to check
            
        Returns:
            Dict with health status information
        """
        try:
            path_obj = Path(path)
            
            if not path_obj.exists():
                return {
                    'healthy': False,
                    'exists': False,
                    'message': 'Directory does not exist',
                    'path': path
                }
            
            # Check permissions
            permissions = self.check_permissions(path)
            
            # Check disk space
            disk_space = self.check_disk_space(path, required_gb=0.5)
            
            # Count files and subdirectories
            try:
                files_count = len([f for f in path_obj.rglob('*') if f.is_file()])
                dirs_count = len([d for d in path_obj.rglob('*') if d.is_dir()])
            except Exception:
                files_count = 0
                dirs_count = 0
            
            # Calculate directory size
            try:
                total_size = sum(f.stat().st_size for f in path_obj.rglob('*') if f.is_file())
                size_mb = total_size / (1024**2)
            except Exception:
                size_mb = 0
            
            # Determine overall health
            healthy = (
                permissions.get('readable', False) and
                permissions.get('writable', False) and
                disk_space.get('sufficient', False)
            )
            
            return {
                'healthy': healthy,
                'exists': True,
                'permissions': permissions,
                'disk_space': disk_space,
                'files_count': files_count,
                'directories_count': dirs_count,
                'size_mb': size_mb,
                'path': path,
                'message': 'Directory health check complete'
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Directory health check failed: {e}")
            return {
                'healthy': False,
                'error': str(e),
                'path': path
            }
    
    def _sanitize_directory_name(self, name: str) -> str:
        """
        Sanitize camera name to be safe for file system directory names
        
        Args:
            name: Original camera name
            
        Returns:
            Sanitized directory name
        """
        # Replace problematic characters
        import re
        
        # Replace spaces and special chars with underscores
        sanitized = re.sub(r'[<>:"/\\|?*]', '_', name)
        sanitized = re.sub(r'\s+', '_', sanitized)
        
        # Remove leading/trailing underscores and dots
        sanitized = sanitized.strip('_.')
        
        # Ensure not empty
        if not sanitized:
            sanitized = 'camera'
        
        # Limit length to 50 characters
        if len(sanitized) > 50:
            sanitized = sanitized[:50].rstrip('_')
        
        return sanitized
    
    def _get_disk_space_gb(self, path: str) -> float:
        """
        Helper method to get available disk space in GB
        
        Args:
            path: Path to check
            
        Returns:
            Available space in GB
        """
        try:
            statvfs = shutil.disk_usage(path)
            return statvfs.free / (1024**3)
        except Exception:
            return 0.0
    
    def get_base_directories(self) -> Dict:
        """
        Get all base directories managed by PathValidator
        
        Returns:
            Dict with base directory paths and their status
        """
        directories = {
            'base_path': str(self.base_path),
            'nvr_downloads': str(self.nvr_downloads_dir),
            'cloud_sync': str(self.cloud_sync_dir),
            'output_clips': str(self.output_clips_dir)
        }
        
        status = {}
        for name, path in directories.items():
            try:
                Path(path).mkdir(parents=True, exist_ok=True)
                status[name] = {
                    'path': path,
                    'exists': True,
                    'writable': os.access(path, os.W_OK)
                }
            except Exception as e:
                status[name] = {
                    'path': path,
                    'exists': False,
                    'error': str(e)
                }
        
        return {
            'directories': directories,
            'status': status,
            'all_healthy': all(s.get('exists', False) and s.get('writable', False) 
                             for s in status.values())
        }

# Global instance for easy import
path_validator = PathValidator()
```
## üìÑ File: `LicenseGuard.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/system/LicenseGuard.py`

```python
# LicenseGuard.py - Module ki·ªÉm tra b·∫£n quy·ªÅn (QR watermark, MAC address)

```
## üìÑ File: `SystemMonitor.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/system/SystemMonitor.py`

```python
# SystemMonitor.py - Module theo d√µi hi·ªáu su·∫•t v√† t√†i nguy√™n h·ªá th·ªëng

```
## üìÑ File: `SystemCalendar.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/system/SystemCalendar.py`

```python
# SystemCalendar.py - Module qu·∫£n l√Ω l·ªãch l√†m vi·ªác (ng√†y ngh·ªâ, ca l√†m vi·ªác)

```
## üìÑ File: `AuditLogger.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/system/AuditLogger.py`

```python
# AuditLogger.py - Module ghi log h·ªá th·ªëng (l·ªãch s·ª≠ x·ª≠ l√Ω, l·ªói, ng∆∞·ªùi d√πng)

```
## üìÑ File: `nvr_downloader.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/nvr_downloader.py`

```python
import os
import json
import sqlite3
from datetime import datetime, timedelta
from modules.db_utils import get_db_connection
from .mock_video_generator import MockVideoGenerator

class NVRDownloader:
    """
    NVR Video Downloader v·ªõi support cho c·∫£ mock v√† real ONVIF downloads
    OPTIMIZED: S·ª≠ d·ª•ng last_downloaded_file tracking thay v√¨ full file tracking
    """
    
    def __init__(self, mock_mode=True, testing_intervals=True):
        """
        Initialize NVRDownloader
        
        Args:
            mock_mode (bool): True = use mock data, False = real ONVIF downloads
            testing_intervals (bool): True = use short intervals for testing
        """
        self.mock_mode = mock_mode
        self.testing_intervals = testing_intervals
        
        if self.mock_mode:
            self.mock_generator = MockVideoGenerator()
            print(f"üé≠ NVRDownloader initialized in MOCK MODE")
        else:
            print(f"üìπ NVRDownloader initialized in REAL MODE")
    
    def download_recordings(self, source_config):
        """
        Main download method - routes to mock or real implementation
        
        Args:
            source_config (dict): Source configuration
                - source_id: Database ID
                - name: Source name
                - selected_cameras: List of camera names
                - working_path: Base download directory
                
        Returns:
            dict: Download results with success status, files, and stats
        """
        print(f"üöÄ Starting download for source: {source_config.get('name')}")
        print(f"üìÅ Working path: {source_config.get('working_path')}")
        print(f"üìπ Cameras: {source_config.get('selected_cameras', [])}")
        
        if self.mock_mode:
            return self._mock_download(source_config)
        else:
            return self._real_onvif_download(source_config)
    
    def _mock_download(self, source_config):
        """
        Mock download implementation using MockVideoGenerator
        OPTIMIZED: Uses last_downloaded_file tracking
        
        Args:
            source_config (dict): Source configuration
            
        Returns:
            dict: Mock download results
        """
        print(f"üé¨ MOCK DOWNLOAD: Generating recordings...")
        
        results = {
            'success': True,
            'downloaded_files': [],
            'total_size': 0,
            'cameras_processed': [],
            'mode': 'mock'
        }
        
        try:
            source_id = source_config.get('source_id')
            selected_cameras = source_config.get('selected_cameras', [])
            working_path = source_config.get('working_path')
            
            if not selected_cameras:
                print("‚ö†Ô∏è No cameras selected for download")
                return results
            
            # Process each camera
            for camera in selected_cameras:
                print(f"üé• Processing camera: {camera}")
                
                # Create camera directory
                camera_dir = os.path.join(working_path, camera.replace(' ', '_'))
                os.makedirs(camera_dir, exist_ok=True)
                print(f"üìÅ Camera directory: {camera_dir}")
                
                # Generate mock files for this camera
                if self.testing_intervals:
                    # Testing mode: Short intervals for development
                    mock_files = self.mock_generator.generate_realtime_testing_videos(
                        camera, 
                        camera_dir, 
                        interval_seconds=120,  # 2 minutes for testing
                        count=15  # 15 files per camera
                    )
                else:
                    # Normal mode: Daily videos with realistic intervals
                    mock_files = self.mock_generator.generate_daily_videos(
                        camera,
                        camera_dir,
                        days=1,
                        schedule='security'  # 4 times per day
                    )
                
                # üÜï OPTIMIZED: Track only latest file instead of all files
                tracked_count = self._track_latest_file_only(source_id, camera, mock_files)
                
                # Update results
                results['downloaded_files'].extend(mock_files)
                results['total_size'] += sum(f['size'] for f in mock_files)
                results['cameras_processed'].append(camera)
                
                print(f"‚úÖ Camera {camera}: {len(mock_files)} files, {tracked_count} efficient tracking")
            
            print(f"üéâ MOCK DOWNLOAD COMPLETED:")
            print(f"   üìä Total files: {len(results['downloaded_files'])}")
            print(f"   üìÅ Total size: {results['total_size']} bytes ({results['total_size']/1024:.1f} KB)")
            print(f"   üé• Cameras processed: {len(results['cameras_processed'])}")
            print(f"   üóÑÔ∏è Database records: {len(results['cameras_processed'])} (optimized)")
            
        except Exception as e:
            print(f"‚ùå Mock download error: {e}")
            results['success'] = False
            results['error'] = str(e)
        
        return results
    
    def _real_onvif_download(self, source_config):
        """
        Real ONVIF download implementation (placeholder for future)
        
        Args:
            source_config (dict): Source configuration
            
        Returns:
            dict: Real download results
        """
        print(f"üìπ REAL ONVIF DOWNLOAD: Not implemented yet")
        
        # TODO: Implement real ONVIF download logic
        # 1. Connect to ONVIF cameras
        # 2. Get last downloaded timestamp from last_downloaded_file table
        # 3. Query ONVIF for recordings newer than last timestamp
        # 4. Download only new files
        # 5. Update last_downloaded_file with latest info
        
        return {
            'success': False,
            'error': 'Real ONVIF download not implemented yet',
            'downloaded_files': [],
            'total_size': 0,
            'cameras_processed': [],
            'mode': 'real'
        }
    
    def _track_latest_file_only(self, source_id, camera_name, file_list):
        """
        üÜï OPTIMIZED: Track only the latest file per camera in last_downloaded_file table
        TEMPORARILY DISABLED: Database tracking disabled for clean workflow
        
        Args:
            source_id (int): Source database ID
            camera_name (str): Camera name
            file_list (list): List of file info dicts
            
        Returns:
            int: Number of files successfully tracked (for compatibility)
        """
        if not file_list:
            return 0
            
        try:
            # Calculate totals for logging
            total_count = len(file_list)
            total_size_mb = sum(f['size'] for f in file_list) / (1024 * 1024)
            
            # Find latest file by timestamp for logging
            latest_file = max(file_list, key=lambda f: f['timestamp'])
            
            # üîß TEMPORARILY DISABLED: Database tracking
            print(f"üìä Efficient tracking DISABLED: Latest file '{latest_file['filename']}' | Total: {total_count} files, {total_size_mb:.1f} MB")
            print(f"‚ö†Ô∏è Database tracking temporarily disabled for clean workflow")
            
            # Return total count for compatibility (without database update)
            return total_count
            
            # üö´ DISABLED CODE BELOW:
            # # Import helper function from database
            # from database import update_last_downloaded_file
            # 
            # # Update database with only latest file info (1 DB operation instead of 15!)
            # success = update_last_downloaded_file(
            #     source_id, camera_name, latest_file, total_count, total_size_mb
            # )
            # 
            # if success:
            #     print(f"üìä Efficient tracking: Latest file '{latest_file['filename']}' | Total: {total_count} files, {total_size_mb:.1f} MB")
            #     return total_count
            # else:
            #     print(f"‚ùå Failed to track latest file for camera: {camera_name}")
            #     return 0
                
        except Exception as e:
            print(f"‚ùå Latest file tracking error: {e}")
            return 0
    
    def _track_downloaded_files(self, source_id, camera_name, file_list):
        """
        ‚ö†Ô∏è DEPRECATED: Legacy method for full file tracking
        Use _track_latest_file_only() instead for better performance
        
        Args:
            source_id (int): Source database ID
            camera_name (str): Camera name
            file_list (list): List of file info dicts
            
        Returns:
            int: Number of files successfully tracked
        """
        print(f"‚ö†Ô∏è Using legacy full file tracking - consider using _track_latest_file_only()")
        
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            
            tracked_count = 0
            
            for file_info in file_list:
                try:
                    cursor.execute("""
                        INSERT INTO downloaded_files (
                            source_id, camera_name, local_file_path, file_size_bytes, 
                            download_timestamp, recording_start_time, original_filename
                        ) VALUES (?, ?, ?, ?, ?, ?, ?)
                    """, (
                        source_id,
                        camera_name,
                        file_info['path'],
                        file_info['size'],
                        datetime.now().isoformat(),
                        file_info['timestamp'].isoformat(),
                        file_info['filename']
                    ))
                    tracked_count += 1
                    
                except sqlite3.IntegrityError:
                    print(f"‚ö†Ô∏è File already tracked: {file_info['filename']}")
                except Exception as e:
                    print(f"‚ùå Failed to track file {file_info['filename']}: {e}")
            
            conn.commit()
            print(f"‚úÖ DB commit & close success for camera: {camera_name}")
            conn.close()
            
            print(f"üìä Legacy tracking: {tracked_count}/{len(file_list)} files")
            return tracked_count
            
        except Exception as e:
            print(f"‚ùå Database tracking error: {e}")
            return 0
    
    def get_download_statistics(self, source_id):
        """
        üÜï OPTIMIZED: Get download statistics using last_downloaded_file table
        
        Args:
            source_id (int): Source database ID
            
        Returns:
            dict: Download statistics
        """
        try:
            # Import helper function from database
            from database import get_camera_download_stats
            
            stats = get_camera_download_stats(source_id)
            
            # Convert to expected format for compatibility
            camera_stats = {}
            for camera_name, camera_info in stats['camera_stats'].items():
                camera_stats[camera_name] = {
                    'file_count': camera_info['files_count'],
                    'total_size': camera_info['size_mb'] * 1024 * 1024  # Convert back to bytes
                }
            
            # Get latest download time
            latest_download = None
            for camera_info in stats['camera_stats'].values():
                if camera_info['last_download']:
                    if not latest_download or camera_info['last_download'] > latest_download:
                        latest_download = camera_info['last_download']
            
            return {
                'total_files': stats['total_files'],
                'total_size': int(stats['total_size_mb'] * 1024 * 1024),  # Convert to bytes
                'total_size_mb': stats['total_size_mb'],
                'camera_stats': camera_stats,
                'latest_download': latest_download,
                'cameras_count': stats['cameras_count']
            }
            
        except Exception as e:
            print(f"‚ùå Statistics error: {e}")
            return {
                'total_files': 0,
                'total_size': 0,
                'total_size_mb': 0,
                'camera_stats': {},
                'latest_download': None,
                'cameras_count': 0
            }
    
    def get_last_downloaded_timestamp(self, source_id, camera_name):
        """
        üÜï NEW: Get last downloaded file timestamp for incremental sync
        
        Args:
            source_id (int): Source database ID
            camera_name (str): Camera name
            
        Returns:
            str: ISO timestamp of last downloaded file
        """
        try:
            from database import get_last_downloaded_timestamp
            return get_last_downloaded_timestamp(source_id, camera_name)
        except Exception as e:
            print(f"‚ùå Error getting last timestamp: {e}")
            return "1970-01-01T00:00:00"  # Default to epoch if error
    
    def cleanup_old_downloads(self, source_id, keep_days=30):
        """
        üÜï OPTIMIZED: Clean up old downloaded files using filesystem + last_downloaded_file
        
        Args:
            source_id (int): Source database ID
            keep_days (int): Number of days to keep
            
        Returns:
            dict: Cleanup results
        """
        try:
            from database import get_camera_download_stats
            
            stats = get_camera_download_stats(source_id)
            cutoff_date = datetime.now() - timedelta(days=keep_days)
            
            deleted_files = 0
            deleted_size = 0
            
            # For each camera, clean up old files from filesystem
            for camera_name, camera_info in stats['camera_stats'].items():
                if camera_info['last_download']:
                    last_download_date = datetime.fromisoformat(camera_info['last_download'])
                    
                    # If last download is older than cutoff, could clean up
                    if last_download_date < cutoff_date:
                        print(f"üßπ Camera {camera_name}: Last download {camera_info['last_download']} is old")
                        # Here you could implement filesystem cleanup logic
                        # For now, just report what would be cleaned
            
            # Update last_downloaded_file table to remove old entries
            conn = get_db_connection()
            cursor = conn.cursor()
            
            cursor.execute("""
                DELETE FROM last_downloaded_file 
                WHERE source_id = ? AND last_download_time < ?
            """, (source_id, cutoff_date.isoformat()))
            
            db_deleted = cursor.rowcount
            conn.commit()
            conn.close()
            
            result = {
                'files_deleted': deleted_files,
                'size_freed': deleted_size,
                'size_freed_mb': round(deleted_size / (1024 * 1024), 2),
                'db_records_deleted': db_deleted
            }
            
            print(f"üßπ Cleanup completed: {deleted_files} files, {result['size_freed_mb']} MB freed, {db_deleted} DB records removed")
            return result
            
        except Exception as e:
            print(f"‚ùå Cleanup error: {e}")
            return {
                'files_deleted': 0,
                'size_freed': 0,
                'size_freed_mb': 0,
                'db_records_deleted': 0,
                'error': str(e)
            }
    
    def test_mock_download(self, test_source_config=None):
        """
        Test method ƒë·ªÉ ki·ªÉm tra mock download functionality
        
        Args:
            test_source_config (dict): Optional test configuration
            
        Returns:
            dict: Test results
        """
        if test_source_config is None:
            test_source_config = {
                'source_id': 999,  # Test source ID
                'name': 'test_nvr',
                'selected_cameras': ['Test Camera 1', 'Test Camera 2'],
                'working_path': '/tmp/nvr_test_download'
            }
        
        print(f"üß™ TESTING OPTIMIZED MOCK DOWNLOAD...")
        print(f"üìã Test config: {test_source_config}")
        
        # Ensure test directory exists
        os.makedirs(test_source_config['working_path'], exist_ok=True)
        
        # Run mock download
        results = self._mock_download(test_source_config)
        
        # Verify results
        if results['success']:
            print(f"‚úÖ Test passed: {len(results['downloaded_files'])} files created")
            print(f"üìä Efficient DB tracking: {len(results['cameras_processed'])} records instead of {len(results['downloaded_files'])}")
            
            # Check actual files exist
            sample_files = results['downloaded_files'][:5]  # Show first 5 files
            for file_info in sample_files:
                if os.path.exists(file_info['path']):
                    actual_size = os.path.getsize(file_info['path'])
                    print(f"   üìÑ {file_info['filename']}: {actual_size} bytes")
                else:
                    print(f"   ‚ùå Missing: {file_info['filename']}")
            
            if len(results['downloaded_files']) > 5:
                print(f"   ... and {len(results['downloaded_files']) - 5} more files")
        else:
            print(f"‚ùå Test failed: {results.get('error', 'Unknown error')}")
        
        return results

# Usage examples v√† test function
def test_nvr_downloader():
    """Test function ƒë·ªÉ verify optimized NVRDownloader functionality"""
    print("=== TESTING OPTIMIZED NVRDownloader ===")
    
    # Test 1: Mock download v·ªõi testing intervals
    print("\n--- Test 1: Optimized Mock Download (Testing Mode) ---")
    downloader = NVRDownloader(mock_mode=True, testing_intervals=True)
    
    test_config = {
        'source_id': 37,
        'name': 'nvr_localhost',
        'selected_cameras': ['Front Door Camera', 'Parking Lot Camera'],
        'working_path': '/tmp/test_nvr_downloads'
    }
    
    results = downloader.test_mock_download(test_config)
    
    # Test 2: Optimized Statistics
    print("\n--- Test 2: Optimized Download Statistics ---")
    stats = downloader.get_download_statistics(37)
    print(f"Statistics: {stats}")
    
    # Test 3: Last downloaded timestamp
    print("\n--- Test 3: Last Downloaded Timestamp ---")
    for camera in test_config['selected_cameras']:
        last_timestamp = downloader.get_last_downloaded_timestamp(37, camera)
        print(f"Camera '{camera}' last download: {last_timestamp}")
    
    # Test 4: Normal intervals
    print("\n--- Test 4: Normal Intervals ---")
    downloader_normal = NVRDownloader(mock_mode=True, testing_intervals=False)
    results_normal = downloader_normal.test_mock_download({
        'source_id': 38,
        'name': 'nvr_normal_test',
        'selected_cameras': ['Normal Test Camera'],
        'working_path': '/tmp/test_nvr_normal'
    })
    
    print("\n‚úÖ All optimized tests completed!")

if __name__ == "__main__":
    test_nvr_downloader()
```
## üìÑ File: `cloud_manager.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/cloud_manager.py`

```python
#!/usr/bin/env python3
"""
Cloud Manager for VTrack - Unified Cloud Interface
Handles connection management, folder discovery, and authentication validation
Supports multiple cloud providers with Google Drive as primary implementation
"""

import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path

# Import existing Google Drive client
from .google_drive_client import GoogleDriveClient

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CloudManager:
    """
    Unified cloud interface for VTrack video source management
    Provides consistent API across different cloud providers
    """
    
    # Supported cloud providers
    SUPPORTED_PROVIDERS = {
        'google_drive': {
            'name': 'Google Drive',
            'client_class': GoogleDriveClient,
            'auth_type': 'oauth2',
            'supports_folders': True,
            'supports_nested': True
        }
        # Future: Dropbox, OneDrive, etc.
    }
    
    def __init__(self, provider: str = 'google_drive'):
        """
        Initialize CloudManager for specified provider
        
        Args:
            provider (str): Cloud provider name ('google_drive', etc.)
        """
        self.provider = provider
        self.client = None
        self.authenticated = False
        self.user_info = {}
        
        # Validate provider
        if provider not in self.SUPPORTED_PROVIDERS:
            raise ValueError(f"Unsupported provider: {provider}. Supported: {list(self.SUPPORTED_PROVIDERS.keys())}")
        
        # Initialize provider-specific client
        self._initialize_client()
        
        logger.info(f"CloudManager initialized for provider: {provider}")
    
    def _initialize_client(self):
        """Initialize the provider-specific client"""
        try:
            provider_config = self.SUPPORTED_PROVIDERS[self.provider]
            client_class = provider_config['client_class']
            
            if self.provider == 'google_drive':
                self.client = client_class()
            else:
                # Future provider initialization
                raise NotImplementedError(f"Provider {self.provider} not yet implemented")
                
            logger.info(f"‚úÖ {provider_config['name']} client initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize {self.provider} client: {e}")
            raise
    
    def test_connection_and_discover_folders(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Test cloud connection and discover available folders
        Main method called by VTrack's /test-source endpoint
        
        Args:
            config (dict): Source configuration containing provider settings
            
        Returns:
            dict: Connection test results with folder discovery
        """
        try:
            logger.info(f"üîç Testing {self.provider} connection and discovering folders...")
            
            # Step 1: Test basic connection
            connection_result = self.test_connection(config)
            
            if not connection_result['success']:
                return {
                    'accessible': False,
                    'message': connection_result['message'],
                    'provider': self.provider,
                    'folders': [],
                    'cameras': []
                }
            
            # Step 2: Discover root folders
            root_folders = self.discover_root_folders()
            
            # Step 3: Analyze folder structure for camera folders
            folder_analysis = self._analyze_folder_structure(root_folders)
            
            logger.info(f"‚úÖ Connection successful: {len(root_folders)} root folders discovered")
            
            return {
                'accessible': True,
                'message': f"{self.provider.title()} connection successful",
                'provider': self.provider,
                'user_info': self.user_info,
                'folders': root_folders,
                'folder_analysis': folder_analysis,
                'cameras': [],  # Will be populated when specific folder is selected
                'connection_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå Connection test failed: {e}")
            return {
                'accessible': False,
                'message': f"Connection failed: {str(e)}",
                'provider': self.provider,
                'folders': [],
                'cameras': [],
                'error': str(e)
            }
    
    def test_connection(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Test basic cloud provider connection
        
        Args:
            config (dict): Provider configuration
            
        Returns:
            dict: Connection test result
        """
        try:
            if self.provider == 'google_drive':
                return self._test_google_drive_connection(config)
            else:
                return {
                    'success': False,
                    'message': f"Provider {self.provider} not implemented"
                }
                
        except Exception as e:
            logger.error(f"‚ùå Connection test error: {e}")
            return {
                'success': False,
                'message': f"Connection test failed: {str(e)}"
            }
    
    def _test_google_drive_connection(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """Test Google Drive specific connection"""
        try:
            # Attempt authentication
            auth_success = self.client.authenticate()
            
            if not auth_success:
                return {
                    'success': False,
                    'message': 'Google Drive authentication failed'
                }
            
            # Test API access
            connection_test = self.client.test_connection()
            
            if connection_test['success']:
                self.authenticated = True
                self.user_info = {
                    'email': connection_test.get('user_email', 'Unknown'),
                    'storage_used_gb': connection_test.get('storage_used_gb', 0),
                    'storage_total_gb': connection_test.get('storage_total_gb', 'Unknown')
                }
                
                logger.info(f"‚úÖ Google Drive authenticated: {self.user_info['email']}")
                return {
                    'success': True,
                    'message': f"Connected to Google Drive: {self.user_info['email']}",
                    'user_info': self.user_info
                }
            else:
                return {
                    'success': False,
                    'message': connection_test['message']
                }
                
        except Exception as e:
            logger.error(f"‚ùå Google Drive connection error: {e}")
            return {
                'success': False,
                'message': f"Google Drive connection failed: {str(e)}"
            }
    
    def discover_root_folders(self) -> List[Dict[str, Any]]:
        """
        Discover root-level folders in cloud storage
        
        Returns:
            list: List of root folder information
        """
        try:
            if not self.authenticated:
                logger.warning("‚ö†Ô∏è Not authenticated - cannot discover folders")
                return []
            
            if self.provider == 'google_drive':
                return self._discover_google_drive_folders()
            else:
                logger.warning(f"‚ö†Ô∏è Folder discovery not implemented for {self.provider}")
                return []
                
        except Exception as e:
            logger.error(f"‚ùå Folder discovery error: {e}")
            return []
    
    def _discover_google_drive_folders(self) -> List[Dict[str, Any]]:
        """Discover Google Drive folders"""
        try:
            # Get root-level folders from Google Drive
            folders = self.client.list_files(folder_id='root', limit=50)
            
            root_folders = []
            for folder in folders:
                if folder.get('mimeType') == 'application/vnd.google-apps.folder':
                    folder_info = {
                        'id': folder['id'],
                        'name': folder['name'],
                        'created_time': folder.get('createdTime'),
                        'size': folder.get('size', 0),
                        'provider': 'google_drive',
                        'type': 'folder',
                        'description': f"Google Drive folder: {folder['name']}"
                    }
                    root_folders.append(folder_info)
            
            logger.info(f"üìÅ Discovered {len(root_folders)} Google Drive root folders")
            return root_folders
            
        except Exception as e:
            logger.error(f"‚ùå Google Drive folder discovery error: {e}")
            return []
    
    def discover_subfolders(self, folder_id: str, credentials: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Discover subfolders within a specific folder
        Used for camera folder detection in nested structures
        
        Args:
            folder_id (str): Parent folder ID
            credentials (dict): Optional authentication credentials
            
        Returns:
            dict: Subfolder discovery results
        """
        try:
            logger.info(f"üîç Discovering subfolders in folder: {folder_id}")
            
            if self.provider == 'google_drive':
                return self._discover_google_drive_subfolders(folder_id, credentials)
            else:
                return {
                    'success': False,
                    'message': f"Subfolder discovery not implemented for {self.provider}",
                    'subfolders': []
                }
                
        except Exception as e:
            logger.error(f"‚ùå Subfolder discovery error: {e}")
            return {
                'success': False,
                'message': f"Subfolder discovery failed: {str(e)}",
                'subfolders': [],
                'error': str(e)
            }
    
    def _discover_google_drive_subfolders(self, folder_id: str, credentials: Optional[Dict] = None) -> Dict[str, Any]:
        """Discover Google Drive subfolders"""
        try:
            # Re-authenticate if credentials provided
            if credentials and not self.authenticated:
                # TODO: Use provided credentials for authentication
                pass
            
            # Get subfolders
            subfolders_raw = self.client.list_files(folder_id=folder_id, limit=100)
            
            subfolders = []
            camera_folders = []
            
            for item in subfolders_raw:
                if item.get('mimeType') == 'application/vnd.google-apps.folder':
                    folder_info = {
                        'id': item['id'],
                        'name': item['name'],
                        'created_time': item.get('createdTime'),
                        'size': item.get('size', 0),
                        'parent_id': folder_id,
                        'provider': 'google_drive',
                        'type': 'folder'
                    }
                    
                    # Check if this looks like a camera folder
                    if self._is_camera_folder(item['name']):
                        folder_info['is_camera_folder'] = True
                        camera_folders.append(folder_info)
                    else:
                        folder_info['is_camera_folder'] = False
                    
                    subfolders.append(folder_info)
            
            logger.info(f"üìÅ Found {len(subfolders)} subfolders, {len(camera_folders)} camera folders")
            
            return {
                'success': True,
                'message': f"Found {len(subfolders)} subfolders",
                'subfolders': subfolders,
                'camera_folders': camera_folders,
                'total_folders': len(subfolders),
                'camera_count': len(camera_folders)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Google Drive subfolder discovery error: {e}")
            return {
                'success': False,
                'message': f"Google Drive subfolder discovery failed: {str(e)}",
                'subfolders': [],
                'error': str(e)
            }
    
    def _is_camera_folder(self, folder_name: str) -> bool:
        """
        Determine if a folder name indicates it contains camera videos
        
        Args:
            folder_name (str): Folder name to analyze
            
        Returns:
            bool: True if likely a camera folder
        """
        camera_keywords = [
            'cam', 'camera', 'channel', 'ch', 'zone', 'area',
            'front', 'back', 'door', 'entrance', 'parking',
            'office', 'lobby', 'security', 'surveillance',
            'nvr', 'dvr', 'cctv', 'ip_cam', 'ipcam'
        ]
        
        folder_lower = folder_name.lower()
        
        # Check for camera keywords
        for keyword in camera_keywords:
            if keyword in folder_lower:
                return True
        
        # Check for camera patterns (e.g., "Camera_01", "CH01", "Zone1")
        import re
        camera_patterns = [
            r'camera[_\s]*\d+',
            r'cam[_\s]*\d+',
            r'ch[_\s]*\d+',
            r'channel[_\s]*\d+',
            r'zone[_\s]*\d+',
            r'area[_\s]*\d+'
        ]
        
        for pattern in camera_patterns:
            if re.search(pattern, folder_lower):
                return True
        
        return False
    
    def _analyze_folder_structure(self, root_folders: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Analyze folder structure to provide insights for UI
        
        Args:
            root_folders (list): List of root folders
            
        Returns:
            dict: Folder structure analysis
        """
        analysis = {
            'total_folders': len(root_folders),
            'camera_folders_at_root': 0,
            'security_related_folders': 0,
            'recommended_folders': [],
            'structure_type': 'unknown'
        }
        
        security_keywords = ['security', 'surveillance', 'camera', 'nvr', 'dvr', 'cctv']
        
        for folder in root_folders:
            folder_name_lower = folder['name'].lower()
            
            # Check if root folder is camera folder
            if self._is_camera_folder(folder['name']):
                analysis['camera_folders_at_root'] += 1
            
            # Check if security-related
            if any(keyword in folder_name_lower for keyword in security_keywords):
                analysis['security_related_folders'] += 1
                analysis['recommended_folders'].append(folder)
        
        # Determine structure type
        if analysis['camera_folders_at_root'] > 0:
            analysis['structure_type'] = 'flat_cameras'
        elif analysis['security_related_folders'] > 0:
            analysis['structure_type'] = 'nested_security'
        else:
            analysis['structure_type'] = 'general'
        
        return analysis
    
    def get_authentication_status(self) -> Dict[str, Any]:
        """
        Get current authentication status
        
        Returns:
            dict: Authentication status information
        """
        return {
            'authenticated': self.authenticated,
            'provider': self.provider,
            'user_info': self.user_info if self.authenticated else {},
            'last_check': datetime.now().isoformat()
        }
    
    def disconnect(self) -> Dict[str, Any]:
        """
        Disconnect from cloud provider
        
        Returns:
            dict: Disconnection result
        """
        try:
            # Provider-specific disconnection logic
            if self.provider == 'google_drive':
                # TODO: Implement Google Drive token revocation
                pass
            
            # Reset local state
            self.authenticated = False
            self.user_info = {}
            self.client = None
            
            # Reinitialize client
            self._initialize_client()
            
            logger.info(f"üîå Disconnected from {self.provider}")
            
            return {
                'success': True,
                'message': f"Disconnected from {self.provider}",
                'provider': self.provider
            }
            
        except Exception as e:
            logger.error(f"‚ùå Disconnection error: {e}")
            return {
                'success': False,
                'message': f"Disconnection failed: {str(e)}",
                'error': str(e)
            }
    
    def get_provider_info(self) -> Dict[str, Any]:
        """
        Get information about the current cloud provider
        
        Returns:
            dict: Provider information
        """
        if self.provider in self.SUPPORTED_PROVIDERS:
            provider_config = self.SUPPORTED_PROVIDERS[self.provider]
            return {
                'provider': self.provider,
                'name': provider_config['name'],
                'auth_type': provider_config['auth_type'],
                'supports_folders': provider_config['supports_folders'],
                'supports_nested': provider_config['supports_nested'],
                'authenticated': self.authenticated,
                'available': True
            }
        else:
            return {
                'provider': self.provider,
                'available': False,
                'error': 'Provider not supported'
            }


def test_cloud_manager():
    """
    Test function for CloudManager functionality
    """
    print("üîß Testing CloudManager...")
    
    try:
        # Initialize CloudManager
        print("\n1. Initializing CloudManager...")
        cloud_manager = CloudManager('google_drive')
        print(f"‚úÖ CloudManager initialized for: {cloud_manager.provider}")
        
        # Get provider info
        print("\n2. Getting provider info...")
        provider_info = cloud_manager.get_provider_info()
        print(f"‚úÖ Provider: {provider_info['name']}")
        print(f"   Supports folders: {provider_info['supports_folders']}")
        print(f"   Supports nested: {provider_info['supports_nested']}")
        
        # Test connection (will attempt authentication)
        print("\n3. Testing connection...")
        test_config = {}  # Empty config for basic test
        connection_result = cloud_manager.test_connection_and_discover_folders(test_config)
        
        if connection_result['accessible']:
            print(f"‚úÖ Connection successful!")
            print(f"   User: {connection_result.get('user_info', {}).get('email', 'Unknown')}")
            print(f"   Folders found: {len(connection_result.get('folders', []))}")
        else:
            print(f"‚ùå Connection failed: {connection_result['message']}")
        
        # Get authentication status
        print("\n4. Checking authentication status...")
        auth_status = cloud_manager.get_authentication_status()
        print(f"‚úÖ Authenticated: {auth_status['authenticated']}")
        
        print("\nüéâ CloudManager test completed!")
        
    except Exception as e:
        print(f"‚ùå CloudManager test failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_cloud_manager()
```
## üìÑ File: `mock_video_generator.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/mock_video_generator.py`

```python
import os
import shutil
from datetime import datetime, timedelta
import json

class MockVideoGenerator:
    """
    T·∫°o mock video files ƒë·ªÉ gi·∫£ l·∫≠p ONVIF camera recordings
    S·ª≠ d·ª•ng cho testing v√† development khi ONVIF Profile G kh√¥ng kh·∫£ d·ª•ng
    """
    
    def __init__(self, base_samples_path=None):
        """
        Initialize MockVideoGenerator
        
        Args:
            base_samples_path (str): Path to sample video files (optional)
        """
        self.samples_path = base_samples_path
        self.mock_file_size = 15 * 1024  # 15KB per mock file
        
        # Common camera recording patterns
        self.recording_schedule = {
            'continuous': list(range(0, 24)),  # Every hour
            'business': [8, 9, 10, 11, 12, 13, 14, 15, 16, 17],  # Business hours
            'security': [6, 12, 18, 22],  # 4 times per day
            'minimal': [9, 15, 21],  # 3 times per day
            'testing': 'every_minute'  # üÜï Special mode for testing
        }
    
    def generate_daily_videos(self, camera_name, target_dir, days=7, schedule='security'):
        """
        T·∫°o mock videos cho m·ªôt camera trong X ng√†y
        
        Args:
            camera_name (str): T√™n camera (VD: "Front Door Camera")
            target_dir (str): Th∆∞ m·ª•c ƒë√≠ch
            days (int): S·ªë ng√†y t·∫°o videos (m·∫∑c ƒë·ªãnh 7)
            schedule (str): Lo·∫°i l·ªãch recording ('continuous', 'business', 'security', 'minimal', 'testing')
            
        Returns:
            list: Danh s√°ch c√°c file ƒë√£ t·∫°o v·ªõi metadata
        """
        print(f"üé¨ Generating mock videos for {camera_name} (schedule: {schedule})...")
        
        # Ensure target directory exists
        os.makedirs(target_dir, exist_ok=True)
        
        videos_created = []
        
        # üÜï TESTING MODE: T·∫°o files v·ªõi interval ng·∫Øn
        if schedule == 'testing':
            return self._generate_testing_videos(camera_name, target_dir, days)
        
        # Original schedule logic for other modes
        hours_schedule = self.recording_schedule.get(schedule, self.recording_schedule['security'])
        
        for i in range(days):
            date = datetime.now() - timedelta(days=i)
            
            for hour in hours_schedule:
                # T·∫°o timestamp cho recording
                timestamp = date.replace(hour=hour, minute=0, second=0, microsecond=0)
                
                # Format filename theo convention th·ª±c t·∫ø
                safe_camera_name = camera_name.replace(' ', '_').replace('/', '_')
                filename = f"{safe_camera_name}_{timestamp.strftime('%Y%m%d_%H%M%S')}.mp4"
                
                target_file = os.path.join(target_dir, filename)
                
                # T·∫°o mock file
                file_info = self._create_mock_video_file(
                    target_file, 
                    camera_name, 
                    timestamp
                )
                
                videos_created.append(file_info)
                
        print(f"‚úÖ Created {len(videos_created)} mock videos for {camera_name}")
    def generate_recent_videos(self, camera_name, target_dir, hours=24):
        """
        T·∫°o videos cho X gi·ªù g·∫ßn ƒë√¢y (ƒë·ªÉ simulate realtime download)
        
        Args:
            camera_name (str): T√™n camera
            target_dir (str): Th∆∞ m·ª•c ƒë√≠ch  
            hours (int): S·ªë gi·ªù g·∫ßn ƒë√¢y (m·∫∑c ƒë·ªãnh 24)
            
        Returns:
            list: Danh s√°ch files ƒë∆∞·ª£c t·∫°o
        """
        print(f"üïê Generating recent {hours}h videos for {camera_name}...")
        
        os.makedirs(target_dir, exist_ok=True)
        videos_created = []
        
        # T·∫°o videos m·ªói 2 gi·ªù trong kho·∫£ng th·ªùi gian ch·ªâ ƒë·ªãnh
        for i in range(0, hours, 2):
            timestamp = datetime.now() - timedelta(hours=i)
            
            safe_camera_name = camera_name.replace(' ', '_').replace('/', '_')
            filename = f"{safe_camera_name}_{timestamp.strftime('%Y%m%d_%H%M%S')}.mp4"
            
            target_file = os.path.join(target_dir, filename)
            
            file_info = self._create_mock_video_file(
                target_file, 
                camera_name, 
                timestamp
            )
            
            videos_created.append(file_info)
        
        print(f"‚úÖ Created {len(videos_created)} recent videos for {camera_name}")
        return videos_created
    
    def _generate_testing_videos(self, camera_name, target_dir, days=1):
        """
        üß™ TESTING MODE: T·∫°o videos v·ªõi interval ng·∫Øn ƒë·ªÉ test nhanh
        
        Args:
            camera_name (str): T√™n camera
            target_dir (str): Th∆∞ m·ª•c ƒë√≠ch
            days (int): S·ªë ng√†y (cho testing th∆∞·ªùng l√† 1)
            
        Returns:
            list: Danh s√°ch files ƒë∆∞·ª£c t·∫°o
        """
        print(f"üß™ TESTING MODE: Creating videos every 1-2 minutes for {camera_name}")
        
        videos_created = []
        base_time = datetime.now()
        
        # T·∫°o videos cho 30 ph√∫t g·∫ßn ƒë√¢y, m·ªói 2 ph√∫t 1 file
        for i in range(15):  # 15 files, m·ªói file c√°ch 2 ph√∫t
            timestamp = base_time - timedelta(minutes=i * 2)
            
            safe_camera_name = camera_name.replace(' ', '_').replace('/', '_')
            filename = f"{safe_camera_name}_{timestamp.strftime('%Y%m%d_%H%M%S')}.mp4"
            
            target_file = os.path.join(target_dir, filename)
            
            file_info = self._create_mock_video_file(
                target_file, 
                camera_name, 
                timestamp
            )
            
            videos_created.append(file_info)
        
        print(f"‚úÖ TESTING: Created {len(videos_created)} videos (2-minute intervals)")
        return videos_created
    
    def generate_realtime_testing_videos(self, camera_name, target_dir, interval_seconds=60, count=5):
        """
        üöÄ REALTIME TESTING: T·∫°o videos v·ªõi kho·∫£ng c√°ch r·∫•t ng·∫Øn cho testing realtime
        
        Args:
            camera_name (str): T√™n camera
            target_dir (str): Th∆∞ m·ª•c ƒë√≠ch
            interval_seconds (int): Kho·∫£ng c√°ch gi·ªØa c√°c file (gi√¢y) - m·∫∑c ƒë·ªãnh 60s
            count (int): S·ªë l∆∞·ª£ng files t·∫°o - m·∫∑c ƒë·ªãnh 5
            
        Returns:
            list: Danh s√°ch files ƒë∆∞·ª£c t·∫°o
        """
        print(f"üöÄ REALTIME TESTING: Creating {count} videos every {interval_seconds}s for {camera_name}")
        
        os.makedirs(target_dir, exist_ok=True)
        videos_created = []
        
        base_time = datetime.now()
        
        for i in range(count):
            # T·∫°o timestamp l√πi l·∫°i theo interval
            timestamp = base_time - timedelta(seconds=i * interval_seconds)
            
            safe_camera_name = camera_name.replace(' ', '_').replace('/', '_')
            filename = f"{safe_camera_name}_{timestamp.strftime('%Y%m%d_%H%M%S')}.mp4"
            
            target_file = os.path.join(target_dir, filename)
            
            file_info = self._create_mock_video_file(
                target_file, 
                camera_name, 
                timestamp
            )
            
            videos_created.append(file_info)
        
        print(f"‚úÖ REALTIME TESTING: Created {len(videos_created)} videos ({interval_seconds}s intervals)")
        return videos_created
        """
        T·∫°o videos cho X gi·ªù g·∫ßn ƒë√¢y (ƒë·ªÉ simulate realtime download)
        
        Args:
            camera_name (str): T√™n camera
            target_dir (str): Th∆∞ m·ª•c ƒë√≠ch  
            hours (int): S·ªë gi·ªù g·∫ßn ƒë√¢y (m·∫∑c ƒë·ªãnh 24)
            
        Returns:
            list: Danh s√°ch files ƒë∆∞·ª£c t·∫°o
        """
        print(f"üïê Generating recent {hours}h videos for {camera_name}...")
        
        os.makedirs(target_dir, exist_ok=True)
        videos_created = []
        
        # T·∫°o videos m·ªói 2 gi·ªù trong kho·∫£ng th·ªùi gian ch·ªâ ƒë·ªãnh
        for i in range(0, hours, 2):
            timestamp = datetime.now() - timedelta(hours=i)
            
            safe_camera_name = camera_name.replace(' ', '_').replace('/', '_')
            filename = f"{safe_camera_name}_{timestamp.strftime('%Y%m%d_%H%M%S')}.mp4"
            
            target_file = os.path.join(target_dir, filename)
            
            file_info = self._create_mock_video_file(
                target_file, 
                camera_name, 
                timestamp
            )
            
            videos_created.append(file_info)
        
        print(f"‚úÖ Created {len(videos_created)} recent videos for {camera_name}")
        return videos_created
    
    def _create_mock_video_file(self, filepath, camera_name, timestamp):
        """
        T·∫°o m·ªôt mock video file v·ªõi metadata th·ª±c t·∫ø
        
        Args:
            filepath (str): ƒê∆∞·ªùng d·∫´n file ƒë·∫ßy ƒë·ªß
            camera_name (str): T√™n camera
            timestamp (datetime): Th·ªùi gian recording
            
        Returns:
            dict: Th√¥ng tin file ƒë√£ t·∫°o
        """
        # T·∫°o mock video content v·ªõi metadata
        video_metadata = {
            "camera": camera_name,
            "timestamp": timestamp.isoformat(),
            "duration_minutes": 60,  # Gi·∫£ l·∫≠p recording 1 gi·ªù
            "resolution": "1920x1080",
            "codec": "H.264",
            "framerate": "30fps",
            "bitrate": "2000kbps",
            "file_type": "MP4",
            "mock_data": True
        }
        
        # T·∫°o file content
        header = f"MOCK VIDEO FILE - {camera_name}\n"
        header += f"Recording Time: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\n"
        header += f"Metadata: {json.dumps(video_metadata, indent=2)}\n"
        header += "=" * 50 + "\n"
        
        # Mock binary data (gi·∫£ l·∫≠p video data)
        mock_binary = b'\x00\x01\x02\x03' * (self.mock_file_size // 4)
        
        # Write file
        with open(filepath, 'wb') as f:
            f.write(header.encode('utf-8'))
            f.write(mock_binary)
        
        # Return file info
        file_info = {
            'filename': os.path.basename(filepath),
            'path': filepath,
            'size': os.path.getsize(filepath),
            'timestamp': timestamp,
            'camera': camera_name,
            'metadata': video_metadata
        }
        
        return file_info
    
    def simulate_continuous_recording(self, camera_name, target_dir, start_time=None, duration_hours=6):
        """
        Gi·∫£ l·∫≠p continuous recording v·ªõi files nh·ªè m·ªói 30 ph√∫t
        
        Args:
            camera_name (str): T√™n camera
            target_dir (str): Th∆∞ m·ª•c ƒë√≠ch
            start_time (datetime): Th·ªùi gian b·∫Øt ƒë·∫ßu (m·∫∑c ƒë·ªãnh l√† 6h tr∆∞·ªõc)
            duration_hours (int): T·ªïng th·ªùi gian recording (gi·ªù)
            
        Returns:
            list: Danh s√°ch files ƒë√£ t·∫°o
        """
        if start_time is None:
            start_time = datetime.now() - timedelta(hours=duration_hours)
        
        print(f"üìπ Simulating continuous recording for {camera_name} ({duration_hours}h)")
        
        os.makedirs(target_dir, exist_ok=True)
        videos_created = []
        
        # T·∫°o file m·ªói 30 ph√∫t
        intervals = duration_hours * 2  # 2 files per hour
        
        for i in range(intervals):
            timestamp = start_time + timedelta(minutes=i * 30)
            
            safe_camera_name = camera_name.replace(' ', '_').replace('/', '_')
            filename = f"{safe_camera_name}_{timestamp.strftime('%Y%m%d_%H%M%S')}.mp4"
            
            target_file = os.path.join(target_dir, filename)
            
            file_info = self._create_mock_video_file(
                target_file, 
                camera_name, 
                timestamp
            )
            
            videos_created.append(file_info)
        
        print(f"‚úÖ Created {len(videos_created)} continuous recording files for {camera_name}")
        return videos_created
    
    def cleanup_old_files(self, target_dir, keep_days=30):
        """
        D·ªçn d·∫πp c√°c mock files c≈© h∆°n X ng√†y
        
        Args:
            target_dir (str): Th∆∞ m·ª•c c·∫ßn d·ªçn d·∫πp
            keep_days (int): S·ªë ng√†y gi·ªØ l·∫°i (m·∫∑c ƒë·ªãnh 30)
            
        Returns:
            int: S·ªë files ƒë√£ x√≥a
        """
        if not os.path.exists(target_dir):
            return 0
        
        cutoff_time = datetime.now() - timedelta(days=keep_days)
        deleted_count = 0
        
        for filename in os.listdir(target_dir):
            filepath = os.path.join(target_dir, filename)
            
            if os.path.isfile(filepath):
                # Get file modification time
                file_time = datetime.fromtimestamp(os.path.getmtime(filepath))
                
                if file_time < cutoff_time:
                    try:
                        os.remove(filepath)
                        deleted_count += 1
                        print(f"üóëÔ∏è Removed old mock file: {filename}")
                    except Exception as e:
                        print(f"‚ùå Failed to remove {filename}: {e}")
        
        if deleted_count > 0:
            print(f"‚úÖ Cleanup completed: {deleted_count} old files removed")
        
        return deleted_count
    
    def get_mock_statistics(self, target_dir):
        """
        L·∫•y th·ªëng k√™ v·ªÅ mock files trong th∆∞ m·ª•c
        
        Args:
            target_dir (str): Th∆∞ m·ª•c c·∫ßn th·ªëng k√™
            
        Returns:
            dict: Th·ªëng k√™ chi ti·∫øt
        """
        if not os.path.exists(target_dir):
            return {
                'total_files': 0,
                'total_size': 0,
                'size_mb': 0,
                'date_range': None
            }
        
        files = [f for f in os.listdir(target_dir) if f.endswith('.mp4')]
        
        if not files:
            return {
                'total_files': 0,
                'total_size': 0,
                'size_mb': 0,
                'date_range': None
            }
        
        total_size = sum(
            os.path.getsize(os.path.join(target_dir, f)) 
            for f in files
        )
        
        # Extract dates from filenames for range
        dates = []
        for filename in files:
            try:
                # Extract date from filename format: CameraName_YYYYMMDD_HHMMSS.mp4
                date_part = filename.split('_')[-2]  # YYYYMMDD
                date_obj = datetime.strptime(date_part, '%Y%m%d')
                dates.append(date_obj)
            except:
                continue
        
        date_range = None
        if dates:
            date_range = {
                'earliest': min(dates).strftime('%Y-%m-%d'),
                'latest': max(dates).strftime('%Y-%m-%d')
            }
        
        return {
            'total_files': len(files),
            'total_size': total_size,
            'size_mb': round(total_size / (1024 * 1024), 2),
            'date_range': date_range,
            'files': files[:10]  # Sample of filenames
        }

# Usage example v√† test functions
def test_mock_generator():
    """Test function ƒë·ªÉ ki·ªÉm tra MockVideoGenerator"""
    generator = MockVideoGenerator()
    
    test_dir = "/tmp/mock_camera_test"
    
    # Test 1: Testing mode (2-minute intervals)
    print("=== Test 1: Testing Mode (2-minute intervals) ===")
    testing_files = generator.generate_daily_videos(
        "Front Door Camera", 
        test_dir, 
        days=1, 
        schedule='testing'
    )
    print(f"Created {len(testing_files)} testing files")
    
    # Test 2: Realtime testing (1-minute intervals)
    print("\n=== Test 2: Realtime Testing Mode (1-minute intervals) ===")
    realtime_files = generator.generate_realtime_testing_videos(
        "Parking Camera",
        test_dir,
        interval_seconds=60,  # 1 ph√∫t
        count=10  # 10 files
    )
    print(f"Created {len(realtime_files)} realtime files")
    
    # Test 3: Ultra-fast testing (30-second intervals)
    print("\n=== Test 3: Ultra-Fast Testing (30-second intervals) ===")
    ultrafast_files = generator.generate_realtime_testing_videos(
        "Test Camera",
        test_dir,
        interval_seconds=30,  # 30 gi√¢y
        count=5  # 5 files
    )
    print(f"Created {len(ultrafast_files)} ultra-fast files")
    
    # Test 4: Statistics
    print("\n=== Test 4: Statistics ===")
    stats = generator.get_mock_statistics(test_dir)
    print(f"Statistics: {stats}")
    
    # Show actual files created
    print("\n=== Files Created ===")
    if os.path.exists(test_dir):
        files = sorted([f for f in os.listdir(test_dir) if f.endswith('.mp4')])
        for i, filename in enumerate(files[:10]):  # Show first 10
            filepath = os.path.join(test_dir, filename)
            size = os.path.getsize(filepath)
            print(f"{i+1:2d}. {filename} ({size} bytes)")
        if len(files) > 10:
            print(f"    ... and {len(files) - 10} more files")
    
    # Cleanup
    import shutil
    if os.path.exists(test_dir):
        shutil.rmtree(test_dir)
        print(f"\n‚úÖ Cleaned up test directory: {test_dir}")

if __name__ == "__main__":
    test_mock_generator()
```
## üìÑ File: `google_picker_service.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/google_picker_service.py`

```python
#!/usr/bin/env python3
"""
Google Picker Service for VTrack Cloud Integration
Handles Google Picker API token generation with security and rate limiting
"""

import os
import json
import time
import hashlib
import logging
from datetime import datetime
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials

# Configure logging
logger = logging.getLogger(__name__)

class PickerRateLimiter:
    """Rate limiting for Picker token requests"""
    
    def __init__(self, max_requests=10, window_minutes=1):
        self.max_requests = max_requests
        self.window_seconds = window_minutes * 60
        self.requests = {}  # {client_ip: [request_times]}
    
    def is_allowed(self, client_ip):
        """Check if request is allowed under rate limit"""
        current_time = time.time()
        
        # Clean old entries
        if client_ip in self.requests:
            self.requests[client_ip] = [
                req_time for req_time in self.requests[client_ip]
                if current_time - req_time < self.window_seconds
            ]
        else:
            self.requests[client_ip] = []
        
        # Check limit
        if len(self.requests[client_ip]) >= self.max_requests:
            return False
        
        # Add current request
        self.requests[client_ip].append(current_time)
        return True
    
    def get_remaining_requests(self, client_ip):
        """Get number of remaining requests for client"""
        current_time = time.time()
        
        if client_ip not in self.requests:
            return self.max_requests
        
        # Clean old entries
        recent_requests = [
            req_time for req_time in self.requests[client_ip]
            if current_time - req_time < self.window_seconds
        ]
        
        return max(0, self.max_requests - len(recent_requests))

class PickerTokenValidator:
    """Validates tokens and scopes for Picker API"""
    
    REQUIRED_PICKER_SCOPES = [
        'https://www.googleapis.com/auth/drive.readonly',
        'https://www.googleapis.com/auth/drive.metadata.readonly'
    ]
    
    @classmethod
    def validate_scopes(cls, token_scopes):
        """Validate that token has required scopes for Picker"""
        if not token_scopes:
            return False, "No scopes found in token"
        
        missing_scopes = [
            scope for scope in cls.REQUIRED_PICKER_SCOPES 
            if scope not in token_scopes
        ]
        
        if missing_scopes:
            return False, f"Missing required scopes: {', '.join(missing_scopes)}"
        
        return True, "All required scopes present"
    
    @classmethod
    def calculate_expires_in(cls, credentials, default_seconds=3600):
        """Calculate token expiry time in seconds"""
        if not credentials.expiry:
            return default_seconds
        
        time_until_expiry = (credentials.expiry - datetime.now()).total_seconds()
        return min(default_seconds, max(300, int(time_until_expiry)))  # Min 5 minutes

class PickerTokenService:
    """Main service for Google Picker token operations"""
    
    def __init__(self, tokens_directory=None):
        self.tokens_dir = tokens_directory or os.path.join(
            os.path.dirname(__file__), 'tokens'
        )
        self.rate_limiter = PickerRateLimiter(max_requests=10, window_minutes=1)
        self.validator = PickerTokenValidator()
    
    def generate_picker_token(self, client_ip, user_email=None):
        """
        Generate access token for Google Picker API
        
        Args:
            client_ip (str): Client IP address for rate limiting
            user_email (str, optional): Specific user email
            
        Returns:
            dict: Token response or error
        """
        try:
            # Rate limiting check
            if not self.rate_limiter.is_allowed(client_ip):
                remaining = self.rate_limiter.get_remaining_requests(client_ip)
                logger.warning(f"‚ö†Ô∏è Rate limit exceeded for IP: {client_ip}")
                return {
                    'success': False,
                    'error_type': 'rate_limit_exceeded',
                    'message': 'Rate limit exceeded. Please wait before requesting another token.',
                    'remaining_requests': remaining,
                    'retry_after_seconds': 60
                }, 429
            
            # Find and load credentials
            credential_data, user_info = self._load_credentials(user_email)
            if not credential_data:
                return {
                    'success': False,
                    'error_type': 'no_credentials',
                    'message': 'No stored credentials found. Please authenticate first.'
                }, 401
            
            # Create credentials object
            credentials = self._create_credentials_object(credential_data)
            
            # Handle token refresh if needed
            refresh_result = self._refresh_token_if_needed(credentials, credential_data)
            if not refresh_result['success']:
                return refresh_result, 401
            
            # Validate scopes for Picker
            scope_valid, scope_message = self.validator.validate_scopes(credentials.scopes)
            if not scope_valid:
                logger.error(f"‚ùå Scope validation failed: {scope_message}")
                return {
                    'success': False,
                    'error_type': 'insufficient_scopes',
                    'message': scope_message
                }, 403
            
            # Generate token response
            expires_in = self.validator.calculate_expires_in(credentials)
            issued_at = datetime.now().isoformat()
            
            logger.info(f"‚úÖ Picker token generated for: {user_info.get('email')}")
            logger.info(f"   Token expires in: {expires_in} seconds")
            
            return {
                'success': True,
                'picker_token': credentials.token,
                'expires_in': expires_in,
                'user_email': user_info.get('email'),
                'user_info': user_info,
                'issued_at': issued_at,
                'scopes': list(credentials.scopes) if credentials.scopes else [],
                'message': 'Picker token generated successfully'
            }, 200
            
        except FileNotFoundError as e:
            logger.error(f"‚ùå Credentials file not found: {e}")
            return {
                'success': False,
                'error_type': 'credentials_not_found',
                'message': 'Credentials file not found. Please authenticate first.'
            }, 404
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Invalid credentials file format: {e}")
            return {
                'success': False,
                'error_type': 'invalid_credentials_format',
                'message': 'Invalid credentials file. Please re-authenticate.'
            }, 500
            
        except Exception as e:
            logger.error(f"‚ùå Picker token generation error: {e}")
            return {
                'success': False,
                'error_type': 'server_error',
                'message': f'Failed to generate picker token: {str(e)}'
            }, 500
    
    def _load_credentials(self, user_email=None):
        """Load credentials from storage"""
        if not os.path.exists(self.tokens_dir):
            logger.error("‚ùå No tokens directory found")
            return None, None
        
        # Get credential files
        token_files = [
            f for f in os.listdir(self.tokens_dir) 
            if f.startswith('google_drive_') and f.endswith('.json')
        ]
        
        if not token_files:
            logger.error("‚ùå No stored credentials found")
            return None, None
        
        # Select appropriate credential file
        token_filepath = self._select_credential_file(token_files, user_email)
        if not token_filepath:
            return None, None
        
        # Load credential data
        with open(token_filepath, 'r') as f:
            credential_data = json.load(f)
        
        user_info = credential_data.get('user_info', {})
        return credential_data, user_info
    
    def _select_credential_file(self, token_files, user_email=None):
        """Select appropriate credential file"""
        if user_email:
            # Find credentials for specific user
            email_hash = hashlib.sha256(user_email.encode()).hexdigest()[:16]
            target_filename = f"google_drive_{email_hash}.json"
            target_filepath = os.path.join(self.tokens_dir, target_filename)
            
            if os.path.exists(target_filepath):
                return target_filepath
            else:
                logger.error(f"‚ùå No credentials found for user: {user_email}")
                return None
        else:
            # Use first available credentials
            return os.path.join(self.tokens_dir, token_files[0])
    
    def _create_credentials_object(self, credential_data):
        """Create Google credentials object from stored data"""
        return Credentials(
            token=credential_data['token'],
            refresh_token=credential_data['refresh_token'],
            token_uri=credential_data['token_uri'],
            client_id=credential_data['client_id'],
            client_secret=credential_data['client_secret'],
            scopes=credential_data['scopes']
        )
    
    def _refresh_token_if_needed(self, credentials, credential_data):
        """Refresh token if expired"""
        if not credentials.expired:
            return {'success': True}
        
        if not credentials.refresh_token:
            logger.error("‚ùå Token expired and no refresh token available")
            return {
                'success': False,
                'error_type': 'refresh_required',
                'message': 'Token expired and cannot be refreshed. Please re-authenticate.'
            }
        
        try:
            logger.info("üîÑ Refreshing expired token...")
            credentials.refresh(Request())
            
            # Update stored credentials with new token
            self._update_stored_credentials(credential_data, credentials)
            
            logger.info("‚úÖ Token refreshed and stored successfully")
            return {'success': True}
            
        except Exception as refresh_error:
            logger.error(f"‚ùå Token refresh failed: {refresh_error}")
            return {
                'success': False,
                'error_type': 'refresh_failed',
                'message': 'Failed to refresh expired token. Please re-authenticate.'
            }
    
    def _update_stored_credentials(self, credential_data, credentials):
        """Update stored credentials with refreshed token"""
        # Find the original file path
        user_info = credential_data.get('user_info', {})
        user_email = user_info.get('email', 'unknown')
        
        email_hash = hashlib.sha256(user_email.encode()).hexdigest()[:16]
        token_filename = f"google_drive_{email_hash}.json"
        token_filepath = os.path.join(self.tokens_dir, token_filename)
        
        # Update credential data
        credential_data['token'] = credentials.token
        credential_data['expires_at'] = credentials.expiry.isoformat() if credentials.expiry else None
        
        # Write back to file
        with open(token_filepath, 'w') as f:
            json.dump(credential_data, f, indent=2)
    
    def get_rate_limit_status(self, client_ip):
        """Get current rate limit status for client"""
        remaining = self.rate_limiter.get_remaining_requests(client_ip)
        return {
            'remaining_requests': remaining,
            'max_requests': self.rate_limiter.max_requests,
            'window_seconds': self.rate_limiter.window_seconds,
            'is_allowed': remaining > 0
        }

# Global service instance
_picker_service = None

def get_picker_service():
    """Get global PickerTokenService instance"""
    global _picker_service
    if _picker_service is None:
        _picker_service = PickerTokenService()
    return _picker_service

def generate_picker_token_for_request(request):
    """
    Convenience function to generate picker token from Flask request
    
    Args:
        request: Flask request object
        
    Returns:
        tuple: (response_dict, status_code)
    """
    service = get_picker_service()
    client_ip = request.remote_addr
    
    # Get user email from request data
    data = request.get_json() or {}
    user_email = data.get('user_email')
    
    return service.generate_picker_token(client_ip, user_email)
```
## üìÑ File: `google_drive_client.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/google_drive_client.py`

```python
# Copy the code from the artifact above
#!/usr/bin/env python3
"""
Google Drive Client for VTrack Cloud Integration
Handles authentication, upload, download, and folder management
"""

import os
import json
import logging
from datetime import datetime
from pathlib import Path

from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GoogleDriveClient:
    """Google Drive API client for VTrack video backup"""
    
    # Google Drive API scopes
    SCOPES = ['https://www.googleapis.com/auth/drive.file']
    
    def __init__(self, credentials_path='google_drive_credentials_web.json', token_path='token.json'):
        """
        Initialize Google Drive client
        
        Args:
            credentials_path (str): Path to OAuth2 credentials file
            token_path (str): Path to store access tokens
        """
        self.credentials_path = os.path.join(os.path.dirname(__file__), credentials_path)
        self.token_path = os.path.join(os.path.dirname(__file__), token_path)
        self.service = None
        self.creds = None
        
        logger.info(f"GoogleDriveClient initialized")
        logger.info(f"Credentials path: {self.credentials_path}")
        logger.info(f"Token path: {self.token_path}")
    
    def authenticate(self):
        """
        Authenticate with Google Drive API using OAuth2
        
        Returns:
            bool: True if authentication successful, False otherwise
        """
        try:
            # Load existing token if available
            if os.path.exists(self.token_path):
                self.creds = Credentials.from_authorized_user_file(self.token_path, self.SCOPES)
            
            # If no valid credentials, start OAuth flow
            if not self.creds or not self.creds.valid:
                if self.creds and self.creds.expired and self.creds.refresh_token:
                    logger.info("Refreshing expired credentials...")
                    self.creds.refresh(Request())
                else:
                    logger.info("Starting OAuth2 authentication flow...")
                    flow = InstalledAppFlow.from_client_secrets_file(
                        self.credentials_path, self.SCOPES)
                    self.creds = flow.run_local_server(port=0)
                
                # Save credentials for next time
                with open(self.token_path, 'w') as token:
                    token.write(self.creds.to_json())
                logger.info("Credentials saved successfully")
            
            # Build Drive service
            self.service = build('drive', 'v3', credentials=self.creds)
            logger.info("‚úÖ Google Drive authentication successful")
            return True
            
        except FileNotFoundError:
            logger.error(f"‚ùå Credentials file not found: {self.credentials_path}")
            return False
        except Exception as e:
            logger.error(f"‚ùå Authentication failed: {e}")
            return False
    
    def test_connection(self):
        """
        Test Google Drive API connection
        
        Returns:
            dict: Connection test result
        """
        try:
            if not self.service:
                if not self.authenticate():
                    return {"success": False, "message": "Authentication failed"}
            
            # Test API call - get user info
            about = self.service.about().get(fields='user, storageQuota').execute()
            user_email = about.get('user', {}).get('emailAddress', 'Unknown')
            
            # Storage info
            quota = about.get('storageQuota', {})
            total_gb = int(quota.get('limit', 0)) / (1024**3) if quota.get('limit') else 'Unlimited'
            used_gb = int(quota.get('usage', 0)) / (1024**3)
            
            logger.info(f"‚úÖ Connected to Google Drive: {user_email}")
            
            return {
                "success": True,
                "message": f"Connected to Google Drive: {user_email}",
                "user_email": user_email,
                "storage_total_gb": total_gb,
                "storage_used_gb": round(used_gb, 2)
            }
            
        except HttpError as e:
            logger.error(f"‚ùå Google Drive API error: {e}")
            return {"success": False, "message": f"API error: {e}"}
        except Exception as e:
            logger.error(f"‚ùå Connection test failed: {e}")
            return {"success": False, "message": f"Connection failed: {str(e)}"}
    
    def create_folder(self, folder_name, parent_folder_id='root'):
        """
        Create folder in Google Drive
        
        Args:
            folder_name (str): Name of folder to create
            parent_folder_id (str): Parent folder ID ('root' for root directory)
            
        Returns:
            str: Created folder ID, None if failed
        """
        try:
            folder_metadata = {
                'name': folder_name,
                'mimeType': 'application/vnd.google-apps.folder',
                'parents': [parent_folder_id]
            }
            
            folder = self.service.files().create(body=folder_metadata, fields='id').execute()
            folder_id = folder.get('id')
            
            logger.info(f"‚úÖ Folder created: {folder_name} (ID: {folder_id})")
            return folder_id
            
        except HttpError as e:
            logger.error(f"‚ùå Failed to create folder {folder_name}: {e}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Folder creation error: {e}")
            return None
    
    def find_folder(self, folder_name, parent_folder_id='root'):
        """
        Find folder by name in Google Drive
        
        Args:
            folder_name (str): Name of folder to find
            parent_folder_id (str): Parent folder ID to search in
            
        Returns:
            str: Folder ID if found, None otherwise
        """
        try:
            query = f"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and '{parent_folder_id}' in parents"
            results = self.service.files().list(q=query, fields='files(id, name)').execute()
            folders = results.get('files', [])
            
            if folders:
                folder_id = folders[0]['id']
                logger.info(f"‚úÖ Found folder: {folder_name} (ID: {folder_id})")
                return folder_id
            else:
                logger.info(f"üìÅ Folder not found: {folder_name}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Folder search error: {e}")
            return None
    
    def get_or_create_folder(self, folder_name, parent_folder_id='root'):
        """
        Get existing folder or create new one
        
        Args:
            folder_name (str): Name of folder
            parent_folder_id (str): Parent folder ID
            
        Returns:
            str: Folder ID
        """
        folder_id = self.find_folder(folder_name, parent_folder_id)
        if not folder_id:
            folder_id = self.create_folder(folder_name, parent_folder_id)
        return folder_id
    
    def upload_file(self, file_path, folder_id='root', custom_name=None):
        """
        Upload file to Google Drive
        
        Args:
            file_path (str): Local file path to upload
            folder_id (str): Google Drive folder ID to upload to
            custom_name (str): Custom name for uploaded file
            
        Returns:
            dict: Upload result with file ID and metadata
        """
        try:
            if not os.path.exists(file_path):
                return {"success": False, "message": f"File not found: {file_path}"}
            
            file_name = custom_name or os.path.basename(file_path)
            file_size = os.path.getsize(file_path)
            
            logger.info(f"üì§ Uploading {file_name} ({file_size} bytes) to Google Drive...")
            
            # File metadata
            file_metadata = {
                'name': file_name,
                'parents': [folder_id]
            }
            
            # Create media upload
            media = MediaFileUpload(file_path, resumable=True)
            
            # Upload file
            file = self.service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id, name, size, createdTime'
            ).execute()
            
            file_id = file.get('id')
            upload_size = file.get('size')
            created_time = file.get('createdTime')
            
            logger.info(f"‚úÖ Upload successful: {file_name}")
            logger.info(f"   File ID: {file_id}")
            logger.info(f"   Size: {upload_size} bytes")
            
            return {
                "success": True,
                "message": f"File uploaded successfully: {file_name}",
                "file_id": file_id,
                "file_name": file_name,
                "file_size": upload_size,
                "created_time": created_time,
                "drive_url": f"https://drive.google.com/file/d/{file_id}/view"
            }
            
        except HttpError as e:
            logger.error(f"‚ùå Upload failed: {e}")
            return {"success": False, "message": f"Upload failed: {e}"}
        except Exception as e:
            logger.error(f"‚ùå Upload error: {e}")
            return {"success": False, "message": f"Upload error: {str(e)}"}
    
    def upload_video(self, video_path, camera_name=None):
        """
        Upload video file with organized folder structure
        
        Args:
            video_path (str): Path to video file
            camera_name (str): Camera name for folder organization
            
        Returns:
            dict: Upload result
        """
        try:
            # Create VTrack main folder
            vtrack_folder_id = self.get_or_create_folder("VTrack_Videos")
            
            # Create camera folder if specified
            if camera_name:
                camera_folder_id = self.get_or_create_folder(camera_name, vtrack_folder_id)
                upload_folder_id = camera_folder_id
            else:
                upload_folder_id = vtrack_folder_id
            
            # Generate custom filename with timestamp
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            original_name = Path(video_path).stem
            extension = Path(video_path).suffix
            custom_name = f"{original_name}_{timestamp}{extension}"
            
            # Upload file
            result = self.upload_file(video_path, upload_folder_id, custom_name)
            
            if result["success"]:
                result["folder_structure"] = f"VTrack_Videos/{camera_name or 'General'}"
                
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Video upload error: {e}")
            return {"success": False, "message": f"Video upload failed: {str(e)}"}
    
    def list_files(self, folder_id='root', limit=10):
        """
        List files in Google Drive folder
        
        Args:
            folder_id (str): Folder ID to list files from
            limit (int): Maximum number of files to return
            
        Returns:
            list: List of file metadata
        """
        try:
            query = f"'{folder_id}' in parents"
            results = self.service.files().list(
                q=query,
                pageSize=limit,
                fields='files(id, name, size, createdTime, mimeType)'
            ).execute()
            
            files = results.get('files', [])
            logger.info(f"üìã Found {len(files)} files in folder")
            
            return files
            
        except Exception as e:
            logger.error(f"‚ùå File listing error: {e}")
            return []
    
    def download_file(self, file_id, download_path):
        """
        Download file from Google Drive
        
        Args:
            file_id (str): Google Drive file ID
            download_path (str): Local path to save file
            
        Returns:
            dict: Download result
        """
        try:
            # Get file metadata
            file_metadata = self.service.files().get(fileId=file_id).execute()
            file_name = file_metadata.get('name')
            
            logger.info(f"üì• Downloading {file_name} from Google Drive...")
            
            # Download file content
            request = self.service.files().get_media(fileId=file_id)
            
            with open(download_path, 'wb') as file:
                downloader = MediaIoBaseDownload(file, request)
                done = False
                while done is False:
                    status, done = downloader.next_chunk()
                    if status:
                        logger.info(f"Download progress: {int(status.progress() * 100)}%")
            
            logger.info(f"‚úÖ Download completed: {download_path}")
            
            return {
                "success": True,
                "message": f"File downloaded successfully: {file_name}",
                "file_name": file_name,
                "local_path": download_path
            }
            
        except Exception as e:
            logger.error(f"‚ùå Download error: {e}")
            return {"success": False, "message": f"Download failed: {str(e)}"}
    
    def delete_file(self, file_id):
        """
        Delete file from Google Drive
        
        Args:
            file_id (str): Google Drive file ID
            
        Returns:
            dict: Deletion result
        """
        try:
            self.service.files().delete(fileId=file_id).execute()
            logger.info(f"‚úÖ File deleted: {file_id}")
            
            return {
                "success": True,
                "message": f"File deleted successfully: {file_id}"
            }
            
        except Exception as e:
            logger.error(f"‚ùå Delete error: {e}")
            return {"success": False, "message": f"Delete failed: {str(e)}"}


def test_google_drive_client():
    """
    Test function for Google Drive client
    """
    print("üîß Testing Google Drive Client...")
    
    # Initialize client
    client = GoogleDriveClient()
    
    # Test authentication
    print("\n1. Testing authentication...")
    auth_result = client.authenticate()
    print(f"Authentication: {'‚úÖ Success' if auth_result else '‚ùå Failed'}")
    
    if not auth_result:
        return
    
    # Test connection
    print("\n2. Testing connection...")
    conn_result = client.test_connection()
    print(f"Connection: {'‚úÖ Success' if conn_result['success'] else '‚ùå Failed'}")
    print(f"Message: {conn_result['message']}")
    
    if conn_result['success']:
        print(f"User: {conn_result.get('user_email', 'Unknown')}")
        print(f"Storage: {conn_result.get('storage_used_gb', 0):.2f}GB used")
    
    # Test folder creation
    print("\n3. Testing folder creation...")
    vtrack_folder_id = client.get_or_create_folder("VTrack_Test")
    if vtrack_folder_id:
        print(f"‚úÖ VTrack_Test folder ready: {vtrack_folder_id}")
    
    # Test file listing
    print("\n4. Testing file listing...")
    files = client.list_files(limit=5)
    print(f"‚úÖ Found {len(files)} files in root directory")
    
    print("\nüéâ Google Drive Client test completed!")


if __name__ == "__main__":
    test_google_drive_client()
```
## üìÑ File: `cloud_auth.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/cloud_auth.py`

```python
#!/usr/bin/env python3
"""
Cloud Authentication Handler for VTrack
Manages OAuth2 flows, token storage, and session management
Supports Google Drive OAuth2 with extensible design for other providers
"""

import os
import json
import uuid
import logging
import hashlib
import secrets
from datetime import datetime, timedelta
from typing import Dict, Optional, Any, Tuple
from pathlib import Path
import threading
import time

# OAuth2 and Google API imports
try:
    from google.auth.transport.requests import Request
    from google.oauth2.credentials import Credentials
    from google_auth_oauthlib.flow import Flow
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
except ImportError:
    logging.warning("Google API libraries not installed. Run: pip install google-auth google-auth-oauthlib google-api-python-client")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CloudAuthManager:
    """
    Manages OAuth2 authentication flows for cloud providers
    Handles token storage, refresh, and session management
    """
    
    # OAuth2 scopes for different providers
    PROVIDER_SCOPES = {
        'google_drive': [
            'https://www.googleapis.com/auth/drive.readonly',
            'https://www.googleapis.com/auth/drive.metadata.readonly'
        ]
    }
    
    # OAuth2 endpoints
    OAUTH_ENDPOINTS = {
        'google_drive': {
            'auth_uri': 'https://accounts.google.com/o/oauth2/auth',
            'token_uri': 'https://oauth2.googleapis.com/token',
            'client_secrets_file': 'google_drive_credentials_web.json'
        }
    }
    
    def __init__(self, provider: str = 'google_drive', base_dir: Optional[str] = None):
        """
        Initialize CloudAuthManager
        
        Args:
            provider (str): Cloud provider ('google_drive', etc.)
            base_dir (str): Base directory for credential storage
        """
        self.provider = provider
        self.base_dir = base_dir or os.path.dirname(__file__)
        
        # Authentication state
        self.auth_sessions = {}  # Active auth sessions
        self.credentials_cache = {}  # Cached credentials
        
        # Thread safety
        self.auth_lock = threading.Lock()
        
        # Credential file paths
        self.credentials_dir = os.path.join(self.base_dir, 'credentials')
        self.tokens_dir = os.path.join(self.base_dir, 'tokens')
        
        # Ensure directories exist
        os.makedirs(self.credentials_dir, exist_ok=True)
        os.makedirs(self.tokens_dir, exist_ok=True)
        
        logger.info(f"CloudAuthManager initialized for {provider}")
    
    def initiate_oauth_flow(self, redirect_uri: str = 'http://localhost:8080/oauth/callback') -> Dict[str, Any]:
        """
        Initiate OAuth2 authentication flow
        
        Args:
            redirect_uri (str): OAuth2 redirect URI
            
        Returns:
            dict: OAuth flow information including auth URL
        """
        try:
            logger.info(f"üîê Initiating OAuth2 flow for {self.provider}")
            
            if self.provider == 'google_drive':
                return self._initiate_google_oauth(redirect_uri)
            else:
                return {
                    'success': False,
                    'message': f"OAuth2 not implemented for {self.provider}"
                }
                
        except Exception as e:
            logger.error(f"‚ùå OAuth2 initiation failed: {e}")
            return {
                'success': False,
                'message': f"OAuth2 initiation failed: {str(e)}",
                'error': str(e)
            }
    
    def _initiate_google_oauth(self, redirect_uri: str) -> Dict[str, Any]:
        """Initiate Google Drive OAuth2 flow"""
        try:
            # Get client secrets file path
            client_secrets_file = os.path.join(
                self.credentials_dir, 
                self.OAUTH_ENDPOINTS['google_drive']['client_secrets_file']
            )
            
            if not os.path.exists(client_secrets_file):
                return {
                    'success': False,
                    'message': f"Google Drive credentials file not found: {client_secrets_file}",
                    'setup_required': True
                }
            
            # Create OAuth2 flow
            flow = Flow.from_client_secrets_file(
                client_secrets_file,
                scopes=self.PROVIDER_SCOPES['google_drive'],
                redirect_uri=redirect_uri
            )
            
            # Generate state parameter for security
            state = secrets.token_urlsafe(32)
            
            # Generate authorization URL
            auth_url, _ = flow.authorization_url(
                access_type='offline',
                include_granted_scopes='true',
                state=state,
                prompt='consent'  # Force consent to get refresh token
            )
            
            # Store flow in session for later completion
            session_id = str(uuid.uuid4())
            
            with self.auth_lock:
                self.auth_sessions[session_id] = {
                    'flow': flow,
                    'state': state,
                    'provider': self.provider,
                    'created_at': datetime.now().isoformat(),
                    'redirect_uri': redirect_uri,
                    'status': 'pending'
                }
            
            logger.info(f"‚úÖ Google OAuth2 flow created with session: {session_id}")
            
            return {
                'success': True,
                'auth_url': auth_url,
                'session_id': session_id,
                'state': state,
                'provider': self.provider,
                'message': 'OAuth2 flow initiated successfully'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Google OAuth2 initiation error: {e}")
            return {
                'success': False,
                'message': f"Google OAuth2 initiation failed: {str(e)}",
                'error': str(e)
            }
    
    def complete_oauth_flow(self, session_id: str, authorization_code: str, state: str) -> Dict[str, Any]:
        """
        Complete OAuth2 flow with authorization code
        
        Args:
            session_id (str): OAuth session ID
            authorization_code (str): OAuth authorization code
            state (str): OAuth state parameter
            
        Returns:
            dict: OAuth completion result with credentials
        """
        try:
            logger.info(f"üîê Completing OAuth2 flow for session: {session_id}")
            
            # Retrieve session
            with self.auth_lock:
                if session_id not in self.auth_sessions:
                    return {
                        'success': False,
                        'message': 'OAuth session not found or expired'
                    }
                
                session = self.auth_sessions[session_id]
                
                # Validate state parameter
                if session['state'] != state:
                    return {
                        'success': False,
                        'message': 'OAuth state mismatch - potential security issue'
                    }
                
                # Complete flow
                flow = session['flow']
            
            # Exchange authorization code for tokens
            flow.fetch_token(code=authorization_code)
            credentials = flow.credentials
            
            # Validate credentials
            if not credentials.valid:
                return {
                    'success': False,
                    'message': 'Invalid credentials received from OAuth flow'
                }
            
            # Get user information
            user_info = self._get_user_info(credentials)
            
            # Store credentials securely
            credential_storage_result = self._store_credentials(credentials, user_info)
            
            if not credential_storage_result['success']:
                return credential_storage_result
            
            # Update session status
            with self.auth_lock:
                if session_id in self.auth_sessions:
                    self.auth_sessions[session_id]['status'] = 'completed'
                    self.auth_sessions[session_id]['completed_at'] = datetime.now().isoformat()
            
            logger.info(f"‚úÖ OAuth2 flow completed for: {user_info.get('email', 'Unknown')}")
            
            return {
                'success': True,
                'message': 'OAuth2 authentication completed successfully',
                'user_info': user_info,
                'credentials': {
                    'token': credentials.token,
                    'refresh_token': credentials.refresh_token,
                    'token_uri': credentials.token_uri,
                    'client_id': credentials.client_id,
                    'client_secret': credentials.client_secret,
                    'scopes': credentials.scopes
                },
                'provider': self.provider,
                'authenticated_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå OAuth2 completion error: {e}")
            return {
                'success': False,
                'message': f"OAuth2 completion failed: {str(e)}",
                'error': str(e)
            }
    
    def _get_user_info(self, credentials: Credentials) -> Dict[str, Any]:
        """
        Get user information from OAuth2 credentials
        
        Args:
            credentials: OAuth2 credentials
            
        Returns:
            dict: User information
        """
        try:
            if self.provider == 'google_drive':
                return self._get_google_user_info(credentials)
            else:
                return {'email': 'unknown', 'name': 'Unknown User'}
                
        except Exception as e:
            logger.error(f"‚ùå Error getting user info: {e}")
            return {'email': 'unknown', 'name': 'Unknown User', 'error': str(e)}
    
    def _get_google_user_info(self, credentials: Credentials) -> Dict[str, Any]:
        """Get Google user information"""
        try:
            # Build Drive service to get user info
            service = build('drive', 'v3', credentials=credentials)
            about = service.about().get(fields='user,storageQuota').execute()
            
            user = about.get('user', {})
            quota = about.get('storageQuota', {})
            
            return {
                'email': user.get('emailAddress', 'unknown'),
                'name': user.get('displayName', 'Unknown User'),
                'photo_url': user.get('photoLink'),
                'storage_used_gb': int(quota.get('usage', 0)) / (1024**3) if quota.get('usage') else 0,
                'storage_total_gb': int(quota.get('limit', 0)) / (1024**3) if quota.get('limit') else 'Unlimited'
            }
            
        except Exception as e:
            logger.error(f"‚ùå Google user info error: {e}")
            return {'email': 'unknown', 'name': 'Unknown User', 'error': str(e)}
    
    def _store_credentials(self, credentials: Credentials, user_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        Securely store OAuth2 credentials
        
        Args:
            credentials: OAuth2 credentials
            user_info: User information
            
        Returns:
            dict: Storage result
        """
        try:
            # Create credential data
            credential_data = {
                'token': credentials.token,
                'refresh_token': credentials.refresh_token,
                'token_uri': credentials.token_uri,
                'client_id': credentials.client_id,
                'client_secret': credentials.client_secret,
                'scopes': list(credentials.scopes) if credentials.scopes else [],
                'provider': self.provider,
                'user_info': user_info,
                'created_at': datetime.now().isoformat(),
                'expires_at': credentials.expiry.isoformat() if credentials.expiry else None
            }
            
            # Generate secure filename based on user email
            user_email = user_info.get('email', 'unknown')
            email_hash = hashlib.sha256(user_email.encode()).hexdigest()[:16]
            token_filename = f"{self.provider}_{email_hash}.json"
            token_filepath = os.path.join(self.tokens_dir, token_filename)
            
            # Store credentials
            with open(token_filepath, 'w') as f:
                json.dump(credential_data, f, indent=2)
            
            # Set restrictive permissions
            os.chmod(token_filepath, 0o600)
            
            # Cache credentials
            with self.auth_lock:
                self.credentials_cache[user_email] = {
                    'credentials': credentials,
                    'user_info': user_info,
                    'filepath': token_filepath,
                    'cached_at': datetime.now()
                }
            
            logger.info(f"‚úÖ Credentials stored for: {user_email}")
            
            return {
                'success': True,
                'message': 'Credentials stored successfully',
                'filepath': token_filepath
            }
            
        except Exception as e:
            logger.error(f"‚ùå Credential storage error: {e}")
            return {
                'success': False,
                'message': f"Credential storage failed: {str(e)}",
                'error': str(e)
            }
    
    def load_stored_credentials(self, user_email: Optional[str] = None) -> Optional[Credentials]:
        """
        Load stored credentials for user
        
        Args:
            user_email (str): User email (if None, loads first available)
            
        Returns:
            Credentials: OAuth2 credentials if found
        """
        try:
            # Check cache first
            if user_email and user_email in self.credentials_cache:
                cached = self.credentials_cache[user_email]
                if (datetime.now() - cached['cached_at']).seconds < 3600:  # 1 hour cache
                    logger.info(f"‚úÖ Using cached credentials for: {user_email}")
                    return cached['credentials']
            
            # Load from file
            token_files = []
            for filename in os.listdir(self.tokens_dir):
                if filename.startswith(f"{self.provider}_") and filename.endswith('.json'):
                    token_files.append(filename)
            
            if not token_files:
                logger.info("üì≠ No stored credentials found")
                return None
            
            # If specific user requested, find their file
            if user_email:
                email_hash = hashlib.sha256(user_email.encode()).hexdigest()[:16]
                target_filename = f"{self.provider}_{email_hash}.json"
                if target_filename in token_files:
                    token_files = [target_filename]
                else:
                    logger.warning(f"‚ö†Ô∏è No credentials found for: {user_email}")
                    return None
            
            # Load the first (or specified) credential file
            token_filepath = os.path.join(self.tokens_dir, token_files[0])
            
            with open(token_filepath, 'r') as f:
                credential_data = json.load(f)
            
            # Reconstruct credentials
            credentials = Credentials(
                token=credential_data['token'],
                refresh_token=credential_data['refresh_token'],
                token_uri=credential_data['token_uri'],
                client_id=credential_data['client_id'],
                client_secret=credential_data['client_secret'],
                scopes=credential_data['scopes']
            )
            
            # Refresh if expired
            if credentials.expired and credentials.refresh_token:
                logger.info("üîÑ Refreshing expired credentials...")
                credentials.refresh(Request())
                
                # Update stored credentials
                credential_data['token'] = credentials.token
                credential_data['expires_at'] = credentials.expiry.isoformat() if credentials.expiry else None
                
                with open(token_filepath, 'w') as f:
                    json.dump(credential_data, f, indent=2)
            
            # Cache credentials
            stored_user_email = credential_data['user_info']['email']
            with self.auth_lock:
                self.credentials_cache[stored_user_email] = {
                    'credentials': credentials,
                    'user_info': credential_data['user_info'],
                    'filepath': token_filepath,
                    'cached_at': datetime.now()
                }
            
            logger.info(f"‚úÖ Loaded credentials for: {stored_user_email}")
            return credentials
            
        except Exception as e:
            logger.error(f"‚ùå Error loading credentials: {e}")
            return None
    
    def get_authentication_status(self, user_email: Optional[str] = None) -> Dict[str, Any]:
        """
        Get current authentication status
        
        Args:
            user_email (str): Optional user email to check
            
        Returns:
            dict: Authentication status
        """
        try:
            credentials = self.load_stored_credentials(user_email)
            
            if credentials and credentials.valid:
                # Get user info from cache or credentials
                user_info = {}
                if user_email and user_email in self.credentials_cache:
                    user_info = self.credentials_cache[user_email]['user_info']
                
                return {
                    'authenticated': True,
                    'provider': self.provider,
                    'user_email': user_info.get('email', 'unknown'),
                    'user_name': user_info.get('name', 'Unknown'),
                    'expires_at': credentials.expiry.isoformat() if credentials.expiry else None,
                    'scopes': list(credentials.scopes) if credentials.scopes else [],
                    'last_check': datetime.now().isoformat()
                }
            else:
                return {
                    'authenticated': False,
                    'provider': self.provider,
                    'message': 'No valid credentials found',
                    'last_check': datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"‚ùå Authentication status check error: {e}")
            return {
                'authenticated': False,
                'provider': self.provider,
                'error': str(e),
                'last_check': datetime.now().isoformat()
            }
    
    def revoke_credentials(self, user_email: Optional[str] = None) -> Dict[str, Any]:
        """
        Revoke stored credentials
        
        Args:
            user_email (str): User email (if None, revokes all)
            
        Returns:
            dict: Revocation result
        """
        try:
            revoked_count = 0
            
            if user_email:
                # Revoke specific user credentials
                email_hash = hashlib.sha256(user_email.encode()).hexdigest()[:16]
                token_filename = f"{self.provider}_{email_hash}.json"
                token_filepath = os.path.join(self.tokens_dir, token_filename)
                
                if os.path.exists(token_filepath):
                    os.remove(token_filepath)
                    revoked_count = 1
                    
                    # Remove from cache
                    with self.auth_lock:
                        if user_email in self.credentials_cache:
                            del self.credentials_cache[user_email]
            else:
                # Revoke all credentials for provider
                for filename in os.listdir(self.tokens_dir):
                    if filename.startswith(f"{self.provider}_") and filename.endswith('.json'):
                        os.remove(os.path.join(self.tokens_dir, filename))
                        revoked_count += 1
                
                # Clear cache
                with self.auth_lock:
                    self.credentials_cache.clear()
            
            logger.info(f"üîå Revoked {revoked_count} credential(s) for {self.provider}")
            
            return {
                'success': True,
                'message': f"Revoked {revoked_count} credential(s)",
                'revoked_count': revoked_count,
                'provider': self.provider
            }
            
        except Exception as e:
            logger.error(f"‚ùå Credential revocation error: {e}")
            return {
                'success': False,
                'message': f"Credential revocation failed: {str(e)}",
                'error': str(e)
            }
    
    def cleanup_expired_sessions(self, max_age_hours: int = 1):
        """
        Clean up expired OAuth sessions
        
        Args:
            max_age_hours (int): Maximum session age in hours
        """
        try:
            cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
            expired_sessions = []
            
            with self.auth_lock:
                for session_id, session_data in list(self.auth_sessions.items()):
                    created_at = datetime.fromisoformat(session_data['created_at'])
                    if created_at < cutoff_time:
                        expired_sessions.append(session_id)
                
                for session_id in expired_sessions:
                    del self.auth_sessions[session_id]
            
            if expired_sessions:
                logger.info(f"üßπ Cleaned up {len(expired_sessions)} expired OAuth sessions")
                
        except Exception as e:
            logger.error(f"‚ùå Session cleanup error: {e}")


def test_cloud_auth():
    """
    Test function for CloudAuthManager functionality
    """
    print("üîß Testing CloudAuthManager...")
    
    try:
        # Initialize CloudAuthManager
        print("\n1. Initializing CloudAuthManager...")
        auth_manager = CloudAuthManager('google_drive')
        print("‚úÖ CloudAuthManager initialized")
        
        # Check authentication status
        print("\n2. Checking authentication status...")
        auth_status = auth_manager.get_authentication_status()
        print(f"‚úÖ Authenticated: {auth_status['authenticated']}")
        
        if auth_status['authenticated']:
            print(f"   User: {auth_status.get('user_email', 'Unknown')}")
        else:
            print("   No existing credentials found")
        
        # Load stored credentials (if any)
        print("\n3. Loading stored credentials...")
        credentials = auth_manager.load_stored_credentials()
        
        if credentials:
            print(f"‚úÖ Credentials loaded successfully")
            print(f"   Valid: {credentials.valid}")
            print(f"   Scopes: {list(credentials.scopes) if credentials.scopes else 'None'}")
        else:
            print("üì≠ No stored credentials found")
        
        print("\nüéâ CloudAuthManager test completed!")
        
    except Exception as e:
        print(f"‚ùå CloudAuthManager test failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_cloud_auth()

```
## üìÑ File: `nvr_client.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/nvr_client.py`

```python
# nvr_client.py - Fixed Authentication for ZM v1.34.26
import requests
import logging
import socket
import random
import json
import os
from typing import Dict, List, Tuple
from datetime import datetime, timedelta
from .onvif_client import onvif_client

class NVRClient:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.session = requests.Session()
        self.base_url = None
        # üÜï JWT Token storage
        self.access_token = None
        self.auth_credentials = None
    
    def _authenticate_zoneminder(self, username: str, password: str) -> bool:
        """üîß DEBUG: ZoneMinder authentication with detailed logging"""
        try:
            auth_data = {
                'user': username,
                'pass': password
            }
            
            login_url = f"{self.base_url}/host/login.json"
            self.logger.info(f"üîê Attempting login to: {login_url}")
            self.logger.info(f"üîê Login data: user={username}, pass=***")
            
            response = self.session.post(login_url, data=auth_data, timeout=10)
            
            self.logger.info(f"üîê Login response status: {response.status_code}")
            
            if response.status_code == 200:
                data = response.json()
                self.logger.info(f"üîê Login response data: {json.dumps(data, indent=2)}")
                
                # üéØ PRIORITY: Use auth credentials (works with current ZM config)
                if 'credentials' in data and data.get('credentials'):
                    self.auth_credentials = data['credentials']  # "auth=abc123"
                    self.logger.info(f"‚úÖ ZoneMinder auth hash successful: {self.auth_credentials}")
                    return True
                
                # Fallback: JWT token (if ZM configured differently)
                elif 'access_token' in data and data.get('access_token'):
                    self.access_token = data['access_token']
                    self.session.headers.update({
                        'Authorization': f'Bearer {self.access_token}'
                    })
                    self.logger.info("‚úÖ ZoneMinder JWT authentication successful")
                    return True
                
                # Simple success
                elif data.get('success', False):
                    self.logger.info("‚úÖ ZoneMinder basic auth successful")
                    return True
                
                else:
                    self.logger.error("‚ùå ZoneMinder authentication failed - no valid response")
                    return False
            else:
                self.logger.error(f"‚ùå ZoneMinder auth request failed: {response.status_code}")
                self.logger.error(f"‚ùå Response text: {response.text}")
                return False
                
        except Exception as e:
            self.logger.error(f"‚ùå ZoneMinder authentication error: {e}")
            return False
    
    def _make_authenticated_request(self, url: str, **kwargs):
        """üîß DEBUG: Make request with detailed logging"""
        
        self.logger.info(f"üåê Making request to: {url}")
        
        # Priority: Auth credentials (current working method)
        if self.auth_credentials:
            separator = '&' if '?' in url else '?'
            auth_url = f"{url}{separator}{self.auth_credentials}"
            self.logger.info(f"üîë Using auth hash URL: {auth_url}")
            response = self.session.get(auth_url, **kwargs)
            self.logger.info(f"üåê Auth hash response status: {response.status_code}")
            if response.status_code != 200:
                self.logger.error(f"‚ùå Auth hash response error: {response.text[:200]}")
            return response
        
        # Fallback: JWT token
        elif self.access_token:
            self.logger.info(f"üîë Using JWT token in headers")
            response = self.session.get(url, **kwargs)
            self.logger.info(f"üåê JWT response status: {response.status_code}")
            return response
        
        # No auth - try direct request
        else:
            self.logger.info(f"üîì No auth - direct request")
            response = self.session.get(url, **kwargs)
            self.logger.info(f"üåê Direct response status: {response.status_code}")
            return response

    def _discover_zoneminder_real(self, url: str, config: dict) -> dict:
        """üîß FIXED: Auth first, then version check"""
        self.base_url = f"http://{url}/zm/api"
        username = config.get('username', '')
        password = config.get('password', '')
        
        self.logger.info(f"üéØ === ZONEMINDER DISCOVERY START ===")
        self.logger.info(f"üéØ Base URL: {self.base_url}")
        self.logger.info(f"üéØ Username: {username}")
        self.logger.info(f"üéØ Password provided: {'Yes' if password else 'No'}")
        
        try:
            # Step 1: Authentication FIRST (if credentials provided)
            if username and password:
                self.logger.info(f"üîê Step 1: Authenticating with credentials")
                auth_success = self._authenticate_zoneminder(username, password)
                if not auth_success:
                    error_msg = "ZoneMinder authentication failed"
                    self.logger.error(f"‚ùå {error_msg}")
                    return self._error_response(error_msg)
            elif username or password:
                error_msg = "Both username and password required for authentication"
                self.logger.error(f"‚ùå {error_msg}")
                return self._error_response(error_msg)
            else:
                self.logger.info(f"üîì Step 1: No credentials provided - skipping auth")
            
            # Step 2: Test connectivity & get version (AFTER auth)
            self.logger.info(f"üì° Step 2: Testing version endpoint")
            version_response = self._make_authenticated_request(f"{self.base_url}/host/getVersion.json", timeout=10)
            if version_response.status_code != 200:
                error_msg = f"ZoneMinder API not accessible. Status: {version_response.status_code}"
                self.logger.error(f"‚ùå {error_msg}")
                return self._error_response(error_msg)
            
            version_data = version_response.json()
            zm_version = version_data.get('version', 'Unknown')
            api_version = version_data.get('apiversion', 'Unknown')
            
            self.logger.info(f"‚úÖ ZoneMinder version: {zm_version}, API: {api_version}")
            
            # Step 3: Get real monitors with authentication
            self.logger.info(f"üìπ Step 3: Getting monitors")
            monitors_response = self._make_authenticated_request(f"{self.base_url}/monitors.json", timeout=10)
            if monitors_response.status_code != 200:
                if monitors_response.status_code == 401:
                    error_msg = "Authentication required but failed. Check username/password."
                    self.logger.error(f"‚ùå {error_msg}")
                    return self._error_response(error_msg)
                else:
                    error_msg = f"Failed to get monitors. Status: {monitors_response.status_code}"
                    self.logger.error(f"‚ùå {error_msg}")
                    return self._error_response(error_msg)
            
            monitors_data = monitors_response.json()
            monitors = monitors_data.get('monitors', [])
            
            self.logger.info(f"‚úÖ Found {len(monitors)} monitors")
            
            if not monitors:
                error_msg = "No monitors found in ZoneMinder"
                self.logger.error(f"‚ùå {error_msg}")
                return self._error_response(error_msg)
            
            # Step 4: Process real monitor data
            cameras = []
            for monitor_data in monitors:
                monitor = monitor_data.get('Monitor', {})
                monitor_status = monitor_data.get('Monitor_Status', {})
                
                monitor_id = monitor.get('Id')
                monitor_name = monitor.get('Name', f"Monitor_{monitor_id}")
                
                camera_info = {
                    "id": f"zm_monitor_{monitor_id}",
                    "name": monitor_name,
                    "description": f"ZM {monitor_name} ({monitor.get('Function', 'Record')})",
                    "zm_id": monitor_id,
                    "status": monitor_status.get('Status', 'Unknown'),
                    "resolution": f"{monitor.get('Width', 'Unknown')}x{monitor.get('Height', 'Unknown')}",
                    "function": monitor.get('Function', 'Record'),
                    "enabled": monitor.get('Enabled') == '1',
                    "type": monitor.get('Type', 'Unknown'),
                    "fps": {
                        "capture": float(monitor_status.get('CaptureFPS', '0.00')),
                        "analysis": float(monitor_status.get('AnalysisFPS', '0.00'))
                    },
                    "capabilities": self._get_zm_capabilities(monitor)
                }
                
                # Add path information
                monitor_path = monitor.get('Path', '')
                if monitor.get('Type') == 'File' and monitor_path:
                    camera_info['file_path'] = monitor_path
                elif monitor_path.startswith('rtsp://') or monitor_path.startswith('http://'):
                    camera_info['stream_url'] = monitor_path
                
                cameras.append(camera_info)
                
                self.logger.info(f"üìπ Found ZM monitor: {monitor_name} (ID: {monitor_id}, Status: {camera_info['status']})")
            
            # Step 5: Get system information
            self.logger.info(f"üîß Step 5: Getting system info")
            system_info = self._get_zoneminder_system_info()
            
            success_result = {
                "accessible": True,
                "message": f"ZoneMinder connection successful - Discovered {len(cameras)} camera(s)",
                "source_type": "nvr",
                "protocol": "zoneminder",
                "cameras": cameras,
                "device_info": {
                    "manufacturer": "ZoneMinder",
                    "model": "Open Source NVR",
                    "firmware": zm_version,
                    "api_version": api_version,
                    "disk_usage": system_info.get('disk_usage', 'Unknown'),
                    "total_cameras": len(cameras),
                    "api_url": self.base_url,
                    "auth_method": "Auth Hash" if self.auth_credentials else ("JWT Token" if self.access_token else "No Auth")
                }
            }
            
            self.logger.info(f"üéØ === ZONEMINDER DISCOVERY SUCCESS ===")
            return success_result
            
        except requests.exceptions.RequestException as e:
            error_msg = f"ZoneMinder API connection failed: {str(e)}"
            self.logger.error(f"‚ùå Request error: {error_msg}")
            return self._error_response(error_msg)
        except Exception as e:
            error_msg = f"ZoneMinder discovery failed: {str(e)}"
            self.logger.error(f"‚ùå Unexpected error: {error_msg}")
            return self._error_response(error_msg)
    
    def _get_zoneminder_system_info(self) -> dict:
        """üîß FIXED: Get ZoneMinder system information with auth"""
        system_info = {}
        
        try:
            # Get disk usage with authentication
            disk_response = self._make_authenticated_request(f"{self.base_url}/host/getDiskPercent.json", timeout=5)
            if disk_response.status_code == 200:
                disk_data = disk_response.json()
                usage = disk_data.get('usage', {})
                total_usage = usage.get('Total', {}).get('space', 'Unknown')
                system_info['disk_usage'] = f"{total_usage}% used" if total_usage != 'Unknown' else 'Unknown'
                
                self.logger.info(f"ZoneMinder disk usage: {system_info['disk_usage']}")
            
        except Exception as e:
            self.logger.warning(f"Failed to get ZoneMinder system info: {e}")
            system_info['disk_usage'] = 'Unknown'
        
        return system_info
    
    def test_connection_and_discover_cameras(self, source_data: dict) -> dict:
        """
        Universal NVR connection test and camera discovery
        Supports: ZoneMinder (Real), ONVIF (Mock), RTSP, etc.
        """
        url = source_data.get('path', '')
        config = source_data.get('config', {})
        protocol = config.get('protocol', 'onvif').lower()
        username = config.get('username', '')
        password = config.get('password', '')
        
        self.logger.info(f"Testing NVR connection to {url} using {protocol}")
        
        try:
            # Basic validation
            if not url:
                return self._error_response("NVR URL is required")
            
            # Extract host for network check
            host = self._extract_host(url)
            
            # Network connectivity check
            if not self._check_network_connectivity(host):
                return self._error_response(f"Cannot reach NVR at {host}. Check network connectivity.")
            
            # Protocol-specific discovery
            if protocol == 'zoneminder':
                return self._discover_zoneminder_real(url, config)
            elif protocol == 'onvif':
                return self._discover_onvif_real(url, config)
            elif protocol == 'rtsp':
                return self._discover_rtsp_mock(url, config)
            elif protocol == 'hikvision':
                return self._discover_vendor_mock(url, config, 'hikvision')
            elif protocol == 'dahua':
                return self._discover_vendor_mock(url, config, 'dahua')
            else:
                return self._discover_generic_mock(url, config)
                
        except Exception as e:
            self.logger.error(f"NVR connection test failed: {e}")
            return self._error_response(f"Connection test failed: {str(e)}")
    
    # ... (rest of the methods remain the same)
    
    def _get_zm_capabilities(self, monitor: dict) -> List[str]:
        """Get ZoneMinder monitor capabilities"""
        capabilities = []
        
        function = monitor.get('Function', '')
        if function in ['Record', 'Mocord']:
            capabilities.append('recording')
        if function in ['Monitor', 'Modect', 'Mocord']:
            capabilities.append('monitoring')
        if function in ['Modect', 'Mocord']:
            capabilities.append('motion_detection')
        
        if monitor.get('Controllable') == '1':
            capabilities.append('ptz')
        
        if monitor.get('RecordAudio') == '1':
            capabilities.append('audio')
            
        return capabilities
    
    def _extract_host(self, url: str) -> str:
        """Extract hostname/IP from URL"""
        url = url.replace('http://', '').replace('https://', '').replace('rtsp://', '')
        host = url.split(':')[0].split('/')[0]
        return host
    
    def _check_network_connectivity(self, host: str) -> bool:
        """Check network connectivity"""
        try:
            socket.gethostbyname(host)
            return True
        except socket.gaierror:
            # For local IPs and localhost, assume reachable
            if host.startswith('192.168.') or host.startswith('10.') or host.startswith('172.') or host in ['localhost', '127.0.0.1']:
                return True
            return False
    
    def _error_response(self, message: str) -> dict:
        """Standard error response"""
        return {
            "accessible": False,
            "message": message,
            "source_type": "nvr",
            "cameras": [],
            "device_info": {}
        }
    
    # Mock implementations for other protocols
    def _discover_onvif_mock(self, url: str, config: dict) -> dict:
        """Mock ONVIF discovery (for other NVR types)"""
        if not config.get('username') or not config.get('password'):
            return self._error_response("Username and password are required for ONVIF")
        
        host = self._extract_host(url)
        num_cameras = random.randint(2, 6)
        cameras = []
        
        camera_names = ["Front Door", "Parking", "Warehouse", "Office", "Storage", "Loading"]
        
        for i in range(num_cameras):
            cameras.append({
                "id": f"onvif_profile_{i+1}",
                "name": camera_names[i] if i < len(camera_names) else f"Camera {i+1}",
                "description": f"ONVIF Camera {i+1}",
                "stream_url": f"rtsp://{host}:554/stream{i+1}",
                "resolution": random.choice(["1920x1080", "1280x720", "2560x1440"]),
                "codec": random.choice(["H264", "H265"]),
                "capabilities": ["recording"] + (["ptz"] if i < 2 else [])
            })
        
        return {
            "accessible": True,
            "message": f"ONVIF connection successful - Discovered {num_cameras} cameras",
            "source_type": "nvr",
            "protocol": "onvif",
            "cameras": cameras,
            "device_info": {
                "manufacturer": "Generic ONVIF",
                "model": f"NVR-{num_cameras}CH",
                "firmware": f"V{random.randint(2,5)}.{random.randint(0,9)}.0"
            }
        }
    
    def _discover_rtsp_mock(self, url: str, config: dict) -> dict:
        """Mock RTSP discovery"""
        if not config.get('username') or not config.get('password'):
            return self._error_response("Username and password are required for RTSP")
        
        return {
            "accessible": True,
            "message": "RTSP connection successful - Found 2 streams",
            "source_type": "nvr",
            "protocol": "rtsp",
            "cameras": [
                {"id": "rtsp_1", "name": "Main Stream", "stream_url": f"rtsp://{url}/stream1"},
                {"id": "rtsp_2", "name": "Sub Stream", "stream_url": f"rtsp://{url}/stream2"}
            ],
            "device_info": {"manufacturer": "Generic RTSP", "model": "RTSP Server"}
        }
    
    def _discover_vendor_mock(self, url: str, config: dict, vendor: str) -> dict:
        """Mock vendor-specific discovery"""
        return {
            "accessible": False,
            "message": f"{vendor.title()} API integration coming soon. Use ONVIF protocol for now.",
            "source_type": "nvr",
            "protocol": vendor,
            "cameras": [],
            "device_info": {}
        }
    
    def _discover_generic_mock(self, url: str, config: dict) -> dict:
        """Mock generic discovery"""
        return {
            "accessible": False,
            "message": "Generic HTTP API not implemented. Try ONVIF, RTSP, or ZoneMinder protocols.",
            "source_type": "nvr",
            "protocol": "generic",
            "cameras": [],
            "device_info": {}
        }
    def _discover_onvif_real(self, url: str, config: dict) -> dict:
        """Real ONVIF discovery"""
        try:
            host = self._extract_host(url)
            port = int(config.get('port', 80))
            username = config.get('username', '')
            password = config.get('password', '')
            
            response = onvif_client.test_device_connection(host, port, username, password)
            
            # Validate cameras is array
            if 'cameras' in response and not isinstance(response['cameras'], list):
                response['cameras'] = [response['cameras']]
            
            # Handle multiple cameras and generate IDs
            if 'cameras' in response:
                for i, camera in enumerate(response['cameras']):
                    camera['id'] = f"onvif_{host}_channel_{i+1}"
            
            return response
            
        except Exception as e:
            return self._error_response(f"ONVIF l·ªói: {str(e)}")
```
## üìÑ File: `cloud_endpoints.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/cloud_endpoints.py`

```python
#!/usr/bin/env python3

from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import Flow
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import hashlib
import json
import os
import logging
from datetime import datetime, timedelta
from flask import Blueprint, request, jsonify, session
from google.oauth2.credentials import Credentials
from flask_cors import CORS, cross_origin

from functools import wraps
from flask import g
import time
from collections import defaultdict

# üÜï Import lazy folder routes
from modules.sources.cloud_lazy_folder_routes import lazy_folder_bp

# üÜï Rate limiting storage (in-memory for simplicity)
rate_limit_storage = defaultdict(list)

# üÜï Caching storage for performance optimization
cache_storage = {}
CACHE_DURATIONS = {
    'auth_status': 300,      # 5 minutes
    'subfolders': 180,       # 3 minutes
    'user_info': 600,        # 10 minutes
    'picker_token': 60       # 1 minute
}

def get_cache_key(endpoint, *args):
    """Generate cache key"""
    key_parts = [endpoint] + [str(arg) for arg in args]
    return hashlib.sha256(':'.join(key_parts).encode()).hexdigest()[:16]

def get_cached_data(cache_key):
    """Get cached data if valid"""
    if cache_key in cache_storage:
        cached_item = cache_storage[cache_key]
        if time.time() < cached_item['expires_at']:
            return cached_item['data']
        else:
            # Remove expired cache
            del cache_storage[cache_key]
    return None

def set_cached_data(cache_key, data, cache_type='default'):
    """Cache data with expiration"""
    duration = CACHE_DURATIONS.get(cache_type, 300)
    cache_storage[cache_key] = {
        'data': data,
        'expires_at': time.time() + duration,
        'created_at': time.time()
    }

RATE_LIMITS = {
    'picker_token': {'calls': 10, 'window': 60},  # 10 calls per minute
    'auth_status': {'calls': 30, 'window': 60},   # 30 calls per minute  
    'default': {'calls': 60, 'window': 60}        # 60 calls per minute default
}

def rate_limit(endpoint_type='default'):
    """Rate limiting decorator"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            client_ip = request.remote_addr
            current_time = time.time()
            
            # Get rate limit config
            limit_config = RATE_LIMITS.get(endpoint_type, RATE_LIMITS['default'])
            max_calls = limit_config['calls']
            time_window = limit_config['window']
            
            # Clean old entries
            cutoff_time = current_time - time_window
            rate_limit_storage[client_ip] = [
                call_time for call_time in rate_limit_storage[client_ip] 
                if call_time > cutoff_time
            ]
            
            # Check rate limit
            if len(rate_limit_storage[client_ip]) >= max_calls:
                logger.warning(f"üö´ Rate limit exceeded for {client_ip} on {endpoint_type}")
                return jsonify({
                    'success': False,
                    'message': f'Rate limit exceeded. Max {max_calls} calls per {time_window} seconds.',
                    'retry_after': int(time_window - (current_time - rate_limit_storage[client_ip][0]))
                }), 429
            
            # Record this call
            rate_limit_storage[client_ip].append(current_time)
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator

# Configure logging
logger = logging.getLogger(__name__)

# Create Blueprint for cloud endpoints
cloud_bp = Blueprint('cloud', __name__, url_prefix='/api/cloud')
# üîß FIX: Add CORS to cloud blueprint
CORS(cloud_bp, 
     origins=['http://localhost:3000', 'http://127.0.0.1:3000'],
     supports_credentials=True,
     allow_headers=['Content-Type', 'Authorization', 'X-Requested-With'],
     methods=['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'])

# üÜï Register lazy folder routes AFTER CORS setup
cloud_bp.register_blueprint(lazy_folder_bp)

@cloud_bp.route('/authenticate', methods=['POST', 'OPTIONS'])
@cross_origin(origins=['http://localhost:3000'], supports_credentials=True)
def cloud_authenticate():
    """Google OAuth2 authentication - FIXED for multiple environments"""
    try:
        data = request.get_json()
        provider = data.get('provider', 'google_drive')
        action = data.get('action', 'initiate_auth')
        
        # üÜï NEW: Get redirect URI from request or determine automatically
        custom_redirect = data.get('redirect_uri')
        
        logger.info(f"üîê Cloud authentication request: {provider}, action: {action}")
        
        if action == 'initiate_auth':
            CLIENT_SECRETS_FILE = os.path.join(
                os.path.dirname(__file__), 
                'credentials/google_drive_credentials_web.json'
            )
            
            if not os.path.exists(CLIENT_SECRETS_FILE):
                return jsonify({
                    'success': False,
                    'message': f'Credentials file not found: {CLIENT_SECRETS_FILE}',
                    'setup_required': True
                }), 400
            
            SCOPES = [
                'https://www.googleapis.com/auth/drive.file',
                'https://www.googleapis.com/auth/drive.readonly',
                'https://www.googleapis.com/auth/drive.metadata.readonly'
            ]
            
            # Create flow
            flow = Flow.from_client_secrets_file(
                CLIENT_SECRETS_FILE, 
                scopes=SCOPES
            )
            
            # üîß FIX: Determine redirect URI dynamically
            if custom_redirect:
                redirect_uri = custom_redirect
            else:
                # Auto-detect based on request headers
                host = request.headers.get('Host', 'localhost:8080')
                if '127.0.0.1' in host:
                    redirect_uri = 'http://127.0.0.1:8080/api/cloud/oauth/callback'
                else:
                    redirect_uri = 'http://localhost:8080/api/cloud/oauth/callback'
            
            flow.redirect_uri = redirect_uri
            
            # Generate authorization URL
            authorization_url, state = flow.authorization_url(
                access_type='offline',
                include_granted_scopes='true',
                prompt='consent'
            )
            
            # Store in session
            session['oauth2_state'] = state
            session['oauth2_flow_data'] = {
                'scopes': SCOPES,
                'redirect_uri': flow.redirect_uri,  # ‚úÖ Store used URI
                'client_secrets_file': CLIENT_SECRETS_FILE
            }
            session.permanent = True
            
            logger.info(f"‚úÖ OAuth flow initiated")
            logger.info(f"   Auth URL: {authorization_url}")
            logger.info(f"   Redirect URI: {flow.redirect_uri}")
            
            return jsonify({
                'success': True,
                'auth_url': authorization_url,
                'state': state,
                'redirect_uri': flow.redirect_uri,
                'message': 'OAuth flow initiated - open popup window'
            }), 200
            
        else:
            return jsonify({
                'success': False,
                'message': f'Unknown action: {action}'
            }), 400
            
    except Exception as e:
        logger.error(f"‚ùå Cloud authentication error: {e}")
        return jsonify({
            'success': False,
            'message': f'Cloud authentication failed: {str(e)}'
        }), 500

@cloud_bp.route('/oauth/callback', methods=['GET', 'OPTIONS'])
@cross_origin(origins=['http://localhost:3000'], supports_credentials=True)
def cloud_oauth_callback():
    """OAuth2 callback handler - FIXED for session management and CORS"""
    try:
        logger.info("üîÑ Processing OAuth callback...")
        logger.info(f"   Request URL: {request.url}")
        logger.info(f"   Session ID: {session.get('_id', 'no-session')}")
        
        # Get OAuth parameters
        code = request.args.get('code')
        state = request.args.get('state')
        error = request.args.get('error')
        error_description = request.args.get('error_description')
        
        # Handle errors
        if error:
            logger.error(f"‚ùå OAuth error: {error}")
            return _create_error_page(f"OAuth error: {error}", error_description)
        
        if not code or not state:
            logger.error("‚ùå Missing required OAuth parameters")
            return _create_error_page("Missing OAuth parameters", "Authorization code or state missing")
        
        # üîß FIX: More flexible state verification
        stored_state = session.get('oauth2_state')
        if not stored_state:
            logger.warning("‚ö†Ô∏è No stored state found, but proceeding (session might have expired)")
            # Don't fail immediately - try to continue with OAuth
        elif state != stored_state:
            logger.error(f"‚ùå State mismatch: got {state}, expected {stored_state}")
            return _create_error_page("Security verification failed", "Please try authenticating again")
        
        # Get flow data (with fallback)
        flow_data = session.get('oauth2_flow_data')
        if not flow_data:
            logger.warning("‚ö†Ô∏è No flow data, using defaults")
            flow_data = {
                'scopes': [
                    'https://www.googleapis.com/auth/drive.file',
                    'https://www.googleapis.com/auth/drive.readonly',
                    'https://www.googleapis.com/auth/drive.metadata.readonly'
                ],
                'redirect_uri': 'http://localhost:8080/api/cloud/oauth/callback',
                'client_secrets_file': os.path.join(
                    os.path.dirname(__file__), 
                    'credentials/google_drive_credentials_web.json'
                )
            }
        
        # Recreate flow
        flow = Flow.from_client_secrets_file(
            flow_data['client_secrets_file'], 
            scopes=flow_data['scopes']
        )
        flow.redirect_uri = flow_data['redirect_uri']
        
        logger.info(f"   Using redirect URI: {flow.redirect_uri}")
        
        # Exchange code for tokens
        try:
            logger.info(f"üîÑ Attempting token exchange...")
            flow.fetch_token(code=code)
            credentials = flow.credentials
            logger.info("‚úÖ Token exchange successful")
        except Exception as token_error:
            logger.error(f"‚ùå Token exchange failed: {token_error}")
            return _create_error_page("Token exchange failed", str(token_error))
        
        # Get user info
        try:
            service = build('drive', 'v3', credentials=credentials)
            about = service.about().get(fields='user,storageQuota').execute()
            
            user_info = {
                'email': about.get('user', {}).get('emailAddress', 'unknown'),
                'name': about.get('user', {}).get('displayName', 'Unknown User'),
                'photo_url': about.get('user', {}).get('photoLink'),
                'storage_used_gb': int(about.get('storageQuota', {}).get('usage', 0)) / (1024**3),
                'storage_total_gb': int(about.get('storageQuota', {}).get('limit', 0)) / (1024**3) if about.get('storageQuota', {}).get('limit') else 'Unlimited'
            }
            logger.info(f"‚úÖ User info retrieved: {user_info['email']}")
            
        except Exception as user_error:
            logger.error(f"‚ùå Failed to get user info: {user_error}")
            user_info = {'email': 'unknown', 'name': 'Unknown User'}
        
        # üîß FIX: Store credentials safely first
        credentials_dict = None
        try:
            credentials_dict = _store_credentials_safely(credentials, user_info)
            logger.info("‚úÖ Credentials stored successfully")
        except Exception as storage_error:
            logger.warning(f"‚ö†Ô∏è Failed to store credentials: {storage_error}")
            # Continue anyway
        
        # üÜï UPDATED: Get only root folders (not all folders) for lazy loading
        folders = []
        try:
            # Import lazy loading service
            from modules.sources.google_drive_service import GoogleDriveFolderService
            
            # Initialize folder service for lazy loading
            folder_service = GoogleDriveFolderService(credentials)
            
            # Get only root level folders
            root_folders = folder_service.get_subfolders('root', 50)
            
            for folder in root_folders:
                folders.append({
                    'id': folder['id'],
                    'name': folder['name'],
                    'type': 'folder',
                    'depth': 1,  # Root level folders are depth 1
                    'selectable': False,  # Only depth 4 is selectable
                    'has_subfolders': folder_service.has_subfolders(folder['id']),
                    'created': folder.get('created'),
                    'path': f"/My Drive/{folder['name']}"
                })
            
            logger.info(f"üìÅ Loaded {len(folders)} root folders for lazy loading")
            
        except Exception as folder_error:
            logger.warning(f"‚ö†Ô∏è Failed to load root folders: {folder_error}")
            # Continue without folders
        
        # üîß FIX: Create comprehensive session result
        session_result = {
            'success': True,
            'authenticated': True,
            'user_info': user_info,
            'user_email': user_info['email'],
            'folders': folders,  # Only root folders
            'lazy_loading_enabled': True,  # üÜï NEW: Indicate lazy loading support
            'credentials': credentials_dict or {
                'token': credentials.token,
                'refresh_token': credentials.refresh_token,
                'token_uri': credentials.token_uri,
                'client_id': credentials.client_id,
                'client_secret': credentials.client_secret,
                'scopes': list(credentials.scopes) if credentials.scopes else []
            },
            'existing_auth': False,
            'message': f'Successfully authenticated as {user_info["email"]}',
            'backend_port': 8080,
            'timestamp': datetime.now().isoformat()
        }
        
        # Store in session with longer lifetime
        session['auth_result'] = session_result
        session.permanent = True
        
        # üîß FIX: Clear OAuth session data
        session.pop('oauth2_state', None)
        session.pop('oauth2_flow_data', None)
        
        logger.info(f"‚úÖ OAuth completed successfully for: {user_info['email']}")
        
        # Return success page with postMessage
        return _create_success_page_with_postmessage(session_result)
        
    except Exception as e:
        logger.error(f"‚ùå OAuth callback error: {e}")
        import traceback
        traceback.print_exc()
        return _create_error_page("Authentication error", str(e))

def _store_credentials_safely(credentials, user_info):
    """Store credentials safely and return credentials dict"""
    try:
        tokens_dir = os.path.join(os.path.dirname(__file__), 'tokens')
        os.makedirs(tokens_dir, exist_ok=True)
        
        email_hash = hashlib.sha256(user_info['email'].encode()).hexdigest()[:16]
        token_filename = f"google_drive_{email_hash}.json"
        token_filepath = os.path.join(tokens_dir, token_filename)
        
        credential_data = {
            'token': credentials.token,
            'refresh_token': credentials.refresh_token,
            'token_uri': credentials.token_uri,
            'client_id': credentials.client_id,
            'client_secret': credentials.client_secret,
            'scopes': list(credentials.scopes) if credentials.scopes else [],
            'user_info': user_info,
            'created_at': datetime.now().isoformat(),
            'expires_at': credentials.expiry.isoformat() if credentials.expiry else None
        }
        
        with open(token_filepath, 'w') as f:
            json.dump(credential_data, f, indent=2)
        
        os.chmod(token_filepath, 0o600)
        logger.info(f"‚úÖ Credentials stored to: {token_filepath}")
        
        # Return credentials for session
        return {
            'token': credentials.token,
            'refresh_token': credentials.refresh_token,
            'token_uri': credentials.token_uri,
            'client_id': credentials.client_id,
            'client_secret': credentials.client_secret,
            'scopes': list(credentials.scopes) if credentials.scopes else []
        }
        
    except Exception as e:
        logger.error(f"‚ùå Credential storage error: {e}")
        raise

def _create_success_page_with_postmessage(session_result):
    """Success page with postMessage for COOP compatibility"""
    return f"""
    <!DOCTYPE html>
    <html>
        <head>
            <title>VTrack - Authentication Successful</title>
            <meta charset="utf-8">
            <style>
                body {{
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                    text-align: center;
                    padding: 50px;
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    color: white;
                    margin: 0;
                    min-height: 100vh;
                }}
                .container {{
                    background: white;
                    color: #333;
                    padding: 40px;
                    border-radius: 15px;
                    display: inline-block;
                    box-shadow: 0 20px 40px rgba(0,0,0,0.1);
                    max-width: 500px;
                }}
                .success-icon {{ font-size: 4em; margin-bottom: 20px; }}
                .user-info {{
                    background: #d4edda;
                    border: 1px solid #c3e6cb;
                    padding: 20px;
                    margin: 20px 0;
                    border-radius: 8px;
                    text-align: left;
                }}
                .status {{
                    background: #cce5ff;
                    border: 1px solid #99ccff;
                    padding: 15px;
                    margin: 15px 0;
                    border-radius: 8px;
                    text-align: left;
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="success-icon">‚úÖ</div>
                <h1 style="color: #28a745;">Authentication Successful!</h1>
                
                <div class="user-info">
                    <h3>Google Drive Connected (Lazy Loading)</h3>
                    <p><strong>Account:</strong> {session_result['user_email']}</p>
                    <p><strong>Name:</strong> {session_result['user_info']['name']}</p>
                    <p><strong>Root Folders:</strong> {len(session_result['folders'])}</p>
                    <p><strong>Mode:</strong> Lazy Loading Tree Navigation</p>
                    <p><strong>Backend:</strong> localhost:8080</p>
                </div>
                
                <div class="status" id="status">
                    <strong>Status:</strong> <span id="statusText">Notifying VTrack...</span>
                </div>
                
                <p style="color: #28a745; font-weight: bold;">
                    üéâ You can now close this window and return to VTrack!
                </p>
                
                <p style="font-size: 0.9em; color: #666;">
                    This window will close automatically in <span id="countdown">10</span> seconds.
                </p>
                
                <button onclick="window.close()" style="padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer; margin: 10px;">
                    Close Window
                </button>
            </div>
            
            <script>
                console.log('‚úÖ OAuth success page loaded');
                
                const statusEl = document.getElementById('statusText');
                const countdownEl = document.getElementById('countdown');
                
                // Prepare data for postMessage
                const authData = {json.dumps(session_result)};
                
                // Function to notify parent window
                function notifyParent() {{
                    try {{
                        if (window.opener && !window.opener.closed) {{
                            console.log('üì¨ Sending success message to parent window');
                            window.opener.postMessage({{
                                type: 'OAUTH_SUCCESS',
                                ...authData
                            }}, window.location.origin.replace(':8080', ':3000')); // Send to frontend port
                            
                            statusEl.textContent = 'VTrack notified successfully!';
                            statusEl.style.color = '#28a745';
                        }} else {{
                            console.log('‚ö†Ô∏è Parent window not available');
                            statusEl.textContent = 'Parent window not found';
                            statusEl.style.color = '#856404';
                        }}
                    }} catch (error) {{
                        console.error('‚ùå Error notifying parent:', error);
                        statusEl.textContent = 'Error notifying VTrack';
                        statusEl.style.color = '#dc3545';
                    }}
                }}
                
                // Try multiple notification methods
                function attemptNotification() {{
                    // Method 1: Direct postMessage to opener
                    notifyParent();
                    
                    // Method 2: Try broadcasting to all windows (fallback)
                    setTimeout(() => {{
                        try {{
                            window.postMessage({{
                                type: 'OAUTH_SUCCESS',
                                ...authData
                            }}, '*');
                            console.log('üì° Broadcasted success message');
                        }} catch (error) {{
                            console.error('‚ùå Broadcast error:', error);
                        }}
                    }}, 500);
                    
                    // Method 3: Try localStorage as fallback (if available)
                    setTimeout(() => {{
                        try {{
                            localStorage.setItem('vtrack_oauth_result', JSON.stringify({{
                                type: 'OAUTH_SUCCESS',
                                timestamp: Date.now(),
                                ...authData
                            }}));
                            console.log('üíæ Stored auth result in localStorage');
                        }} catch (error) {{
                            console.log('‚ö†Ô∏è localStorage not available:', error);
                        }}
                    }}, 1000);
                }}
                
                // Start notification attempts
                attemptNotification();
                
                // Countdown and auto-close
                let countdown = 10;
                
                function updateCountdown() {{
                    countdownEl.textContent = countdown;
                    if (countdown <= 0) {{
                        console.log('üö™ Auto-closing window');
                        window.close();
                    }} else {{
                        countdown--;
                        setTimeout(updateCountdown, 1000);
                    }}
                }}
                
                updateCountdown();
                
                // Also try to close when parent receives message
                window.addEventListener('beforeunload', () => {{
                    console.log('üö™ Window closing');
                }});
            </script>
        </body>
    </html>
    """

def _create_error_page(error_message, error_details=None):
    """Error page for port 8080"""
    return f"""
    <!DOCTYPE html>
    <html>
        <head>
            <title>VTrack - Authentication Failed</title>
            <meta charset="utf-8">
            <style>
                body {{
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                    text-align: center;
                    padding: 50px;
                    background: linear-gradient(135deg, #ff6b6b 0%, #ee5a52 100%);
                    color: white;
                    margin: 0;
                    min-height: 100vh;
                }}
                .container {{
                    background: white;
                    color: #333;
                    padding: 40px;
                    border-radius: 15px;
                    display: inline-block;
                    box-shadow: 0 20px 40px rgba(0,0,0,0.1);
                }}
                .error-icon {{ font-size: 4em; margin-bottom: 20px; }}
                .error-details {{
                    background: #f8d7da;
                    border: 1px solid #f5c6cb;
                    padding: 15px;
                    margin: 20px 0;
                    border-radius: 8px;
                    text-align: left;
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="error-icon">‚ùå</div>
                <h1 style="color: #dc3545;">Authentication Failed</h1>
                
                <div class="error-details">
                    <h4>Error Details:</h4>
                    <p><strong>Message:</strong> {error_message}</p>
                    {f"<p><strong>Details:</strong> {error_details}</p>" if error_details else ""}
                    <p><strong>Backend:</strong> localhost:8080</p>
                </div>
                
                <p>Please try again or contact support.</p>
                <button onclick="window.close()" style="padding: 10px 20px; background: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer;">
                    Close Window
                </button>
            </div>
            
            <script>
                // Notify parent window of error
                if (window.opener) {{
                    window.opener.postMessage({{
                        type: 'OAUTH_ERROR',
                        error: '{error_message}',
                        details: '{error_details or ""}',
                        backend_port: 8080
                    }}, '*');
                }}
                
                setTimeout(() => window.close(), 10000);
            </script>
        </body>
    </html>
    """, 400

# üÜï NEW: Auth status check with lazy loading support
@cloud_bp.route('/auth-status', methods=['GET', 'OPTIONS'])
@cross_origin(origins=['http://localhost:3000'], supports_credentials=True)
@rate_limit('auth_status')
def auth_status():
    """Check authentication status"""

    # Handle OPTIONS request for CORS preflight
    if request.method == 'OPTIONS':
        response = jsonify({'status': 'ok'})
        response.headers.add('Access-Control-Allow-Origin', 'http://localhost:3000')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
        response.headers.add('Access-Control-Allow-Methods', 'GET,OPTIONS')
        response.headers.add('Access-Control-Allow-Credentials', 'true')
        return response
    
    try:
        cache_key = get_cache_key('auth_status', session.get('_id', 'anonymous'))
        cached_result = get_cached_data(cache_key)
        
        if cached_result:
            logger.debug("üìã Auth status cache hit")
            return jsonify(cached_result), 200
        
        auth_result = session.get('auth_result')
        
        if not auth_result or not auth_result.get('authenticated'):
            result = {
                'success': False,
                'authenticated': False,
                'message': 'No authentication found',
                'lazy_loading_enabled': False
            }
        else:
            result = {
                'success': True,
                'authenticated': True,
                'user_email': auth_result.get('user_email'),
                'user_info': auth_result.get('user_info', {}),
                'credentials': auth_result.get('credentials', {}),
                'folders': auth_result.get('folders', []),  # Root folders only
                'lazy_loading_enabled': auth_result.get('lazy_loading_enabled', True),
                'message': f"Authenticated as {auth_result.get('user_email')}",
                'existing_auth': True,
                'backend_port': 8080
            }
        
        set_cached_data(cache_key, result, 'auth_status')
        return jsonify(result), 200
        
    except Exception as e:
        logger.error(f"‚ùå Auth status error: {e}")
        return jsonify({
            'success': False,
            'authenticated': False,
            'message': f'Auth status check failed: {str(e)}'
        }), 500

# üÜï NEW: Disconnect endpoint
@cloud_bp.route('/disconnect', methods=['POST'])
def cloud_disconnect():
    """Disconnect from cloud provider"""
    try:
        data = request.get_json()
        provider = data.get('provider', 'google_drive')
        user_email = data.get('user_email')
        
        logger.info(f"üîå Disconnecting {provider} for {user_email}")
        
        # Clear session
        session.pop('auth_result', None)
        session.pop('oauth2_state', None)
        session.pop('oauth2_flow_data', None)
        
        # Clear cache
        cache_storage.clear()
        
        # Optionally remove stored token file
        if user_email:
            try:
                tokens_dir = os.path.join(os.path.dirname(__file__), 'tokens')
                email_hash = hashlib.sha256(user_email.encode()).hexdigest()[:16]
                token_filename = f"google_drive_{email_hash}.json"
                token_filepath = os.path.join(tokens_dir, token_filename)
                
                if os.path.exists(token_filepath):
                    os.remove(token_filepath)
                    logger.info(f"üóëÔ∏è Removed token file: {token_filename}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not remove token file: {e}")
        
        return jsonify({
            'success': True,
            'message': f'Successfully disconnected from {provider}',
            'provider': provider
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Disconnect error: {e}")
        return jsonify({
            'success': False,
            'message': f'Disconnect failed: {str(e)}'
        }), 500
```
## üìÑ File: `auto_sync_service.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/auto_sync_service.py`

```python
import threading
import logging
import time
from datetime import datetime, timedelta
import json
from modules.db_utils import get_db_connection
from modules.sources.nvr_downloader import NVRDownloader  # Assuming this exists or will be implemented
from database import get_sync_status, initialize_sync_status

logger = logging.getLogger(__name__)

class AutoSyncService:
    def __init__(self):
        self.sync_timers = {}  # Store timers for each source
        self.sync_locks = {}   # Locks to prevent concurrent syncs
        self.downloader = NVRDownloader()
        
    def start_auto_sync(self, source_config: dict) -> bool:
        """Start auto-sync for a source"""
        source_id = source_config.get('id')
        if not source_id:
            logger.error("Source ID required to start sync")
            return False
            
        if source_id in self.sync_timers:
            logger.warning(f"Sync already running for source {source_id}")
            return True
            
        # Initialize status if not exists
        current_status = get_sync_status(source_id)
        if not current_status:
            initialize_sync_status(source_id, sync_enabled=True, interval_minutes=10)
            
        self.sync_locks[source_id] = threading.Lock()
        self._schedule_next_sync(source_id)
        
        logger.info(f"Auto-sync started for source {source_id}")
        return True
        
    def stop_auto_sync(self, source_id: int) -> bool:
        """Stop auto-sync for a source"""
        try:
            if source_id not in self.sync_timers:
                logger.warning(f"No active sync for source {source_id}")
                return True
                
            # Cancel timer
            self.sync_timers[source_id].cancel()
            del self.sync_timers[source_id]
            del self.sync_locks[source_id]
            
            # Update status
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE sync_status 
                SET sync_enabled = 0, 
                    last_sync_status = 'stopped',
                    last_sync_message = 'Auto-sync stopped by user'
                WHERE source_id = ?
            """, (source_id,))
            conn.commit()
            conn.close()
            
            logger.info(f"Auto-sync stopped for source {source_id}")
            return True
            
        except Exception as e:
            logger.error(f"Error stopping sync for {source_id}: {e}")
            return False
            
    def get_sync_status(self, source_id: int) -> dict:
        """Get current sync status"""
        return get_sync_status(source_id) or {}
        
    def _sync_latest_recordings(self, source_id: int) -> dict:
        """Perform sync of latest recordings"""
        with self.sync_locks.get(source_id, threading.Lock()):
            try:
                # Get source config
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT config FROM video_sources 
                    WHERE id = ?
                """, (source_id,))
                result = cursor.fetchone()
                conn.close()
                
                if not result:
                    return {'success': False, 'message': 'Source not found'}
                    
                config = json.loads(result[0])
                
                # Update status to in_progress
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    UPDATE sync_status 
                    SET last_sync_status = 'in_progress',
                        last_sync_message = 'Sync started'
                    WHERE source_id = ?
                """, (source_id,))
                conn.commit()
                conn.close()
                
                # Download last 24 hours
                time_range = {
                    'from': datetime.now() - timedelta(hours=24),
                    'to': datetime.now()
                }
                
                download_result = self.downloader.download_latest_recordings(config, time_range)
                
                # Update status
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    UPDATE sync_status 
                    SET last_sync_timestamp = ?,
                        last_sync_status = ?,
                        last_sync_message = ?,
                        files_downloaded_count = files_downloaded_count + ?,
                        total_download_size_mb = total_download_size_mb + ?
                    WHERE source_id = ?
                """, (
                    datetime.now().isoformat(),
                    'success' if download_result['success'] else 'failed',
                    download_result['message'],
                    download_result.get('files_downloaded', 0),
                    download_result.get('total_size_mb', 0.0),
                    source_id
                ))
                conn.commit()
                conn.close()
                
                return download_result
                
            except Exception as e:
                logger.error(f"Sync error for {source_id}: {e}")
                
                # Update error status
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    UPDATE sync_status 
                    SET last_sync_status = 'failed',
                        last_sync_message = ?
                    WHERE source_id = ?
                """, (str(e), source_id))
                conn.commit()
                conn.close()
                
                return {'success': False, 'message': str(e)}
    
    def _schedule_next_sync(self, source_id: int):
        """Schedule next sync run"""
        status = self.get_sync_status(source_id)
        if not status.get('sync_enabled', True):
            return
            
        interval = status.get('sync_interval_minutes', 10)
        next_sync = datetime.now() + timedelta(minutes=interval)
        
        # Update next timestamp
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            UPDATE sync_status 
            SET next_sync_timestamp = ?
            WHERE source_id = ?
        """, (next_sync.isoformat(), source_id))
        conn.commit()
        conn.close()
        
        # Schedule timer
        timer = threading.Timer(interval * 60, self._perform_sync, args=(source_id,))
        timer.daemon = True
        self.sync_timers[source_id] = timer
        timer.start()
        
        logger.info(f"Next sync scheduled for {source_id} at {next_sync}")
    
    def _perform_sync(self, source_id: int):
        """Perform sync and schedule next"""
        self._sync_latest_recordings(source_id)
        self._schedule_next_sync(source_id)
```
## üìÑ File: `path_manager.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/path_manager.py`

```python
import sqlite3
import os
import json
import logging
import uuid
from datetime import datetime
import pytz
from modules.db_utils import get_db_connection
from modules.scheduler.db_sync import db_rwlock

# C·∫•u h√¨nh m√∫i gi·ªù Vi·ªát Nam - ƒê·ªíNG NH·∫§T V·ªöI FILE_LISTER
VIETNAM_TZ = pytz.timezone('Asia/Ho_Chi_Minh')

class PathManager:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
    def get_all_active_sources(self):
        """Get all active video sources from database"""
        try:
            with db_rwlock.gen_rlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT id, source_type, name, path, config, active, created_at 
                    FROM video_sources 
                    WHERE active = 1 
                    ORDER BY source_type, name
                """)
                sources = []
                for row in cursor.fetchall():
                    source = {
                        'id': row[0],
                        'source_type': row[1],
                        'name': row[2],
                        'path': row[3],
                        'config': json.loads(row[4]) if row[4] else {},
                        'active': row[5],
                        'created_at': row[6]
                    }
                    sources.append(source)
                conn.close()
                return sources
        except Exception as e:
            self.logger.error(f"Error getting active sources: {e}")
            return []

    def get_current_active_source(self):
        """Get current active source (Single Active Source)"""
        sources = self.get_all_active_sources()
        return sources[0] if sources else None
    
    def get_source_by_id(self, source_id):
        """Get specific video source by ID"""
        try:
            with db_rwlock.gen_rlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT id, source_type, name, path, config, active, created_at 
                    FROM video_sources 
                    WHERE id = ?
                """, (source_id,))
                row = cursor.fetchone()
                conn.close()
                if row:
                    return {
                        'id': row[0],
                        'source_type': row[1],
                        'name': row[2],
                        'path': row[3],
                        'config': json.loads(row[4]) if row[4] else {},
                        'active': row[5],
                        'created_at': row[6]
                    }
                return None
        except Exception as e:
            self.logger.error(f"Error getting source by id {source_id}: {e}")
            return None
    
    def get_source_id_by_name(self, source_name):
        """Get source ID by name"""
        try:
            with db_rwlock.gen_rlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("SELECT id FROM video_sources WHERE name = ?", (source_name,))
                result = cursor.fetchone()
                conn.close()
                return result[0] if result else None
        except Exception as e:
            self.logger.error(f"Error getting source id by name {source_name}: {e}")
            return None
    
    def set_active_source(self, source_id):
        """Set single active source (disable all others)"""
        try:
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                
                # Disable all sources first
                cursor.execute("UPDATE video_sources SET active = 0")
                
                # Enable the specified source
                cursor.execute("UPDATE video_sources SET active = 1 WHERE id = ?", (source_id,))
                
                if cursor.rowcount == 0:
                    conn.rollback()
                    conn.close()
                    return False, f"No source found with id {source_id}"
                
                conn.commit()
                conn.close()
                
                self.logger.info(f"Set source id {source_id} as active")
                return True, "Active source updated successfully"
                
        except Exception as e:
            self.logger.error(f"Error setting active source: {e}")
            return False, str(e)
    
    def validate_source_accessibility(self, source_config):
        """Check if source is accessible based on type"""
        source_type = source_config.get('source_type')
        path = source_config.get('path')
        config = source_config.get('config', {})
        
        try:
            if source_type == 'local':
                return self._validate_local_path(path)
            elif source_type == 'camera':
                return self._validate_camera_source(path, config)
            elif source_type == 'cloud':
                return self._validate_cloud_source(path, config)
            else:
                return False, f"Unknown source type: {source_type}"
        except Exception as e:
            self.logger.error(f"Error validating source accessibility: {e}")
            return False, str(e)
    
    def _validate_local_path(self, path):
        """Validate local file system path"""
        if not path:
            return False, "Path is required"
        if not os.path.exists(path):
            return False, f"Path does not exist: {path}"
        if not os.access(path, os.R_OK):
            return False, f"No read permission for path: {path}"
        return True, "Local path is accessible"
    
    
    def _validate_camera_source(self, path, config):
        """Validate camera/NVR source"""
        if config.get('type') == 'directory':
            return self._validate_local_path(path)
        elif config.get('type') == 'api':
            api_url = config.get('api_url')
            if not api_url:
                return False, "API URL is required for camera source"
            
            try:
                import requests
                response = requests.get(api_url, timeout=10)
                if response.status_code == 200:
                    return True, "Camera API accessible"
                else:
                    return False, f"Camera API returned status {response.status_code}"
            except ImportError:
                return False, "requests library not installed"
            except Exception as e:
                return False, f"Camera API validation failed: {e}"
        else:
            return False, "Invalid camera source type"
    
    def _validate_cloud_source(self, path, config):
        """Validate cloud storage source"""
        provider = config.get('provider', '').lower()
        
        if provider == 'google_drive':
            return self._validate_google_drive(config)
        elif provider == 'dropbox':
            return self._validate_dropbox(config)
        elif provider == 'onedrive':
            return self._validate_onedrive(config)
        else:
            return False, f"Unsupported cloud provider: {provider}"
    
    def _validate_google_drive(self, config):
        """Validate Google Drive access"""
        try:
            from google.oauth2.credentials import Credentials
            from googleapiclient.discovery import build
            
            credentials_data = config.get('credentials')
            if not credentials_data:
                return False, "Google Drive credentials not found"
            
            credentials = Credentials.from_authorized_user_info(credentials_data)
            service = build('drive', 'v3', credentials=credentials)
            service.files().list(pageSize=1).execute()
            
            return True, "Google Drive connection successful"
            
        except ImportError:
            return False, "Google API library not installed"
        except Exception as e:
            return False, f"Google Drive validation failed: {e}"
    
    def _validate_dropbox(self, config):
        """Validate Dropbox access"""
        try:
            import dropbox
            
            access_token = config.get('access_token')
            if not access_token:
                return False, "Dropbox access token not found"
            
            dbx = dropbox.Dropbox(access_token)
            dbx.users_get_current_account()
            
            return True, "Dropbox connection successful"
            
        except ImportError:
            return False, "Dropbox library not installed"
        except Exception as e:
            return False, f"Dropbox validation failed: {e}"
    
    def _validate_onedrive(self, config):
        """Validate OneDrive access"""
        return False, "OneDrive validation not implemented yet"
    
    def add_source(self, source_type, name, path, config=None):
        """Add new video source"""
        try:
            if not all([source_type, name, path]):
                return False, "source_type, name, and path are required"
            
            config_json = json.dumps(config) if config else None
            
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                
                # Check if name already exists
                cursor.execute("SELECT COUNT(*) FROM video_sources WHERE name = ?", (name,))
                if cursor.fetchone()[0] > 0:
                    conn.close()
                    return False, f"Source name '{name}' already exists"
                
                # ‚úÖ FIXED: Use VIETNAM_TZ for created_at - ƒê·ªíNG NH·∫§T V·ªöI FILE_LISTER
                cursor.execute("""
                    INSERT INTO video_sources (source_type, name, path, config, active, created_at)
                    VALUES (?, ?, ?, ?, 1, ?)
                """, (source_type, name, path, config_json, datetime.now(VIETNAM_TZ)))
                
                source_id = cursor.lastrowid
                conn.commit()
                conn.close()
                
                self.logger.info(f"Added new video source: {name} (id: {source_id})")
                return True, f"Source '{name}' added successfully"
                
        except Exception as e:
            self.logger.error(f"Error adding source: {e}")
            return False, str(e)
    
    def update_source(self, source_id, **kwargs):
        """Update existing video source"""
        try:
            if not source_id:
                return False, "source_id is required"
            
            # Build update query
            update_fields = []
            update_values = []
            
            for field, value in kwargs.items():
                if field in ['source_type', 'name', 'path', 'active']:
                    update_fields.append(f"{field} = ?")
                    update_values.append(value)
                elif field == 'config':
                    update_fields.append("config = ?")
                    update_values.append(json.dumps(value) if value else None)
            
            if not update_fields:
                return False, "No valid fields to update"
            
            update_values.append(source_id)
            
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                
                query = f"UPDATE video_sources SET {', '.join(update_fields)} WHERE id = ?"
                cursor.execute(query, update_values)
                
                if cursor.rowcount == 0:
                    conn.close()
                    return False, f"No source found with id {source_id}"
                
                conn.commit()
                conn.close()
                
                self.logger.info(f"Updated video source id: {source_id}")
                return True, "Source updated successfully"
                
        except Exception as e:
            self.logger.error(f"Error updating source: {e}")
            return False, str(e)
    
    def delete_source(self, source_id):
        """Delete video source"""
        try:
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                
                cursor.execute("DELETE FROM video_sources WHERE id = ?", (source_id,))
                
                if cursor.rowcount == 0:
                    conn.close()
                    return False, f"No source found with id {source_id}"
                
                conn.commit()
                conn.close()
                
                self.logger.info(f"Deleted video source id: {source_id}")
                return True, "Source deleted successfully"
                
        except Exception as e:
            self.logger.error(f"Error deleting source: {e}")
            return False, str(e)
    
    def toggle_source_status(self, source_id, active):
        """Toggle source active status"""
        try:
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                
                cursor.execute("UPDATE video_sources SET active = ? WHERE id = ?", (active, source_id,))
                
                if cursor.rowcount == 0:
                    conn.close()
                    return False, f"No source found with id {source_id}"
                
                conn.commit()
                conn.close()
                
                status = "activated" if active else "deactivated"
                self.logger.info(f"Source id {source_id} {status}")
                return True, f"Source {status} successfully"
                
        except Exception as e:
            self.logger.error(f"Error toggling source status: {e}")
            return False, str(e)
```
## üìÑ File: `cloud_lazy_folder_routes.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/cloud_lazy_folder_routes.py`

```python
#!/usr/bin/env python3

"""
Lazy Loading Folder Tree Routes for Google Drive Integration
Separated from main cloud_endpoints.py for better organization
"""

from flask import Blueprint, request, jsonify, session
from flask_cors import cross_origin
from google.oauth2.credentials import Credentials
from modules.sources.google_drive_service import GoogleDriveFolderService
from datetime import datetime
import logging
from functools import wraps
import time
from collections import defaultdict

logger = logging.getLogger(__name__)

# Rate limiting storage
lazy_folder_rate_limit_storage = defaultdict(list)

LAZY_FOLDER_RATE_LIMITS = {
    'folder_discovery': {'calls': 15, 'window': 60},
    'folder_search': {'calls': 10, 'window': 60},
    'folder_info': {'calls': 20, 'window': 60}
}

def lazy_folder_rate_limit(endpoint_type='folder_discovery'):
    """Rate limiting decorator for lazy folder operations"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            client_ip = request.remote_addr
            current_time = time.time()
            
            limit_config = LAZY_FOLDER_RATE_LIMITS.get(endpoint_type, {'calls': 15, 'window': 60})
            max_calls = limit_config['calls']
            time_window = limit_config['window']
            
            # Clean old entries
            cutoff_time = current_time - time_window
            lazy_folder_rate_limit_storage[client_ip] = [
                call_time for call_time in lazy_folder_rate_limit_storage[client_ip] 
                if call_time > cutoff_time
            ]
            
            # Check rate limit
            if len(lazy_folder_rate_limit_storage[client_ip]) >= max_calls:
                logger.warning(f"üö´ Lazy folder rate limit exceeded for {client_ip} on {endpoint_type}")
                return jsonify({
                    'success': False,
                    'message': f'Rate limit exceeded. Max {max_calls} calls per {time_window} seconds.',
                    'retry_after': int(time_window - (current_time - lazy_folder_rate_limit_storage[client_ip][0]))
                }), 429
            
            # Record this call
            lazy_folder_rate_limit_storage[client_ip].append(current_time)
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator

def get_credentials_from_session():
    """Get Google Drive credentials from session data"""
    try:
        auth_result = session.get('auth_result')
        if not auth_result or not auth_result.get('credentials'):
            return None
        
        cred_data = auth_result['credentials']
        credentials = Credentials(
            token=cred_data['token'],
            refresh_token=cred_data.get('refresh_token'),
            token_uri=cred_data.get('token_uri'),
            client_id=cred_data.get('client_id'),
            client_secret=cred_data.get('client_secret'),
            scopes=cred_data.get('scopes', [])
        )
        
        return credentials
    except Exception as e:
        logger.error(f"‚ùå Error getting credentials from session: {e}")
        return None

# Create Blueprint for lazy folder routes
lazy_folder_bp = Blueprint('lazy_folders', __name__, url_prefix='/folders')

@lazy_folder_bp.route('/list_subfolders', methods=['POST', 'OPTIONS'])
@cross_origin(origins=['http://localhost:3000'], supports_credentials=True)
@lazy_folder_rate_limit('folder_discovery')
def list_subfolders():
    """
    Get subfolders of a specific parent folder with lazy loading
    
    Request JSON:
    {
        "parent_id": "folder_id_or_root",
        "max_results": 50,
        "include_stats": false
    }
    
    Response:
    {
        "success": true,
        "folders": [...],
        "parent_info": {...},
        "total_count": 25,
        "has_more": false
    }
    """
    try:
        data = request.get_json()
        parent_id = data.get('parent_id', 'root')
        max_results = min(data.get('max_results', 50), 100)  # Cap at 100
        include_stats = data.get('include_stats', False)
        
        logger.info(f"üìÇ Listing subfolders for parent: {parent_id}")
        
        # Get credentials
        credentials = get_credentials_from_session()
        if not credentials:
            return jsonify({
                'success': False,
                'message': 'No valid Google Drive credentials found. Please authenticate first.',
                'requires_auth': True
            }), 401
        
        # Initialize folder service
        folder_service = GoogleDriveFolderService(credentials)
        
        # Get subfolders
        subfolders = folder_service.get_subfolders(parent_id, max_results)
        
        # Enrich folder data with depth and selection info
        enriched_folders = []
        for folder in subfolders:
            # Calculate depth for this folder
            depth = folder_service.calculate_folder_depth(folder['id'])
            
            # Check if folder has subfolders (for expand indicator)
            has_subfolders = folder_service.has_subfolders(folder['id'])
            
            enriched_folder = {
                'id': folder['id'],
                'name': folder['name'],
                'type': 'folder',
                'parent_id': parent_id,
                'depth': depth,
                'selectable': folder_service.is_selectable_folder(depth),
                'has_subfolders': has_subfolders,
                'created': folder.get('created'),
                'modified': folder.get('modified'),
                'path': folder_service.build_folder_path(folder['id'])
            }
            
            # Add statistics if requested
            if include_stats:
                stats = folder_service.get_folder_statistics(folder['id'])
                enriched_folder['stats'] = stats
            
            enriched_folders.append(enriched_folder)
        
        # Get parent folder info
        parent_info = {}
        if parent_id != 'root':
            parent_info = folder_service.get_folder_info(parent_id)
        else:
            parent_info = {
                'id': 'root',
                'name': 'My Drive',
                'depth': 0,
                'path': '/My Drive',
                'selectable': False
            }
        
        response_data = {
            'success': True,
            'folders': enriched_folders,
            'parent_info': parent_info,
            'total_count': len(enriched_folders),
            'has_more': len(enriched_folders) == max_results,  # Might have more if we hit the limit
            'cache_info': folder_service.get_cache_info(),
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"‚úÖ Found {len(enriched_folders)} subfolders in {parent_id}")
        return jsonify(response_data), 200
        
    except Exception as e:
        logger.error(f"‚ùå Error listing subfolders: {e}")
        return jsonify({
            'success': False,
            'message': f'Failed to list subfolders: {str(e)}',
            'error_type': type(e).__name__
        }), 500

@lazy_folder_bp.route('/get_depth', methods=['POST', 'OPTIONS'])
@cross_origin(origins=['http://localhost:3000'], supports_credentials=True)
@lazy_folder_rate_limit('folder_info')
def get_folder_depth():
    """
    Get the depth level of a specific folder
    
    Request JSON:
    {
        "folder_id": "folder_id"
    }
    
    Response:
    {
        "success": true,
        "folder_id": "folder_id",
        "depth": 2,
        "selectable": false,
        "path": "/My Drive/Project/Area"
    }
    """
    try:
        data = request.get_json()
        folder_id = data.get('folder_id')
        
        if not folder_id:
            return jsonify({
                'success': False,
                'message': 'folder_id is required'
            }), 400
        
        # Get credentials
        credentials = get_credentials_from_session()
        if not credentials:
            return jsonify({
                'success': False,
                'message': 'No valid Google Drive credentials found',
                'requires_auth': True
            }), 401
        
        # Initialize folder service
        folder_service = GoogleDriveFolderService(credentials)
        
        # Calculate depth
        depth = folder_service.calculate_folder_depth(folder_id)
        path = folder_service.build_folder_path(folder_id)
        selectable = folder_service.is_selectable_folder(depth)
        
        return jsonify({
            'success': True,
            'folder_id': folder_id,
            'depth': depth,
            'selectable': selectable,
            'path': path,
            'timestamp': datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Error getting folder depth: {e}")
        return jsonify({
            'success': False,
            'message': f'Failed to get folder depth: {str(e)}'
        }), 500

@lazy_folder_bp.route('/search', methods=['POST', 'OPTIONS'])
@cross_origin(origins=['http://localhost:3000'], supports_credentials=True)
@lazy_folder_rate_limit('folder_search')
def search_folders():
    """
    Search for folders by name
    
    Request JSON:
    {
        "query": "camera",
        "max_results": 20
    }
    
    Response:
    {
        "success": true,
        "folders": [...],
        "query": "camera",
        "total_found": 15
    }
    """
    try:
        data = request.get_json()
        query = data.get('query', '').strip()
        max_results = min(data.get('max_results', 20), 50)
        
        if not query:
            return jsonify({
                'success': False,
                'message': 'Search query is required'
            }), 400
        
        # Get credentials
        credentials = get_credentials_from_session()
        if not credentials:
            return jsonify({
                'success': False,
                'message': 'No valid Google Drive credentials found',
                'requires_auth': True
            }), 401
        
        # Initialize folder service
        folder_service = GoogleDriveFolderService(credentials)
        
        # Search folders
        search_results = folder_service.search_folders(query, max_results)
        
        return jsonify({
            'success': True,
            'folders': search_results,
            'query': query,
            'total_found': len(search_results),
            'timestamp': datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Error searching folders: {e}")
        return jsonify({
            'success': False,
            'message': f'Failed to search folders: {str(e)}'
        }), 500

@lazy_folder_bp.route('/get_info', methods=['POST', 'OPTIONS'])
@cross_origin(origins=['http://localhost:3000'], supports_credentials=True)
@lazy_folder_rate_limit('folder_info')
def get_folder_info():
    """
    Get comprehensive information about a folder
    
    Request JSON:
    {
        "folder_id": "folder_id",
        "include_stats": true
    }
    """
    try:
        data = request.get_json()
        folder_id = data.get('folder_id')
        include_stats = data.get('include_stats', False)
        
        if not folder_id:
            return jsonify({
                'success': False,
                'message': 'folder_id is required'
            }), 400
        
        # Get credentials
        credentials = get_credentials_from_session()
        if not credentials:
            return jsonify({
                'success': False,
                'message': 'No valid Google Drive credentials found',
                'requires_auth': True
            }), 401
        
        # Initialize folder service
        folder_service = GoogleDriveFolderService(credentials)
        
        # Get folder info
        folder_info = folder_service.get_folder_info(folder_id)
        
        if include_stats:
            stats = folder_service.get_folder_statistics(folder_id)
            folder_info['stats'] = stats
        
        return jsonify({
            'success': True,
            'folder_info': folder_info,
            'timestamp': datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Error getting folder info: {e}")
        return jsonify({
            'success': False,
            'message': f'Failed to get folder info: {str(e)}'
        }), 500

@lazy_folder_bp.route('/clear_cache', methods=['POST', 'OPTIONS'])
@cross_origin(origins=['http://localhost:3000'], supports_credentials=True)
@lazy_folder_rate_limit('folder_info')
def clear_folder_cache():
    """Clear Google Drive folder service cache"""
    try:
        # If we have active credentials, clear service cache
        credentials = get_credentials_from_session()
        if credentials:
            folder_service = GoogleDriveFolderService(credentials)
            folder_service.clear_cache()
        
        return jsonify({
            'success': True,
            'message': 'Folder service cache cleared successfully',
            'timestamp': datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Error clearing folder cache: {e}")
        return jsonify({
            'success': False,
            'message': f'Failed to clear folder cache: {str(e)}'
        }), 500

@lazy_folder_bp.route('/breadcrumb', methods=['POST', 'OPTIONS'])
@cross_origin(origins=['http://localhost:3000'], supports_credentials=True)
@lazy_folder_rate_limit('folder_info')
def get_folder_breadcrumb():
    """
    Get breadcrumb navigation for a folder
    
    Request JSON:
    {
        "folder_id": "folder_id"
    }
    
    Response:
    {
        "success": true,
        "breadcrumb": [
            {"id": "root", "name": "My Drive", "depth": 0},
            {"id": "123", "name": "Project", "depth": 1},
            {"id": "456", "name": "Area", "depth": 2}
        ]
    }
    """
    try:
        data = request.get_json()
        folder_id = data.get('folder_id')
        
        if not folder_id:
            return jsonify({
                'success': False,
                'message': 'folder_id is required'
            }), 400
        
        # Get credentials
        credentials = get_credentials_from_session()
        if not credentials:
            return jsonify({
                'success': False,
                'message': 'No valid Google Drive credentials found',
                'requires_auth': True
            }), 401
        
        # Initialize folder service
        folder_service = GoogleDriveFolderService(credentials)
        
        # Build breadcrumb
        breadcrumb = []
        current_id = folder_id
        
        # Traverse up the hierarchy
        while current_id and current_id != 'root' and len(breadcrumb) < 10:
            try:
                folder_info = folder_service.get_folder_info(current_id)
                breadcrumb.insert(0, {
                    'id': current_id,
                    'name': folder_info.get('name', 'Unknown'),
                    'depth': folder_info.get('depth', 0)
                })
                
                # Get parent
                parents = folder_info.get('parents', [])
                current_id = parents[0] if parents else 'root'
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error getting folder info for breadcrumb {current_id}: {e}")
                break
        
        # Add root if not already there
        if not breadcrumb or breadcrumb[0]['id'] != 'root':
            breadcrumb.insert(0, {
                'id': 'root',
                'name': 'My Drive',
                'depth': 0
            })
        
        return jsonify({
            'success': True,
            'breadcrumb': breadcrumb,
            'total_levels': len(breadcrumb),
            'timestamp': datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Error getting breadcrumb: {e}")
        return jsonify({
            'success': False,
            'message': f'Failed to get breadcrumb: {str(e)}'
        }), 500

@lazy_folder_bp.route('/validate_selection', methods=['POST', 'OPTIONS'])
@cross_origin(origins=['http://localhost:3000'], supports_credentials=True)
@lazy_folder_rate_limit('folder_info')
def validate_folder_selection():
    """
    Validate if selected folders meet the depth requirements
    
    Request JSON:
    {
        "folder_ids": ["id1", "id2", "id3"]
    }
    
    Response:
    {
        "success": true,
        "valid_selections": [...],
        "invalid_selections": [...],
        "total_valid": 2
    }
    """
    try:
        data = request.get_json()
        folder_ids = data.get('folder_ids', [])
        
        if not folder_ids:
            return jsonify({
                'success': False,
                'message': 'folder_ids array is required'
            }), 400
        
        # Get credentials
        credentials = get_credentials_from_session()
        if not credentials:
            return jsonify({
                'success': False,
                'message': 'No valid Google Drive credentials found',
                'requires_auth': True
            }), 401
        
        # Initialize folder service
        folder_service = GoogleDriveFolderService(credentials)
        
        valid_selections = []
        invalid_selections = []
        
        for folder_id in folder_ids:
            try:
                depth = folder_service.calculate_folder_depth(folder_id)
                selectable = folder_service.is_selectable_folder(depth)
                folder_info = folder_service.get_folder_info(folder_id)
                
                selection_info = {
                    'id': folder_id,
                    'name': folder_info.get('name', 'Unknown'),
                    'depth': depth,
                    'selectable': selectable,
                    'path': folder_info.get('path', ''),
                    'reason': 'Valid camera folder' if selectable else f'Wrong depth (level {depth}, need level 4)'
                }
                
                if selectable:
                    valid_selections.append(selection_info)
                else:
                    invalid_selections.append(selection_info)
                    
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error validating folder {folder_id}: {e}")
                invalid_selections.append({
                    'id': folder_id,
                    'name': 'Unknown',
                    'depth': -1,
                    'selectable': False,
                    'path': '',
                    'reason': f'Validation error: {str(e)}'
                })
        
        return jsonify({
            'success': True,
            'valid_selections': valid_selections,
            'invalid_selections': invalid_selections,
            'total_valid': len(valid_selections),
            'total_invalid': len(invalid_selections),
            'timestamp': datetime.now().isoformat()
        }), 200
        
    except Exception as e:
        logger.error(f"‚ùå Error validating folder selection: {e}")
        return jsonify({
            'success': False,
            'message': f'Failed to validate selection: {str(e)}'
        }), 500
```
## üìÑ File: `onvif_client.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/onvif_client.py`

```python
# onvif_client.py - ONVIF cho VTrack
import logging
import socket
import requests
from typing import Dict

logger = logging.getLogger(__name__)

class VTrackOnvifClient:
    def __init__(self):
        self.connected_cameras = {}
        
    def test_device_connection(self, ip: str, port: int, username: str = '', password: str = '') -> Dict:
        """Test ONVIF connection - discover multiple cameras from multiple ports"""
        logger.info(f"üéØ Testing ONVIF multiple camera discovery on {ip}")
        
        try:
            # Multiple ports for docker-compose setup
            ports_to_test = [1000, 1001, 1002] if port in [80, 1000] else [port]
            
            discovered_cameras = []
            accessible_ports = []
            
            for test_port in ports_to_test:
                try:
                    # Test socket connection
                    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                    sock.settimeout(3)
                    result = sock.connect_ex((ip, test_port))
                    sock.close()
                    
                    if result == 0:
                        logger.info(f"‚úÖ Port {test_port} accessible")
                        
                        # Test ONVIF service
                        camera = self._test_single_port(ip, test_port, username, password)
                        if camera:
                            discovered_cameras.append(camera)
                            accessible_ports.append(test_port)
                            logger.info(f"‚úÖ Camera discovered on port {test_port}: {camera['name']}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Port {test_port} accessible but no ONVIF camera")
                    else:
                        logger.info(f"‚ùå Port {test_port} not accessible")
                        
                except Exception as port_error:
                    logger.warning(f"‚ùå Error testing port {test_port}: {port_error}")
                    continue
            
            if discovered_cameras:
                return {
                    'accessible': True,
                    'message': f'ONVIF Multi-Camera Discovery - Found {len(discovered_cameras)} camera(s) on ports: {accessible_ports}',
                    'source_type': 'nvr',
                    'protocol': 'onvif',
                    'cameras': discovered_cameras,
                    'device_info': {
                        'manufacturer': 'Multiple ONVIF Devices',
                        'model': 'Multi-Camera System',
                        'firmware': 'Various',
                        'total_cameras': len(discovered_cameras),
                        'discovered_ports': accessible_ports
                    }
                }
            else:
                return {
                    'accessible': False,
                    'message': f'No ONVIF cameras found on {ip} ports: {ports_to_test}',
                    'source_type': 'nvr',
                    'protocol': 'onvif',
                    'cameras': []
                }
                
        except Exception as e:
            logger.error(f"‚ùå Multiple camera discovery failed: {e}")
            return {
                'accessible': False,
                'message': f'Discovery error: {str(e)}',
                'source_type': 'nvr',
                'protocol': 'onvif',
                'cameras': []
            }

    def _test_single_port(self, ip: str, port: int, username: str = '', password: str = '') -> Dict:
        """Test single ONVIF camera on specific port"""
        try:
            soap_request = '''<?xml version="1.0" encoding="UTF-8"?>
<soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope" xmlns:tds="http://www.onvif.org/ver10/device/wsdl">
<soap:Header/>
<soap:Body>
<tds:GetDeviceInformation/>
</soap:Body>
</soap:Envelope>'''
            
            headers = {
                'Content-Type': 'application/soap+xml; charset=utf-8',
                'Content-Length': str(len(soap_request))
            }
            
            response = requests.post(
                f'http://{ip}:{port}/onvif/device_service',
                data=soap_request,
                headers=headers,
                timeout=5
            )
            
            if response.status_code == 200 and 'GetDeviceInformationResponse' in response.text:
                # Parse device info
                manufacturer = self._extract_xml_value(response.text, 'tds:Manufacturer', 'ACME Security')
                model = self._extract_xml_value(response.text, 'tds:Model', f'Camera-{port}')
                firmware = self._extract_xml_value(response.text, 'tds:FirmwareVersion', '2.0')
                
                # Port-based camera mapping
                camera_names = {
                    1000: "Front Door Camera",
                    1001: "Parking Lot Camera", 
                    1002: "Warehouse Camera"
                }
                
                rtsp_ports = {
                    1000: 8554,
                    1001: 8555,
                    1002: 8556
                }
                
                resolutions = {
                    1000: "1920x1080",
                    1001: "1280x720",
                    1002: "800x600"
                }
                
                codecs = {
                    1000: "H264",
                    1001: "H265", 
                    1002: "MPEG4"
                }
                
                camera_name = camera_names.get(port, f"Camera Port {port}")
                rtsp_port = rtsp_ports.get(port, 8554)
                resolution = resolutions.get(port, "640x480")
                codec = codecs.get(port, "H264")
                
                return {
                    'id': f"onvif_{ip}_{port}",
                    'name': camera_name,
                    'description': f"ONVIF {model} ({firmware})",
                    'stream_url': f"rtsp://{ip}:{rtsp_port}/stream",
                    'resolution': resolution,
                    'codec': codec,
                    'capabilities': ['recording'] + (['ptz'] if port == 1000 else []),
                    'onvif_port': port,
                    'rtsp_port': rtsp_port,
                    'manufacturer': manufacturer,
                    'model': model,
                    'firmware': firmware
                }
            else:
                return None
                
        except Exception as e:
            logger.warning(f"Failed to test port {port}: {e}")
            return None

    def _extract_xml_value(self, xml_text: str, tag: str, default: str = '') -> str:
        """Extract value from XML tag"""
        try:
            start_tag = f'<{tag}>'
            end_tag = f'</{tag}>'
            if start_tag in xml_text:
                start = xml_text.find(start_tag) + len(start_tag)
                end = xml_text.find(end_tag)
                return xml_text[start:end].strip() or default
            return default
        except:
            return default

# Global instance
onvif_client = VTrackOnvifClient()
```
## üìÑ File: `google_drive_service.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/sources/google_drive_service.py`

```python
#!/usr/bin/env python3

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from google.oauth2.credentials import Credentials
import time
import logging
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

class GoogleDriveFolderService:
    """Service class for Google Drive folder operations with lazy loading support"""
    
    def __init__(self, credentials: Credentials):
        """Initialize service with Google Drive credentials"""
        self.credentials = credentials
        self.service = build('drive', 'v3', credentials=credentials)
        self.cache = {}
        self.cache_duration = 180  # 3 minutes cache
    
    def _get_cache_key(self, operation: str, *args) -> str:
        """Generate cache key for operations"""
        return f"{operation}:{'_'.join(str(arg) for arg in args)}"
    
    def _is_cache_valid(self, cache_key: str) -> bool:
        """Check if cached data is still valid"""
        if cache_key not in self.cache:
            return False
        
        cached_time = self.cache[cache_key].get('timestamp', 0)
        return time.time() - cached_time < self.cache_duration
    
    def _set_cache(self, cache_key: str, data: any):
        """Cache data with timestamp"""
        self.cache[cache_key] = {
            'data': data,
            'timestamp': time.time()
        }
    
    def _get_cache(self, cache_key: str) -> any:
        """Get cached data if valid"""
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]['data']
        return None
    
    def get_subfolders(self, parent_id: str = 'root', max_results: int = 50) -> List[Dict]:
        """
        Get subfolders of a parent folder with caching
        
        Args:
            parent_id: Parent folder ID ('root' for root folders)
            max_results: Maximum number of folders to return
            
        Returns:
            List of folder dictionaries with id, name, parents, createdTime
        """
        cache_key = self._get_cache_key('subfolders', parent_id, max_results)
        cached_result = self._get_cache(cache_key)
        
        if cached_result is not None:
            logger.debug(f"üìã Cache hit for subfolders: {parent_id}")
            return cached_result
        
        try:
            logger.info(f"üìÇ Fetching subfolders for parent: {parent_id}")
            
            # Build query for folders only
            if parent_id == 'root':
                query = "mimeType='application/vnd.google-apps.folder' and 'root' in parents and trashed=false"
            else:
                query = f"mimeType='application/vnd.google-apps.folder' and '{parent_id}' in parents and trashed=false"
            
            results = self.service.files().list(
                q=query,
                pageSize=min(max_results, 100),  # Google Drive max is 100
                fields="files(id, name, parents, createdTime, modifiedTime)",
                orderBy="name"
            ).execute()
            
            folders = results.get('files', [])
            
            # Format folder data
            formatted_folders = []
            for folder in folders:
                formatted_folder = {
                    'id': folder['id'],
                    'name': folder['name'],
                    'type': 'folder',
                    'parent_id': parent_id,
                    'parents': folder.get('parents', []),
                    'created': folder.get('createdTime'),
                    'modified': folder.get('modifiedTime')
                }
                formatted_folders.append(formatted_folder)
            
            # Cache the result
            self._set_cache(cache_key, formatted_folders)
            
            logger.info(f"‚úÖ Found {len(formatted_folders)} subfolders in {parent_id}")
            return formatted_folders
            
        except HttpError as e:
            logger.error(f"‚ùå HTTP error getting subfolders for {parent_id}: {e}")
            return []
        except Exception as e:
            logger.error(f"‚ùå Error getting subfolders for {parent_id}: {e}")
            return []
    
    def calculate_folder_depth(self, folder_id: str) -> int:
        """
        Calculate the depth level of a folder (0=root, 1=level1, etc.)
        
        Args:
            folder_id: Folder ID to calculate depth for
            
        Returns:
            Integer depth level (0-based)
        """
        if folder_id == 'root':
            return 0
        
        cache_key = self._get_cache_key('depth', folder_id)
        cached_result = self._get_cache(cache_key)
        
        if cached_result is not None:
            return cached_result
        
        try:
            depth = 0
            current_id = folder_id
            
            # Traverse up the folder hierarchy
            while current_id != 'root' and depth < 10:  # Prevent infinite loops
                try:
                    folder_info = self.service.files().get(
                        fileId=current_id,
                        fields="parents"
                    ).execute()
                    
                    parents = folder_info.get('parents', [])
                    if not parents:
                        break
                    
                    current_id = parents[0]  # Use first parent
                    depth += 1
                    
                    # Root check
                    if current_id == 'root':
                        break
                        
                except HttpError as e:
                    logger.warning(f"‚ö†Ô∏è Cannot get parent for {current_id}: {e}")
                    break
            
            # Cache the result
            self._set_cache(cache_key, depth)
            
            logger.debug(f"üìè Folder {folder_id} is at depth {depth}")
            return depth
            
        except Exception as e:
            logger.error(f"‚ùå Error calculating depth for {folder_id}: {e}")
            return 0
    
    def build_folder_path(self, folder_id: str) -> str:
        """
        Build the full path string for a folder
        
        Args:
            folder_id: Folder ID to build path for
            
        Returns:
            Full folder path string (e.g., "/Project/Area/Date/Camera")
        """
        if folder_id == 'root':
            return "/My Drive"
        
        cache_key = self._get_cache_key('path', folder_id)
        cached_result = self._get_cache(cache_key)
        
        if cached_result is not None:
            return cached_result
        
        try:
            path_parts = []
            current_id = folder_id
            
            # Traverse up the hierarchy collecting names
            while current_id != 'root' and len(path_parts) < 10:
                try:
                    folder_info = self.service.files().get(
                        fileId=current_id,
                        fields="name, parents"
                    ).execute()
                    
                    folder_name = folder_info.get('name', 'Unknown')
                    path_parts.insert(0, folder_name)
                    
                    parents = folder_info.get('parents', [])
                    if not parents:
                        break
                    
                    current_id = parents[0]
                    
                except HttpError as e:
                    logger.warning(f"‚ö†Ô∏è Cannot get folder info for {current_id}: {e}")
                    break
            
            # Build full path
            if path_parts:
                full_path = "/My Drive/" + "/".join(path_parts)
            else:
                full_path = "/My Drive"
            
            # Cache the result
            self._set_cache(cache_key, full_path)
            
            logger.debug(f"üìÅ Folder path for {folder_id}: {full_path}")
            return full_path
            
        except Exception as e:
            logger.error(f"‚ùå Error building path for {folder_id}: {e}")
            return "/My Drive/Unknown"
    
    def is_selectable_folder(self, folder_depth: int) -> bool:
        """
        Check if a folder at given depth can be selected
        
        Args:
            folder_depth: Depth level of the folder
            
        Returns:
            True if folder can be selected (depth == 4), False otherwise
        """
        return folder_depth == 4
    
    def get_folder_info(self, folder_id: str) -> Dict:
        """
        Get comprehensive information about a folder
        
        Args:
            folder_id: Folder ID to get info for
            
        Returns:
            Dictionary with folder information
        """
        cache_key = self._get_cache_key('info', folder_id)
        cached_result = self._get_cache(cache_key)
        
        if cached_result is not None:
            return cached_result
        
        try:
            folder_info = self.service.files().get(
                fileId=folder_id,
                fields="id, name, parents, createdTime, modifiedTime, size, mimeType"
            ).execute()
            
            depth = self.calculate_folder_depth(folder_id)
            path = self.build_folder_path(folder_id)
            
            info = {
                'id': folder_info['id'],
                'name': folder_info['name'],
                'parents': folder_info.get('parents', []),
                'created': folder_info.get('createdTime'),
                'modified': folder_info.get('modifiedTime'),
                'depth': depth,
                'path': path,
                'selectable': self.is_selectable_folder(depth),
                'mime_type': folder_info.get('mimeType')
            }
            
            # Cache the result
            self._set_cache(cache_key, info)
            
            return info
            
        except HttpError as e:
            logger.error(f"‚ùå HTTP error getting folder info for {folder_id}: {e}")
            return {}
        except Exception as e:
            logger.error(f"‚ùå Error getting folder info for {folder_id}: {e}")
            return {}
    
    def search_folders(self, query: str, max_results: int = 20) -> List[Dict]:
        """
        Search for folders by name
        
        Args:
            query: Search query string
            max_results: Maximum number of results
            
        Returns:
            List of matching folders
        """
        try:
            logger.info(f"üîç Searching folders: {query}")
            
            # Escape query for Google Drive search
            escaped_query = query.replace("'", "\\'").replace("\\", "\\\\")
            
            search_query = f"mimeType='application/vnd.google-apps.folder' and name contains '{escaped_query}' and trashed=false"
            
            results = self.service.files().list(
                q=search_query,
                pageSize=min(max_results, 100),
                fields="files(id, name, parents, createdTime)",
                orderBy="name"
            ).execute()
            
            folders = results.get('files', [])
            
            # Add depth and path information
            enriched_folders = []
            for folder in folders:
                depth = self.calculate_folder_depth(folder['id'])
                path = self.build_folder_path(folder['id'])
                
                enriched_folder = {
                    'id': folder['id'],
                    'name': folder['name'],
                    'parents': folder.get('parents', []),
                    'created': folder.get('createdTime'),
                    'depth': depth,
                    'path': path,
                    'selectable': self.is_selectable_folder(depth)
                }
                enriched_folders.append(enriched_folder)
            
            logger.info(f"‚úÖ Found {len(enriched_folders)} folders matching '{query}'")
            return enriched_folders
            
        except Exception as e:
            logger.error(f"‚ùå Error searching folders: {e}")
            return []
    
    def has_subfolders(self, folder_id: str) -> bool:
        """
        Check if a folder has any subfolders (for UI expand indicators)
        
        Args:
            folder_id: Folder ID to check
            
        Returns:
            True if folder has subfolders, False otherwise
        """
        cache_key = self._get_cache_key('has_subfolders', folder_id)
        cached_result = self._get_cache(cache_key)
        
        if cached_result is not None:
            return cached_result
        
        try:
            query = f"mimeType='application/vnd.google-apps.folder' and '{folder_id}' in parents and trashed=false"
            
            results = self.service.files().list(
                q=query,
                pageSize=1,  # Only need to know if any exist
                fields="files(id)"
            ).execute()
            
            has_folders = len(results.get('files', [])) > 0
            
            # Cache the result
            self._set_cache(cache_key, has_folders)
            
            return has_folders
            
        except Exception as e:
            logger.error(f"‚ùå Error checking subfolders for {folder_id}: {e}")
            return False
    
    def get_folder_statistics(self, folder_id: str) -> Dict:
        """
        Get statistics about a folder (file count, total size, etc.)
        
        Args:
            folder_id: Folder ID to get stats for
            
        Returns:
            Dictionary with folder statistics
        """
        try:
            # Get all files in folder
            query = f"'{folder_id}' in parents and trashed=false"
            
            results = self.service.files().list(
                q=query,
                pageSize=1000,  # Get more files for accurate count
                fields="files(id, name, size, mimeType)"
            ).execute()
            
            files = results.get('files', [])
            
            # Calculate statistics
            total_files = len(files)
            total_size = 0
            video_count = 0
            folder_count = 0
            
            video_mimes = [
                'video/mp4', 'video/avi', 'video/mov', 'video/mkv',
                'video/m4v', 'video/wmv', 'video/flv', 'video/webm'
            ]
            
            for file in files:
                mime_type = file.get('mimeType', '')
                size = int(file.get('size', 0))
                
                total_size += size
                
                if mime_type == 'application/vnd.google-apps.folder':
                    folder_count += 1
                elif any(vm in mime_type for vm in video_mimes):
                    video_count += 1
            
            stats = {
                'total_files': total_files,
                'total_size_bytes': total_size,
                'total_size_mb': round(total_size / (1024 * 1024), 2),
                'video_count': video_count,
                'folder_count': folder_count,
                'other_files': total_files - video_count - folder_count
            }
            
            logger.debug(f"üìä Stats for {folder_id}: {stats}")
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå Error getting folder statistics for {folder_id}: {e}")
            return {
                'total_files': 0,
                'total_size_bytes': 0,
                'total_size_mb': 0,
                'video_count': 0,
                'folder_count': 0,
                'other_files': 0
            }
    
    def clear_cache(self):
        """Clear all cached data"""
        self.cache.clear()
        logger.info("üßπ Cleared Google Drive folder service cache")
    
    def get_cache_info(self) -> Dict:
        """Get information about current cache state"""
        valid_entries = 0
        expired_entries = 0
        
        current_time = time.time()
        
        for key, entry in self.cache.items():
            if current_time - entry['timestamp'] < self.cache_duration:
                valid_entries += 1
            else:
                expired_entries += 1
        
        return {
            'total_entries': len(self.cache),
            'valid_entries': valid_entries,
            'expired_entries': expired_entries,
            'cache_duration_seconds': self.cache_duration
        }
```
## üìÑ File: `TG.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/db_utils/TG.py`

```python

```
## üìÑ File: `__init__.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/db_utils/__init__.py`

```python
from .db_utils import find_project_root, get_db_connection

```
## üìÑ File: `db_utils.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/db_utils/db_utils.py`

```python
import sqlite3
import os

# H√†m t√¨m th∆∞ m·ª•c g·ªëc d·ª± √°n d·ª±a tr√™n t√™n th∆∞ m·ª•c
def find_project_root(start_path):
    current_path = os.path.abspath(start_path)
    while os.path.basename(current_path) != "V_Track":
        parent_path = os.path.dirname(current_path)
        if parent_path == current_path:  # ƒê√£ ƒë·∫øn th∆∞ m·ª•c g·ªëc c·ªßa h·ªá th·ªëng (/)
            raise ValueError("Could not find project root (V_Track directory)")
        current_path = parent_path
    return current_path

# X√°c ƒë·ªãnh th∆∞ m·ª•c g·ªëc c·ªßa d·ª± √°n
BASE_DIR = find_project_root(os.path.abspath(__file__))

# ƒê·ªãnh nghƒ©a DB_PATH m·∫∑c ƒë·ªãnh d·ª±a tr√™n BASE_DIR
DEFAULT_DB_PATH = os.path.join(BASE_DIR, "backend/database", "events.db")
os.makedirs(os.path.dirname(DEFAULT_DB_PATH), exist_ok=True)  # T·∫°o th∆∞ m·ª•c database n·∫øu ch∆∞a c√≥

# H√†m l·∫•y DB_PATH t·ª´ processing_config
def get_db_path():
    try:
        conn = sqlite3.connect(DEFAULT_DB_PATH)  # K·∫øt n·ªëi t·∫°m th·ªùi ƒë·ªÉ truy v·∫•n
        cursor = conn.cursor()
        cursor.execute("SELECT db_path FROM processing_config WHERE id = 1")
        result = cursor.fetchone()
        conn.close()
        return result[0] if result else DEFAULT_DB_PATH
    except Exception as e:
        print(f"Error getting DB_PATH from database: {e}")
        return DEFAULT_DB_PATH

DB_PATH = get_db_path()

def get_db_connection():
    if not os.path.exists(DB_PATH):
        raise FileNotFoundError(f"Database file not found: {DB_PATH}")
    if not os.access(DB_PATH, os.R_OK):
        raise PermissionError(f"No read permission for database: {DB_PATH}")
    if not os.access(DB_PATH, os.W_OK):
        raise PermissionError(f"No write permission for database: {DB_PATH}")
    return sqlite3.connect(DB_PATH, check_same_thread=False)

```
## üìÑ File: `__init__.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/account/__init__.py`

```python

```
## üìÑ File: `account.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/account/account.py`

```python

```
## üìÑ File: `query.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/query/query.py`

```python
from flask import Blueprint, request, jsonify
from datetime import datetime
import csv
import io
import os
import base64
import pandas as pd
import json
from io import BytesIO
from modules.db_utils import find_project_root, get_db_connection
from ..utils.file_parser import parse_uploaded_file
from modules.scheduler.db_sync import db_rwlock  # Th√™m import db_rwlock

query_bp = Blueprint('query', __name__)

# X√°c ƒë·ªãnh th∆∞ m·ª•c g·ªëc c·ªßa d·ª± √°n
BASE_DIR = find_project_root(os.path.abspath(__file__))

# ƒê·ªãnh nghƒ©a DB_PATH d·ª±a tr√™n BASE_DIR
DB_PATH = os.path.join(BASE_DIR, "database", "events.db")
os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)

@query_bp.route('/get-csv-headers', methods=['POST'])
def get_csv_headers():
    data = request.get_json()
    file_content = data.get('file_content', '')
    file_path = data.get('file_path', '')
    is_excel = data.get('is_excel', False)

    if file_content:
        if not file_content.strip():
            return jsonify({"error": "File CSV is empty. Please provide a valid CSV file with content."}), 400

        try:
            df = parse_uploaded_file(file_content=file_content, is_excel=is_excel)
            rows = [df.columns.tolist()]
        except Exception as e:
            return jsonify({"error": f"Failed to read file content: {str(e)}. Ensure the content is properly formatted."}), 400
    elif file_path:
        if not os.path.exists(file_path):
            return jsonify({"error": f"File not found at path: {file_path}. Please check the file path and try again."}), 404

        try:
            with open(file_path, "rb") as f:
                file_content = base64.b64encode(f.read()).decode("utf-8")
            df = parse_uploaded_file(file_content=file_content, is_excel=is_excel)
            rows = [df.columns.tolist()]
        except Exception as e:
            return jsonify({"error": f"Failed to read file from path {file_path}: {str(e)}. Ensure the file is accessible and properly formatted."}), 400
    else:
        return jsonify({"error": "No file content or path provided. Please provide either file content or a valid file path."}), 400

    if not rows or len(rows) < 1:
        return jsonify({"error": "CSV file has no header. Please ensure the CSV file contains at least one row with headers."}), 400

    header = rows[0]
    if not header:
        return jsonify({"error": "CSV file header is empty. Please ensure the first row contains valid headers."}), 400

    return jsonify({"headers": header}), 200

@query_bp.route('/parse-csv', methods=['POST'])
def parse_csv():
    data = request.get_json()
    file_content = data.get('file_content', '')
    file_path = data.get('file_path', '')
    column_name = data.get('column_name', 'tracking_codes')
    is_excel = data.get('is_excel', False)

    try:
        if file_content:
            df = parse_uploaded_file(file_content=file_content, is_excel=is_excel)
        elif file_path:
            with open(file_path, "rb") as f:
                file_content = base64.b64encode(f.read()).decode("utf-8")
            df = parse_uploaded_file(file_content=file_content, is_excel=is_excel)
        else:
            return jsonify({"error": "No file provided"}), 400

        if column_name not in df.columns:
            return jsonify({"error": f"C·ªôt '{column_name}' kh√¥ng t·ªìn t·∫°i trong file."}), 400

        values = df[column_name].dropna().astype(str).tolist()
        codes = []
        for val in values:
            # Th·ª≠ c·∫Øt chu·ªói theo d·∫•u ph·∫©y tr∆∞·ªõc
            split_vals = val.split(',')
            if len(split_vals) == 1:  # N·∫øu kh√¥ng c·∫Øt ƒë∆∞·ª£c, th·ª≠ d·∫•u ch·∫•m ph·∫©y
                split_vals = val.split(';')
            codes.extend(v.strip() for v in split_vals if v.strip())
        codes = list(set(codes))  # Lo·∫°i b·ªè tr√πng l·∫∑p

        return jsonify({"tracking_codes": codes}), 200

    except Exception as e:
        return jsonify({"error": f"Failed to parse CSV: {str(e)}. Ensure the file and column name are valid."}), 500

@query_bp.route('/query', methods=['POST'])
def query_events():
    data = request.get_json()
    print(f"Received data: {data}")  # Log d·ªØ li·ªáu nh·∫≠n ƒë∆∞·ª£c
    search_string = data.get('search_string', '')
    default_days = data.get('default_days', 7)  # Th√™m gi√° tr·ªã m·∫∑c ƒë·ªãnh 7 n·∫øu kh√¥ng c√≥ trong request
    from_time = data.get('from_time')
    to_time = data.get('to_time')
    selected_cameras = data.get('selected_cameras', [])  # L·∫•y selected_cameras

    # T√°ch search_string theo d√≤ng v√† lo·∫°i b·ªè s·ªë th·ª© t·ª±
    tracking_codes = []
    if search_string:
        lines = search_string.splitlines()
        for line in lines:
            line = line.strip()
            if line:
                # Lo·∫°i b·ªè s·ªë th·ª© t·ª± (e.g., "1. " ho·∫∑c "2. ")
                code = line.split('. ', 1)[-1].strip()
                if code:
                    tracking_codes.append(code)
    print(f"Parsed tracking_codes from search_string: {tracking_codes}")  # Log tracking_codes ƒë√£ t√°ch

    try:
        if from_time and to_time:
            try:
                from_timestamp = int(datetime.fromisoformat(from_time.replace('Z', '+00:00')).timestamp() * 1000)
                to_timestamp = int(datetime.fromisoformat(to_time.replace('Z', '+00:00')).timestamp() * 1000)
            except ValueError as e:
                return jsonify({"error": f"Invalid time format for from_time or to_time: {str(e)}. Use ISO format (e.g., 2023-10-01T00:00:00Z)."}), 400
        else:
            to_timestamp = int(datetime.now().timestamp() * 1000)
            from_timestamp = to_timestamp - (default_days * 24 * 60 * 60 * 1000)
        print(f"Time range: from_timestamp={from_timestamp}, to_timestamp={to_timestamp}")  # Log kho·∫£ng th·ªùi gian

        with db_rwlock.gen_rlock():  # Th√™m kh√≥a ƒë·ªçc
            conn = get_db_connection()
            cursor = conn.cursor()

            query = """
                SELECT event_id, ts, te, duration, tracking_codes, video_file, packing_time_start, packing_time_end
                FROM events
                WHERE is_processed = 0
            """
            params = []
            # Ch·ªâ th√™m ƒëi·ªÅu ki·ªán th·ªùi gian n·∫øu packing_time_start kh√¥ng null
            if from_timestamp and to_timestamp:
                query += " AND (packing_time_start IS NULL OR (packing_time_start >= ? AND packing_time_start <= ?))"
                params.extend([from_timestamp, to_timestamp])
            if selected_cameras:
                query += " AND camera_name IN ({})".format(','.join('?' * len(selected_cameras)))
                params.extend(selected_cameras)

            print(f"Executing query: {query} with params: {params}")  # Log truy v·∫•n
            cursor.execute(query, params)
            events = cursor.fetchall()
            print(f"Fetched events: {events}")  # Log k·∫øt qu·∫£ truy v·∫•n

            filtered_events = []
            for event in events:
                event_dict = {
                    'event_id': event[0],
                    'ts': event[1],
                    'te': event[2],
                    'duration': event[3],
                    'tracking_codes': event[4],
                    'video_file': event[5],
                    'packing_time_start': event[6],
                    'packing_time_end': event[7]
                }
                print(f"Raw tracking_codes for event {event[0]}: {event[4]}")  # Log gi√° tr·ªã th√¥ c·ªßa tracking_codes
                try:
                    tracking_codes_list = json.loads(event[4]) if event[4] else []
                    if not isinstance(tracking_codes_list, list):
                        raise ValueError("tracking_codes is not a list")
                except Exception:
                    print(f"[WARN] tracking_codes fallback for event {event[0]}")
                    tracking_codes_list = []
                    if event[4]:
                        raw = event[4].strip("[]").replace("'", "").replace('"', "")
                        tracking_codes_list = [code.strip() for code in raw.split(',')]
                print(f"Parsed tracking_codes for event {event[0]}: {tracking_codes_list}")  # Log tracking_codes ƒë√£ parse
                if not tracking_codes:
                    filtered_events.append(event_dict)
                else:
                    for code in tracking_codes:
                        if code in tracking_codes_list:
                            filtered_events.append(event_dict)
                            break
            print(f"Filtered events: {filtered_events}")  # Log k·∫øt qu·∫£ sau khi l·ªçc

            conn.close()
        return jsonify({'events': filtered_events}), 200
    except Exception as e:
        print(f"Error in query_events: {str(e)}")  # Log l·ªói chi ti·∫øt
        return jsonify({"error": f"Failed to query events: {str(e)}. Ensure the database is accessible and the events table exists."}), 500
```
## üìÑ File: `__init__.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/query/__init__.py`

```python

```
## üìÑ File: `trigger_processor.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/trigger_processor.py`

```python
import cv2
import logging
import time
import os
from datetime import timedelta
from modules.db_utils import get_db_connection
from modules.scheduler.db_sync import db_rwlock

def run_trigger_logic(
    core_sampler,
    video_capture,
    video_metadata,
    trigger_roi_coords_for_state_check,
    get_log_handle_callback
):
    core_sampler.logger.info(f"TRIGGER_PROCESSOR: Starting for {video_metadata['base_video_name']}")
    frame_idx_counter_tr = 0
    frame_states_buffer_list_tr = []
    mvd_buffer_list_tr = []
    last_recorded_state_tr = None
    last_recorded_mvd_tr = ""
    second = 0
    current_start_second = 0
    current_end_second = core_sampler.log_segment_duration
    log_file = os.path.join(core_sampler.log_dir_output_segments, f"log_{video_metadata['base_video_name']}_{current_start_second:04d}_{current_end_second:04d}.txt")
    log_file_handle = open(log_file, 'w')
    log_file_handle.write(f"# Start: {current_start_second}, End: {current_end_second}, Start_Time: {(video_metadata['start_time_obj'] + timedelta(seconds=current_start_second)).strftime('%Y-%m-%d %H:%M:%S')}, Camera_Name: {video_metadata['camera_name']}, Video_File: {video_metadata['absolute_video_path']}\n")
    log_file_handle.flush()
    with db_rwlock.gen_wlock():
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT 1 FROM processed_logs WHERE log_file = ?", (log_file,))
        log_exists = cursor.fetchone()
        if not log_exists:
            cursor.execute("INSERT INTO processed_logs (log_file, is_processed) VALUES (?, 0)", (log_file,))
        conn.commit()
        conn.close()
    while video_capture.isOpened():
        ret, bgr_frame = video_capture.read()
        if not ret: break
        frame_idx_counter_tr += 1
        if frame_idx_counter_tr % core_sampler.frame_interval != 0: continue
        state_val, mvd_val = core_sampler._internal_process_frame_qr(
            bgr_frame,
            frame_idx_counter_tr,
            trigger_roi_coords_for_state_check=trigger_roi_coords_for_state_check
        )
        frame_states_buffer_list_tr.append(state_val)
        mvd_buffer_list_tr.append(mvd_val)
        second_in_video = (frame_idx_counter_tr - 1) / core_sampler.fps
        second = round(second_in_video)
        if second >= current_end_second:
            log_file_handle.close()
            current_start_second = current_end_second
            current_end_second += core_sampler.log_segment_duration
            log_file = os.path.join(core_sampler.log_dir_output_segments, f"log_{video_metadata['base_video_name']}_{current_start_second:04d}_{current_end_second:04d}.txt")
            log_file_handle = open(log_file, 'w')
            log_file_handle.write(f"# Start: {current_start_second}, End: {current_end_second}, Start_Time: {(video_metadata['start_time_obj'] + timedelta(seconds=current_start_second)).strftime('%Y-%m-%d %H:%M:%S')}, Camera_Name: {video_metadata['camera_name']}, Video_File: {video_metadata['absolute_video_path']}\n")
            log_file_handle.flush()
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("SELECT 1 FROM processed_logs WHERE log_file = ?", (log_file,))
                log_exists = cursor.fetchone()
                if not log_exists:
                    cursor.execute("INSERT INTO processed_logs (log_file, is_processed) VALUES (?, 0)", (log_file,))
                conn.commit()
                conn.close()
        if len(frame_states_buffer_list_tr) == 5:
            on_count_tr = frame_states_buffer_list_tr.count("On")
            determined_final_state_tr = "On" if on_count_tr >= 3 else "Off"
            determined_final_mvd_tr = mvd_buffer_list_tr[-1] if mvd_buffer_list_tr else ""
            if determined_final_state_tr != last_recorded_state_tr or determined_final_mvd_tr != last_recorded_mvd_tr:
                log_handle_tr = get_log_handle_callback(second_in_video)
                log_handle_tr.write(f"{second},{determined_final_state_tr},{determined_final_mvd_tr}\n")
                log_handle_tr.flush()
                last_recorded_state_tr = determined_final_state_tr
                last_recorded_mvd_tr = determined_final_mvd_tr
            frame_states_buffer_list_tr.clear()
            mvd_buffer_list_tr.clear()
    log_file_handle.close()
    core_sampler.logger.info(f"TRIGGER_PROCESSOR: Finished for {video_metadata['base_video_name']}")
```
## üìÑ File: `IdleMonitor.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/IdleMonitor.py`

```python
import cv2
import mediapipe as mp
import queue
import os
import logging
from datetime import datetime
import uuid
from modules.config.logging_config import get_logger

class IdleMonitor:
    def __init__(self, processing_config=None):
        """Kh·ªüi t·∫°o IdleMonitor v·ªõi queue v√† processing_config."""
        self.video_file = None
        self.logger = get_logger("app", {"video_id": None})
        self.logger.setLevel(logging.INFO)
        self.work_block_queue = queue.Queue()  # Queue l∆∞u work block
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.6)
        self.IDLE_GAP = 120  # seconds
        self.HAND_SAMPLE_INTERVAL = 1  # seconds
        self.MIN_WORK_BLOCK = 10  # seconds
        self.MIN_PACKING_TIME = processing_config.get('min_packing_time', 5) if processing_config else 5  # seconds
        self.CHUNK_SIZE = int(self.MIN_PACKING_TIME * 0.8) # seconds
        self.video_id = str(uuid.uuid4())  # ƒê·ªãnh danh duy nh·∫•t cho video

    def process_video(self, video_file, camera_name, packing_area):
        """X·ª≠ l√Ω video, x√°c ƒë·ªãnh work block, l∆∞u v√†o queue, d√πng packing_area t·ª´ program_runner."""
        self.video_file = video_file
        self.logger = get_logger("app", {"video_id": os.path.basename(self.video_file)})
        # ƒê·ªçc video
        cap = cv2.VideoCapture(video_file)
        if not cap.isOpened():
            self.logger.error(f"Failed to open video: {video_file}")
            return

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        video_duration = int(total_frames / fps)
        self.logger.info(f"Processing video: {video_file}, Duration: {video_duration}s, Video ID: {self.video_id}")

        # Ki·ªÉm tra packing_area
        roi = packing_area
        if not roi:
            self.logger.warning(f"No packing_area for {camera_name}, using full frame")
            roi = None

        hand_timeline = []
        event_id = 0

        # Qu√©t video theo chunk
        sec = 0
        while sec < video_duration:
            chunk_end = min(sec + self.CHUNK_SIZE, video_duration)
            chunk_has_hand = False
            check_time = sec
            # Qu√©t ƒë·ªÅu to√†n chunk
            while check_time < chunk_end:
                frame_id = int(check_time * fps)
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_id)
                ret, frame = cap.read()
                if not ret:
                    break

                # √Åp d·ª•ng ROI n·∫øu c√≥
                if roi:
                    x, y, w, h = roi
                    frame_height, frame_width = frame.shape[:2]
                    if w > 0 and h > 0 and y + h <= frame_height and x + w <= frame_width:
                        frame = frame[y:y+h, x:x+w]
                    else:
                        self.logger.warning(f"Invalid ROI for frame {frame_id}: {roi}")
                        frame = frame

                # Hand detection
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = self.hands.process(rgb_frame)
                if results.multi_hand_landmarks is not None:
                    chunk_has_hand = True
                    break
                check_time += self.HAND_SAMPLE_INTERVAL

            hand_timeline.append(chunk_has_hand)
            #self.logger.info(f"[Chunk {sec:04d}-{chunk_end:04d}s] Hand: {chunk_has_hand}, Video ID: {self.video_id}")
            sec += self.CHUNK_SIZE

        # Ph√°t hi·ªán idle block
        idle_gap_list = []
        idle_candidate_start = None
        for tick_time, hand_detected in enumerate(hand_timeline):
            if hand_detected:
                if idle_candidate_start is not None:
                    idle_duration = tick_time - idle_candidate_start
                    if idle_duration * self.CHUNK_SIZE >= self.IDLE_GAP:
                        idle_gap_list.append({'start': idle_candidate_start * self.CHUNK_SIZE, 'end': tick_time * self.CHUNK_SIZE})
                    idle_candidate_start = None
            else:
                if idle_candidate_start is None:
                    idle_candidate_start = tick_time

        if idle_candidate_start is not None:
            idle_duration = len(hand_timeline) - idle_candidate_start
            if idle_duration * self.CHUNK_SIZE >= self.IDLE_GAP:
                idle_gap_list.append({'start': idle_candidate_start * self.CHUNK_SIZE, 'end': len(hand_timeline) * self.CHUNK_SIZE})

        # Ph√°t hi·ªán work block
        work_blocks = []
        prev_end = 0
        for idle in idle_gap_list:
            if idle['start'] > prev_end:
                work_blocks.append({'start': prev_end, 'end': idle['start']})
            prev_end = idle['end']
        if prev_end < len(hand_timeline) * self.CHUNK_SIZE:
            work_blocks.append({'start': prev_end, 'end': len(hand_timeline) * self.CHUNK_SIZE})

        # L∆∞u work block v√†o queue
        for idx, block in enumerate(work_blocks):
            duration = block['end'] - block['start']
            event_id += 1
            if duration < self.MIN_WORK_BLOCK:
                self.logger.info(f"Skipping work block {idx+1}: duration {duration}s < {self.MIN_WORK_BLOCK}s")
                continue
            self.work_block_queue.put({
                'video_id': self.video_id,
                'event_id': f"evt_{event_id:03d}",
                'file_path': video_file,
                'start_time': block['start'],
                'end_time': block['end']
            })
            self.logger.info(f"Work block {idx+1}: {block['start']}s --> {block['end']}s (duration: {duration}s), Video ID: {self.video_id}")
            if duration < self.MIN_WORK_BLOCK:
                self.logger.warning(f"Block shorter than {self.MIN_WORK_BLOCK}s")

        cap.release()
        self.hands.close()

    def get_work_block_queue(self):
        """Tr·∫£ v·ªÅ queue ch·ª©a work block."""
        return self.work_block_queue
```
## üìÑ File: `qr_detector.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/qr_detector.py`

```python
import cv2
import os
import json
import logging
import queue
import threading
import time
import glob
import traceback
from datetime import datetime
from modules.config.logging_config import get_logger


# ƒê·∫£m b·∫£o th∆∞ m·ª•c LOG t·ªìn t·∫°i
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
LOG_DIR = os.path.join(BASE_DIR, "resources", "output_clips", "LOG")
os.makedirs(LOG_DIR, exist_ok=True)

# Kh·ªüi t·∫°o logger m√† kh√¥ng s·ª≠ d·ª•ng video_path
logger = get_logger(__name__, {"module": "qr_detector"})
logger.info("Logging initialized")

# ƒê∆∞·ªùng d·∫´n t·ªõi m√¥ h√¨nh WeChat QRCode (t∆∞∆°ng ƒë·ªëi)
MODEL_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "models", "wechat_qr")
DETECT_PROTO = os.path.join(MODEL_DIR, "detect.prototxt")
DETECT_MODEL = os.path.join(MODEL_DIR, "detect.caffemodel")
SR_PROTO = os.path.join(MODEL_DIR, "sr.prototxt")
SR_MODEL = os.path.join(MODEL_DIR, "sr.caffemodel")

# ƒê∆∞·ªùng d·∫´n l∆∞u ·∫£nh
CAMERA_ROI_DIR = os.path.join(BASE_DIR, "resources", "output_clips", "CameraROI")

def select_qr_roi(video_path, camera_id, roi_frame_path, step="mvd"):
    """
    Cho ph√©p ng∆∞·ªùi d√πng v·∫Ω ROI cho m√£ QR (1 ho·∫∑c 2 v√πng cho mvd), sau ƒë√≥ x·ª≠ l√Ω video.
    Args:
        video_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file video.
        camera_id (str): ID c·ªßa camera.
        roi_frame_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh t·∫°m cu·ªëi c√πng t·ª´ b∆∞·ªõc tr∆∞·ªõc (ƒë√£ c√≥ ROI v·∫Ω s·∫µn).
        step (str): Giai ƒëo·∫°n hi·ªán t·∫°i (mvd).
    Returns:
        dict: {'success': bool, 'rois': [{'x': int, 'y': int, 'w': int, 'h': int, 'type': str}, ...], 
               'roi_frame': str, 'qr_detected': bool, 'qr_detected_roi1': bool, 'qr_detected_roi2': bool, 
               'qr_content': str, 'trigger_detected': bool, 'table_type': str}
              ho·∫∑c {'success': false, 'error': str}
    """
    try:
        logger.debug(f"[MVD] B·∫Øt ƒë·∫ßu select_qr_roi v·ªõi video_path: {video_path}, camera_id: {camera_id}, roi_frame_path: {roi_frame_path}, step: {step}")

        # Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa c√°c m√¥ h√¨nh
        for model_file in [DETECT_PROTO, DETECT_MODEL, SR_PROTO, SR_MODEL]:
            logger.debug(f"[MVD] Ki·ªÉm tra file m√¥ h√¨nh: {model_file}")
            if not os.path.exists(model_file):
                logger.error(f"[MVD] File m√¥ h√¨nh kh√¥ng t√¨m th·∫•y: {model_file}")
                cv2.destroyAllWindows()
                return {"success": False, "error": f"File m√¥ h√¨nh kh√¥ng t√¨m th·∫•y: {model_file}"}

        # Ki·ªÉm tra file ·∫£nh v√† video
        logger.debug(f"[MVD] Ki·ªÉm tra ·∫£nh t·∫°m: {roi_frame_path}")
        if not os.path.exists(roi_frame_path):
            logger.error(f"[MVD] ·∫¢nh t·∫°m kh√¥ng t·ªìn t·∫°i: {roi_frame_path}")
            cv2.destroyAllWindows()
            return {"success": False, "error": f"·∫¢nh t·∫°m kh√¥ng t·ªìn t·∫°i: {roi_frame_path}"}
        
        logger.debug(f"[MVD] Ki·ªÉm tra video: {video_path}")
        if not os.path.exists(video_path):
            logger.error(f"[MVD] Video kh√¥ng t·ªìn t·∫°i: {video_path}")
            cv2.destroyAllWindows()
            return {"success": False, "error": f"Video kh√¥ng t·ªìn t·∫°i: {video_path}"}

        # ƒê·ªçc frame t·ª´ ·∫£nh t·∫°m
        try:
            logger.debug(f"[MVD] ƒê·ªçc ·∫£nh t·∫°m: {roi_frame_path}")
            frame = cv2.imread(roi_frame_path)
            if frame is None:
                logger.error(f"[MVD] Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh t·∫°m: {roi_frame_path}")
                cv2.destroyAllWindows()
                return {"success": False, "error": f"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh t·∫°m: {roi_frame_path}"}
            logger.debug(f"[MVD] K√≠ch th∆∞·ªõc ·∫£nh t·∫°m: {frame.shape[:2]}")
        except Exception as e:
            logger.error(f"[MVD] OpenCV imread error: {str(e)}\n{traceback.format_exc()}")
            cv2.destroyAllWindows()
            return {"success": False, "error": f"OpenCV imread error: {str(e)}"}

        # Ch·ªçn lo·∫°i b√†n ƒë√≥ng g√≥i
        table_type = None
        while table_type is None:
            current_frame = frame.copy()
            window_title = "**** Nhan 1 cho ban tieu chuan, 2 cho ban khong tieu chuan, q thoat ****"
            cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)
            cv2.imshow(window_title, current_frame)
            key = cv2.waitKey(0) & 0xFF
            cv2.destroyAllWindows()
            if key == ord('1'):
                table_type = "standard"
                logger.debug("[MVD] Ch·ªçn b√†n ti√™u chu·∫©n")
            elif key == ord('2'):
                table_type = "non_standard"
                logger.debug("[MVD] Ch·ªçn b√†n kh√¥ng ti√™u chu·∫©n")
            elif key == ord('q'):
                logger.debug("[MVD] Ng∆∞·ªùi d√πng tho√°t")
                cv2.destroyAllWindows()
                return {"success": False, "error": "Ng∆∞·ªùi d√πng tho√°t"}
            else:
                logger.debug("[MVD] Ph√≠m kh√¥ng h·ª£p l·ªá, hi·ªÉn th·ªã l·∫°i h∆∞·ªõng d·∫´n")
                continue

        while True:
            # T·∫°o b·∫£n sao m·ªõi c·ªßa frame m·ªói l·∫ßn v·∫Ω l·∫°i
            current_frame = frame.copy()
            rois = []

            # V·∫Ω ROI 1 (m√£ QR)
            window_title = "**** Keo chuot ve vung ma QR. Enter xac nhan, Esc huy ****"
            try:
                logger.debug("[MVD] G·ªçi cv2.selectROI cho MVD ROI 1")
                cv2.destroyAllWindows()
                cv2.startWindowThread()
                cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)
                roi1 = cv2.selectROI(window_title, current_frame, showCrosshair=True, fromCenter=False)
                cv2.destroyAllWindows()
                x1, y1, w1, h1 = map(int, roi1)
                if w1 > 0 and h1 > 0:
                    rois.append({"x": x1, "y": y1, "w": w1, "h": h1, "type": "mvd"})
                    cv2.rectangle(current_frame, (x1, y1), (x1 + w1, y1 + h1), (0, 0, 255), 2)  # M√†u ƒë·ªè cho MVD
                    cv2.putText(current_frame, "ShippingLabel", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    logger.debug(f"[MVD] ƒê√£ ch·ªçn MVD ROI 1: x={x1}, y={y1}, w={w1}, h={h1}")
                    cv2.namedWindow("**** Da ve vung ma QR ****", cv2.WINDOW_NORMAL)
                    cv2.imshow("**** Da ve vung ma QR ****", current_frame)
                    cv2.waitKey(500)
                    cv2.destroyAllWindows()
                else:
                    logger.debug("[MVD] ROI 1 kh√¥ng h·ª£p l·ªá")
                    cv2.namedWindow("**** Loi: ROI khong hop le. Ve lai vung ma QR ****", cv2.WINDOW_NORMAL)
                    cv2.imshow("**** Loi: ROI khong hop le. Ve lai vung ma QR ****", current_frame)
                    cv2.waitKey(2000)
                    cv2.destroyAllWindows()
                    continue

                # Ch·ªâ v·∫Ω ROI 2 (trigger) cho b√†n ti√™u chu·∫©n
                if table_type == "standard":
                    window_title = "**** Ve vung ma trigger (QR: TimeGo). Enter xac nhan, Esc huy ****"
                    roi2_label = "Trigger"
                    logger.debug("[MVD] G·ªçi cv2.selectROI cho ROI 2")
                    cv2.destroyAllWindows()
                    cv2.startWindowThread()
                    cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)
                    roi2 = cv2.selectROI(window_title, current_frame, showCrosshair=True, fromCenter=False)
                    cv2.destroyAllWindows()
                    x2, y2, w2, h2 = map(int, roi2)
                    if w2 > 0 and h2 > 0:
                        roi_type = "trigger"
                        rois.append({"x": x2, "y": y2, "w": w2, "h": h2, "type": roi_type})
                        cv2.rectangle(current_frame, (x2, y2), (x2 + w2, y2 + h2), (0, 0, 255), 2)  # M√†u ƒë·ªè
                        cv2.putText(current_frame, roi2_label, (x2, y2 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                        logger.debug(f"[MVD] ƒê√£ ch·ªçn ROI 2: x={x2}, y={y2}, w={w2}, h={h2}, type={roi_type}")
            except Exception as e:
                logger.error(f"[MVD] OpenCV selectROI error: {str(e)}\n{traceback.format_exc()}")
                cv2.destroyAllWindows()
                return {"success": False, "error": f"OpenCV selectROI error: {str(e)}"}

            # L∆∞u ·∫£nh v√†o CameraROI n·∫øu c√≥ ROI h·ª£p l·ªá
            if rois:
                roi_frame_path_new = os.path.join(CAMERA_ROI_DIR, f"camera_{camera_id}_roi_MVD.jpg")
                try:
                    logger.debug(f"[MVD] L∆∞u ·∫£nh v·ªõi ROI v√†o: {roi_frame_path_new}")
                    ret = cv2.imwrite(roi_frame_path_new, current_frame)
                    if not ret:
                        logger.error(f"[MVD] Kh√¥ng th·ªÉ l∆∞u ·∫£nh t·∫°i: {roi_frame_path_new}")
                        cv2.destroyAllWindows()
                        return {"success": False, "error": f"Kh√¥ng th·ªÉ l∆∞u ·∫£nh t·∫°i {roi_frame_path_new}"}
                    logger.info(f"[MVD] ƒê√£ l∆∞u frame v·ªõi ROI v√†o: {roi_frame_path_new}")
                except Exception as e:
                    logger.error(f"[MVD] OpenCV imwrite error: {str(e)}\n{traceback.format_exc()}")
                    cv2.destroyAllWindows()
                    return {"success": False, "error": f"OpenCV imwrite error: {str(e)}"}
                break
            else:
                logger.debug("[MVD] Kh√¥ng ch·ªçn ƒë∆∞·ª£c ROI h·ª£p l·ªá, hi·ªÉn th·ªã l·∫°i ·∫£nh tr∆∞·ªõc ƒë√≥ ƒë·ªÉ v·∫Ω l·∫°i.")
                cv2.namedWindow("**** Loi: ROI khong hop le. Ve lai vung ma QR ****", cv2.WINDOW_NORMAL)
                cv2.imshow("**** Loi: ROI khong hop le. Ve lai vung ma QR ****", current_frame)
                cv2.waitKey(2000)
                cv2.destroyAllWindows()
                continue

        # Ki·ªÉm tra t√≠nh t∆∞∆°ng th√≠ch c·ªßa ·∫£nh packing v·ªõi MVD
        logger.debug(f"[MVD] Ki·ªÉm tra t√≠nh t∆∞∆°ng th√≠ch c·ªßa ·∫£nh packing v·ªõi MVD: {roi_frame_path}")

        # Kh·ªüi t·∫°o danh s√°ch h√†ng ƒë·ª£i v√† c·ªù tho√°t
        frame_queues = [queue.Queue(maxsize=50) for _ in range(len(rois))]
        exit_flag = threading.Event()
        qr_detected = False
        qr_detected_roi1 = False
        qr_detected_roi2 = False
        qr_content = ""
        trigger_detected = False

        def process_roi(video_file, roi_index, x, y, w, h, interval=5):
            nonlocal qr_detected, qr_detected_roi1, qr_detected_roi2, qr_content, trigger_detected
            try:
                logger.debug(f"[MVD] Kh·ªüi t·∫°o WeChatQRCode cho ROI {roi_index + 1}")
                local_detector = cv2.wechat_qrcode_WeChatQRCode(DETECT_PROTO, DETECT_MODEL, SR_PROTO, SR_MODEL)
                logger.debug(f"[MVD] WeChatQRCode kh·ªüi t·∫°o th√†nh c√¥ng cho ROI {roi_index + 1}")
            except Exception as e:
                logger.error(f"[MVD] OpenCV WeChatQRCode error in ROI {roi_index + 1}: {str(e)}\n{traceback.format_exc()}")
                return

            try:
                logger.debug(f"[MVD] M·ªü video cho ROI {roi_index + 1}: {video_file}")
                cap = cv2.VideoCapture(video_file)
                if not cap.isOpened():
                    logger.error(f"[MVD] Kh√¥ng th·ªÉ m·ªü video '{video_file}' cho ROI {roi_index + 1}")
                    return
                logger.debug(f"[MVD] Video m·ªü th√†nh c√¥ng cho ROI {roi_index + 1}")
            except Exception as e:
                logger.error(f"[MVD] OpenCV VideoCapture error in ROI {roi_index + 1}: {str(e)}\n{traceback.format_exc()}")
                return

            frame_count = 0
            start_time = time.time()

            while not exit_flag.is_set():
                try:
                    ret, frame = cap.read()
                    if not ret:
                        logger.debug(f"[MVD] K·∫øt th√∫c video '{video_file}' (ROI {roi_index + 1})")
                        break

                    frame_count += 1
                    if frame_count % interval != 0:
                        continue

                    logger.debug(f"[MVD] X·ª≠ l√Ω frame {frame_count} cho ROI {roi_index + 1}")
                    roi_frame = frame[y:y+h, x:x+w]
                    if roi_frame.size == 0 or roi_frame.shape[0] == 0 or roi_frame.shape[1] == 0:
                        logger.warning(f"[MVD] ROI {roi_index + 1} kh√¥ng h·ª£p l·ªá, b·ªè qua frame")
                        continue

                    if len(roi_frame.shape) == 2:
                        roi_frame = cv2.cvtColor(roi_frame, cv2.COLOR_GRAY2BGR)

                    logger.debug(f"[MVD] Ph√°t hi·ªán QR trong ROI {roi_index + 1}")
                    texts, points = local_detector.detectAndDecode(roi_frame)
                    if texts:
                        qr_detected = True
                        if roi_index == 0:
                            qr_detected_roi1 = True
                        elif roi_index == 1 and table_type == "standard":
                            qr_detected_roi2 = True
                        qr_content = texts[0]  # L∆∞u n·ªôi dung QR ƒë·∫ßu ti√™n
                        # Ki·ªÉm tra trigger cho ROI 2 (b√†n ti√™u chu·∫©n)
                        if table_type == "standard" and roi_index == 1 and texts[0].lower() == "timego":
                            trigger_detected = True
                            logger.info(f"[MVD] [ROI {roi_index + 1}] Ph√°t hi·ªán trigger: {texts[0]}")
                        for text, box in zip(texts, points):
                            logger.info(f"[MVD] [ROI {roi_index + 1}] N·ªôi dung m√£ QR: {text}")
                            # V·∫Ω khung vi·ªÅn QR
                            for i in range(4):
                                pt1 = tuple(map(int, box[i]))
                                pt2 = tuple(map(int, box[(i + 1) % 4]))
                                cv2.line(roi_frame, pt1, pt2, (0, 255, 0), 2)
                            # Hi·ªÉn th·ªã n·ªôi dung QR d∆∞·ªõi khung vi·ªÅn
                            bottom_left = tuple(map(int, box[2]))  # G√≥c d∆∞·ªõi tr√°i
                            cv2.putText(roi_frame, text[:20], (bottom_left[0], bottom_left[1] + 30), 
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                    elapsed_time = time.time() - start_time
                    elapsed_time_text = f"Time: {elapsed_time:.1f}"
                    cv2.putText(roi_frame, elapsed_time_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
                    cv2.putText(roi_frame, "Dang phat hien ma QR. Noi dung hien thi neu tim thay", 
                                (10, roi_frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    frame_queues[roi_index].put(roi_frame)
                    logger.debug(f"[MVD] ƒê√£ ƒë·∫©y frame cho ROI {roi_index + 1} v√†o h√†ng ƒë·ª£i")
                except Exception as e:
                    logger.error(f"[MVD] OpenCV processing error in process_roi (ROI {roi_index + 1}): {str(e)}\n{traceback.format_exc()}")
                    break

            logger.debug(f"[MVD] Gi·∫£i ph√≥ng video capture cho ROI {roi_index + 1}")
            cap.release()

        # Kh·ªüi ch·∫°y lu·ªìng x·ª≠ l√Ω video cho t·ª´ng ROI
        threads = []
        for i, roi in enumerate(rois):
            if roi["w"] > 0 and roi["h"] > 0:
                logger.debug(f"[MVD] Kh·ªüi ch·∫°y thread cho ROI {i + 1}")
                thread = threading.Thread(target=process_roi, args=(video_path, i, roi["x"], roi["y"], roi["w"], roi["h"], 5))
                thread.start()
                threads.append(thread)
                logger.info(f"[MVD] Thread cho ROI {i + 1} ƒë√£ kh·ªüi ch·∫°y")
            else:
                logger.warning(f"[MVD] ROI {i + 1} kh√¥ng h·ª£p l·ªá, b·ªè qua")

        # Kh·ªüi t·∫°o c·ª≠a s·ªï cho t·ª´ng ROI
        for i in range(len(frame_queues)):
            try:
                logger.debug(f"[MVD] Kh·ªüi t·∫°o c·ª≠a s·ªï cho ROI {i + 1}")
                window_title = f"**** Dang phat hien ma QR. Noi dung hien thi neu tim thay (ROI {i + 1}) ****"
                cv2.namedWindow(window_title, cv2.WINDOW_AUTOSIZE)
                logger.debug(f"[MVD] C·ª≠a s·ªï cho ROI {i + 1} ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
            except Exception as e:
                logger.error(f"[MVD] OpenCV namedWindow error: {str(e)}\n{traceback.format_exc()}")
                cv2.destroyAllWindows()
                return {"success": False, "error": f"OpenCV namedWindow error: {str(e)}"}

        # Hi·ªÉn th·ªã m·ªói ROI trong c·ª≠a s·ªï ri√™ng
        while any(thread.is_alive() for thread in threads) or any(not q.empty() for q in frame_queues):
            for i in range(len(frame_queues)):
                try:
                    frame = frame_queues[i].get(timeout=0.1)
                    window_name = f"**** Dang phat hien ma QR. Noi dung hien thi neu tim thay (ROI {i + 1}) ****"
                    cv2.imshow(window_name, frame)
                    logger.debug(f"[MVD] Hi·ªÉn th·ªã frame cho {window_name}")
                except queue.Empty:
                    pass
                except Exception as e:
                    logger.error(f"[MVD] OpenCV imshow error in loop: {str(e)}\n{traceback.format_exc()}")
                    cv2.destroyAllWindows()
                    return {"success": False, "error": f"OpenCV imshow error: {str(e)}"}

            try:
                if cv2.waitKey(10) & 0xFF == ord('q'):
                    logger.debug("[MVD] Nh·∫≠n l·ªánh tho√°t t·ª´ ng∆∞·ªùi d√πng")
                    exit_flag.set()
                    break
            except Exception as e:
                logger.error(f"[MVD] OpenCV waitKey error: {str(e)}\n{traceback.format_exc()}")
                cv2.destroyAllWindows()
                return {"success": False, "error": f"OpenCV waitKey error: {str(e)}"}

        logger.debug("[MVD] ƒê√≥ng t·∫•t c·∫£ c·ª≠a s·ªï OpenCV")
        cv2.destroyAllWindows()
        for thread in threads:
            logger.debug(f"[MVD] Ch·ªù thread ROI {threads.index(thread) + 1} k·∫øt th√∫c")
            thread.join()

        # L∆∞u k·∫øt qu·∫£ v√†o /tmp/qr_roi.json
        result = {
            "success": True,
            "rois": rois,
            "roi_frame": os.path.relpath(roi_frame_path_new, BASE_DIR),
            "qr_detected": qr_detected,
            "qr_detected_roi1": qr_detected_roi1,
            "qr_detected_roi2": qr_detected_roi2 if table_type == "standard" else False,
            "qr_content": qr_content,
            "trigger_detected": trigger_detected,
            "table_type": table_type
        }
        logger.debug(f"[MVD] L∆∞u k·∫øt qu·∫£ v√†o /tmp/qr_roi.json: {result}")
        try:
            with open("/tmp/qr_roi.json", "w") as f:
                json.dump(result, f)
            logger.info("[MVD] ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o /tmp/qr_roi.json")
        except Exception as e:
            logger.error(f"[MVD] L·ªói khi l∆∞u /tmp/qr_roi.json: {str(e)}\n{traceback.format_exc()}")
            cv2.destroyAllWindows()
            return {"success": False, "error": f"L·ªói khi l∆∞u /tmp/qr_roi.json: {str(e)}"}

        logger.info(f"[MVD] Ho√†n t·∫•t select_qr_roi cho camera_id: {camera_id}, step: {step}")
        cv2.destroyAllWindows()
        return result

    except Exception as e:
        logger.error(f"[MVD] L·ªói trong select_qr_roi: {str(e)}\n{traceback.format_exc()}")
        cv2.destroyAllWindows()
        return {"success": False, "error": f"L·ªói h·ªá th·ªëng: {str(e)}"}

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 4:
        logger.error("Usage: python3 qr_detector.py <video_path> <camera_id> <roi_frame_path>")
        sys.exit(1)

    video_path = sys.argv[1]
    camera_id = sys.argv[2]
    roi_frame_path = sys.argv[3]
    try:
        result = select_qr_roi(video_path, camera_id, roi_frame_path, step="mvd")
        if not result["success"]:
            logger.error(result["error"])
    except Exception as e:
        logger.error(f"[MVD] L·ªói khi ch·∫°y script: {str(e)}\n{traceback.format_exc()}")
        cv2.destroyAllWindows()

```
## üìÑ File: `roi_preview.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/roi_preview.py`

```python
import cv2
import argparse
import os
import logging

def setup_logging():
    log_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "resources", "output_clips", "LOG")
    os.makedirs(log_dir, exist_ok=True)
    log_file_path = os.path.join(log_dir, f"roi_preview_{os.getpid()}.log")
    logging.basicConfig(
        filename=log_file_path,
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    logging.info(f"ROI Preview started with PID {os.getpid()}")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--video', required=True, help='File video .mp4')
    parser.add_argument('--roi', nargs=4, type=int, required=True, help='T·ªça ƒë·ªô ROI: x y w h')
    args = parser.parse_args()

    setup_logging()
    x, y, w, h = args.roi
    cap = cv2.VideoCapture(args.video)
    if not cap.isOpened():
        logging.error(f"Cannot open {args.video}")
        return

    win = "ROI Preview"
    cv2.namedWindow(win, cv2.WINDOW_NORMAL)
    cv2.resizeWindow(win, w, h)

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        crop = frame[y:y+h, x:x+w]
        cv2.imshow(win, crop)
        if cv2.waitKey(30) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    logging.info("ROI Preview closed")

if __name__ == "__main__":
    main()
```
## üìÑ File: `event_detector.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/event_detector.py`

```python
from flask import Blueprint, jsonify
import os
import sqlite3
import logging
from datetime import datetime
from modules.db_utils import get_db_connection
from modules.scheduler.db_sync import db_rwlock
from modules.config.logging_config import get_logger


# ƒê·ªãnh nghƒ©a BASE_DIR
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

event_detector_bp = Blueprint('event_detector', __name__)

def calculate_duration(ts, te):
    if ts is None or te is None:
        return None
    if te < ts:
        return None
    return te - ts

def process_single_log(log_file_path):
    if not os.path.isfile(log_file_path):
        logging.warning(f"Log file not found: {log_file_path}, skipping.")
        return
    # Kh·ªüi t·∫°o logger v·ªõi context log_file
    logger = get_logger(__name__, {"log_file": log_file_path})
    logger.info("Logging initialized for process_single_log")

    try:
        with db_rwlock.gen_wlock():
            conn = get_db_connection()
            cursor = conn.cursor()

            # Ki·ªÉm tra tr·∫°ng th√°i is_processed c·ªßa file log
            cursor.execute("SELECT is_processed FROM processed_logs WHERE log_file = ?", (log_file_path,))
            result = cursor.fetchone()
            if result and result[0] == 1:
                logging.info(f"Log file {log_file_path} already processed, skipping")
                conn.close()
                return

            with open(log_file_path, "r") as f:
                header = f.readline().strip()
                logging.info(f"Header: {header}")
                start_time = int(header.split("Start: ")[1].split(",")[0])
                end_time = int(header.split("End: ")[1].split(",")[0])
                start_time_str = header.split("Start_Time: ")[1].split(",")[0].strip()
                camera_name = header.split("Camera_Name: ")[1].split(",")[0].strip()
                video_path = header.split("Video_File: ")[1].split(",")[0].strip()
                start_time_dt = datetime.strptime(start_time_str, "%Y-%m-%d %H:%M:%S")
                logging.info(f"Parsed header - Start: {start_time}, End: {end_time}, Start_Time: {start_time_str}, Camera_Name: {camera_name}, Video_File: {video_path}")

                # Ki·ªÉm tra n·∫øu file log r·ªóng
                first_data_line = f.readline().strip()
                if not first_data_line:
                    logging.info(f"Log file {log_file_path} is empty, skipping")
                    cursor.execute("UPDATE processed_logs SET is_processed = 1, processed_at = ? WHERE log_file = ?", (datetime.now(), log_file_path))
                    conn.commit()
                    conn.close()
                    return

                # N·∫øu c√≥ d·ªØ li·ªáu, quay l·∫°i v√† x·ª≠ l√Ω
                f.seek(0)
                next(f)
                frame_sampler_data = []
                for line in f:
                    parts = line.strip().split(",")
                    try:
                        second, state = parts[0], parts[1]
                        codes = [parts[2]] if len(parts) > 2 and parts[2] else []
                        frame_sampler_data.append({"second": float(second), "state": state, "tracking_codes": codes})
                    except Exception as e:
                        logging.info(f"Error parsing line '{line.strip()}': {str(e)}")

            # L·∫•y min_packing_time t·ª´ Processing_config
            cursor.execute("SELECT min_packing_time FROM Processing_config LIMIT 1")
            min_packing_time_row = cursor.fetchone()
            min_packing_time = min_packing_time_row[0] if min_packing_time_row else 5
            logging.info(f"Min packing time: {min_packing_time}")

            # L·∫•y pending_event m·ªõi nh·∫•t theo ts
            cursor.execute("SELECT event_id, ts, tracking_codes, video_file FROM events WHERE te IS NULL AND camera_name = ? ORDER BY event_id DESC LIMIT 1", (camera_name,))
            pending_event = cursor.fetchone()
            logging.info(f"Pending event: {pending_event}")
            ts = pending_event[1] if pending_event else None
            pending_tracking_codes = eval(pending_event[2]) if pending_event and pending_event[2] else []
            pending_video_file = pending_event[3] if pending_event else None
            event_id = pending_event[0] if pending_event else None
            segments = []
            prev_state = None
            has_pending = ts is not None and ts <= start_time

            for data in frame_sampler_data:
                current_state = data["state"]
                current_second = data["second"]
                current_tracking_codes = data["tracking_codes"]

                if has_pending and ts is not None:
                    if current_state == "On":
                        te = current_second
                        total_duration = calculate_duration(ts, te)
                        
                        # T√°ch tracking_codes th√†nh c√°c s·ª± ki·ªán li√™n ti·∫øp
                        all_tracking_codes = list(set(pending_tracking_codes + current_tracking_codes))
                        num_codes = len(all_tracking_codes) if all_tracking_codes else 1
                        duration_per_event = max(round(total_duration / num_codes), min_packing_time)  # L√†m tr√≤n v√† ƒë·∫£m b·∫£o >= min_packing_time
                        total_duration = duration_per_event * num_codes  # C·∫≠p nh·∫≠t total_duration
                        te = ts + total_duration if ts is not None else te
                        logging.info(f"ƒêi·ªÅu ch·ªânh pending event: Ts={ts}, Te={te}, Duration m·ªói s·ª± ki·ªán th√†nh {duration_per_event}")
                        
                        if pending_video_file == video_path:
                            current_ts = ts
                            for i, code in enumerate(all_tracking_codes):
                                current_te = current_ts + duration_per_event if current_ts is not None else te
                                if i == 0:
                                    # C·∫≠p nh·∫≠t pending event cho m√£ ƒë·∫ßu ti√™n
                                    segments.append((current_ts, current_te, duration_per_event, [code], video_path, event_id))
                                    logging.info(f"C·∫≠p nh·∫≠t pending event li√™n ti·∫øp {i+1}/{num_codes}: Ts={current_ts}, Te={current_te}, Duration={duration_per_event}, Tracking_code={code}")
                                else:
                                    # Th√™m s·ª± ki·ªán m·ªõi cho c√°c m√£ ti·∫øp theo
                                    segments.append((current_ts, current_te, duration_per_event, [code], video_path, None))
                                    logging.info(f"Th√™m s·ª± ki·ªán li√™n ti·∫øp m·ªõi {i+1}/{num_codes}: Ts={current_ts}, Te={current_te}, Duration={duration_per_event}, Tracking_code={code}")
                                current_ts = current_te
                        else:
                            current_ts = None
                            for i, code in enumerate(all_tracking_codes):
                                current_te = te - (num_codes - i - 1) * duration_per_event
                                segments.append((current_ts, current_te, duration_per_event, [code], video_path, None))
                                logging.info(f"Th√™m pending event li√™n ti·∫øp {i+1}/{num_codes}: Ts={current_ts}, Te={current_te}, Duration={duration_per_event}, Tracking_code={code}")
                                current_ts = current_te
                        
                        ts = None
                        has_pending = False
                    elif current_state == "Off":
                        pending_tracking_codes.extend([code for code in current_tracking_codes if code and code not in pending_tracking_codes])
                        # Ki·ªÉm tra v√† x√≥a s·ª± ki·ªán d·ªü dang n·∫øu kh√¥ng c√≥ tracking_codes
                        if not pending_tracking_codes and not current_tracking_codes:
                            cursor.execute("DELETE FROM events WHERE te IS NULL AND event_id = (SELECT MAX(event_id) FROM events WHERE te IS NULL AND camera_name = ?)", (camera_name,))
                            logging.info(f"X√≥a s·ª± ki·ªán d·ªü dang cu·ªëi c√πng c·ªßa camera {camera_name} do kh√¥ng c√≥ tracking_codes")              
                elif not has_pending:
                    if prev_state == "On" and current_state == "Off":
                        ts = current_second
                        pending_tracking_codes = current_tracking_codes[:]
                        logging.info(f"Ph√°t hi·ªán s·ª± ki·ªán Ts t·∫°i gi√¢y {current_second}")

                    elif prev_state == "Off" and current_state == "On" and ts is not None:
                        te = current_second
                        total_duration = calculate_duration(ts, te)
                        
                        # T√°ch tracking_codes th√†nh c√°c s·ª± ki·ªán li√™n ti·∫øp
                        all_tracking_codes = list(set(pending_tracking_codes + current_tracking_codes))  # Lo·∫°i b·ªè tr√πng l·∫∑p
                        num_codes = len(all_tracking_codes) if all_tracking_codes else 1
                        duration_per_event = max(round(total_duration / num_codes), min_packing_time)  # L√†m tr√≤n v√† ƒë·∫£m b·∫£o >= min_packing_time
                        total_duration = duration_per_event * num_codes  # C·∫≠p nh·∫≠t total_duration
                        te = ts + total_duration if ts is not None else te
                        logging.info(f"ƒêi·ªÅu ch·ªânh s·ª± ki·ªán: Ts={ts}, Te={te}, Duration m·ªói s·ª± ki·ªán th√†nh {duration_per_event}")
                        
                        if all_tracking_codes:
                            current_ts = ts
                            for i, code in enumerate(all_tracking_codes):
                                current_te = current_ts + duration_per_event if current_ts is not None else te
                                segments.append((current_ts, current_te, duration_per_event, [code], video_path, None))
                                logging.info(f"Th√™m s·ª± ki·ªán li√™n ti·∫øp {i+1}/{num_codes}: Ts={current_ts}, Te={current_te}, Duration={duration_per_event}, Tracking_code={code}")
                                current_ts = current_te
                        else:
                            segments.append((ts, te, duration_per_event, [], video_path, None))
                            logging.info(f"Th√™m s·ª± ki·ªán kh√¥ng c√≥ tracking_code: Ts={ts}, Te={te}, Duration={duration_per_event}")
                        
                        ts = None
                        pending_tracking_codes = []

                    elif ts is not None and current_state == "Off":
                        pending_tracking_codes.extend([code for code in current_tracking_codes if code and code not in pending_tracking_codes])

                prev_state = current_state

            if ts is not None:
                segments.append((ts, None, None, pending_tracking_codes, video_path, None))
                logging.info(f"Gi√¢y {frame_sampler_data[-1]['second']}: Ts={ts}, Te=Not finished")

            logging.info(f"All segments detected: {segments}")

            for segment in segments:
                ts, te, duration, tracking_codes, segment_video_path, segment_event_id = segment
                if te is not None and not tracking_codes:
                    logging.info(f"B·ªè qua s·ª± ki·ªán ho√†n ch·ªânh do tracking_codes r·ªóng: ts={ts}, te={te}")
                    continue
                packing_time_start = int((start_time_dt.timestamp() + ts) * 1000) if ts is not None else None
                packing_time_end = int((start_time_dt.timestamp() + te) * 1000) if te is not None else None
                if segment_event_id is not None:
                    cursor.execute("UPDATE events SET te=?, duration=?, tracking_codes=?, packing_time_end=? WHERE event_id=?",
                                   (te, duration, str(tracking_codes), packing_time_end, segment_event_id))
                    logging.info(f"Updated event_id {segment_event_id}: ts={ts}, te={te}, duration={duration}")
                else:
                    cursor.execute('''INSERT INTO events (ts, te, duration, tracking_codes, video_file, buffer, camera_name, packing_time_start, packing_time_end)
                                      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                                   (ts, te, duration, str(tracking_codes), segment_video_path, 0, camera_name, packing_time_start, packing_time_end))
                    logging.info(f"Inserted new event: ts={ts}, te={te}, duration={duration}")

            cursor.execute("UPDATE processed_logs SET is_processed = 1, processed_at = ? WHERE log_file = ?", (datetime.now(), log_file_path))
            conn.commit()
            logging.info("Database changes committed")

    except Exception as e:
        logging.error(f"Error in process_single_log: {str(e)}")
        raise
    finally:
        conn.close()

@event_detector_bp.route('/process-events', methods=['GET'])
def process_events():
    try:
        with db_rwlock.gen_rlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("""
                SELECT DISTINCT log_file_path, (
                    SELECT CAST(SUBSTR(header, INSTR(header, 'Start: ') + 7, INSTR(SUBSTR(header, INSTR(header, 'Start: ') + 7), ',') - 1) AS INTEGER)
                    FROM (
                        SELECT SUBSTR(CAST(READFILE(log_file_path) AS TEXT), 1, INSTR(CAST(READFILE(log_file_path) AS TEXT), '\n') - 1) AS header
                    )
                ) AS start_time
                FROM file_list 
                WHERE is_processed = 1 AND log_file_path IS NOT NULL 
                AND log_file_path IN (SELECT log_file FROM processed_logs WHERE is_processed = 0)
                ORDER BY start_time
            """)
            log_files = [row[0] for row in cursor.fetchall()]
            logging.info(f"Log files to process: {log_files}")
            conn.close()

        for log_file in log_files:
            if not os.path.isfile(log_file):
                logging.warning(f"Log file not found, skipping: {log_file}")
                continue
            if os.path.exists(log_file):
                logging.info(f"Starting to process file: {log_file}")
                process_single_log(log_file)
                logging.info(f"Finished processing file: {log_file}")
            else:
                logging.info(f"File not found: {log_file}")

        return jsonify({"message": "Event detection completed successfully"}), 200
    except Exception as e:
        logging.error(f"Error in process_events: {str(e)}")
        return jsonify({"error": str(e)}), 500

```
## üìÑ File: `__init__.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/__init__.py`

```python

```
## üìÑ File: `hand_detection.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/hand_detection.py`

```python
import cv2
import mediapipe as mp
import time
import logging
import json
import os
import glob
from datetime import datetime
from modules.config.logging_config import get_logger


# ƒê·ªãnh nghƒ©a BASE_DIR
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

# Kh·ªüi t·∫°o logger m√† kh√¥ng s·ª≠ d·ª•ng video_path
logger = get_logger(__name__, {"module": "hand_detection"})
logger.info("Logging initialized")

mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# ƒê·∫∑t b∆∞·ªõc nh·∫£y frame
FRAME_STEP = 5

# ƒê∆∞·ªùng d·∫´n l∆∞u ·∫£nh
CAMERA_ROI_DIR = os.path.join(BASE_DIR, "resources", "output_clips", "CameraROI")

def ensure_directory_exists(directory):
    """ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i, n·∫øu kh√¥ng th√¨ t·∫°o m·ªõi."""
    try:
        if not os.path.exists(directory):
            os.makedirs(directory)
            logging.debug(f"ƒê√£ t·∫°o th∆∞ m·ª•c: {directory}")
        # Ki·ªÉm tra quy·ªÅn truy c·∫≠p
        if not os.access(directory, os.W_OK):
            logging.error(f"Kh√¥ng c√≥ quy·ªÅn ghi v√†o th∆∞ m·ª•c {directory}")
            raise PermissionError(f"Kh√¥ng c√≥ quy·ªÅn ghi v√†o th∆∞ m·ª•c {directory}")
    except Exception as e:
        logging.error(f"L·ªói khi t·∫°o th∆∞ m·ª•c {directory}: {str(e)}")
        raise

def select_roi(video_path, camera_id, step="packing"):
    """
    M·ªü video v√† cho ph√©p ng∆∞·ªùi d√πng v·∫Ω ROI b·∫±ng OpenCV, l∆∞u k·∫øt qu·∫£ v√†o CameraROI, sau ƒë√≥ ph√°t hi·ªán tay.
    Args:
        video_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file video.
        camera_id (str): ID c·ªßa camera.
        step (str): Giai ƒëo·∫°n hi·ªán t·∫°i (packing, trigger).
    Returns:
        dict: {'success': bool, 'roi': {'x': int, 'y': int, 'w': int, 'h': int}, 'roi_frame': str, 'hand_detected': bool} ho·∫∑c {'success': false, 'error': str}
    """
    try:
        logging.debug(f"B·∫Øt ƒë·∫ßu select_roi v·ªõi video_path: {video_path}, camera_id: {camera_id}, step: {step}")
        
        # ƒê·∫£m b·∫£o th∆∞ m·ª•c CameraROI t·ªìn t·∫°i
        ensure_directory_exists(CAMERA_ROI_DIR)

        # M·ªü video
        logging.debug("ƒêang m·ªü video...")
        cap = cv2.VideoCapture(video_path)
        try:
            if not cap.isOpened():
                logging.error("Kh√¥ng th·ªÉ m·ªü video.")
                return {"success": False, "error": "Kh√¥ng th·ªÉ m·ªü video."}
            
            # ƒê·ªçc frame ƒë·∫ßu ti√™n
            logging.debug("ƒêang ƒë·ªçc frame ƒë·∫ßu ti√™n...")
            ret, frame = cap.read()
            if not ret:
                logging.error("Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ video.")
                return {"success": False, "error": "Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ video."}
            
            # L∆∞u frame g·ªëc n·∫øu ·ªü b∆∞·ªõc packing
            if step == "packing":
                original_frame_path = os.path.join(CAMERA_ROI_DIR, f"camera_{camera_id}_original.jpg")
                ret = cv2.imwrite(original_frame_path, frame)
                if not ret:
                    logging.error(f"Kh√¥ng th·ªÉ l∆∞u ·∫£nh g·ªëc t·∫°i: {original_frame_path}")
                    return {"success": False, "error": f"Kh√¥ng th·ªÉ l∆∞u ·∫£nh g·ªëc t·∫°i {original_frame_path}"}
                logging.debug(f"ƒê√£ l∆∞u frame g·ªëc v√†o: {original_frame_path}")
            
            while True:
                # Hi·ªÉn th·ªã giao di·ªán ch·ªçn ROI
                logging.debug("G·ªçi cv2.selectROI...")
                current_frame = frame.copy()
                roi = cv2.selectROI(f"Click va keo chuot de chon -Vung {step.capitalize()}-", current_frame, showCrosshair=True, fromCenter=False)
                logging.debug(f"ROI tr·∫£ v·ªÅ: {roi}")
                cv2.destroyAllWindows()
                
                # Ki·ªÉm tra n·∫øu ROI h·ª£p l·ªá
                x, y, w, h = map(int, roi)
                if w == 0 or h == 0:
                    logging.debug("ROI kh√¥ng h·ª£p l·ªá, hi·ªÉn th·ªã l·∫°i frame g·ªëc ƒë·ªÉ v·∫Ω l·∫°i.")
                    continue  # Hi·ªÉn th·ªã l·∫°i frame g·ªëc, kh√¥ng l∆∞u file
                
                # V·∫Ω ROI l√™n frame
                color = (0, 255, 0) if step == "packing" else (0, 255, 255)
                cv2.rectangle(current_frame, (x, y), (x + w, y + h), color, 2)
                # Th√™m ti√™u ƒë·ªÅ "Packing" n·∫øu ·ªü b∆∞·ªõc packing
                if step == "packing":
                    cv2.putText(current_frame, "Packing", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                
                # Hi·ªÉn th·ªã frame v·ªõi ROI v√† ti√™u ƒë·ªÅ
                cv2.namedWindow("**** Da ve vung Packing ****", cv2.WINDOW_NORMAL)
                cv2.imshow("**** Da ve vung Packing ****", current_frame)
                cv2.waitKey(500)
                cv2.destroyAllWindows()
                
                # L∆∞u frame v·ªõi ROI v√†o CameraROI
                if step == "packing":
                    roi_frame_path = os.path.join(CAMERA_ROI_DIR, f"camera_{camera_id}_roi_packing.jpg")
                else:  # step == "trigger"
                    roi_frame_path = os.path.join(CAMERA_ROI_DIR, f"camera_{camera_id}_roi_trigger.jpg")
                
                ret = cv2.imwrite(roi_frame_path, current_frame)
                if not ret:
                    logging.error(f"Kh√¥ng th·ªÉ l∆∞u ·∫£nh t·∫°i: {roi_frame_path}")
                    return {"success": False, "error": f"Kh√¥ng th·ªÉ l∆∞u ·∫£nh t·∫°i {roi_frame_path}"}
                logging.debug(f"ƒê√£ l∆∞u frame v·ªõi ROI v√†o: {roi_frame_path}")
                
                # Ki·ªÉm tra file ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng
                if not os.path.exists(roi_frame_path):
                    logging.error(f"File kh√¥ng t·ªìn t·∫°i sau khi l∆∞u: {roi_frame_path}")
                    return {"success": False, "error": f"File kh√¥ng t·ªìn t·∫°i sau khi l∆∞u: {roi_frame_path}"}
                
                # N·∫øu l√† b∆∞·ªõc packing, g·ªçi detect_hands ƒë·ªÉ ki·ªÉm tra tay
                hand_detected = False
                if step == "packing":
                    detect_result = detect_hands(video_path, {"x": x, "y": y, "w": w, "h": h})
                    if not detect_result["success"]:
                        logging.error(f"L·ªói khi ph√°t hi·ªán tay: {detect_result['error']}")
                        return {"success": False, "error": detect_result["error"]}
                    hand_detected = detect_result["hand_detected"]
                
                # L∆∞u t·ªça ƒë·ªô ROI v√† tr·∫°ng th√°i hand_detected v√†o /tmp/roi.json
                result = {
                    "success": True,
                    "roi": {"x": x, "y": y, "w": w, "h": h},
                    "roi_frame": os.path.relpath(roi_frame_path, BASE_DIR),
                    "hand_detected": hand_detected
                }
                logging.debug(f"L∆∞u ROI v√†o /tmp/roi.json: {result}")
                with open("/tmp/roi.json", "w") as f:
                    json.dump(result, f)
                
                logging.debug(f"ROI h·ª£p l·ªá: x={x}, y={y}, w={w}, h={h}, hand_detected: {hand_detected}")
                return result
            
        finally:
            cap.release()
            logging.debug("ƒê√£ gi·∫£i ph√≥ng t√†i nguy√™n video (cap.release).")
        
    except Exception as e:
        logging.error(f"L·ªói trong select_roi: {str(e)}")
        cv2.destroyAllWindows()
        return {"success": False, "error": f"L·ªói h·ªá th·ªëng: {str(e)}"}

def detect_hands(video_path, roi):
    """
    Hi·ªÉn th·ªã video v·ªõi ph√°t hi·ªán tay trong v√πng ROI, tr·∫£ v·ªÅ tr·∫°ng th√°i ph√°t hi·ªán tay.
    Args:
        video_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file video.
        roi (dict): T·ªça ƒë·ªô ROI {'x': int, 'y': int, 'w': int, 'h': int}.
    Returns:
        dict: {'success': bool, 'hand_detected': bool, 'error': str n·∫øu c√≥ l·ªói}
    """
    try:
        x, y, w, h = roi["x"], roi["y"], roi["w"], roi["h"]
        if w <= 0 or h <= 0:
            logging.error("ROI kh√¥ng h·ª£p l·ªá (chi·ªÅu r·ªông ho·∫∑c chi·ªÅu cao b·∫±ng 0).")
            return {"success": False, "hand_detected": False, "error": "ROI kh√¥ng h·ª£p l·ªá."}

        # M·ªü video
        logging.debug("ƒêang m·ªü video ƒë·ªÉ ph√°t hi·ªán tay...")
        cap = cv2.VideoCapture(video_path)
        try:
            if not cap.isOpened():
                logging.error("Kh√¥ng th·ªÉ m·ªü video.")
                return {"success": False, "hand_detected": False, "error": "Kh√¥ng th·ªÉ m·ªü video."}

            hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)
            frame_count = 0
            start_time = time.time()
            hand_detected = False

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # C·∫Øt video theo ROI
                roi_frame = frame[y:y+h, x:x+w]

                # Ch·ªâ x·ª≠ l√Ω m·ªói FRAME_STEP frame
                if frame_count % FRAME_STEP == 0:
                    # Chuy·ªÉn ƒë·ªïi BGR sang RGB
                    rgb_frame = cv2.cvtColor(roi_frame, cv2.COLOR_BGR2RGB)

                    # Ph√°t hi·ªán b√†n tay
                    results = hands.process(rgb_frame)

                    # Ki·ªÉm tra v√† x√°c nh·∫≠n ph√°t hi·ªán tay
                    if results.multi_hand_landmarks:
                        hand_detected = True
                        for hand_landmarks in results.multi_hand_landmarks:
                            # V·∫Ω keypoints ngay khi ph√°t hi·ªán tay
                            mp_drawing.draw_landmarks(roi_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                # Hi·ªÉn th·ªã video
                elapsed_time = time.time() - start_time
                cv2.putText(roi_frame, f"Time: {elapsed_time:.2f}s", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                cv2.imshow("ROI Hand Detection", roi_frame)

                if cv2.waitKey(1) == ord("q"):
                    break

                frame_count += 1

            logging.debug(f"Ph√°t hi·ªán tay: {hand_detected}")
            return {"success": True, "hand_detected": hand_detected}
        
        finally:
            cap.release()
            cv2.destroyWindow("ROI Hand Detection")  # Ch·ªâ ƒë√≥ng c·ª≠a s·ªï c·ªßa detect_hands
            logging.debug("ƒê√£ gi·∫£i ph√≥ng t√†i nguy√™n video (cap.release) trong detect_hands.")
    
    except Exception as e:
        logging.error(f"L·ªói trong detect_hands: {str(e)}")
        return {"success": False, "hand_detected": False, "error": f"L·ªói h·ªá th·ªëng: {str(e)}"}

def finalize_roi(video_path, camera_id, rois):
    """
    V·∫Ω t·∫•t c·∫£ c√°c v√πng ROI (packing, MVD, trigger) l√™n frame v√† l∆∞u v√†o th∆∞ m·ª•c CameraROI.
    Args:
        video_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file video.
        camera_id (str): ID c·ªßa camera.
        rois (list): Danh s√°ch c√°c v√πng ROI [{'type': str, 'x': int, 'y': int, 'w': int, 'h': int}, ...].
    Returns:
        dict: {'success': bool, 'final_roi_frame': str, 'error': str n·∫øu c√≥ l·ªói}
    """
    try:
        # ƒê·∫£m b·∫£o th∆∞ m·ª•c CameraROI t·ªìn t·∫°i
        ensure_directory_exists(CAMERA_ROI_DIR)

        # M·ªü video v√† l·∫•y frame ƒë·∫ßu ti√™n
        logging.debug("ƒêang m·ªü video ƒë·ªÉ t·∫°o ·∫£nh t·ªïng h·ª£p...")
        cap = cv2.VideoCapture(video_path)
        try:
            if not cap.isOpened():
                logging.error("Kh√¥ng th·ªÉ m·ªü video.")
                return {"success": False, "error": "Kh√¥ng th·ªÉ m·ªü video."}

            ret, frame = cap.read()
            if not ret:
                logging.error("Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ video.")
                return {"success": False, "error": "Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ video."}

            # V·∫Ω c√°c v√πng ROI v·ªõi m√†u s·∫Øc kh√°c nhau
            for roi in rois:
                x, y, w, h = roi["x"], roi["y"], roi["w"], roi["h"]
                roi_type = roi["type"]

                # ƒê·ªãnh nghƒ©a m√†u s·∫Øc cho t·ª´ng lo·∫°i ROI
                if roi_type == "packing":
                    color = (0, 255, 0)  # Xanh l√°
                elif roi_type == "mvd":
                    color = (0, 0, 255)  # ƒê·ªè
                elif roi_type == "trigger":
                    color = (0, 255, 255)  # V√†ng
                else:
                    color = (255, 255, 255)  # Tr·∫Øng (m·∫∑c ƒë·ªãnh)

                # V·∫Ω ROI l√™n frame
                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
                # Th√™m nh√£n cho v√πng ROI
                cv2.putText(frame, roi_type.upper(), (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

            # T·∫°o t√™n file v·ªõi timestamp v√† camera_id
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            final_roi_frame_path = os.path.join(CAMERA_ROI_DIR, f"camera_{camera_id}_roi_final_{timestamp}.jpg")

            # L∆∞u ·∫£nh t·ªïng h·ª£p
            ret = cv2.imwrite(final_roi_frame_path, frame)
            if not ret:
                logging.error(f"Kh√¥ng th·ªÉ l∆∞u ·∫£nh t·ªïng h·ª£p t·∫°i: {final_roi_frame_path}")
                return {"success": False, "error": f"Kh√¥ng th·ªÉ l∆∞u ·∫£nh t·ªïng h·ª£p t·∫°i {final_roi_frame_path}"}
            logging.debug(f"ƒê√£ l∆∞u ·∫£nh t·ªïng h·ª£p v·ªõi t·∫•t c·∫£ ROI v√†o: {final_roi_frame_path}")

            return {"success": True, "final_roi_frame": os.path.relpath(final_roi_frame_path, BASE_DIR)}
        
        finally:
            cap.release()
            logging.debug("ƒê√£ gi·∫£i ph√≥ng t√†i nguy√™n video (cap.release) trong finalize_roi.")
    
    except Exception as e:
        logging.error(f"L·ªói trong finalize_roi: {str(e)}")
        return {"success": False, "error": f"L·ªói h·ªá th·ªëng: {str(e)}"}

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 3:
        print("Usage: python3 hand_detection.py <video_path> <camera_id>")
        sys.exit(1)
    
    video_path = sys.argv[1]
    camera_id = sys.argv[2]
    try:
        roi_result = select_roi(video_path, camera_id)
        if not roi_result["success"]:
            print(roi_result["error"])
    except Exception as e:
        logging.error(f"L·ªói khi ch·∫°y script: {str(e)}")
        print(f"L·ªói khi ch·∫°y script: {str(e)}")

```
## üìÑ File: `frame_sampler_no_trigger.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/frame_sampler_no_trigger.py`

```python
import cv2
import os
import logging
import sqlite3
import threading
import subprocess
import json
import queue
import numpy as np
import mediapipe as mp
from datetime import datetime, timezone, timedelta
from modules.db_utils import get_db_connection
from modules.scheduler.db_sync import frame_sampler_event, db_rwlock
import math
from modules.config.logging_config import get_logger


BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
MODEL_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "models", "wechat_qr")
DETECT_PROTO = os.path.join(MODEL_DIR, "detect.prototxt")
DETECT_MODEL = os.path.join(MODEL_DIR, "detect.caffemodel")
SR_PROTO = os.path.join(MODEL_DIR, "sr.prototxt")
SR_MODEL = os.path.join(MODEL_DIR, "sr.caffemodel")

class FrameSamplerNoTrigger:
    def __init__(self):
        self.setup_logging()
        self.load_config()
        self.video_lock = threading.Lock()
        self.setup_wechat_qr()
        # Initialize MediaPipe Hands
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)
        # Initialize log queue and writer thread
        self.log_queue = queue.Queue()
        self.log_thread = threading.Thread(target=self._log_writer)
        self.log_thread.daemon = True
        self.log_thread.start()

    def setup_logging(self):
        self.logger = get_logger(__name__, {"video_id": os.path.basename(self.video_file)})
        self.logger.info("Logging initialized")

    def setup_wechat_qr(self):
        for model_file in [DETECT_PROTO, DETECT_MODEL, SR_PROTO, SR_MODEL]:
            if not os.path.exists(model_file):
                logging.error(f"Model file not found: {model_file}")
                raise FileNotFoundError(f"Model file not found: {model_file}")
        try:
            self.qr_detector = cv2.wechat_qrcode_WeChatQRCode(DETECT_PROTO, DETECT_MODEL, SR_PROTO, SR_MODEL)
            logging.info("WeChat QRCode detector initialized")
        except Exception as e:
            logging.error(f"Failed to initialize WeChat QRCode: {str(e)}")
            raise

    def load_config(self):
        logging.info("Loading configuration from database")
        with db_rwlock.gen_rlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT input_path FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            self.video_root = result[0] if result else os.path.join(BASE_DIR, "Inputvideo")
            cursor.execute("SELECT output_path FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            self.output_path = result[0] if result else os.path.join(BASE_DIR, "output_clips")
            self.log_dir = os.path.join(self.output_path, "LOG", "Frame")
            os.makedirs(self.log_dir, exist_ok=True)
            cursor.execute("SELECT timezone FROM general_info WHERE id = 1")
            result = cursor.fetchone()
            tz_hours = int(result[0].split("+")[1]) if result and "+" in result[0] else 7
            self.video_timezone = timezone(timedelta(hours=tz_hours))
            cursor.execute("SELECT frame_rate, frame_interval, min_packing_time, motion_threshold, stable_duration_sec FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            self.fps, self.frame_interval, self.min_packing_time, self.motion_threshold, self.stable_duration_sec = result if result else (30, 5, 3, 0.1, 1.0)
            conn.close()
            logging.info(f"Config loaded: video_root={self.video_root}, output_path={self.output_path}, timezone={self.video_timezone}, fps={self.fps}, frame_interval={self.frame_interval}, min_packing_time={self.min_packing_time}, motion_threshold={self.motion_threshold}, stable_duration_sec={self.stable_duration_sec}")

    def get_packing_area(self, camera_name):
        logging.info(f"Querying qr_mvd_area for camera {camera_name}")
        with db_rwlock.gen_rlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT qr_mvd_area FROM packing_profiles WHERE profile_name = ?", (camera_name,))
            result = cursor.fetchone()
            conn.close()
        if result and result[0]:
            try:
                qr_mvd_area = result[0]
                if qr_mvd_area.startswith('(') and qr_mvd_area.endswith(')'):
                    x, y, w, h = map(int, qr_mvd_area.strip('()').split(','))
                else:
                    parsed = json.loads(qr_mvd_area)
                    if isinstance(parsed, list) and len(parsed) == 4:
                        x, y, w, h = parsed
                    else:
                        x, y, w, h = parsed['x'], parsed['y'], parsed['w'], parsed['h']
                roi = (x, y, w, h)
                logging.info(f"Using qr_mvd_area: {roi}")
            except (ValueError, json.JSONDecodeError, KeyError, TypeError) as e:
                logging.error(f"Error parsing qr_mvd_area for camera {camera_name}: {str(e)}")
                roi = None
        else:
            logging.warning(f"No qr_mvd_area found for camera {camera_name}")
            roi = None
        return roi

    def get_video_duration(self, video_file):
        try:
            cmd = ["ffprobe", "-v", "error", "-show_entries", "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", video_file]
            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            return float(result.stdout.strip())
        except Exception:
            logging.error(f"Failed to get duration of video {video_file}")
            return None

    def load_video_files(self):
        with db_rwlock.gen_rlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT file_path FROM file_list WHERE is_processed = 0 AND status != 'xong' ORDER BY priority DESC, created_at ASC")
            video_files = [row[0] for row in cursor.fetchall()]
            conn.close()
        if not video_files:
            logging.info("No video files found with is_processed = 0 and status != 'xong'.")
        return video_files

    def process_frame(self, frame, frame_count):
        try:
            if len(frame.shape) == 2:
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
            texts, _ = self.qr_detector.detectAndDecode(frame)
            for text in texts:
                if text and text != "TimeGo":
                    logging.info(f"Second {round((frame_count - 1) / self.fps)}: QR texts={texts}, mvd={text}")
                    return text
            return ""
        except Exception as e:
            logging.error(f"Error processing frame {frame_count}: {str(e)}")
            return ""

    def detect_hand(self, frame):
        try:
            # Convert BGR to RGB
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            # Process frame with MediaPipe Hands
            results = self.hands.process(rgb_frame)
            # Return True if hand landmarks are detected
            return bool(results.multi_hand_landmarks)
        except Exception as e:
            logging.error(f"Error in hand detection: {str(e)}")
            return False

    def compute_motion_level(self, prev_frame, curr_frame):
        try:
            if len(prev_frame.shape) == 3:
                prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
            if len(curr_frame.shape) == 3:
                curr_frame = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)
            diff = cv2.absdiff(prev_frame, curr_frame)
            motion_level = np.mean(diff) / 255.0
            return motion_level
        except Exception as e:
            logging.error(f"Error computing motion level: {str(e)}")
            return 1.0

    def _get_video_start_time(self, video_file):
        try:
            result = subprocess.check_output(['ffprobe', '-v', 'quiet', '-show_entries', 'format_tags=creation_time', '-of', 'default=noprint_wrappers=1:nokey=1', video_file])
            return datetime.strptime(result.decode().strip(), '%Y-%m-%dT%H:%M:%S.%fZ').replace(tzinfo=timezone.utc).astimezone(self.video_timezone)
        except (subprocess.CalledProcessError, ValueError):
            try:
                result = subprocess.check_output(['exiftool', '-CreateDate', '-d', '%Y-%m-%d %H:%M:%S', video_file])
                return datetime.strptime(result.decode().split('CreateDate')[1].strip().split('\n')[0].strip(), '%Y-%m-%d %H:%M:%S').replace(tzinfo=self.video_timezone)
            except (subprocess.CalledProcessError, IndexError):
                try:
                    result = subprocess.check_output(['exiftool', '-FileCreateDate', '-d', '%Y-%m-%d %H:%M:%S', video_file])
                    return datetime.strptime(result.decode().split('FileCreateDate')[1].strip().split('\n')[0].strip(), '%Y-%m-%d %H:%M:%S').replace(tzinfo=self.video_timezone)
                except (subprocess.CalledProcessError, IndexError):
                    logging.warning("No metadata found, using file creation time.")
                    return datetime.fromtimestamp(os.path.getctime(video_file), tz=self.video_timezone)

    def _log_writer(self):
        while True:
            log_file, entry, timestamp = self.log_queue.get()
            with threading.Lock():
                mode = 'w' if not os.path.exists(log_file) else 'a'
                with open(log_file, mode) as f:
                    if mode == 'w':
                        f.write(f"# Start: {timestamp['start']}, End: {timestamp['end']}, Start_Time: {timestamp['start_time']}, Camera_Name: {timestamp['camera']}, Video_File: {timestamp['video']}\n")
                    f.write(f"{entry}\n")
                    f.flush()
            self.log_queue.task_done()

    def _update_log_file(self, log_file, start_second, end_second, start_time, camera_name, video_file):
        timestamp = {
            'start': start_second,
            'end': end_second,
            'start_time': start_time.strftime('%Y-%m-%d %H:%M:%S'),
            'camera': camera_name,
            'video': video_file
        }
        with db_rwlock.gen_wlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT 1 FROM processed_logs WHERE log_file = ?", (log_file,))
            if not cursor.fetchone():
                cursor.execute("INSERT INTO processed_logs (log_file, is_processed) VALUES (?, 0)", (log_file,))
            conn.commit()
            conn.close()
        return lambda entry, ts: self.log_queue.put((log_file, f"{ts},{entry}", timestamp))

    def run(self):
        while True:
            frame_sampler_event.wait()
            video_files = self.load_video_files()
            if not video_files:
                logging.info("No videos to process")
                frame_sampler_event.clear()
                continue
            for video_file in video_files:
                log_file = self.process_video(video_file, self.video_lock, self.get_packing_area, self.process_frame, self.frame_interval)
                if log_file:
                    logging.info(f"Completed processing video {video_file}, log at {log_file}")
                else:
                    logging.error(f"Failed to process video {video_file}")
            frame_sampler_event.clear()

    def process_video(self, video_file, video_lock, get_packing_area_func, process_frame_func, frame_interval, start_time=0, end_time=None):
        with video_lock:
            logging.info(f"Processing video: {video_file} from {start_time}s to {end_time}s")
            if not os.path.exists(video_file):
                logging.error(f"File '{video_file}' does not exist")
                with db_rwlock.gen_wlock():
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("l·ªói", video_file))
                    conn.commit()
                    conn.close()
                return None
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("ƒëang frame sampler ...", video_file))
                cursor.execute("SELECT camera_name FROM file_list WHERE file_path = ?", (video_file,))
                result = cursor.fetchone()
                camera_name = result[0] if result and result[0] else "CamTest"
                conn.commit()
                conn.close()
            video = cv2.VideoCapture(video_file)
            if not video.isOpened():
                logging.error(f"Failed to open video '{video_file}'")
                with db_rwlock.gen_wlock():
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("l·ªói", video_file))
                    conn.commit()
                    conn.close()
                return None
            start_time_obj = self._get_video_start_time(video_file)
            roi = get_packing_area_func(camera_name)
            total_seconds = self.get_video_duration(video_file)
            if total_seconds is None:
                logging.error(f"Failed to get duration of video {video_file}")
                with db_rwlock.gen_wlock():
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("l·ªói", video_file))
                    conn.commit()
                    conn.close()
                return None
            logging.info(f"Video duration {video_file}: {total_seconds} seconds")
            video_name = os.path.splitext(os.path.basename(video_file))[0]
            segment_duration = 300
            # X√°c ƒë·ªãnh c√°c ƒëo·∫°n 300s ch·ª©a [start_time, end_time]
            end_time = total_seconds if end_time is None else min(end_time, total_seconds)
            start_segment = math.floor(start_time / segment_duration) * segment_duration
            end_segment = math.ceil(end_time / segment_duration) * segment_duration
            current_start_second = start_segment
            current_end_second = min(current_start_second + segment_duration, end_segment)
            camera_log_dir = os.path.join(self.log_dir, camera_name)
            os.makedirs(camera_log_dir, exist_ok=True)
            log_file = os.path.join(camera_log_dir, f"log_{video_name}_{current_start_second:04d}_{current_end_second:04d}.txt")
            log_file_handle = self._update_log_file(log_file, current_start_second, current_end_second, start_time_obj + timedelta(seconds=current_start_second), camera_name, video_file)
            # B·∫Øt ƒë·∫ßu t·ª´ khung h√¨nh t·∫°i start_time
            start_frame = int(start_time * self.fps)
            end_frame = int(end_time * self.fps)
            video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            frame_count = start_frame
            prev_frame = None
            stable_segments = []
            qr_events = []
            stable_start = None
            last_te = -self.min_packing_time * self.fps
            is_stable = False
            while video.isOpened() and frame_count < end_frame:
                ret, frame = video.read()
                if not ret:
                    break
                if roi:
                    x, y, w, h = roi
                    frame_height, frame_width = frame.shape[:2]
                    if w > 0 and h > 0 and y + h <= frame_height and x + w <= frame_width:
                        frame = frame[y:y + h, x:x + w]
                    else:
                        logging.warning(f"Invalid ROI for frame {frame_count}: {roi}, frame_size: {frame_width}x{frame_height}")
                        frame = frame
                frame_count += 1
                if frame_count % frame_interval != 0:
                    continue
                if frame.size == 0 or frame.shape[0] == 0 or frame.shape[1] == 0:
                    logging.warning(f"Empty frame {frame_count}, skipping")
                    continue
                # QR detection
                mvd = process_frame_func(frame, frame_count)
                if mvd:
                    qr_events.append((frame_count, mvd))
                # Motion detection
                if prev_frame is not None:
                    motion_level = self.compute_motion_level(prev_frame, frame)
                    min_stable_frames = max(6, int(self.fps * self.stable_duration_sec / self.frame_interval))
                    if motion_level < self.motion_threshold:
                        if not is_stable:
                            stable_start = frame_count
                            is_stable = True
                    else:
                        if is_stable and (frame_count - stable_start) >= min_stable_frames * frame_interval:
                            start_second = round((stable_start - 1) / self.fps, 1)
                            end_second = round((frame_count - frame_interval - 1) / self.fps, 1)
                            if start_second >= start_time and end_second <= end_time:
                                stable_segments.append((stable_start, frame_count - frame_interval))
                                logging.info(f"Stable segment: start={start_second}s, end={end_second}s")
                        is_stable = False
                prev_frame = frame.copy()
                second_in_video = (frame_count - 1) / self.fps
                second = round(second_in_video)
                if second >= current_end_second and second < end_time:
                    current_start_second = current_end_second
                    current_end_second = min(current_start_second + segment_duration, end_segment)
                    camera_log_dir = os.path.join(self.log_dir, camera_name)
                    os.makedirs(camera_log_dir, exist_ok=True)
                    log_file = os.path.join(camera_log_dir, f"log_{video_name}_{current_start_second:04d}_{current_end_second:04d}.txt")
                    log_file_handle = self._update_log_file(log_file, current_start_second, current_end_second, start_time_obj + timedelta(seconds=current_start_second), camera_name, video_file)
            if is_stable and (frame_count - stable_start) >= min_stable_frames * frame_interval:
                start_second = round((stable_start - 1) / self.fps, 1)
                end_second = round((frame_count - 1) / self.fps, 1)
                if start_second >= start_time and end_second <= end_time:
                    stable_segments.append((stable_start, frame_count))
                    logging.info(f"Stable segment: start={start_second}s, end={end_second}s")
            # Group QR codes and select the last frame of each sequence
            grouped_qr = []
            current_mvd = None
            current_frames = []
            for frame, mvd in qr_events:
                if mvd == "TimeGo":
                    continue
                if mvd != current_mvd:
                    if current_mvd and current_frames:
                        grouped_qr.append((current_frames[-1], current_mvd))
                    current_mvd = mvd
                    current_frames = [frame]
                else:
                    current_frames.append(frame)
            if current_mvd and current_frames:
                grouped_qr.append((current_frames[-1], current_mvd))
            # Log last QR event
            if grouped_qr:
                last_qr_frame, last_qr_code = grouped_qr[-1]
                last_qr_second = round((last_qr_frame - 1) / self.fps, 1)
                if last_qr_second >= start_time and last_qr_second <= end_time:
                    logging.info(f"Last QR event: Te={last_qr_second}s, QR={last_qr_code}")
            # Find Ts/Te
            video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            frame_count = start_frame
            last_te = -self.min_packing_time * self.fps
            prev_te_frame = None
            for idx, (te_frame, qr_code) in enumerate(grouped_qr):
                if te_frame <= last_te + self.min_packing_time * self.fps:
                    logging.info(f"Skipping event for QR {qr_code} at frame {te_frame}: too close to last_te {last_te}")
                    continue
                second_te = round((te_frame - 1) / self.fps)
                if second_te < start_time or second_te > end_time:
                    continue
                segment_index = math.floor(second_te / segment_duration)
                target_start_second = segment_index * segment_duration
                target_end_second = (segment_index + 1) * segment_duration
                if second_te >= current_end_second or target_start_second != current_start_second:
                    current_start_second = target_start_second
                    current_end_second = min(target_start_second + segment_duration, end_segment)
                    camera_log_dir = os.path.join(self.log_dir, camera_name)
                    os.makedirs(camera_log_dir, exist_ok=True)
                    log_file = os.path.join(camera_log_dir, f"log_{video_name}_{current_start_second:04d}_{current_end_second:04d}.txt")
                    log_file_handle = self._update_log_file(log_file, current_start_second, current_end_second, start_time_obj + timedelta(seconds=current_start_second), camera_name, video_file)
                ts_frame = None
                # Tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát: Te ƒë·∫ßu ti√™n
                if idx == 0:
                    has_stable_segment = any(start <= te_frame for start, end in stable_segments)
                    if not has_stable_segment:
                        log_file_handle(f"On,{qr_code}", second_te)
                        logging.info(f"Logged only Te for QR {qr_code} at second {second_te}: no stable segments for first Te")
                        last_te = te_frame
                        prev_te_frame = te_frame
                        continue
                # T√¨m v√πng ·ªïn ƒë·ªãnh sau Te ph√≠a tr∆∞·ªõc (ho·∫∑c ƒë·∫ßu video n·∫øu kh√¥ng c√≥ Te tr∆∞·ªõc)
                closest_stable = None
                search_start = max(prev_te_frame if prev_te_frame is not None else start_frame, start_frame)
                for start, end in stable_segments:
                    if start > search_start and end < te_frame:
                        if closest_stable is None or start < closest_stable[0]:
                            closest_stable = (start, end)
                if closest_stable:
                    # T√¨m tay sau v√πng ·ªïn ƒë·ªãnh
                    video.set(cv2.CAP_PROP_POS_FRAMES, closest_stable[1])
                    hand_frame_count = closest_stable[1]
                    while hand_frame_count < te_frame and hand_frame_count < end_frame:
                        ret, frame = video.read()
                        if not ret:
                            break
                        if roi:
                            x, y, w, h = roi
                            frame_height, frame_width = frame.shape[:2]
                            if w > 0 and h > 0 and y + h <= frame_height and x + w <= frame_width:
                                frame = frame[y:y + h, x:x + w]
                        hand_frame_count += 1
                        if hand_frame_count % self.frame_interval != 0:
                            continue
                        if self.detect_hand(frame) and hand_frame_count > last_te + self.min_packing_time * self.fps:
                            ts_frame = hand_frame_count
                            second_ts = round((ts_frame - 1) / self.fps, 1)
                            if second_ts >= start_time and second_ts <= end_time:
                                logging.info(f"Hand detected for Ts: frame={ts_frame}, time={second_ts}s")
                                break
                            ts_frame = None
                else:
                    # Kh√¥ng c√≥ v√πng ·ªïn ƒë·ªãnh, t√¨m tay ngay sau Te ph√≠a tr∆∞·ªõc
                    if prev_te_frame is not None:
                        video.set(cv2.CAP_PROP_POS_FRAMES, max(prev_te_frame, start_frame))
                        hand_frame_count = max(prev_te_frame, start_frame)
                        while hand_frame_count < te_frame and hand_frame_count < end_frame:
                            ret, frame = video.read()
                            if not ret:
                                break
                            if roi:
                                x, y, w, h = roi
                                frame_height, frame_width = frame.shape[:2]
                                if w > 0 and h > 0 and y + h <= frame_height and x + w <= frame_width:
                                    frame = frame[y:y + h, x:x + w]
                            hand_frame_count += 1
                            if hand_frame_count % self.frame_interval != 0:
                                continue
                            if self.detect_hand(frame) and hand_frame_count > last_te + self.min_packing_time * self.fps:
                                ts_frame = hand_frame_count
                                second_ts = round((ts_frame - 1) / self.fps, 1)
                                if second_ts >= start_time and second_ts <= end_time:
                                    logging.info(f"Hand detected for Ts: frame={ts_frame}, time={second_ts}s")
                                    break
                                ts_frame = None
                # Ghi log
                if ts_frame:
                    second_ts = round((ts_frame - 1) / self.fps)
                    segment_index = math.floor(max(second_ts, second_te) / segment_duration)
                    target_start_second = segment_index * segment_duration
                    target_end_second = (segment_index + 1) * segment_duration
                    if max(second_ts, second_te) >= current_end_second or target_start_second != current_start_second:
                        current_start_second = target_start_second
                        current_end_second = min(target_start_second + segment_duration, end_segment)
                        camera_log_dir = os.path.join(self.log_dir, camera_name)
                        os.makedirs(camera_log_dir, exist_ok=True)
                        log_file = os.path.join(camera_log_dir, f"log_{video_name}_{current_start_second:04d}_{current_end_second:04d}.txt")
                        log_file_handle = self._update_log_file(log_file, current_start_second, current_end_second, start_time_obj + timedelta(seconds=current_start_second), camera_name, video_file)
                    log_file_handle("On,", second_ts - 1)
                    log_file_handle("Off,", second_ts)
                    log_file_handle("Off,", second_te - 1)
                    log_file_handle(f"On,{qr_code}", second_te)
                    logging.info(f"Event logged: Ts={second_ts}, Te={second_te}, QR={qr_code}")
                else:
                    second_ts = second_te - self.min_packing_time - 1
                    if second_ts >= start_time and second_ts >= (last_te / self.fps):
                        segment_index = math.floor(max(second_ts, second_te) / segment_duration)
                        target_start_second = segment_index * segment_duration
                        target_end_second = (segment_index + 1) * segment_duration
                        if max(second_ts, second_te) >= current_end_second or target_start_second != current_start_second:
                            current_start_second = target_start_second
                            current_end_second = min(target_start_second + segment_duration, end_segment)
                            camera_log_dir = os.path.join(self.log_dir, camera_name)
                            os.makedirs(camera_log_dir, exist_ok=True)
                            log_file = os.path.join(camera_log_dir, f"log_{video_name}_{current_start_second:04d}_{current_end_second:04d}.txt")
                            log_file_handle = self._update_log_file(log_file, current_start_second, current_end_second, start_time_obj + timedelta(seconds=current_start_second), camera_name, video_file)
                        log_file_handle("On,", second_ts - 1)
                        log_file_handle("Off,", second_ts)
                        log_file_handle("Off,", second_te - 1)
                        log_file_handle(f"On,{qr_code}", second_te)
                        logging.info(f"Assumed Ts={second_ts} for Te={second_te}, QR={qr_code}")
                    else:
                        log_file_handle("Off,", second_te - 1)
                        log_file_handle(f"On,{qr_code}", second_te)
                        logging.info(f"Logged only Te for QR {qr_code} at second {second_te}: assumed Ts={second_ts} invalid (out of range or too close to last_te)")
                last_te = te_frame
                prev_te_frame = te_frame
            video.release()
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("UPDATE file_list SET is_processed = 1, status = ? WHERE file_path = ?", ("xong", video_file))
                conn.commit()
                conn.close()
            logging.info(f"Completed processing video: {video_file}")
            return log_file

```
## üìÑ File: `frame_sampler_trigger.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/frame_sampler_trigger.py`

```python
import cv2
import os
import logging
import sqlite3
import threading
import subprocess
import json
import numpy as np
from datetime import datetime, timezone, timedelta
from modules.db_utils import get_db_connection
from modules.scheduler.db_sync import frame_sampler_event, db_rwlock
import math
from modules.config.logging_config import get_logger


BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
MODEL_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "models", "wechat_qr")
DETECT_PROTO = os.path.join(MODEL_DIR, "detect.prototxt")
DETECT_MODEL = os.path.join(MODEL_DIR, "detect.caffemodel")
SR_PROTO = os.path.join(MODEL_DIR, "sr.prototxt")
SR_MODEL = os.path.join(MODEL_DIR, "sr.caffemodel")

class FrameSamplerTrigger:
    def __init__(self):
        self.setup_logging()
        self.load_config()
        self.video_lock = threading.Lock()
        self.setup_wechat_qr()

    def setup_logging(self):
        self.logger = get_logger(__name__, {"video_id": os.path.basename(self.video_file)})
        self.logger.info("Logging initialized")

    def load_config(self):
        logging.info("Loading configuration from database")
        with db_rwlock.gen_rlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT input_path FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            self.video_root = result[0] if result else os.path.join(BASE_DIR, "Inputvideo")
            cursor.execute("SELECT output_path FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            self.output_path = result[0] if result else os.path.join(BASE_DIR, "output_clips")
            self.log_dir = os.path.join(self.output_path, "LOG", "Frame")
            os.makedirs(self.log_dir, exist_ok=True)
            cursor.execute("SELECT timezone FROM general_info WHERE id = 1")
            result = cursor.fetchone()
            tz_hours = int(result[0].split("+")[1]) if result and "+" in result[0] else 7
            self.video_timezone = timezone(timedelta(hours=tz_hours))
            cursor.execute("SELECT frame_rate, frame_interval, min_packing_time FROM processing_config WHERE id = 1")
            result = cursor.fetchone()
            self.fps, self.frame_interval, self.min_packing_time = result if result else (30, 5, 5)
            logging.info(f"Config loaded: video_root={self.video_root}, output_path={self.output_path}, timezone={self.video_timezone}, fps={self.fps}, frame_interval={self.frame_interval}, min_packing_time={self.min_packing_time}")

    def get_packing_area(self, camera_name):
        logging.info(f"Querying qr_mvd_area and jump_time_ratio for camera {camera_name}")
        with db_rwlock.gen_rlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT qr_mvd_area, jump_time_ratio FROM packing_profiles WHERE profile_name = ?", (camera_name,))
            result = cursor.fetchone()
            cursor.execute("SELECT qr_trigger_area FROM packing_profiles WHERE profile_name = ?", (camera_name,))
            trigger_result = cursor.fetchone()
            conn.close()
        if result and result[1] is not None:
            self.jump_time_ratio = float(result[1])
            logging.info(f"Loaded jump_time_ratio: {self.jump_time_ratio}")
        else:
            self.jump_time_ratio = 0.5
            logging.info(f"Using default jump_time_ratio: {self.jump_time_ratio}")

        if result and result[0]:
            try:
                qr_mvd_area = result[0]
                if qr_mvd_area.startswith('(') and qr_mvd_area.endswith(')'):
                    x, y, w, h = map(int, qr_mvd_area.strip('()').split(','))
                else:
                    parsed = json.loads(qr_mvd_area)
                    if isinstance(parsed, list) and len(parsed) == 4:
                        x, y, w, h = parsed
                    else:
                        x, y, w, h = parsed['x'], parsed['y'], parsed['w'], parsed['h']
                roi = (x, y, w, h)
                logging.info(f"Using qr_mvd_area: {roi}")
            except (ValueError, json.JSONDecodeError, KeyError, TypeError) as e:
                logging.error(f"Error parsing qr_mvd_area for camera {camera_name}: {str(e)}")
                roi = None
        else:
            logging.warning(f"No qr_mvd_area found for camera {camera_name}")
            roi = None
        trigger = json.loads(trigger_result[0]) if trigger_result and trigger_result[0] else [0, 0, 0, 0]
        logging.info(f"Using trigger: {trigger}")
        return roi, trigger

    def get_video_duration(self, video_file):
        try:
            cmd = ["ffprobe", "-v", "error", "-show_entries", "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", video_file]
            result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            return float(result.stdout.strip())
        except Exception:
            logging.error(f"Failed to get duration of video {video_file}")
            return None

    def load_video_files(self):
        with db_rwlock.gen_rlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT file_path FROM file_list WHERE is_processed = 0 AND status != 'xong' ORDER BY priority DESC, created_at ASC")
            video_files = [row[0] for row in cursor.fetchall()]
            conn.close()
        if not video_files:
            logging.info("No video files found with is_processed = 0 and status != 'xong'.")
        return video_files

    def process_frame(self, frame, frame_count):
        try:
            if len(frame.shape) == 2:
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
            texts, _ = self.qr_detector.detectAndDecode(frame)
            state = "Off"
            mvd = ""
            for text in texts:
                if text == "TimeGo":
                    state = "On"
                elif text:
                    mvd = text
            return state, mvd
        except Exception as e:
            logging.error(f"Error processing frame {frame_count}: {str(e)}")
            return "", ""

    def _get_video_start_time(self, video_file):
        try:
            result = subprocess.check_output(['ffprobe', '-v', 'quiet', '-show_entries', 'format_tags=creation_time', '-of', 'default=noprint_wrappers=1:nokey=1', video_file])
            return datetime.strptime(result.decode().strip(), '%Y-%m-%dT%H:%M:%S.%fZ').replace(tzinfo=timezone.utc).astimezone(self.video_timezone)
        except (subprocess.CalledProcessError, ValueError):
            try:
                result = subprocess.check_output(['exiftool', '-CreateDate', '-d', '%Y-%m-%d %H:%M:%S', video_file])
                return datetime.strptime(result.decode().split('CreateDate')[1].strip().split('\n')[0].strip(), '%Y-%m-%d %H:%M:%S').replace(tzinfo=self.video_timezone)
            except (subprocess.CalledProcessError, IndexError):
                try:
                    result = subprocess.check_output(['exiftool', '-FileCreateDate', '-d', '%Y-%m-%d %H:%M:%S', video_file])
                    return datetime.strptime(result.decode().split('FileCreateDate')[1].strip().split('\n')[0].strip(), '%Y-%m-%d %H:%M:%S').replace(tzinfo=self.video_timezone)
                except (subprocess.CalledProcessError, IndexError):
                    logging.warning("No metadata found, using file creation time.")
                    return datetime.fromtimestamp(os.path.getctime(video_file), tz=self.video_timezone)

    def _update_log_file(self, log_file, start_second, end_second, start_time, camera_name, video_file):
        log_file_handle = open(log_file, 'w')
        log_file_handle.write(f"# Start: {start_second}, End: {end_second}, Start_Time: {start_time.strftime('%Y-%m-%d %H:%M:%S')}, Camera_Name: {camera_name}, Video_File: {video_file}\n")
        log_file_handle.flush()
        with db_rwlock.gen_wlock():
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT 1 FROM processed_logs WHERE log_file = ?", (log_file,))
            if not cursor.fetchone():
                cursor.execute("INSERT INTO processed_logs (log_file, is_processed) VALUES (?, 0)", (log_file,))
            conn.commit()
            conn.close()
        return log_file_handle

    def run(self):
        while True:
            frame_sampler_event.wait()
            video_files = self.load_video_files()
            if not video_files:
                logging.info("No videos to process")
                frame_sampler_event.clear()
                continue
            for video_file in video_files:
                log_file = self.process_video(video_file, self.video_lock, self.get_packing_area, self.process_frame, self.frame_interval)
                if log_file:
                    logging.info(f"Completed processing video {video_file}, log at {log_file}")
                else:
                    logging.error(f"Failed to process video {video_file}")
            frame_sampler_event.clear()

    def process_video(self, video_file, video_lock, get_packing_area_func, process_frame_func, frame_interval, start_time=0, end_time=None):
        with video_lock:
            logging.info(f"Processing video: {video_file} from {start_time}s to {end_time}s")
            if not os.path.exists(video_file):
                logging.error(f"File '{video_file}' does not exist")
                with db_rwlock.gen_wlock():
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("l·ªói", video_file))
                    conn.commit()
                    conn.close()
                return None
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("ƒëang frame sampler ...", video_file))
                cursor.execute("SELECT camera_name FROM file_list WHERE file_path = ?", (video_file,))
                result = cursor.fetchone()
                camera_name = result[0] if result and result[0] else "CamTest"
                conn.commit()
                conn.close()
            video = cv2.VideoCapture(video_file)
            if not video.isOpened():
                logging.error(f"Failed to open video '{video_file}'")
                with db_rwlock.gen_wlock():
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("l·ªói", video_file))
                    conn.commit()
                    conn.close()
                return None
            start_time_obj = self._get_video_start_time(video_file)
            roi, trigger = get_packing_area_func(camera_name)
            total_seconds = self.get_video_duration(video_file)
            if total_seconds is None:
                logging.error(f"Failed to get duration of video {video_file}")
                with db_rwlock.gen_wlock():
                    conn = get_db_connection()
                    cursor = conn.cursor()
                    cursor.execute("UPDATE file_list SET status = ? WHERE file_path = ?", ("l·ªói", video_file))
                    conn.commit()
                    conn.close()
                return None
            logging.info(f"Video duration {video_file}: {total_seconds} seconds")
            video_name = os.path.splitext(os.path.basename(video_file))[0]
            segment_duration = 300
            # X√°c ƒë·ªãnh c√°c ƒëo·∫°n 300s ch·ª©a [start_time, end_time]
            end_time = total_seconds if end_time is None else min(end_time, total_seconds)
            start_segment = math.floor(start_time / segment_duration) * segment_duration
            end_segment = math.ceil(end_time / segment_duration) * segment_duration
            current_start_second = start_segment
            current_end_second = min(current_start_second + segment_duration, end_segment)
            camera_log_dir = os.path.join(self.log_dir, camera_name)
            os.makedirs(camera_log_dir, exist_ok=True)
            log_file = os.path.join(camera_log_dir, f"log_{video_name}_{current_start_second:04d}_{current_end_second:04d}.txt")
            log_file_handle = self._update_log_file(log_file, current_start_second, current_end_second, start_time_obj + timedelta(seconds=current_start_second), camera_name, video_file)
            # B·∫Øt ƒë·∫ßu t·ª´ khung h√¨nh t·∫°i start_time
            start_frame = int(start_time * self.fps)
            end_frame = int(end_time * self.fps)
            video.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            frame_count = start_frame
            frame_states = []
            mvd_list = []
            last_state = None
            last_mvd = ""
            jump_time_ratio = getattr(self, 'jump_time_ratio', 0.5)  # L·∫•y t·ª´ config ho·∫∑c m·∫∑c ƒë·ªãnh 0.5
            while video.isOpened() and frame_count < end_frame:
                ret, frame = video.read()
                if not ret:
                    break
                if roi:
                    x, y, w, h = roi
                    frame_height, frame_width = frame.shape[:2]
                    if w > 0 and h > 0 and y + h <= frame_height and x + w <= frame_width:
                        frame = frame[y:y + h, x:x + w]
                    else:
                        logging.warning(f"Invalid ROI for frame {frame_count}: {roi}, frame size: {frame_width}x{frame_height}")
                        frame = frame
                frame_count += 1
                if frame_count % frame_interval != 0:
                    continue
                if frame.size == 0 or frame.shape[0] == 0 or frame.shape[1] == 0:
                    logging.warning(f"Empty frame {frame_count}, skipping")
                    continue
                state, mvd = process_frame_func(frame, frame_count)
                second_in_video = (frame_count - 1) / self.fps
                second = round(second_in_video)
                if second >= current_end_second and second < end_time:
                    log_file_handle.close()
                    current_start_second = current_end_second
                    current_end_second = min(current_start_second + segment_duration, end_segment)
                    camera_log_dir = os.path.join(self.log_dir, camera_name)
                    os.makedirs(camera_log_dir, exist_ok=True)
                    log_file = os.path.join(camera_log_dir, f"log_{video_name}_{current_start_second:04d}_{current_end_second:04d}.txt")
                    log_file_handle = self._update_log_file(log_file, current_start_second, current_end_second, start_time_obj + timedelta(seconds=current_start_second), camera_name, video_file)
                if second >= start_time and second <= end_time:
                    # Ghi MVD ngay n·∫øu c√≥ v√† kh√°c last_mvd
                    if mvd and mvd != last_mvd:
                        log_line = f"{second},{state},{mvd}\n"
                        log_file_handle.write(log_line)
                        logging.info(f"Log second {second}: state={state}, mvd={mvd}")
                        log_file_handle.flush()
                        last_mvd = mvd
                    # Ti·∫øp t·ª•c thu th·∫≠p tr·∫°ng th√°i cho final_state
                    frame_states.append(state)
                    mvd_list.append(mvd)
                    if len(frame_states) == 5:
                        on_count = sum(1 for s in frame_states if s == "On")
                        off_count = sum(1 for s in frame_states if s == "Off")
                        frame_states_str = " ".join(frame_states).lower()
                        final_state = None
                        if on_count >= 3:
                            final_state = "On"
                        elif off_count == 5:
                            final_state = "Off"
                        if final_state:
                            if final_state != last_state:
                                log_line = f"{second},{final_state},\n"
                                log_file_handle.write(log_line)
                                logging.info(f"Log second {second}: {frame_states_str}: {final_state}")
                                log_file_handle.flush()
                                if last_state == "On" and final_state == "Off":
                                    jump_frames = int(jump_time_ratio * self.min_packing_time * self.fps)
                                    new_frame_count = frame_count + jump_frames
                                    if new_frame_count < end_frame:
                                        video.set(cv2.CAP_PROP_POS_FRAMES, new_frame_count)
                                        frame_count = new_frame_count
                                        logging.info(f"Jumped {jump_frames} frames to {frame_count} after On->Off transition")
                                last_state = final_state
                        else:
                            logging.info(f"Skipped second {second}: {frame_states_str}, on_count={on_count}, off_count={off_count}")
                            log_file_handle.flush()
                        frame_states = []
                        mvd_list = []
            log_file_handle.close()
            video.release()
            with db_rwlock.gen_wlock():
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("UPDATE file_list SET is_processed = 1, status = ? WHERE file_path = ?", ("xong", video_file))
                conn.commit()
                conn.close()
            logging.info(f"Completed processing video: {video_file}")
            return log_file

```
## üìÑ File: `cutter_complete.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/cutter/cutter_complete.py`

```python
import subprocess

def cut_complete_event(event, video_buffer, video_length, output_file):
    """C·∫Øt video cho s·ª± ki·ªán ho√†n ch·ªânh (c√≥ c·∫£ ts v√† te)."""
    ts = event.get("ts")
    te = event.get("te")
    video_file = event.get("video_file")

    start_time = max(0, ts - video_buffer)  # Th√™m buffer tr∆∞·ªõc ts
    end_time = min(te + video_buffer, video_length)  # Th√™m buffer sau te
    duration = end_time - start_time

    if duration <= 0:
        print(f"B·ªè qua: Duration kh√¥ng h·ª£p l·ªá ({duration}s) cho s·ª± ki·ªán {event.get('event_id')}")
        return False

    try:
        cmd = [
            "ffmpeg",
            "-i", video_file,
            "-ss", str(start_time),
            "-t", str(duration),
            "-c:v", "copy",
            "-c:a", "copy",
            "-y",
            output_file
        ]
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print(f"ƒê√£ c·∫Øt video: {output_file}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"L·ªói khi c·∫Øt video {video_file}: {e}")
        return False
    except Exception as e:
        print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")
        return False
```
## üìÑ File: `cutter_incomplete.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/cutter/cutter_incomplete.py`

```python
import os
import subprocess
from .cutter_utils import generate_merged_filename, generate_output_filename

def cut_incomplete_event(event, video_buffer, video_length, output_file):
    """C·∫Øt video cho s·ª± ki·ªán d·ªü dang (thi·∫øu ts ho·∫∑c te)."""
    ts = event.get("ts")
    te = event.get("te")
    video_file = event.get("video_file")

    # Log ƒë·ªô d√†i video g·ªëc
    print(f"Video g·ªëc {video_file} c√≥ ƒë·ªô d√†i: {video_length} gi√¢y")

    # Log gi√° tr·ªã video_buffer
    print(f"S·ª≠ d·ª•ng video_buffer: {video_buffer} gi√¢y")

    if ts is not None and te is None:  # Ch·ªâ c√≥ ts
        start_time = max(0, ts - video_buffer)
        duration = video_length - start_time
    elif ts is None and te is not None:  # Ch·ªâ c√≥ te
        start_time = 0
        duration = min(te + video_buffer, video_length)
    else:
        print(f"B·ªè qua: S·ª± ki·ªán {event.get('event_id')} kh√¥ng c√≥ ts ho·∫∑c te")
        return False

    if duration <= 0:
        print(f"B·ªè qua: Duration kh√¥ng h·ª£p l·ªá ({duration}s) cho s·ª± ki·ªán {event.get('event_id')}")
        return False

    try:
        cmd = [
            "ffmpeg",
            "-i", video_file,
            "-ss", str(start_time),
            "-t", str(duration),
            "-c:v", "copy",
            "-c:a", "copy",
            "-y",
            output_file
        ]
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print(f"ƒê√£ c·∫Øt video: {output_file}")

        # Log ƒë·ªô d√†i c·ªßa file d·ªü dang v·ª´a t·∫°o
        probe = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", output_file],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )
        duration = float(probe.stdout.strip())
        print(f"File d·ªü dang {output_file} c√≥ ƒë·ªô d√†i: {duration} gi√¢y")

        event["cut_video_file"] = output_file
        return True
    except subprocess.CalledProcessError as e:
        print(f"L·ªói khi c·∫Øt video {video_file}: {e}")
        return False
    except Exception as e:
        print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {e}")
        return False

def merge_incomplete_events(event_a, event_b, video_buffer, video_length_a, video_length_b, output_dir, max_packing_time, brand_name="Alan"):
    """Gh√©p n·ªëi hai s·ª± ki·ªán d·ªü dang (A c√≥ ts, B c√≥ te) v√† t·∫°o file gh√©p v·ªõi t√™n t·ªëi ∆∞u."""
    video_file_a = event_a.get("video_file")
    video_file_b = event_b.get("video_file")

    # Ki·ªÉm tra n·∫øu file ƒë√£ ƒë∆∞·ª£c c·∫Øt s·∫µn
    temp_file_a = event_a.get("cut_video_file")
    temp_file_b = event_b.get("cut_video_file")
    files_to_cleanup = []

    # T·∫°o th∆∞ m·ª•c temp_clips ƒë·ªÉ l∆∞u file t·∫°m
    temp_clips_dir = os.path.join(os.path.dirname(output_dir), "temp_clips")
    if not os.path.exists(temp_clips_dir):
        os.makedirs(temp_clips_dir)

    # N·∫øu kh√¥ng c√≥ file c·∫Øt s·∫µn, c·∫Øt ngay l·∫≠p t·ª©c v√† l∆∞u v√†o temp_clips_dir
    if not temp_file_a or not os.path.exists(temp_file_a):
        temp_file_a = os.path.join(temp_clips_dir, f"temp_a_{event_a.get('event_id')}_incomplete.mp4")
        if not cut_incomplete_event(event_a, video_buffer, video_length_a, temp_file_a):
            print(f"L·ªói: Kh√¥ng th·ªÉ c·∫Øt file t·∫°m cho s·ª± ki·ªán {event_a.get('event_id')}")
            return None
    if not temp_file_b or not os.path.exists(temp_file_b):
        temp_file_b = os.path.join(temp_clips_dir, f"temp_b_{event_b.get('event_id')}_incomplete.mp4")
        if not cut_incomplete_event(event_b, video_buffer, video_length_b, temp_file_b):
            print(f"L·ªói: Kh√¥ng th·ªÉ c·∫Øt file t·∫°m cho s·ª± ki·ªán {event_b.get('event_id')}")
            return None

    # T·∫°o t√™n file ƒë·∫ßu ra t·ªëi ∆∞u d·ª±a tr√™n temp_file_a v√† temp_file_b
    file_name_a = os.path.basename(temp_file_a)
    file_name_b = os.path.basename(temp_file_b)
    parts_a = file_name_a.split("_")
    parts_b = file_name_b.split("_")

    # L·∫•y Brand t·ª´ file ƒë·∫ßu ti√™n
    brand_name = parts_a[0]

    # L·∫•y m√£ v·∫≠n ƒë∆°n t·ª´ c·∫£ hai file, lo·∫°i b·ªè "NoCode"
    tracking_codes = []
    if len(parts_a) >= 2 and parts_a[1] != "NoCode":
        tracking_codes.append(parts_a[1])
    if len(parts_b) >= 2 and parts_b[1] != "NoCode":
        tracking_codes.append(parts_b[1])

    # L·∫•y th·ªùi gian t·ª´ file ƒë·∫ßu ti√™n
    date = parts_a[2] if len(parts_a) >= 3 else "unknown"
    hour = parts_a[3].split(".")[0] if len(parts_a) >= 4 else "0000"
    time_str = f"{date}_{hour}"

    # T·∫°o t√™n m√£ v·∫≠n ƒë∆°n: d√πng m·ªôt m√£ ho·∫∑c gh√©p nhi·ªÅu m√£ b·∫±ng "-"
    tracking_str = "-".join(tracking_codes) if tracking_codes else "unknown"

    # T·∫°o t√™n file ƒë·∫ßu ra
    output_file = os.path.join(output_dir, f"{brand_name}_{tracking_str}_{time_str}.mp4")

    # Gh√©p n·ªëi video A v√† B
    concat_list_file = os.path.join(output_dir, f"concat_list_{event_a.get('event_id')}.txt")
    try:
        with open(concat_list_file, 'w') as f:
            f.write(f"file '{temp_file_a}'\nfile '{temp_file_b}'\n")

        cmd_concat = [
            "ffmpeg",
            "-f", "concat",
            "-safe", "0",
            "-i", concat_list_file,
            "-c", "copy",
            "-y",
            output_file
        ]
        subprocess.run(cmd_concat, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

        print(f"ƒê√£ gh√©p v√† c·∫Øt video: {output_file}")

        # Log ƒë·ªô d√†i c·ªßa file gh√©p
        probe = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration", "-of", "default=noprint_wrappers=1:nokey=1", output_file],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )
        duration = float(probe.stdout.strip())
        print(f"File gh√©p {output_file} c√≥ ƒë·ªô d√†i: {duration} gi√¢y")

        # X√≥a c√°c file t·∫°m v√† file concat_list sau khi gh√©p th√†nh c√¥ng
        if os.path.exists(temp_file_a):
            os.remove(temp_file_a)
        if os.path.exists(temp_file_b):
            os.remove(temp_file_b)
        if os.path.exists(concat_list_file):
            os.remove(concat_list_file)

        return output_file

    except subprocess.CalledProcessError as e:
        print(f"L·ªói khi gh√©p video: {e}")
        # X√≥a c√°c file t·∫°m v√† file concat_list trong tr∆∞·ªùng h·ª£p l·ªói
        if os.path.exists(temp_file_a):
            os.remove(temp_file_a)
        if os.path.exists(temp_file_b):
            os.remove(temp_file_b)
        if os.path.exists(concat_list_file):
            os.remove(concat_list_file)
        return None
    except Exception as e:
        print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh khi gh√©p video: {e}")
        # X√≥a c√°c file t·∫°m v√† file concat_list trong tr∆∞·ªùng h·ª£p l·ªói
        if os.path.exists(temp_file_a):
            os.remove(temp_file_a)
        if os.path.exists(temp_file_b):
            os.remove(temp_file_b)
        if os.path.exists(concat_list_file):
            os.remove(concat_list_file)
        return None
```
## üìÑ File: `cutter_utils.py`
**ƒê∆∞·ªùng d·∫´n:** `/Users/annhu/vtrack_app/V_Track/backend/modules/technician/cutter/cutter_utils.py`

```python
import os
from datetime import datetime
import ast

def is_reasonable_timestamp(ts):
    """Ki·ªÉm tra xem timestamp c√≥ h·ª£p l·ªá kh√¥ng (l·ªõn h∆°n nƒÉm 2020)."""
    return ts and int(ts) > 1577836800000  # Tr√™n nƒÉm 2020

def generate_output_filename(event, tracking_codes_filter, output_dir, brand_name="Alan"):
    """T·∫°o t√™n file ƒë·∫ßu ra d·ª±a tr√™n tracking code v√† th·ªùi gian ∆∞u ti√™n: packing_time_start > packing_time_end."""
    tracking_codes_str = event.get("tracking_codes")
    packing_time_start = event.get("packing_time_start")
    packing_time_end = event.get("packing_time_end")

    try:
        tracking_codes = ast.literal_eval(tracking_codes_str) if tracking_codes_str else []
    except (ValueError, SyntaxError) as e:
        print(f"L·ªói parse tracking_codes_str cho event {event.get('event_id')}: {e}")
        tracking_codes = []

    # Ch·ªçn tracking code ∆∞u ti√™n
    if tracking_codes_filter:
        selected_tracking_code = next((code for code in tracking_codes_filter if code in tracking_codes), "NoCode")
    else:
        selected_tracking_code = tracking_codes[-1] if tracking_codes else "NoCode"

    # ∆Øu ti√™n ch·ªçn th·ªùi gian: packing_time_start > packing_time_end > fallback
    timestamp = next(
        (t for t in [packing_time_start, packing_time_end] if is_reasonable_timestamp(t)),
        0  # Fallback
    )
    try:
        time_str = datetime.fromtimestamp(int(timestamp) / 1000).strftime("%Y%m%d_%H%M")
    except Exception:
        time_str = "19700101_0000"

    return os.path.join(output_dir, f"{brand_name}_{selected_tracking_code}_{time_str}.mp4")

def generate_merged_filename(event_a, event_b, output_dir, brand_name="Alan"):
    """T·∫°o t√™n file gh√©p cho hai s·ª± ki·ªán d·ªü dang, ∆∞u ti√™n th·ªùi gian: packing_time_start > packing_time_end."""
    tracking_codes_a_str = event_a.get("tracking_codes")
    tracking_codes_b_str = event_b.get("tracking_codes")
    packing_time_start_a = event_a.get("packing_time_start")
    packing_time_end_b = event_b.get("packing_time_end")

    # Ch·ªçn tracking code (∆∞u ti√™n s·ª± ki·ªán c√≥ m√£ v·∫≠n ƒë∆°n)
    try:
        tracking_codes_a = ast.literal_eval(tracking_codes_a_str) if tracking_codes_a_str else []
    except (ValueError, SyntaxError):
        tracking_codes_a = []
    try:
        tracking_codes_b = ast.literal_eval(tracking_codes_b_str) if tracking_codes_b_str else []
    except (ValueError, SyntaxError):
        tracking_codes_b = []

    selected_tracking_code = tracking_codes_b[-1] if tracking_codes_b else (tracking_codes_a[-1] if tracking_codes_a else "NoCode")

    # ∆Øu ti√™n ch·ªçn th·ªùi gian: packing_time_start > packing_time_end > fallback
    timestamp = next(
        (t for t in [packing_time_start_a, packing_time_end_b] if is_reasonable_timestamp(t)),
        0  # Fallback
    )
    try:
        time_str = datetime.fromtimestamp(int(timestamp) / 1000).strftime("%Y%m%d_%H%M")
    except Exception:
        time_str = "19700101_0000"

    return os.path.join(output_dir, f"{brand_name}_{selected_tracking_code}_{time_str}.mp4")

def update_event_in_db(cursor, event_id, output_file):
    """C·∫≠p nh·∫≠t CSDL cho m·ªôt s·ª± ki·ªán."""
    cursor.execute("""
        UPDATE events 
        SET is_processed = 1, output_file = ? 
        WHERE event_id = ?
    """, (output_file, event_id))
```